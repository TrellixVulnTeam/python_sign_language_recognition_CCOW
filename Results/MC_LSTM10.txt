---------------------------------
Run id: lstmmodel_coursera
Log directory: /tmp/tflearn_logs/
[?25l---------------------------------
Training samples: 10000
Validation samples: 700
--
Training Step: 1  | time: 6.537s
[2K| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 00064/10000
[A[ATraining Step: 2  | total loss: [1m[32m2.30998[0m[0m | time: 7.114s
[2K| Adam | epoch: 001 | loss: 2.30998 - acc: 0.0422 -- iter: 00128/10000
[A[ATraining Step: 3  | total loss: [1m[32m2.55152[0m[0m | time: 7.686s
[2K| Adam | epoch: 001 | loss: 2.55152 - acc: 0.1994 -- iter: 00192/10000
[A[ATraining Step: 4  | total loss: [1m[32m2.52574[0m[0m | time: 8.260s
[2K| Adam | epoch: 001 | loss: 2.52574 - acc: 0.1905 -- iter: 00256/10000
[A[ATraining Step: 5  | total loss: [1m[32m2.47001[0m[0m | time: 8.836s
[2K| Adam | epoch: 001 | loss: 2.47001 - acc: 0.1235 -- iter: 00320/10000
[A[ATraining Step: 6  | total loss: [1m[32m2.45845[0m[0m | time: 9.409s
[2K| Adam | epoch: 001 | loss: 2.45845 - acc: 0.1446 -- iter: 00384/10000
[A[ATraining Step: 7  | total loss: [1m[32m2.42929[0m[0m | time: 9.987s
[2K| Adam | epoch: 001 | loss: 2.42929 - acc: 0.2359 -- iter: 00448/10000
[A[ATraining Step: 8  | total loss: [1m[32m2.43223[0m[0m | time: 10.588s
[2K| Adam | epoch: 001 | loss: 2.43223 - acc: 0.2175 -- iter: 00512/10000
[A[ATraining Step: 9  | total loss: [1m[32m2.39628[0m[0m | time: 11.187s
[2K| Adam | epoch: 001 | loss: 2.39628 - acc: 0.2512 -- iter: 00576/10000
[A[ATraining Step: 10  | total loss: [1m[32m2.41658[0m[0m | time: 11.764s
[2K| Adam | epoch: 001 | loss: 2.41658 - acc: 0.2584 -- iter: 00640/10000
[A[ATraining Step: 11  | total loss: [1m[32m2.33136[0m[0m | time: 12.349s
[2K| Adam | epoch: 001 | loss: 2.33136 - acc: 0.1804 -- iter: 00704/10000
[A[ATraining Step: 12  | total loss: [1m[32m2.31038[0m[0m | time: 12.925s
[2K| Adam | epoch: 001 | loss: 2.31038 - acc: 0.1977 -- iter: 00768/10000
[A[ATraining Step: 13  | total loss: [1m[32m2.36825[0m[0m | time: 13.517s
[2K| Adam | epoch: 001 | loss: 2.36825 - acc: 0.2000 -- iter: 00832/10000
[A[ATraining Step: 14  | total loss: [1m[32m2.27000[0m[0m | time: 14.102s
[2K| Adam | epoch: 001 | loss: 2.27000 - acc: 0.2524 -- iter: 00896/10000
[A[ATraining Step: 15  | total loss: [1m[32m2.33524[0m[0m | time: 14.667s
[2K| Adam | epoch: 001 | loss: 2.33524 - acc: 0.2270 -- iter: 00960/10000
[A[ATraining Step: 16  | total loss: [1m[32m2.27189[0m[0m | time: 15.255s
[2K| Adam | epoch: 001 | loss: 2.27189 - acc: 0.2708 -- iter: 01024/10000
[A[ATraining Step: 17  | total loss: [1m[32m2.26463[0m[0m | time: 15.842s
[2K| Adam | epoch: 001 | loss: 2.26463 - acc: 0.2746 -- iter: 01088/10000
[A[ATraining Step: 18  | total loss: [1m[32m2.15984[0m[0m | time: 16.438s
[2K| Adam | epoch: 001 | loss: 2.15984 - acc: 0.2769 -- iter: 01152/10000
[A[ATraining Step: 19  | total loss: [1m[32m2.18534[0m[0m | time: 17.036s
[2K| Adam | epoch: 001 | loss: 2.18534 - acc: 0.2419 -- iter: 01216/10000
[A[ATraining Step: 20  | total loss: [1m[32m2.16378[0m[0m | time: 17.635s
[2K| Adam | epoch: 001 | loss: 2.16378 - acc: 0.2445 -- iter: 01280/10000
[A[ATraining Step: 21  | total loss: [1m[32m2.11552[0m[0m | time: 18.229s
[2K| Adam | epoch: 001 | loss: 2.11552 - acc: 0.2462 -- iter: 01344/10000
[A[ATraining Step: 22  | total loss: [1m[32m2.08828[0m[0m | time: 18.828s
[2K| Adam | epoch: 001 | loss: 2.08828 - acc: 0.2661 -- iter: 01408/10000
[A[ATraining Step: 23  | total loss: [1m[32m2.06969[0m[0m | time: 19.434s
[2K| Adam | epoch: 001 | loss: 2.06969 - acc: 0.2750 -- iter: 01472/10000
[A[ATraining Step: 24  | total loss: [1m[32m2.07418[0m[0m | time: 20.017s
[2K| Adam | epoch: 001 | loss: 2.07418 - acc: 0.2592 -- iter: 01536/10000
[A[ATraining Step: 25  | total loss: [1m[32m2.04702[0m[0m | time: 20.648s
[2K| Adam | epoch: 001 | loss: 2.04702 - acc: 0.2610 -- iter: 01600/10000
[A[ATraining Step: 26  | total loss: [1m[32m2.02098[0m[0m | time: 21.270s
[2K| Adam | epoch: 001 | loss: 2.02098 - acc: 0.2994 -- iter: 01664/10000
[A[ATraining Step: 27  | total loss: [1m[32m1.97718[0m[0m | time: 21.895s
[2K| Adam | epoch: 001 | loss: 1.97718 - acc: 0.3068 -- iter: 01728/10000
[A[ATraining Step: 28  | total loss: [1m[32m1.92018[0m[0m | time: 22.519s
[2K| Adam | epoch: 001 | loss: 1.92018 - acc: 0.3199 -- iter: 01792/10000
[A[ATraining Step: 29  | total loss: [1m[32m1.89358[0m[0m | time: 23.148s
[2K| Adam | epoch: 001 | loss: 1.89358 - acc: 0.3333 -- iter: 01856/10000
[A[ATraining Step: 30  | total loss: [1m[32m1.90300[0m[0m | time: 23.778s
[2K| Adam | epoch: 001 | loss: 1.90300 - acc: 0.3284 -- iter: 01920/10000
[A[ATraining Step: 31  | total loss: [1m[32m1.86736[0m[0m | time: 24.415s
[2K| Adam | epoch: 001 | loss: 1.86736 - acc: 0.3608 -- iter: 01984/10000
[A[ATraining Step: 32  | total loss: [1m[32m1.86704[0m[0m | time: 25.047s
[2K| Adam | epoch: 001 | loss: 1.86704 - acc: 0.3605 -- iter: 02048/10000
[A[ATraining Step: 33  | total loss: [1m[32m1.87879[0m[0m | time: 25.644s
[2K| Adam | epoch: 001 | loss: 1.87879 - acc: 0.3499 -- iter: 02112/10000
[A[ATraining Step: 34  | total loss: [1m[32m1.86996[0m[0m | time: 26.272s
[2K| Adam | epoch: 001 | loss: 1.86996 - acc: 0.3654 -- iter: 02176/10000
[A[ATraining Step: 35  | total loss: [1m[32m1.89692[0m[0m | time: 26.894s
[2K| Adam | epoch: 001 | loss: 1.89692 - acc: 0.3641 -- iter: 02240/10000
[A[ATraining Step: 36  | total loss: [1m[32m1.85053[0m[0m | time: 27.516s
[2K| Adam | epoch: 001 | loss: 1.85053 - acc: 0.3791 -- iter: 02304/10000
[A[ATraining Step: 37  | total loss: [1m[32m1.87922[0m[0m | time: 28.143s
[2K| Adam | epoch: 001 | loss: 1.87922 - acc: 0.3689 -- iter: 02368/10000
[A[ATraining Step: 38  | total loss: [1m[32m1.87176[0m[0m | time: 28.764s
[2K| Adam | epoch: 001 | loss: 1.87176 - acc: 0.3640 -- iter: 02432/10000
[A[ATraining Step: 39  | total loss: [1m[32m1.84146[0m[0m | time: 29.386s
[2K| Adam | epoch: 001 | loss: 1.84146 - acc: 0.3841 -- iter: 02496/10000
[A[ATraining Step: 40  | total loss: [1m[32m1.78845[0m[0m | time: 30.008s
[2K| Adam | epoch: 001 | loss: 1.78845 - acc: 0.4117 -- iter: 02560/10000
[A[ATraining Step: 41  | total loss: [1m[32m1.77333[0m[0m | time: 30.647s
[2K| Adam | epoch: 001 | loss: 1.77333 - acc: 0.4135 -- iter: 02624/10000
[A[ATraining Step: 42  | total loss: [1m[32m1.74578[0m[0m | time: 31.259s
[2K| Adam | epoch: 001 | loss: 1.74578 - acc: 0.4347 -- iter: 02688/10000
[A[ATraining Step: 43  | total loss: [1m[32m1.71510[0m[0m | time: 31.855s
[2K| Adam | epoch: 001 | loss: 1.71510 - acc: 0.4435 -- iter: 02752/10000
[A[ATraining Step: 44  | total loss: [1m[32m1.74690[0m[0m | time: 32.464s
[2K| Adam | epoch: 001 | loss: 1.74690 - acc: 0.4397 -- iter: 02816/10000
[A[ATraining Step: 45  | total loss: [1m[32m1.80500[0m[0m | time: 33.091s
[2K| Adam | epoch: 001 | loss: 1.80500 - acc: 0.4287 -- iter: 02880/10000
[A[ATraining Step: 46  | total loss: [1m[32m1.78824[0m[0m | time: 33.721s
[2K| Adam | epoch: 001 | loss: 1.78824 - acc: 0.4172 -- iter: 02944/10000
[A[ATraining Step: 47  | total loss: [1m[32m1.76218[0m[0m | time: 34.345s
[2K| Adam | epoch: 001 | loss: 1.76218 - acc: 0.4103 -- iter: 03008/10000
[A[ATraining Step: 48  | total loss: [1m[32m1.71742[0m[0m | time: 34.972s
[2K| Adam | epoch: 001 | loss: 1.71742 - acc: 0.4071 -- iter: 03072/10000
[A[ATraining Step: 49  | total loss: [1m[32m1.72524[0m[0m | time: 35.601s
[2K| Adam | epoch: 001 | loss: 1.72524 - acc: 0.4021 -- iter: 03136/10000
[A[ATraining Step: 50  | total loss: [1m[32m1.73482[0m[0m | time: 36.234s
[2K| Adam | epoch: 001 | loss: 1.73482 - acc: 0.4003 -- iter: 03200/10000
[A[ATraining Step: 51  | total loss: [1m[32m1.74067[0m[0m | time: 36.855s
[2K| Adam | epoch: 001 | loss: 1.74067 - acc: 0.4012 -- iter: 03264/10000
[A[ATraining Step: 52  | total loss: [1m[32m1.75803[0m[0m | time: 37.489s
[2K| Adam | epoch: 001 | loss: 1.75803 - acc: 0.3902 -- iter: 03328/10000
[A[ATraining Step: 53  | total loss: [1m[32m1.75178[0m[0m | time: 38.128s
[2K| Adam | epoch: 001 | loss: 1.75178 - acc: 0.3926 -- iter: 03392/10000
[A[ATraining Step: 54  | total loss: [1m[32m1.68067[0m[0m | time: 38.759s
[2K| Adam | epoch: 001 | loss: 1.68067 - acc: 0.4218 -- iter: 03456/10000
[A[ATraining Step: 55  | total loss: [1m[32m1.69052[0m[0m | time: 39.387s
[2K| Adam | epoch: 001 | loss: 1.69052 - acc: 0.4240 -- iter: 03520/10000
[A[ATraining Step: 56  | total loss: [1m[32m1.69316[0m[0m | time: 40.021s
[2K| Adam | epoch: 001 | loss: 1.69316 - acc: 0.4193 -- iter: 03584/10000
[A[ATraining Step: 57  | total loss: [1m[32m1.71411[0m[0m | time: 40.678s
[2K| Adam | epoch: 001 | loss: 1.71411 - acc: 0.4067 -- iter: 03648/10000
[A[ATraining Step: 58  | total loss: [1m[32m1.75052[0m[0m | time: 41.308s
[2K| Adam | epoch: 001 | loss: 1.75052 - acc: 0.4130 -- iter: 03712/10000
[A[ATraining Step: 59  | total loss: [1m[32m1.72867[0m[0m | time: 41.937s
[2K| Adam | epoch: 001 | loss: 1.72867 - acc: 0.4226 -- iter: 03776/10000
[A[ATraining Step: 60  | total loss: [1m[32m1.73588[0m[0m | time: 42.571s
[2K| Adam | epoch: 001 | loss: 1.73588 - acc: 0.4184 -- iter: 03840/10000
[A[ATraining Step: 61  | total loss: [1m[32m1.70705[0m[0m | time: 43.199s
[2K| Adam | epoch: 001 | loss: 1.70705 - acc: 0.4229 -- iter: 03904/10000
[A[ATraining Step: 62  | total loss: [1m[32m1.69919[0m[0m | time: 43.826s
[2K| Adam | epoch: 001 | loss: 1.69919 - acc: 0.4228 -- iter: 03968/10000
[A[ATraining Step: 63  | total loss: [1m[32m1.66946[0m[0m | time: 44.456s
[2K| Adam | epoch: 001 | loss: 1.66946 - acc: 0.4227 -- iter: 04032/10000
[A[ATraining Step: 64  | total loss: [1m[32m1.65636[0m[0m | time: 45.095s
[2K| Adam | epoch: 001 | loss: 1.65636 - acc: 0.4265 -- iter: 04096/10000
[A[ATraining Step: 65  | total loss: [1m[32m1.65824[0m[0m | time: 45.738s
[2K| Adam | epoch: 001 | loss: 1.65824 - acc: 0.4259 -- iter: 04160/10000
[A[ATraining Step: 66  | total loss: [1m[32m1.68376[0m[0m | time: 46.379s
[2K| Adam | epoch: 001 | loss: 1.68376 - acc: 0.4235 -- iter: 04224/10000
[A[ATraining Step: 67  | total loss: [1m[32m1.71827[0m[0m | time: 47.019s
[2K| Adam | epoch: 001 | loss: 1.71827 - acc: 0.4233 -- iter: 04288/10000
[A[ATraining Step: 68  | total loss: [1m[32m1.71139[0m[0m | time: 47.657s
[2K| Adam | epoch: 001 | loss: 1.71139 - acc: 0.4324 -- iter: 04352/10000
[A[ATraining Step: 69  | total loss: [1m[32m1.69943[0m[0m | time: 48.295s
[2K| Adam | epoch: 001 | loss: 1.69943 - acc: 0.4421 -- iter: 04416/10000
[A[ATraining Step: 70  | total loss: [1m[32m1.69827[0m[0m | time: 48.925s
[2K| Adam | epoch: 001 | loss: 1.69827 - acc: 0.4470 -- iter: 04480/10000
[A[ATraining Step: 71  | total loss: [1m[32m1.68407[0m[0m | time: 49.569s
[2K| Adam | epoch: 001 | loss: 1.68407 - acc: 0.4530 -- iter: 04544/10000
[A[ATraining Step: 72  | total loss: [1m[32m1.69084[0m[0m | time: 50.213s
[2K| Adam | epoch: 001 | loss: 1.69084 - acc: 0.4460 -- iter: 04608/10000
[A[ATraining Step: 73  | total loss: [1m[32m1.66433[0m[0m | time: 50.869s
[2K| Adam | epoch: 001 | loss: 1.66433 - acc: 0.4520 -- iter: 04672/10000
[A[ATraining Step: 74  | total loss: [1m[32m1.63118[0m[0m | time: 51.505s
[2K| Adam | epoch: 001 | loss: 1.63118 - acc: 0.4556 -- iter: 04736/10000
[A[ATraining Step: 75  | total loss: [1m[32m1.64971[0m[0m | time: 52.145s
[2K| Adam | epoch: 001 | loss: 1.64971 - acc: 0.4468 -- iter: 04800/10000
[A[ATraining Step: 76  | total loss: [1m[32m1.65347[0m[0m | time: 52.781s
[2K| Adam | epoch: 001 | loss: 1.65347 - acc: 0.4458 -- iter: 04864/10000
[A[ATraining Step: 77  | total loss: [1m[32m1.66851[0m[0m | time: 53.428s
[2K| Adam | epoch: 001 | loss: 1.66851 - acc: 0.4416 -- iter: 04928/10000
[A[ATraining Step: 78  | total loss: [1m[32m1.65439[0m[0m | time: 54.069s
[2K| Adam | epoch: 001 | loss: 1.65439 - acc: 0.4510 -- iter: 04992/10000
[A[ATraining Step: 79  | total loss: [1m[32m1.64828[0m[0m | time: 54.710s
[2K| Adam | epoch: 001 | loss: 1.64828 - acc: 0.4545 -- iter: 05056/10000
[A[ATraining Step: 80  | total loss: [1m[32m1.64430[0m[0m | time: 55.348s
[2K| Adam | epoch: 001 | loss: 1.64430 - acc: 0.4495 -- iter: 05120/10000
[A[ATraining Step: 81  | total loss: [1m[32m1.61630[0m[0m | time: 55.988s
[2K| Adam | epoch: 001 | loss: 1.61630 - acc: 0.4499 -- iter: 05184/10000
[A[ATraining Step: 82  | total loss: [1m[32m1.60967[0m[0m | time: 56.629s
[2K| Adam | epoch: 001 | loss: 1.60967 - acc: 0.4455 -- iter: 05248/10000
[A[ATraining Step: 83  | total loss: [1m[32m1.62785[0m[0m | time: 57.268s
[2K| Adam | epoch: 001 | loss: 1.62785 - acc: 0.4354 -- iter: 05312/10000
[A[ATraining Step: 84  | total loss: [1m[32m1.60836[0m[0m | time: 57.907s
[2K| Adam | epoch: 001 | loss: 1.60836 - acc: 0.4340 -- iter: 05376/10000
[A[ATraining Step: 85  | total loss: [1m[32m1.61703[0m[0m | time: 58.550s
[2K| Adam | epoch: 001 | loss: 1.61703 - acc: 0.4344 -- iter: 05440/10000
[A[ATraining Step: 86  | total loss: [1m[32m1.61275[0m[0m | time: 59.188s
[2K| Adam | epoch: 001 | loss: 1.61275 - acc: 0.4269 -- iter: 05504/10000
[A[ATraining Step: 87  | total loss: [1m[32m1.60115[0m[0m | time: 59.834s
[2K| Adam | epoch: 001 | loss: 1.60115 - acc: 0.4264 -- iter: 05568/10000
[A[ATraining Step: 88  | total loss: [1m[32m1.59525[0m[0m | time: 60.474s
[2K| Adam | epoch: 001 | loss: 1.59525 - acc: 0.4353 -- iter: 05632/10000
[A[ATraining Step: 89  | total loss: [1m[32m1.58561[0m[0m | time: 61.169s
[2K| Adam | epoch: 001 | loss: 1.58561 - acc: 0.4449 -- iter: 05696/10000
[A[ATraining Step: 90  | total loss: [1m[32m1.57804[0m[0m | time: 61.823s
[2K| Adam | epoch: 001 | loss: 1.57804 - acc: 0.4457 -- iter: 05760/10000
[A[ATraining Step: 91  | total loss: [1m[32m1.55958[0m[0m | time: 62.508s
[2K| Adam | epoch: 001 | loss: 1.55958 - acc: 0.4558 -- iter: 05824/10000
[A[ATraining Step: 92  | total loss: [1m[32m1.57033[0m[0m | time: 63.206s
[2K| Adam | epoch: 001 | loss: 1.57033 - acc: 0.4509 -- iter: 05888/10000
[A[ATraining Step: 93  | total loss: [1m[32m1.52832[0m[0m | time: 63.901s
[2K| Adam | epoch: 001 | loss: 1.52832 - acc: 0.4589 -- iter: 05952/10000
[A[ATraining Step: 94  | total loss: [1m[32m1.52951[0m[0m | time: 64.653s
[2K| Adam | epoch: 001 | loss: 1.52951 - acc: 0.4661 -- iter: 06016/10000
[A[ATraining Step: 95  | total loss: [1m[32m1.50974[0m[0m | time: 65.356s
[2K| Adam | epoch: 001 | loss: 1.50974 - acc: 0.4836 -- iter: 06080/10000
[A[ATraining Step: 96  | total loss: [1m[32m1.51962[0m[0m | time: 66.099s
[2K| Adam | epoch: 001 | loss: 1.51962 - acc: 0.4837 -- iter: 06144/10000
[A[ATraining Step: 97  | total loss: [1m[32m1.52465[0m[0m | time: 66.781s
[2K| Adam | epoch: 001 | loss: 1.52465 - acc: 0.4759 -- iter: 06208/10000
[A[ATraining Step: 98  | total loss: [1m[32m1.53148[0m[0m | time: 67.455s
[2K| Adam | epoch: 001 | loss: 1.53148 - acc: 0.4752 -- iter: 06272/10000
[A[ATraining Step: 99  | total loss: [1m[32m1.52846[0m[0m | time: 68.125s
[2K| Adam | epoch: 001 | loss: 1.52846 - acc: 0.4824 -- iter: 06336/10000
[A[ATraining Step: 100  | total loss: [1m[32m1.51718[0m[0m | time: 72.504s
[2K| Adam | epoch: 001 | loss: 1.51718 - acc: 0.4888 | val_loss: 1.50845 - val_acc: 0.4543 -- iter: 06400/10000
--
Training Step: 101  | total loss: [1m[32m1.51725[0m[0m | time: 73.588s
[2K| Adam | epoch: 001 | loss: 1.51725 - acc: 0.4931 -- iter: 06464/10000
[A[ATraining Step: 102  | total loss: [1m[32m1.51199[0m[0m | time: 74.493s
[2K| Adam | epoch: 001 | loss: 1.51199 - acc: 0.4922 -- iter: 06528/10000
[A[ATraining Step: 103  | total loss: [1m[32m1.51828[0m[0m | time: 75.521s
[2K| Adam | epoch: 001 | loss: 1.51828 - acc: 0.4774 -- iter: 06592/10000
[A[ATraining Step: 104  | total loss: [1m[32m1.50958[0m[0m | time: 76.606s
[2K| Adam | epoch: 001 | loss: 1.50958 - acc: 0.4765 -- iter: 06656/10000
[A[ATraining Step: 105  | total loss: [1m[32m1.52590[0m[0m | time: 77.638s
[2K| Adam | epoch: 001 | loss: 1.52590 - acc: 0.4663 -- iter: 06720/10000
[A[ATraining Step: 106  | total loss: [1m[32m1.49361[0m[0m | time: 78.466s
[2K| Adam | epoch: 001 | loss: 1.49361 - acc: 0.4775 -- iter: 06784/10000
[A[ATraining Step: 107  | total loss: [1m[32m1.47286[0m[0m | time: 79.249s
[2K| Adam | epoch: 001 | loss: 1.47286 - acc: 0.4876 -- iter: 06848/10000
[A[ATraining Step: 108  | total loss: [1m[32m1.45573[0m[0m | time: 80.003s
[2K| Adam | epoch: 001 | loss: 1.45573 - acc: 0.4904 -- iter: 06912/10000
[A[ATraining Step: 109  | total loss: [1m[32m1.44707[0m[0m | time: 80.684s
[2K| Adam | epoch: 001 | loss: 1.44707 - acc: 0.4913 -- iter: 06976/10000
[A[ATraining Step: 110  | total loss: [1m[32m1.44557[0m[0m | time: 81.338s
[2K| Adam | epoch: 001 | loss: 1.44557 - acc: 0.4953 -- iter: 07040/10000
[A[ATraining Step: 111  | total loss: [1m[32m1.44579[0m[0m | time: 81.988s
[2K| Adam | epoch: 001 | loss: 1.44579 - acc: 0.4942 -- iter: 07104/10000
[A[ATraining Step: 112  | total loss: [1m[32m1.43477[0m[0m | time: 82.639s
[2K| Adam | epoch: 001 | loss: 1.43477 - acc: 0.4979 -- iter: 07168/10000
[A[ATraining Step: 113  | total loss: [1m[32m1.43624[0m[0m | time: 83.274s
[2K| Adam | epoch: 001 | loss: 1.43624 - acc: 0.5060 -- iter: 07232/10000
[A[ATraining Step: 114  | total loss: [1m[32m1.44029[0m[0m | time: 83.935s
[2K| Adam | epoch: 001 | loss: 1.44029 - acc: 0.5038 -- iter: 07296/10000
[A[ATraining Step: 115  | total loss: [1m[32m1.45091[0m[0m | time: 84.630s
[2K| Adam | epoch: 001 | loss: 1.45091 - acc: 0.4940 -- iter: 07360/10000
[A[ATraining Step: 116  | total loss: [1m[32m1.44057[0m[0m | time: 85.275s
[2K| Adam | epoch: 001 | loss: 1.44057 - acc: 0.4993 -- iter: 07424/10000
[A[ATraining Step: 117  | total loss: [1m[32m1.45993[0m[0m | time: 85.910s
[2K| Adam | epoch: 001 | loss: 1.45993 - acc: 0.4931 -- iter: 07488/10000
[A[ATraining Step: 118  | total loss: [1m[32m1.46829[0m[0m | time: 86.637s
[2K| Adam | epoch: 001 | loss: 1.46829 - acc: 0.4891 -- iter: 07552/10000
[A[ATraining Step: 119  | total loss: [1m[32m1.45459[0m[0m | time: 87.389s
[2K| Adam | epoch: 001 | loss: 1.45459 - acc: 0.4965 -- iter: 07616/10000
[A[ATraining Step: 120  | total loss: [1m[32m1.44291[0m[0m | time: 88.154s
[2K| Adam | epoch: 001 | loss: 1.44291 - acc: 0.4968 -- iter: 07680/10000
[A[ATraining Step: 121  | total loss: [1m[32m1.43027[0m[0m | time: 88.808s
[2K| Adam | epoch: 001 | loss: 1.43027 - acc: 0.4971 -- iter: 07744/10000
[A[ATraining Step: 122  | total loss: [1m[32m1.41550[0m[0m | time: 89.486s
[2K| Adam | epoch: 001 | loss: 1.41550 - acc: 0.5052 -- iter: 07808/10000
[A[ATraining Step: 123  | total loss: [1m[32m1.39681[0m[0m | time: 90.113s
[2K| Adam | epoch: 001 | loss: 1.39681 - acc: 0.5094 -- iter: 07872/10000
[A[ATraining Step: 124  | total loss: [1m[32m1.39050[0m[0m | time: 90.759s
[2K| Adam | epoch: 001 | loss: 1.39050 - acc: 0.5085 -- iter: 07936/10000
[A[ATraining Step: 125  | total loss: [1m[32m1.40507[0m[0m | time: 91.474s
[2K| Adam | epoch: 001 | loss: 1.40507 - acc: 0.5076 -- iter: 08000/10000
[A[ATraining Step: 126  | total loss: [1m[32m1.61292[0m[0m | time: 92.148s
[2K| Adam | epoch: 001 | loss: 1.61292 - acc: 0.4709 -- iter: 08064/10000
[A[ATraining Step: 127  | total loss: [1m[32m1.59165[0m[0m | time: 92.827s
[2K| Adam | epoch: 001 | loss: 1.59165 - acc: 0.4738 -- iter: 08128/10000
[A[ATraining Step: 128  | total loss: [1m[32m1.58750[0m[0m | time: 93.454s
[2K| Adam | epoch: 001 | loss: 1.58750 - acc: 0.4796 -- iter: 08192/10000
[A[ATraining Step: 129  | total loss: [1m[32m1.56280[0m[0m | time: 94.110s
[2K| Adam | epoch: 001 | loss: 1.56280 - acc: 0.4910 -- iter: 08256/10000
[A[ATraining Step: 130  | total loss: [1m[32m1.53472[0m[0m | time: 94.748s
[2K| Adam | epoch: 001 | loss: 1.53472 - acc: 0.4919 -- iter: 08320/10000
[A[ATraining Step: 131  | total loss: [1m[32m1.49864[0m[0m | time: 95.376s
[2K| Adam | epoch: 001 | loss: 1.49864 - acc: 0.5005 -- iter: 08384/10000
[A[ATraining Step: 132  | total loss: [1m[32m1.49259[0m[0m | time: 96.050s
[2K| Adam | epoch: 001 | loss: 1.49259 - acc: 0.5005 -- iter: 08448/10000
[A[ATraining Step: 133  | total loss: [1m[32m1.47713[0m[0m | time: 96.727s
[2K| Adam | epoch: 001 | loss: 1.47713 - acc: 0.4942 -- iter: 08512/10000
[A[ATraining Step: 134  | total loss: [1m[32m1.46556[0m[0m | time: 97.386s
[2K| Adam | epoch: 001 | loss: 1.46556 - acc: 0.4947 -- iter: 08576/10000
[A[ATraining Step: 135  | total loss: [1m[32m1.44513[0m[0m | time: 98.019s
[2K| Adam | epoch: 001 | loss: 1.44513 - acc: 0.5015 -- iter: 08640/10000
[A[ATraining Step: 136  | total loss: [1m[32m1.43035[0m[0m | time: 98.657s
[2K| Adam | epoch: 001 | loss: 1.43035 - acc: 0.5061 -- iter: 08704/10000
[A[ATraining Step: 137  | total loss: [1m[32m1.43623[0m[0m | time: 99.296s
[2K| Adam | epoch: 001 | loss: 1.43623 - acc: 0.5023 -- iter: 08768/10000
[A[ATraining Step: 138  | total loss: [1m[32m1.43526[0m[0m | time: 99.932s
[2K| Adam | epoch: 001 | loss: 1.43526 - acc: 0.4990 -- iter: 08832/10000
[A[ATraining Step: 139  | total loss: [1m[32m1.41246[0m[0m | time: 100.592s
[2K| Adam | epoch: 001 | loss: 1.41246 - acc: 0.5053 -- iter: 08896/10000
[A[ATraining Step: 140  | total loss: [1m[32m1.39645[0m[0m | time: 101.228s
[2K| Adam | epoch: 001 | loss: 1.39645 - acc: 0.5064 -- iter: 08960/10000
[A[ATraining Step: 141  | total loss: [1m[32m1.39867[0m[0m | time: 101.872s
[2K| Adam | epoch: 001 | loss: 1.39867 - acc: 0.5057 -- iter: 09024/10000
[A[ATraining Step: 142  | total loss: [1m[32m1.40508[0m[0m | time: 102.527s
[2K| Adam | epoch: 001 | loss: 1.40508 - acc: 0.5176 -- iter: 09088/10000
[A[ATraining Step: 143  | total loss: [1m[32m1.38257[0m[0m | time: 103.146s
[2K| Adam | epoch: 001 | loss: 1.38257 - acc: 0.5299 -- iter: 09152/10000
[A[ATraining Step: 144  | total loss: [1m[32m1.37922[0m[0m | time: 103.760s
[2K| Adam | epoch: 001 | loss: 1.37922 - acc: 0.5316 -- iter: 09216/10000
[A[ATraining Step: 145  | total loss: [1m[32m1.36849[0m[0m | time: 104.382s
[2K| Adam | epoch: 001 | loss: 1.36849 - acc: 0.5347 -- iter: 09280/10000
[A[ATraining Step: 146  | total loss: [1m[32m1.36603[0m[0m | time: 104.996s
[2K| Adam | epoch: 001 | loss: 1.36603 - acc: 0.5344 -- iter: 09344/10000
[A[ATraining Step: 147  | total loss: [1m[32m1.34937[0m[0m | time: 105.615s
[2K| Adam | epoch: 001 | loss: 1.34937 - acc: 0.5481 -- iter: 09408/10000
[A[ATraining Step: 148  | total loss: [1m[32m1.34962[0m[0m | time: 106.239s
[2K| Adam | epoch: 001 | loss: 1.34962 - acc: 0.5496 -- iter: 09472/10000
[A[ATraining Step: 149  | total loss: [1m[32m1.32847[0m[0m | time: 106.863s
[2K| Adam | epoch: 001 | loss: 1.32847 - acc: 0.5602 -- iter: 09536/10000
[A[ATraining Step: 150  | total loss: [1m[32m1.32375[0m[0m | time: 107.484s
[2K| Adam | epoch: 001 | loss: 1.32375 - acc: 0.5589 -- iter: 09600/10000
[A[ATraining Step: 151  | total loss: [1m[32m1.30496[0m[0m | time: 108.118s
[2K| Adam | epoch: 001 | loss: 1.30496 - acc: 0.5655 -- iter: 09664/10000
[A[ATraining Step: 152  | total loss: [1m[32m1.28300[0m[0m | time: 108.785s
[2K| Adam | epoch: 001 | loss: 1.28300 - acc: 0.5746 -- iter: 09728/10000
[A[ATraining Step: 153  | total loss: [1m[32m1.25286[0m[0m | time: 109.464s
[2K| Adam | epoch: 001 | loss: 1.25286 - acc: 0.5796 -- iter: 09792/10000
[A[ATraining Step: 154  | total loss: [1m[32m1.28420[0m[0m | time: 110.105s
[2K| Adam | epoch: 001 | loss: 1.28420 - acc: 0.5763 -- iter: 09856/10000
[A[ATraining Step: 155  | total loss: [1m[32m1.30061[0m[0m | time: 110.762s
[2K| Adam | epoch: 001 | loss: 1.30061 - acc: 0.5609 -- iter: 09920/10000
[A[ATraining Step: 156  | total loss: [1m[32m1.28877[0m[0m | time: 111.401s
[2K| Adam | epoch: 001 | loss: 1.28877 - acc: 0.5673 -- iter: 09984/10000
[A[ATraining Step: 157  | total loss: [1m[32m1.28485[0m[0m | time: 113.338s
[2K| Adam | epoch: 001 | loss: 1.28485 - acc: 0.5637 | val_loss: 1.39780 - val_acc: 0.4743 -- iter: 10000/10000
--
Training Step: 158  | total loss: [1m[32m1.25031[0m[0m | time: 0.287s
[2K| Adam | epoch: 002 | loss: 1.25031 - acc: 0.5761 -- iter: 00064/10000
[A[ATraining Step: 159  | total loss: [1m[32m1.21088[0m[0m | time: 0.893s
[2K| Adam | epoch: 002 | loss: 1.21088 - acc: 0.5935 -- iter: 00128/10000
[A[ATraining Step: 160  | total loss: [1m[32m1.21506[0m[0m | time: 1.525s
[2K| Adam | epoch: 002 | loss: 1.21506 - acc: 0.5873 -- iter: 00192/10000
[A[ATraining Step: 161  | total loss: [1m[32m1.21282[0m[0m | time: 2.133s
[2K| Adam | epoch: 002 | loss: 1.21282 - acc: 0.5848 -- iter: 00256/10000
[A[ATraining Step: 162  | total loss: [1m[32m1.23952[0m[0m | time: 2.774s
[2K| Adam | epoch: 002 | loss: 1.23952 - acc: 0.5810 -- iter: 00320/10000
[A[ATraining Step: 163  | total loss: [1m[32m1.23859[0m[0m | time: 3.405s
[2K| Adam | epoch: 002 | loss: 1.23859 - acc: 0.5760 -- iter: 00384/10000
[A[ATraining Step: 164  | total loss: [1m[32m1.25033[0m[0m | time: 4.056s
[2K| Adam | epoch: 002 | loss: 1.25033 - acc: 0.5669 -- iter: 00448/10000
[A[ATraining Step: 165  | total loss: [1m[32m1.27435[0m[0m | time: 4.657s
[2K| Adam | epoch: 002 | loss: 1.27435 - acc: 0.5633 -- iter: 00512/10000
[A[ATraining Step: 166  | total loss: [1m[32m1.29677[0m[0m | time: 5.296s
[2K| Adam | epoch: 002 | loss: 1.29677 - acc: 0.5585 -- iter: 00576/10000
[A[ATraining Step: 167  | total loss: [1m[32m1.28583[0m[0m | time: 6.002s
[2K| Adam | epoch: 002 | loss: 1.28583 - acc: 0.5605 -- iter: 00640/10000
[A[ATraining Step: 168  | total loss: [1m[32m1.28732[0m[0m | time: 6.710s
[2K| Adam | epoch: 002 | loss: 1.28732 - acc: 0.5638 -- iter: 00704/10000
[A[ATraining Step: 169  | total loss: [1m[32m1.32081[0m[0m | time: 7.383s
[2K| Adam | epoch: 002 | loss: 1.32081 - acc: 0.5559 -- iter: 00768/10000
[A[ATraining Step: 170  | total loss: [1m[32m1.32468[0m[0m | time: 8.044s
[2K| Adam | epoch: 002 | loss: 1.32468 - acc: 0.5550 -- iter: 00832/10000
[A[ATraining Step: 171  | total loss: [1m[32m1.30459[0m[0m | time: 8.681s
[2K| Adam | epoch: 002 | loss: 1.30459 - acc: 0.5682 -- iter: 00896/10000
[A[ATraining Step: 172  | total loss: [1m[32m1.29424[0m[0m | time: 9.316s
[2K| Adam | epoch: 002 | loss: 1.29424 - acc: 0.5708 -- iter: 00960/10000
[A[ATraining Step: 173  | total loss: [1m[32m1.27898[0m[0m | time: 9.941s
[2K| Adam | epoch: 002 | loss: 1.27898 - acc: 0.5793 -- iter: 01024/10000
[A[ATraining Step: 174  | total loss: [1m[32m1.27444[0m[0m | time: 10.570s
[2K| Adam | epoch: 002 | loss: 1.27444 - acc: 0.5730 -- iter: 01088/10000
[A[ATraining Step: 175  | total loss: [1m[32m1.28809[0m[0m | time: 11.207s
[2K| Adam | epoch: 002 | loss: 1.28809 - acc: 0.5750 -- iter: 01152/10000
[A[ATraining Step: 176  | total loss: [1m[32m1.29997[0m[0m | time: 11.832s
[2K| Adam | epoch: 002 | loss: 1.29997 - acc: 0.5644 -- iter: 01216/10000
[A[ATraining Step: 177  | total loss: [1m[32m1.27993[0m[0m | time: 12.482s
[2K| Adam | epoch: 002 | loss: 1.27993 - acc: 0.5720 -- iter: 01280/10000
[A[ATraining Step: 178  | total loss: [1m[32m1.24837[0m[0m | time: 13.110s
[2K| Adam | epoch: 002 | loss: 1.24837 - acc: 0.5804 -- iter: 01344/10000
[A[ATraining Step: 179  | total loss: [1m[32m1.26766[0m[0m | time: 13.767s
[2K| Adam | epoch: 002 | loss: 1.26766 - acc: 0.5802 -- iter: 01408/10000
[A[ATraining Step: 180  | total loss: [1m[32m1.27518[0m[0m | time: 14.410s
[2K| Adam | epoch: 002 | loss: 1.27518 - acc: 0.5784 -- iter: 01472/10000
[A[ATraining Step: 181  | total loss: [1m[32m1.26847[0m[0m | time: 15.039s
[2K| Adam | epoch: 002 | loss: 1.26847 - acc: 0.5753 -- iter: 01536/10000
[A[ATraining Step: 182  | total loss: [1m[32m1.24910[0m[0m | time: 15.666s
[2K| Adam | epoch: 002 | loss: 1.24910 - acc: 0.5787 -- iter: 01600/10000
[A[ATraining Step: 183  | total loss: [1m[32m1.25660[0m[0m | time: 16.273s
[2K| Adam | epoch: 002 | loss: 1.25660 - acc: 0.5771 -- iter: 01664/10000
[A[ATraining Step: 184  | total loss: [1m[32m1.24883[0m[0m | time: 16.990s
[2K| Adam | epoch: 002 | loss: 1.24883 - acc: 0.5819 -- iter: 01728/10000
[A[ATraining Step: 185  | total loss: [1m[32m1.25199[0m[0m | time: 17.636s
[2K| Adam | epoch: 002 | loss: 1.25199 - acc: 0.5784 -- iter: 01792/10000
[A[ATraining Step: 186  | total loss: [1m[32m1.26406[0m[0m | time: 18.264s
[2K| Adam | epoch: 002 | loss: 1.26406 - acc: 0.5752 -- iter: 01856/10000
[A[ATraining Step: 187  | total loss: [1m[32m1.26748[0m[0m | time: 18.890s
[2K| Adam | epoch: 002 | loss: 1.26748 - acc: 0.5724 -- iter: 01920/10000
[A[ATraining Step: 188  | total loss: [1m[32m1.26504[0m[0m | time: 19.522s
[2K| Adam | epoch: 002 | loss: 1.26504 - acc: 0.5714 -- iter: 01984/10000
[A[ATraining Step: 189  | total loss: [1m[32m1.27188[0m[0m | time: 20.174s
[2K| Adam | epoch: 002 | loss: 1.27188 - acc: 0.5674 -- iter: 02048/10000
[A[ATraining Step: 190  | total loss: [1m[32m1.25831[0m[0m | time: 20.809s
[2K| Adam | epoch: 002 | loss: 1.25831 - acc: 0.5763 -- iter: 02112/10000
[A[ATraining Step: 191  | total loss: [1m[32m1.25734[0m[0m | time: 21.441s
[2K| Adam | epoch: 002 | loss: 1.25734 - acc: 0.5608 -- iter: 02176/10000
[A[ATraining Step: 192  | total loss: [1m[32m1.26285[0m[0m | time: 22.081s
[2K| Adam | epoch: 002 | loss: 1.26285 - acc: 0.5501 -- iter: 02240/10000
[A[ATraining Step: 193  | total loss: [1m[32m1.28845[0m[0m | time: 22.709s
[2K| Adam | epoch: 002 | loss: 1.28845 - acc: 0.5404 -- iter: 02304/10000
[A[ATraining Step: 194  | total loss: [1m[32m1.26817[0m[0m | time: 23.363s
[2K| Adam | epoch: 002 | loss: 1.26817 - acc: 0.5504 -- iter: 02368/10000
[A[ATraining Step: 195  | total loss: [1m[32m1.25844[0m[0m | time: 24.003s
[2K| Adam | epoch: 002 | loss: 1.25844 - acc: 0.5500 -- iter: 02432/10000
[A[ATraining Step: 196  | total loss: [1m[32m1.25676[0m[0m | time: 24.627s
[2K| Adam | epoch: 002 | loss: 1.25676 - acc: 0.5528 -- iter: 02496/10000
[A[ATraining Step: 197  | total loss: [1m[32m1.24570[0m[0m | time: 25.267s
[2K| Adam | epoch: 002 | loss: 1.24570 - acc: 0.5601 -- iter: 02560/10000
[A[ATraining Step: 198  | total loss: [1m[32m1.22945[0m[0m | time: 25.902s
[2K| Adam | epoch: 002 | loss: 1.22945 - acc: 0.5650 -- iter: 02624/10000
[A[ATraining Step: 199  | total loss: [1m[32m1.25475[0m[0m | time: 26.537s
[2K| Adam | epoch: 002 | loss: 1.25475 - acc: 0.5601 -- iter: 02688/10000
[A[ATraining Step: 200  | total loss: [1m[32m1.24943[0m[0m | time: 28.828s
[2K| Adam | epoch: 002 | loss: 1.24943 - acc: 0.5572 | val_loss: 1.69132 - val_acc: 0.3971 -- iter: 02752/10000
--
Training Step: 201  | total loss: [1m[32m1.21410[0m[0m | time: 29.436s
[2K| Adam | epoch: 002 | loss: 1.21410 - acc: 0.5640 -- iter: 02816/10000
[A[ATraining Step: 202  | total loss: [1m[32m1.22193[0m[0m | time: 30.061s
[2K| Adam | epoch: 002 | loss: 1.22193 - acc: 0.5685 -- iter: 02880/10000
[A[ATraining Step: 203  | total loss: [1m[32m1.24303[0m[0m | time: 30.687s
[2K| Adam | epoch: 002 | loss: 1.24303 - acc: 0.5679 -- iter: 02944/10000
[A[ATraining Step: 204  | total loss: [1m[32m1.23098[0m[0m | time: 31.318s
[2K| Adam | epoch: 002 | loss: 1.23098 - acc: 0.5642 -- iter: 03008/10000
[A[ATraining Step: 205  | total loss: [1m[32m1.24307[0m[0m | time: 31.943s
[2K| Adam | epoch: 002 | loss: 1.24307 - acc: 0.5625 -- iter: 03072/10000
[A[ATraining Step: 206  | total loss: [1m[32m1.22914[0m[0m | time: 32.562s
[2K| Adam | epoch: 002 | loss: 1.22914 - acc: 0.5656 -- iter: 03136/10000
[A[ATraining Step: 207  | total loss: [1m[32m1.22974[0m[0m | time: 33.183s
[2K| Adam | epoch: 002 | loss: 1.22974 - acc: 0.5716 -- iter: 03200/10000
[A[ATraining Step: 208  | total loss: [1m[32m1.20858[0m[0m | time: 33.794s
[2K| Adam | epoch: 002 | loss: 1.20858 - acc: 0.5832 -- iter: 03264/10000
[A[ATraining Step: 209  | total loss: [1m[32m1.19929[0m[0m | time: 34.453s
[2K| Adam | epoch: 002 | loss: 1.19929 - acc: 0.5858 -- iter: 03328/10000
[A[ATraining Step: 210  | total loss: [1m[32m1.18294[0m[0m | time: 35.103s
[2K| Adam | epoch: 002 | loss: 1.18294 - acc: 0.5850 -- iter: 03392/10000
[A[ATraining Step: 211  | total loss: [1m[32m1.18038[0m[0m | time: 35.708s
[2K| Adam | epoch: 002 | loss: 1.18038 - acc: 0.5890 -- iter: 03456/10000
[A[ATraining Step: 212  | total loss: [1m[32m1.15930[0m[0m | time: 36.341s
[2K| Adam | epoch: 002 | loss: 1.15930 - acc: 0.5989 -- iter: 03520/10000
[A[ATraining Step: 213  | total loss: [1m[32m1.15098[0m[0m | time: 36.989s
[2K| Adam | epoch: 002 | loss: 1.15098 - acc: 0.5952 -- iter: 03584/10000
[A[ATraining Step: 214  | total loss: [1m[32m1.13273[0m[0m | time: 37.638s
[2K| Adam | epoch: 002 | loss: 1.13273 - acc: 0.5966 -- iter: 03648/10000
[A[ATraining Step: 215  | total loss: [1m[32m1.12966[0m[0m | time: 38.264s
[2K| Adam | epoch: 002 | loss: 1.12966 - acc: 0.6026 -- iter: 03712/10000
[A[ATraining Step: 216  | total loss: [1m[32m1.12728[0m[0m | time: 38.897s
[2K| Adam | epoch: 002 | loss: 1.12728 - acc: 0.6017 -- iter: 03776/10000
[A[ATraining Step: 217  | total loss: [1m[32m1.14174[0m[0m | time: 39.521s
[2K| Adam | epoch: 002 | loss: 1.14174 - acc: 0.5994 -- iter: 03840/10000
[A[ATraining Step: 218  | total loss: [1m[32m1.15721[0m[0m | time: 40.160s
[2K| Adam | epoch: 002 | loss: 1.15721 - acc: 0.6019 -- iter: 03904/10000
[A[ATraining Step: 219  | total loss: [1m[32m1.16525[0m[0m | time: 40.784s
[2K| Adam | epoch: 002 | loss: 1.16525 - acc: 0.6042 -- iter: 03968/10000
[A[ATraining Step: 220  | total loss: [1m[32m1.14530[0m[0m | time: 41.387s
[2K| Adam | epoch: 002 | loss: 1.14530 - acc: 0.6204 -- iter: 04032/10000
[A[ATraining Step: 221  | total loss: [1m[32m1.12749[0m[0m | time: 42.013s
[2K| Adam | epoch: 002 | loss: 1.12749 - acc: 0.6286 -- iter: 04096/10000
[A[ATraining Step: 222  | total loss: [1m[32m1.14471[0m[0m | time: 42.637s
[2K| Adam | epoch: 002 | loss: 1.14471 - acc: 0.6080 -- iter: 04160/10000
[A[ATraining Step: 223  | total loss: [1m[32m1.14869[0m[0m | time: 43.264s
[2K| Adam | epoch: 002 | loss: 1.14869 - acc: 0.5987 -- iter: 04224/10000
[A[ATraining Step: 224  | total loss: [1m[32m1.17141[0m[0m | time: 43.888s
[2K| Adam | epoch: 002 | loss: 1.17141 - acc: 0.5935 -- iter: 04288/10000
[A[ATraining Step: 225  | total loss: [1m[32m1.15450[0m[0m | time: 44.510s
[2K| Adam | epoch: 002 | loss: 1.15450 - acc: 0.5983 -- iter: 04352/10000
[A[ATraining Step: 226  | total loss: [1m[32m1.16794[0m[0m | time: 45.135s
[2K| Adam | epoch: 002 | loss: 1.16794 - acc: 0.5962 -- iter: 04416/10000
[A[ATraining Step: 227  | total loss: [1m[32m1.15846[0m[0m | time: 45.741s
[2K| Adam | epoch: 002 | loss: 1.15846 - acc: 0.5960 -- iter: 04480/10000
[A[ATraining Step: 228  | total loss: [1m[32m1.15544[0m[0m | time: 46.366s
[2K| Adam | epoch: 002 | loss: 1.15544 - acc: 0.6051 -- iter: 04544/10000
[A[ATraining Step: 229  | total loss: [1m[32m1.15989[0m[0m | time: 46.995s
[2K| Adam | epoch: 002 | loss: 1.15989 - acc: 0.6024 -- iter: 04608/10000
[A[ATraining Step: 230  | total loss: [1m[32m1.16326[0m[0m | time: 47.641s
[2K| Adam | epoch: 002 | loss: 1.16326 - acc: 0.6063 -- iter: 04672/10000
[A[ATraining Step: 231  | total loss: [1m[32m1.16802[0m[0m | time: 48.263s
[2K| Adam | epoch: 002 | loss: 1.16802 - acc: 0.6066 -- iter: 04736/10000
[A[ATraining Step: 232  | total loss: [1m[32m1.15073[0m[0m | time: 48.888s
[2K| Adam | epoch: 002 | loss: 1.15073 - acc: 0.6147 -- iter: 04800/10000
[A[ATraining Step: 233  | total loss: [1m[32m1.15606[0m[0m | time: 49.515s
[2K| Adam | epoch: 002 | loss: 1.15606 - acc: 0.6141 -- iter: 04864/10000
[A[ATraining Step: 234  | total loss: [1m[32m1.14639[0m[0m | time: 50.138s
[2K| Adam | epoch: 002 | loss: 1.14639 - acc: 0.6168 -- iter: 04928/10000
[A[ATraining Step: 235  | total loss: [1m[32m1.14497[0m[0m | time: 50.762s
[2K| Adam | epoch: 002 | loss: 1.14497 - acc: 0.6207 -- iter: 04992/10000
[A[ATraining Step: 236  | total loss: [1m[32m1.14641[0m[0m | time: 51.385s
[2K| Adam | epoch: 002 | loss: 1.14641 - acc: 0.6118 -- iter: 05056/10000
[A[ATraining Step: 237  | total loss: [1m[32m1.11894[0m[0m | time: 52.011s
[2K| Adam | epoch: 002 | loss: 1.11894 - acc: 0.6178 -- iter: 05120/10000
[A[ATraining Step: 238  | total loss: [1m[32m1.10742[0m[0m | time: 52.637s
[2K| Adam | epoch: 002 | loss: 1.10742 - acc: 0.6201 -- iter: 05184/10000
[A[ATraining Step: 239  | total loss: [1m[32m1.11051[0m[0m | time: 53.262s
[2K| Adam | epoch: 002 | loss: 1.11051 - acc: 0.6128 -- iter: 05248/10000
[A[ATraining Step: 240  | total loss: [1m[32m1.10604[0m[0m | time: 53.895s
[2K| Adam | epoch: 002 | loss: 1.10604 - acc: 0.6155 -- iter: 05312/10000
[A[ATraining Step: 241  | total loss: [1m[32m1.09778[0m[0m | time: 54.517s
[2K| Adam | epoch: 002 | loss: 1.09778 - acc: 0.6118 -- iter: 05376/10000
[A[ATraining Step: 242  | total loss: [1m[32m1.11173[0m[0m | time: 55.145s
[2K| Adam | epoch: 002 | loss: 1.11173 - acc: 0.6053 -- iter: 05440/10000
[A[ATraining Step: 243  | total loss: [1m[32m1.09189[0m[0m | time: 55.771s
[2K| Adam | epoch: 002 | loss: 1.09189 - acc: 0.6120 -- iter: 05504/10000
[A[ATraining Step: 244  | total loss: [1m[32m1.11050[0m[0m | time: 56.400s
[2K| Adam | epoch: 002 | loss: 1.11050 - acc: 0.6086 -- iter: 05568/10000
[A[ATraining Step: 245  | total loss: [1m[32m1.10427[0m[0m | time: 57.027s
[2K| Adam | epoch: 002 | loss: 1.10427 - acc: 0.6087 -- iter: 05632/10000
[A[ATraining Step: 246  | total loss: [1m[32m1.13394[0m[0m | time: 57.675s
[2K| Adam | epoch: 002 | loss: 1.13394 - acc: 0.6025 -- iter: 05696/10000
[A[ATraining Step: 247  | total loss: [1m[32m1.12726[0m[0m | time: 58.298s
[2K| Adam | epoch: 002 | loss: 1.12726 - acc: 0.6016 -- iter: 05760/10000
[A[ATraining Step: 248  | total loss: [1m[32m1.10402[0m[0m | time: 58.924s
[2K| Adam | epoch: 002 | loss: 1.10402 - acc: 0.6180 -- iter: 05824/10000
[A[ATraining Step: 249  | total loss: [1m[32m1.11575[0m[0m | time: 59.546s
[2K| Adam | epoch: 002 | loss: 1.11575 - acc: 0.6140 -- iter: 05888/10000
[A[ATraining Step: 250  | total loss: [1m[32m1.10904[0m[0m | time: 60.170s
[2K| Adam | epoch: 002 | loss: 1.10904 - acc: 0.6167 -- iter: 05952/10000
[A[ATraining Step: 251  | total loss: [1m[32m1.09347[0m[0m | time: 60.800s
[2K| Adam | epoch: 002 | loss: 1.09347 - acc: 0.6300 -- iter: 06016/10000
[A[ATraining Step: 252  | total loss: [1m[32m1.08801[0m[0m | time: 61.428s
[2K| Adam | epoch: 002 | loss: 1.08801 - acc: 0.6342 -- iter: 06080/10000
[A[ATraining Step: 253  | total loss: [1m[32m1.08626[0m[0m | time: 62.056s
[2K| Adam | epoch: 002 | loss: 1.08626 - acc: 0.6364 -- iter: 06144/10000
[A[ATraining Step: 254  | total loss: [1m[32m1.08570[0m[0m | time: 62.675s
[2K| Adam | epoch: 002 | loss: 1.08570 - acc: 0.6306 -- iter: 06208/10000
[A[ATraining Step: 255  | total loss: [1m[32m1.09573[0m[0m | time: 63.296s
[2K| Adam | epoch: 002 | loss: 1.09573 - acc: 0.6238 -- iter: 06272/10000
[A[ATraining Step: 256  | total loss: [1m[32m1.11177[0m[0m | time: 63.918s
[2K| Adam | epoch: 002 | loss: 1.11177 - acc: 0.6176 -- iter: 06336/10000
[A[ATraining Step: 257  | total loss: [1m[32m1.10678[0m[0m | time: 64.541s
[2K| Adam | epoch: 002 | loss: 1.10678 - acc: 0.6231 -- iter: 06400/10000
[A[ATraining Step: 258  | total loss: [1m[32m1.11394[0m[0m | time: 65.162s
[2K| Adam | epoch: 002 | loss: 1.11394 - acc: 0.6154 -- iter: 06464/10000
[A[ATraining Step: 259  | total loss: [1m[32m1.13103[0m[0m | time: 65.788s
[2K| Adam | epoch: 002 | loss: 1.13103 - acc: 0.6070 -- iter: 06528/10000
[A[ATraining Step: 260  | total loss: [1m[32m1.12895[0m[0m | time: 66.414s
[2K| Adam | epoch: 002 | loss: 1.12895 - acc: 0.6010 -- iter: 06592/10000
[A[ATraining Step: 261  | total loss: [1m[32m1.14418[0m[0m | time: 67.038s
[2K| Adam | epoch: 002 | loss: 1.14418 - acc: 0.5940 -- iter: 06656/10000
[A[ATraining Step: 262  | total loss: [1m[32m1.12769[0m[0m | time: 67.689s
[2K| Adam | epoch: 002 | loss: 1.12769 - acc: 0.5987 -- iter: 06720/10000
[A[ATraining Step: 263  | total loss: [1m[32m1.11812[0m[0m | time: 68.319s
[2K| Adam | epoch: 002 | loss: 1.11812 - acc: 0.6076 -- iter: 06784/10000
[A[ATraining Step: 264  | total loss: [1m[32m1.13272[0m[0m | time: 68.940s
[2K| Adam | epoch: 002 | loss: 1.13272 - acc: 0.5999 -- iter: 06848/10000
[A[ATraining Step: 265  | total loss: [1m[32m1.11935[0m[0m | time: 69.565s
[2K| Adam | epoch: 002 | loss: 1.11935 - acc: 0.6087 -- iter: 06912/10000
[A[ATraining Step: 266  | total loss: [1m[32m1.12825[0m[0m | time: 70.194s
[2K| Adam | epoch: 002 | loss: 1.12825 - acc: 0.6135 -- iter: 06976/10000
[A[ATraining Step: 267  | total loss: [1m[32m1.10030[0m[0m | time: 70.820s
[2K| Adam | epoch: 002 | loss: 1.10030 - acc: 0.6193 -- iter: 07040/10000
[A[ATraining Step: 268  | total loss: [1m[32m1.08588[0m[0m | time: 71.442s
[2K| Adam | epoch: 002 | loss: 1.08588 - acc: 0.6230 -- iter: 07104/10000
[A[ATraining Step: 269  | total loss: [1m[32m1.08874[0m[0m | time: 72.061s
[2K| Adam | epoch: 002 | loss: 1.08874 - acc: 0.6169 -- iter: 07168/10000
[A[ATraining Step: 270  | total loss: [1m[32m1.07411[0m[0m | time: 72.684s
[2K| Adam | epoch: 002 | loss: 1.07411 - acc: 0.6256 -- iter: 07232/10000
[A[ATraining Step: 271  | total loss: [1m[32m1.06132[0m[0m | time: 73.311s
[2K| Adam | epoch: 002 | loss: 1.06132 - acc: 0.6286 -- iter: 07296/10000
[A[ATraining Step: 272  | total loss: [1m[32m1.05483[0m[0m | time: 73.936s
[2K| Adam | epoch: 002 | loss: 1.05483 - acc: 0.6314 -- iter: 07360/10000
[A[ATraining Step: 273  | total loss: [1m[32m1.07089[0m[0m | time: 74.560s
[2K| Adam | epoch: 002 | loss: 1.07089 - acc: 0.6308 -- iter: 07424/10000
[A[ATraining Step: 274  | total loss: [1m[32m1.05904[0m[0m | time: 75.188s
[2K| Adam | epoch: 002 | loss: 1.05904 - acc: 0.6349 -- iter: 07488/10000
[A[ATraining Step: 275  | total loss: [1m[32m1.05910[0m[0m | time: 75.814s
[2K| Adam | epoch: 002 | loss: 1.05910 - acc: 0.6401 -- iter: 07552/10000
[A[ATraining Step: 276  | total loss: [1m[32m1.04296[0m[0m | time: 76.443s
[2K| Adam | epoch: 002 | loss: 1.04296 - acc: 0.6480 -- iter: 07616/10000
[A[ATraining Step: 277  | total loss: [1m[32m1.02824[0m[0m | time: 77.078s
[2K| Adam | epoch: 002 | loss: 1.02824 - acc: 0.6473 -- iter: 07680/10000
[A[ATraining Step: 278  | total loss: [1m[32m1.03977[0m[0m | time: 77.736s
[2K| Adam | epoch: 002 | loss: 1.03977 - acc: 0.6403 -- iter: 07744/10000
[A[ATraining Step: 279  | total loss: [1m[32m1.03869[0m[0m | time: 78.420s
[2K| Adam | epoch: 002 | loss: 1.03869 - acc: 0.6451 -- iter: 07808/10000
[A[ATraining Step: 280  | total loss: [1m[32m1.05530[0m[0m | time: 79.064s
[2K| Adam | epoch: 002 | loss: 1.05530 - acc: 0.6321 -- iter: 07872/10000
[A[ATraining Step: 281  | total loss: [1m[32m1.07749[0m[0m | time: 79.688s
[2K| Adam | epoch: 002 | loss: 1.07749 - acc: 0.6298 -- iter: 07936/10000
[A[ATraining Step: 282  | total loss: [1m[32m1.09795[0m[0m | time: 80.323s
[2K| Adam | epoch: 002 | loss: 1.09795 - acc: 0.6278 -- iter: 08000/10000
[A[ATraining Step: 283  | total loss: [1m[32m1.08589[0m[0m | time: 80.966s
[2K| Adam | epoch: 002 | loss: 1.08589 - acc: 0.6306 -- iter: 08064/10000
[A[ATraining Step: 284  | total loss: [1m[32m1.60760[0m[0m | time: 81.631s
[2K| Adam | epoch: 002 | loss: 1.60760 - acc: 0.5738 -- iter: 08128/10000
[A[ATraining Step: 285  | total loss: [1m[32m1.54963[0m[0m | time: 82.275s
[2K| Adam | epoch: 002 | loss: 1.54963 - acc: 0.5868 -- iter: 08192/10000
[A[ATraining Step: 286  | total loss: [1m[32m1.49365[0m[0m | time: 82.920s
[2K| Adam | epoch: 002 | loss: 1.49365 - acc: 0.5937 -- iter: 08256/10000
[A[ATraining Step: 287  | total loss: [1m[32m1.43353[0m[0m | time: 83.586s
[2K| Adam | epoch: 002 | loss: 1.43353 - acc: 0.5953 -- iter: 08320/10000
[A[ATraining Step: 288  | total loss: [1m[32m1.37498[0m[0m | time: 84.264s
[2K| Adam | epoch: 002 | loss: 1.37498 - acc: 0.6045 -- iter: 08384/10000
[A[ATraining Step: 289  | total loss: [1m[32m1.32414[0m[0m | time: 84.943s
[2K| Adam | epoch: 002 | loss: 1.32414 - acc: 0.6144 -- iter: 08448/10000
[A[ATraining Step: 290  | total loss: [1m[32m1.29428[0m[0m | time: 85.634s
[2K| Adam | epoch: 002 | loss: 1.29428 - acc: 0.6123 -- iter: 08512/10000
[A[ATraining Step: 291  | total loss: [1m[32m1.26607[0m[0m | time: 86.330s
[2K| Adam | epoch: 002 | loss: 1.26607 - acc: 0.6151 -- iter: 08576/10000
[A[ATraining Step: 292  | total loss: [1m[32m1.23799[0m[0m | time: 87.030s
[2K| Adam | epoch: 002 | loss: 1.23799 - acc: 0.6192 -- iter: 08640/10000
[A[ATraining Step: 293  | total loss: [1m[32m1.22577[0m[0m | time: 87.757s
[2K| Adam | epoch: 002 | loss: 1.22577 - acc: 0.6167 -- iter: 08704/10000
[A[ATraining Step: 294  | total loss: [1m[32m1.23350[0m[0m | time: 88.438s
[2K| Adam | epoch: 002 | loss: 1.23350 - acc: 0.6160 -- iter: 08768/10000
[A[ATraining Step: 295  | total loss: [1m[32m1.20079[0m[0m | time: 89.117s
[2K| Adam | epoch: 002 | loss: 1.20079 - acc: 0.6278 -- iter: 08832/10000
[A[ATraining Step: 296  | total loss: [1m[32m1.16968[0m[0m | time: 89.787s
[2K| Adam | epoch: 002 | loss: 1.16968 - acc: 0.6275 -- iter: 08896/10000
[A[ATraining Step: 297  | total loss: [1m[32m1.16257[0m[0m | time: 90.466s
[2K| Adam | epoch: 002 | loss: 1.16257 - acc: 0.6241 -- iter: 08960/10000
[A[ATraining Step: 298  | total loss: [1m[32m1.15077[0m[0m | time: 91.149s
[2K| Adam | epoch: 002 | loss: 1.15077 - acc: 0.6227 -- iter: 09024/10000
[A[ATraining Step: 299  | total loss: [1m[32m1.12969[0m[0m | time: 91.815s
[2K| Adam | epoch: 002 | loss: 1.12969 - acc: 0.6307 -- iter: 09088/10000
[A[ATraining Step: 300  | total loss: [1m[32m1.11118[0m[0m | time: 94.196s
[2K| Adam | epoch: 002 | loss: 1.11118 - acc: 0.6380 | val_loss: 1.40516 - val_acc: 0.5186 -- iter: 09152/10000
--
Training Step: 301  | total loss: [1m[32m1.09464[0m[0m | time: 94.834s
[2K| Adam | epoch: 002 | loss: 1.09464 - acc: 0.6413 -- iter: 09216/10000
[A[ATraining Step: 302  | total loss: [1m[32m1.08752[0m[0m | time: 95.503s
[2K| Adam | epoch: 002 | loss: 1.08752 - acc: 0.6335 -- iter: 09280/10000
[A[ATraining Step: 303  | total loss: [1m[32m1.08296[0m[0m | time: 96.145s
[2K| Adam | epoch: 002 | loss: 1.08296 - acc: 0.6326 -- iter: 09344/10000
[A[ATraining Step: 304  | total loss: [1m[32m1.08954[0m[0m | time: 96.806s
[2K| Adam | epoch: 002 | loss: 1.08954 - acc: 0.6334 -- iter: 09408/10000
[A[ATraining Step: 305  | total loss: [1m[32m1.09252[0m[0m | time: 97.490s
[2K| Adam | epoch: 002 | loss: 1.09252 - acc: 0.6388 -- iter: 09472/10000
[A[ATraining Step: 306  | total loss: [1m[32m1.09726[0m[0m | time: 98.160s
[2K| Adam | epoch: 002 | loss: 1.09726 - acc: 0.6374 -- iter: 09536/10000
[A[ATraining Step: 307  | total loss: [1m[32m1.09450[0m[0m | time: 98.825s
[2K| Adam | epoch: 002 | loss: 1.09450 - acc: 0.6331 -- iter: 09600/10000
[A[ATraining Step: 308  | total loss: [1m[32m1.07926[0m[0m | time: 99.491s
[2K| Adam | epoch: 002 | loss: 1.07926 - acc: 0.6338 -- iter: 09664/10000
[A[ATraining Step: 309  | total loss: [1m[32m1.05642[0m[0m | time: 100.160s
[2K| Adam | epoch: 002 | loss: 1.05642 - acc: 0.6501 -- iter: 09728/10000
[A[ATraining Step: 310  | total loss: [1m[32m1.03836[0m[0m | time: 100.826s
[2K| Adam | epoch: 002 | loss: 1.03836 - acc: 0.6507 -- iter: 09792/10000
[A[ATraining Step: 311  | total loss: [1m[32m1.03293[0m[0m | time: 101.494s
[2K| Adam | epoch: 002 | loss: 1.03293 - acc: 0.6513 -- iter: 09856/10000
[A[ATraining Step: 312  | total loss: [1m[32m1.04720[0m[0m | time: 102.167s
[2K| Adam | epoch: 002 | loss: 1.04720 - acc: 0.6440 -- iter: 09920/10000
[A[ATraining Step: 313  | total loss: [1m[32m1.04980[0m[0m | time: 102.841s
[2K| Adam | epoch: 002 | loss: 1.04980 - acc: 0.6405 -- iter: 09984/10000
[A[ATraining Step: 314  | total loss: [1m[32m1.03925[0m[0m | time: 105.207s
[2K| Adam | epoch: 002 | loss: 1.03925 - acc: 0.6390 | val_loss: 1.29660 - val_acc: 0.4929 -- iter: 10000/10000
--
Training Step: 315  | total loss: [1m[32m1.03781[0m[0m | time: 0.297s
[2K| Adam | epoch: 003 | loss: 1.03781 - acc: 0.6329 -- iter: 00064/10000
[A[ATraining Step: 316  | total loss: [1m[32m1.05784[0m[0m | time: 0.621s
[2K| Adam | epoch: 003 | loss: 1.05784 - acc: 0.6258 -- iter: 00128/10000
[A[ATraining Step: 317  | total loss: [1m[32m1.06944[0m[0m | time: 1.266s
[2K| Adam | epoch: 003 | loss: 1.06944 - acc: 0.6258 -- iter: 00192/10000
[A[ATraining Step: 318  | total loss: [1m[32m1.07730[0m[0m | time: 1.939s
[2K| Adam | epoch: 003 | loss: 1.07730 - acc: 0.6272 -- iter: 00256/10000
[A[ATraining Step: 319  | total loss: [1m[32m1.07328[0m[0m | time: 2.633s
[2K| Adam | epoch: 003 | loss: 1.07328 - acc: 0.6208 -- iter: 00320/10000
[A[ATraining Step: 320  | total loss: [1m[32m1.06655[0m[0m | time: 3.300s
[2K| Adam | epoch: 003 | loss: 1.06655 - acc: 0.6259 -- iter: 00384/10000
[A[ATraining Step: 321  | total loss: [1m[32m1.07943[0m[0m | time: 3.971s
[2K| Adam | epoch: 003 | loss: 1.07943 - acc: 0.6211 -- iter: 00448/10000
[A[ATraining Step: 322  | total loss: [1m[32m1.06818[0m[0m | time: 4.637s
[2K| Adam | epoch: 003 | loss: 1.06818 - acc: 0.6277 -- iter: 00512/10000
[A[ATraining Step: 323  | total loss: [1m[32m1.06790[0m[0m | time: 5.304s
[2K| Adam | epoch: 003 | loss: 1.06790 - acc: 0.6228 -- iter: 00576/10000
[A[ATraining Step: 324  | total loss: [1m[32m1.05640[0m[0m | time: 5.975s
[2K| Adam | epoch: 003 | loss: 1.05640 - acc: 0.6339 -- iter: 00640/10000
[A[ATraining Step: 325  | total loss: [1m[32m1.07320[0m[0m | time: 6.665s
[2K| Adam | epoch: 003 | loss: 1.07320 - acc: 0.6299 -- iter: 00704/10000
[A[ATraining Step: 326  | total loss: [1m[32m1.07417[0m[0m | time: 7.359s
[2K| Adam | epoch: 003 | loss: 1.07417 - acc: 0.6326 -- iter: 00768/10000
[A[ATraining Step: 327  | total loss: [1m[32m1.06885[0m[0m | time: 8.054s
[2K| Adam | epoch: 003 | loss: 1.06885 - acc: 0.6318 -- iter: 00832/10000
[A[ATraining Step: 328  | total loss: [1m[32m1.05751[0m[0m | time: 8.749s
[2K| Adam | epoch: 003 | loss: 1.05751 - acc: 0.6358 -- iter: 00896/10000
[A[ATraining Step: 329  | total loss: [1m[32m1.03830[0m[0m | time: 9.436s
[2K| Adam | epoch: 003 | loss: 1.03830 - acc: 0.6347 -- iter: 00960/10000
[A[ATraining Step: 330  | total loss: [1m[32m1.04639[0m[0m | time: 10.128s
[2K| Adam | epoch: 003 | loss: 1.04639 - acc: 0.6322 -- iter: 01024/10000
[A[ATraining Step: 331  | total loss: [1m[32m1.01895[0m[0m | time: 10.817s
[2K| Adam | epoch: 003 | loss: 1.01895 - acc: 0.6424 -- iter: 01088/10000
[A[ATraining Step: 332  | total loss: [1m[32m1.01301[0m[0m | time: 11.505s
[2K| Adam | epoch: 003 | loss: 1.01301 - acc: 0.6438 -- iter: 01152/10000
[A[ATraining Step: 333  | total loss: [1m[32m1.01100[0m[0m | time: 12.214s
[2K| Adam | epoch: 003 | loss: 1.01100 - acc: 0.6497 -- iter: 01216/10000
[A[ATraining Step: 334  | total loss: [1m[32m1.01858[0m[0m | time: 12.905s
[2K| Adam | epoch: 003 | loss: 1.01858 - acc: 0.6519 -- iter: 01280/10000
[A[ATraining Step: 335  | total loss: [1m[32m1.01929[0m[0m | time: 13.591s
[2K| Adam | epoch: 003 | loss: 1.01929 - acc: 0.6555 -- iter: 01344/10000
[A[ATraining Step: 336  | total loss: [1m[32m1.02649[0m[0m | time: 14.269s
[2K| Adam | epoch: 003 | loss: 1.02649 - acc: 0.6462 -- iter: 01408/10000
[A[ATraining Step: 337  | total loss: [1m[32m1.04074[0m[0m | time: 14.936s
[2K| Adam | epoch: 003 | loss: 1.04074 - acc: 0.6456 -- iter: 01472/10000
[A[ATraining Step: 338  | total loss: [1m[32m1.02625[0m[0m | time: 15.602s
[2K| Adam | epoch: 003 | loss: 1.02625 - acc: 0.6530 -- iter: 01536/10000
[A[ATraining Step: 339  | total loss: [1m[32m1.02704[0m[0m | time: 16.270s
[2K| Adam | epoch: 003 | loss: 1.02704 - acc: 0.6564 -- iter: 01600/10000
[A[ATraining Step: 340  | total loss: [1m[32m1.02198[0m[0m | time: 16.914s
[2K| Adam | epoch: 003 | loss: 1.02198 - acc: 0.6580 -- iter: 01664/10000
[A[ATraining Step: 341  | total loss: [1m[32m1.03140[0m[0m | time: 17.610s
[2K| Adam | epoch: 003 | loss: 1.03140 - acc: 0.6547 -- iter: 01728/10000
[A[ATraining Step: 342  | total loss: [1m[32m1.01622[0m[0m | time: 18.300s
[2K| Adam | epoch: 003 | loss: 1.01622 - acc: 0.6595 -- iter: 01792/10000
[A[ATraining Step: 343  | total loss: [1m[32m1.01370[0m[0m | time: 18.991s
[2K| Adam | epoch: 003 | loss: 1.01370 - acc: 0.6514 -- iter: 01856/10000
[A[ATraining Step: 344  | total loss: [1m[32m1.00409[0m[0m | time: 19.677s
[2K| Adam | epoch: 003 | loss: 1.00409 - acc: 0.6519 -- iter: 01920/10000
[A[ATraining Step: 345  | total loss: [1m[32m0.98796[0m[0m | time: 20.363s
[2K| Adam | epoch: 003 | loss: 0.98796 - acc: 0.6585 -- iter: 01984/10000
[A[ATraining Step: 346  | total loss: [1m[32m1.00699[0m[0m | time: 21.050s
[2K| Adam | epoch: 003 | loss: 1.00699 - acc: 0.6521 -- iter: 02048/10000
[A[ATraining Step: 347  | total loss: [1m[32m1.01632[0m[0m | time: 21.740s
[2K| Adam | epoch: 003 | loss: 1.01632 - acc: 0.6478 -- iter: 02112/10000
[A[ATraining Step: 348  | total loss: [1m[32m1.01069[0m[0m | time: 22.449s
[2K| Adam | epoch: 003 | loss: 1.01069 - acc: 0.6455 -- iter: 02176/10000
[A[ATraining Step: 349  | total loss: [1m[32m1.01654[0m[0m | time: 23.138s
[2K| Adam | epoch: 003 | loss: 1.01654 - acc: 0.6403 -- iter: 02240/10000
[A[ATraining Step: 350  | total loss: [1m[32m1.00075[0m[0m | time: 23.829s
[2K| Adam | epoch: 003 | loss: 1.00075 - acc: 0.6466 -- iter: 02304/10000
[A[ATraining Step: 351  | total loss: [1m[32m1.01177[0m[0m | time: 24.521s
[2K| Adam | epoch: 003 | loss: 1.01177 - acc: 0.6445 -- iter: 02368/10000
[A[ATraining Step: 352  | total loss: [1m[32m1.00113[0m[0m | time: 25.209s
[2K| Adam | epoch: 003 | loss: 1.00113 - acc: 0.6472 -- iter: 02432/10000
[A[ATraining Step: 353  | total loss: [1m[32m1.01066[0m[0m | time: 25.900s
[2K| Adam | epoch: 003 | loss: 1.01066 - acc: 0.6497 -- iter: 02496/10000
[A[ATraining Step: 354  | total loss: [1m[32m0.98980[0m[0m | time: 26.586s
[2K| Adam | epoch: 003 | loss: 0.98980 - acc: 0.6534 -- iter: 02560/10000
[A[ATraining Step: 355  | total loss: [1m[32m0.99852[0m[0m | time: 27.277s
[2K| Adam | epoch: 003 | loss: 0.99852 - acc: 0.6522 -- iter: 02624/10000
[A[ATraining Step: 356  | total loss: [1m[32m0.99670[0m[0m | time: 27.991s
[2K| Adam | epoch: 003 | loss: 0.99670 - acc: 0.6432 -- iter: 02688/10000
[A[ATraining Step: 357  | total loss: [1m[32m1.01337[0m[0m | time: 28.707s
[2K| Adam | epoch: 003 | loss: 1.01337 - acc: 0.6367 -- iter: 02752/10000
[A[ATraining Step: 358  | total loss: [1m[32m1.00062[0m[0m | time: 29.425s
[2K| Adam | epoch: 003 | loss: 1.00062 - acc: 0.6418 -- iter: 02816/10000
[A[ATraining Step: 359  | total loss: [1m[32m0.98910[0m[0m | time: 30.150s
[2K| Adam | epoch: 003 | loss: 0.98910 - acc: 0.6479 -- iter: 02880/10000
[A[ATraining Step: 360  | total loss: [1m[32m0.99901[0m[0m | time: 30.863s
[2K| Adam | epoch: 003 | loss: 0.99901 - acc: 0.6503 -- iter: 02944/10000
[A[ATraining Step: 361  | total loss: [1m[32m1.00064[0m[0m | time: 31.574s
[2K| Adam | epoch: 003 | loss: 1.00064 - acc: 0.6478 -- iter: 03008/10000
[A[ATraining Step: 362  | total loss: [1m[32m1.01231[0m[0m | time: 32.294s
[2K| Adam | epoch: 003 | loss: 1.01231 - acc: 0.6471 -- iter: 03072/10000
[A[ATraining Step: 363  | total loss: [1m[32m0.98299[0m[0m | time: 33.012s
[2K| Adam | epoch: 003 | loss: 0.98299 - acc: 0.6574 -- iter: 03136/10000
[A[ATraining Step: 364  | total loss: [1m[32m0.97913[0m[0m | time: 33.694s
[2K| Adam | epoch: 003 | loss: 0.97913 - acc: 0.6572 -- iter: 03200/10000
[A[ATraining Step: 365  | total loss: [1m[32m0.99459[0m[0m | time: 34.409s
[2K| Adam | epoch: 003 | loss: 0.99459 - acc: 0.6556 -- iter: 03264/10000
[A[ATraining Step: 366  | total loss: [1m[32m0.99515[0m[0m | time: 35.103s
[2K| Adam | epoch: 003 | loss: 0.99515 - acc: 0.6603 -- iter: 03328/10000
[A[ATraining Step: 367  | total loss: [1m[32m1.00891[0m[0m | time: 35.791s
[2K| Adam | epoch: 003 | loss: 1.00891 - acc: 0.6521 -- iter: 03392/10000
[A[ATraining Step: 368  | total loss: [1m[32m1.01213[0m[0m | time: 36.481s
[2K| Adam | epoch: 003 | loss: 1.01213 - acc: 0.6510 -- iter: 03456/10000
[A[ATraining Step: 369  | total loss: [1m[32m1.00401[0m[0m | time: 37.177s
[2K| Adam | epoch: 003 | loss: 1.00401 - acc: 0.6515 -- iter: 03520/10000
[A[ATraining Step: 370  | total loss: [1m[32m1.01316[0m[0m | time: 37.876s
[2K| Adam | epoch: 003 | loss: 1.01316 - acc: 0.6488 -- iter: 03584/10000
[A[ATraining Step: 371  | total loss: [1m[32m1.02426[0m[0m | time: 38.571s
[2K| Adam | epoch: 003 | loss: 1.02426 - acc: 0.6418 -- iter: 03648/10000
[A[ATraining Step: 372  | total loss: [1m[32m1.00547[0m[0m | time: 39.308s
[2K| Adam | epoch: 003 | loss: 1.00547 - acc: 0.6526 -- iter: 03712/10000
[A[ATraining Step: 373  | total loss: [1m[32m0.99582[0m[0m | time: 40.029s
[2K| Adam | epoch: 003 | loss: 0.99582 - acc: 0.6483 -- iter: 03776/10000
[A[ATraining Step: 374  | total loss: [1m[32m0.96162[0m[0m | time: 40.751s
[2K| Adam | epoch: 003 | loss: 0.96162 - acc: 0.6616 -- iter: 03840/10000
[A[ATraining Step: 375  | total loss: [1m[32m0.97466[0m[0m | time: 41.469s
[2K| Adam | epoch: 003 | loss: 0.97466 - acc: 0.6517 -- iter: 03904/10000
[A[ATraining Step: 376  | total loss: [1m[32m0.97751[0m[0m | time: 42.202s
[2K| Adam | epoch: 003 | loss: 0.97751 - acc: 0.6552 -- iter: 03968/10000
[A[ATraining Step: 377  | total loss: [1m[32m0.98789[0m[0m | time: 42.916s
[2K| Adam | epoch: 003 | loss: 0.98789 - acc: 0.6569 -- iter: 04032/10000
[A[ATraining Step: 378  | total loss: [1m[32m0.97355[0m[0m | time: 43.633s
[2K| Adam | epoch: 003 | loss: 0.97355 - acc: 0.6615 -- iter: 04096/10000
[A[ATraining Step: 379  | total loss: [1m[32m0.97014[0m[0m | time: 44.339s
[2K| Adam | epoch: 003 | loss: 0.97014 - acc: 0.6641 -- iter: 04160/10000
[A[ATraining Step: 380  | total loss: [1m[32m0.97934[0m[0m | time: 45.050s
[2K| Adam | epoch: 003 | loss: 0.97934 - acc: 0.6540 -- iter: 04224/10000
[A[ATraining Step: 381  | total loss: [1m[32m0.98037[0m[0m | time: 45.763s
[2K| Adam | epoch: 003 | loss: 0.98037 - acc: 0.6542 -- iter: 04288/10000
[A[ATraining Step: 382  | total loss: [1m[32m0.99975[0m[0m | time: 46.481s
[2K| Adam | epoch: 003 | loss: 0.99975 - acc: 0.6497 -- iter: 04352/10000
[A[ATraining Step: 383  | total loss: [1m[32m1.00694[0m[0m | time: 47.195s
[2K| Adam | epoch: 003 | loss: 1.00694 - acc: 0.6535 -- iter: 04416/10000
[A[ATraining Step: 384  | total loss: [1m[32m1.01013[0m[0m | time: 47.906s
[2K| Adam | epoch: 003 | loss: 1.01013 - acc: 0.6413 -- iter: 04480/10000
[A[ATraining Step: 385  | total loss: [1m[32m1.02101[0m[0m | time: 48.620s
[2K| Adam | epoch: 003 | loss: 1.02101 - acc: 0.6428 -- iter: 04544/10000
[A[ATraining Step: 386  | total loss: [1m[32m1.02857[0m[0m | time: 49.331s
[2K| Adam | epoch: 003 | loss: 1.02857 - acc: 0.6394 -- iter: 04608/10000
[A[ATraining Step: 387  | total loss: [1m[32m1.01857[0m[0m | time: 50.042s
[2K| Adam | epoch: 003 | loss: 1.01857 - acc: 0.6458 -- iter: 04672/10000
[A[ATraining Step: 388  | total loss: [1m[32m1.00549[0m[0m | time: 50.756s
[2K| Adam | epoch: 003 | loss: 1.00549 - acc: 0.6500 -- iter: 04736/10000
[A[ATraining Step: 389  | total loss: [1m[32m1.00848[0m[0m | time: 51.474s
[2K| Adam | epoch: 003 | loss: 1.00848 - acc: 0.6475 -- iter: 04800/10000
[A[ATraining Step: 390  | total loss: [1m[32m1.01637[0m[0m | time: 52.205s
[2K| Adam | epoch: 003 | loss: 1.01637 - acc: 0.6437 -- iter: 04864/10000
[A[ATraining Step: 391  | total loss: [1m[32m1.03454[0m[0m | time: 52.919s
[2K| Adam | epoch: 003 | loss: 1.03454 - acc: 0.6402 -- iter: 04928/10000
[A[ATraining Step: 392  | total loss: [1m[32m1.03527[0m[0m | time: 53.628s
[2K| Adam | epoch: 003 | loss: 1.03527 - acc: 0.6387 -- iter: 04992/10000
[A[ATraining Step: 393  | total loss: [1m[32m1.01134[0m[0m | time: 54.339s
[2K| Adam | epoch: 003 | loss: 1.01134 - acc: 0.6420 -- iter: 05056/10000
[A[ATraining Step: 394  | total loss: [1m[32m1.01225[0m[0m | time: 55.054s
[2K| Adam | epoch: 003 | loss: 1.01225 - acc: 0.6434 -- iter: 05120/10000
[A[ATraining Step: 395  | total loss: [1m[32m1.03107[0m[0m | time: 55.766s
[2K| Adam | epoch: 003 | loss: 1.03107 - acc: 0.6354 -- iter: 05184/10000
[A[ATraining Step: 396  | total loss: [1m[32m1.04270[0m[0m | time: 56.484s
[2K| Adam | epoch: 003 | loss: 1.04270 - acc: 0.6421 -- iter: 05248/10000
[A[ATraining Step: 397  | total loss: [1m[32m1.03514[0m[0m | time: 57.212s
[2K| Adam | epoch: 003 | loss: 1.03514 - acc: 0.6451 -- iter: 05312/10000
[A[ATraining Step: 398  | total loss: [1m[32m1.00623[0m[0m | time: 57.930s
[2K| Adam | epoch: 003 | loss: 1.00623 - acc: 0.6478 -- iter: 05376/10000
[A[ATraining Step: 399  | total loss: [1m[32m0.99062[0m[0m | time: 58.645s
[2K| Adam | epoch: 003 | loss: 0.99062 - acc: 0.6486 -- iter: 05440/10000
[A[ATraining Step: 400  | total loss: [1m[32m1.00763[0m[0m | time: 61.197s
[2K| Adam | epoch: 003 | loss: 1.00763 - acc: 0.6400 | val_loss: 1.45557 - val_acc: 0.5171 -- iter: 05504/10000
--
Training Step: 401  | total loss: [1m[32m0.99425[0m[0m | time: 61.906s
[2K| Adam | epoch: 003 | loss: 0.99425 - acc: 0.6416 -- iter: 05568/10000
[A[ATraining Step: 402  | total loss: [1m[32m1.00067[0m[0m | time: 62.674s
[2K| Adam | epoch: 003 | loss: 1.00067 - acc: 0.6400 -- iter: 05632/10000
[A[ATraining Step: 403  | total loss: [1m[32m0.99851[0m[0m | time: 63.418s
[2K| Adam | epoch: 003 | loss: 0.99851 - acc: 0.6510 -- iter: 05696/10000
[A[ATraining Step: 404  | total loss: [1m[32m0.98924[0m[0m | time: 64.162s
[2K| Adam | epoch: 003 | loss: 0.98924 - acc: 0.6562 -- iter: 05760/10000
[A[ATraining Step: 405  | total loss: [1m[32m1.02634[0m[0m | time: 64.881s
[2K| Adam | epoch: 003 | loss: 1.02634 - acc: 0.6468 -- iter: 05824/10000
[A[ATraining Step: 406  | total loss: [1m[32m1.03574[0m[0m | time: 65.595s
[2K| Adam | epoch: 003 | loss: 1.03574 - acc: 0.6431 -- iter: 05888/10000
[A[ATraining Step: 407  | total loss: [1m[32m1.01928[0m[0m | time: 66.301s
[2K| Adam | epoch: 003 | loss: 1.01928 - acc: 0.6491 -- iter: 05952/10000
[A[ATraining Step: 408  | total loss: [1m[32m0.99475[0m[0m | time: 67.013s
[2K| Adam | epoch: 003 | loss: 0.99475 - acc: 0.6639 -- iter: 06016/10000
[A[ATraining Step: 409  | total loss: [1m[32m0.99830[0m[0m | time: 67.729s
[2K| Adam | epoch: 003 | loss: 0.99830 - acc: 0.6678 -- iter: 06080/10000
[A[ATraining Step: 410  | total loss: [1m[32m0.97622[0m[0m | time: 68.442s
[2K| Adam | epoch: 003 | loss: 0.97622 - acc: 0.6729 -- iter: 06144/10000
[A[ATraining Step: 411  | total loss: [1m[32m0.96464[0m[0m | time: 69.156s
[2K| Adam | epoch: 003 | loss: 0.96464 - acc: 0.6712 -- iter: 06208/10000
[A[ATraining Step: 412  | total loss: [1m[32m0.98096[0m[0m | time: 69.876s
[2K| Adam | epoch: 003 | loss: 0.98096 - acc: 0.6666 -- iter: 06272/10000
[A[ATraining Step: 413  | total loss: [1m[32m0.97109[0m[0m | time: 70.582s
[2K| Adam | epoch: 003 | loss: 0.97109 - acc: 0.6687 -- iter: 06336/10000
[A[ATraining Step: 414  | total loss: [1m[32m0.97628[0m[0m | time: 71.297s
[2K| Adam | epoch: 003 | loss: 0.97628 - acc: 0.6612 -- iter: 06400/10000
[A[ATraining Step: 415  | total loss: [1m[32m0.97012[0m[0m | time: 72.063s
[2K| Adam | epoch: 003 | loss: 0.97012 - acc: 0.6638 -- iter: 06464/10000
[A[ATraining Step: 416  | total loss: [1m[32m0.98686[0m[0m | time: 72.819s
[2K| Adam | epoch: 003 | loss: 0.98686 - acc: 0.6568 -- iter: 06528/10000
[A[ATraining Step: 417  | total loss: [1m[32m0.98058[0m[0m | time: 73.621s
[2K| Adam | epoch: 003 | loss: 0.98058 - acc: 0.6599 -- iter: 06592/10000
[A[ATraining Step: 418  | total loss: [1m[32m0.98235[0m[0m | time: 74.399s
[2K| Adam | epoch: 003 | loss: 0.98235 - acc: 0.6626 -- iter: 06656/10000
[A[ATraining Step: 419  | total loss: [1m[32m0.97616[0m[0m | time: 75.177s
[2K| Adam | epoch: 003 | loss: 0.97616 - acc: 0.6620 -- iter: 06720/10000
[A[ATraining Step: 420  | total loss: [1m[32m0.97206[0m[0m | time: 75.947s
[2K| Adam | epoch: 003 | loss: 0.97206 - acc: 0.6599 -- iter: 06784/10000
[A[ATraining Step: 421  | total loss: [1m[32m0.99272[0m[0m | time: 76.728s
[2K| Adam | epoch: 003 | loss: 0.99272 - acc: 0.6564 -- iter: 06848/10000
[A[ATraining Step: 422  | total loss: [1m[32m0.97571[0m[0m | time: 77.499s
[2K| Adam | epoch: 003 | loss: 0.97571 - acc: 0.6642 -- iter: 06912/10000
[A[ATraining Step: 423  | total loss: [1m[32m0.98014[0m[0m | time: 78.272s
[2K| Adam | epoch: 003 | loss: 0.98014 - acc: 0.6618 -- iter: 06976/10000
[A[ATraining Step: 424  | total loss: [1m[32m0.94944[0m[0m | time: 79.047s
[2K| Adam | epoch: 003 | loss: 0.94944 - acc: 0.6753 -- iter: 07040/10000
[A[ATraining Step: 425  | total loss: [1m[32m0.93519[0m[0m | time: 79.820s
[2K| Adam | epoch: 003 | loss: 0.93519 - acc: 0.6781 -- iter: 07104/10000
[A[ATraining Step: 426  | total loss: [1m[32m0.94376[0m[0m | time: 80.583s
[2K| Adam | epoch: 003 | loss: 0.94376 - acc: 0.6712 -- iter: 07168/10000
[A[ATraining Step: 427  | total loss: [1m[32m0.91928[0m[0m | time: 81.353s
[2K| Adam | epoch: 003 | loss: 0.91928 - acc: 0.6822 -- iter: 07232/10000
[A[ATraining Step: 428  | total loss: [1m[32m0.92158[0m[0m | time: 82.092s
[2K| Adam | epoch: 003 | loss: 0.92158 - acc: 0.6812 -- iter: 07296/10000
[A[ATraining Step: 429  | total loss: [1m[32m0.91687[0m[0m | time: 82.886s
[2K| Adam | epoch: 003 | loss: 0.91687 - acc: 0.6803 -- iter: 07360/10000
[A[ATraining Step: 430  | total loss: [1m[32m0.96073[0m[0m | time: 83.700s
[2K| Adam | epoch: 003 | loss: 0.96073 - acc: 0.6701 -- iter: 07424/10000
[A[ATraining Step: 431  | total loss: [1m[32m0.93911[0m[0m | time: 84.546s
[2K| Adam | epoch: 003 | loss: 0.93911 - acc: 0.6734 -- iter: 07488/10000
[A[ATraining Step: 432  | total loss: [1m[32m0.93305[0m[0m | time: 85.398s
[2K| Adam | epoch: 003 | loss: 0.93305 - acc: 0.6763 -- iter: 07552/10000
[A[ATraining Step: 433  | total loss: [1m[32m0.94348[0m[0m | time: 86.271s
[2K| Adam | epoch: 003 | loss: 0.94348 - acc: 0.6728 -- iter: 07616/10000
[A[ATraining Step: 434  | total loss: [1m[32m0.92763[0m[0m | time: 87.146s
[2K| Adam | epoch: 003 | loss: 0.92763 - acc: 0.6821 -- iter: 07680/10000
[A[ATraining Step: 435  | total loss: [1m[32m0.90240[0m[0m | time: 88.019s
[2K| Adam | epoch: 003 | loss: 0.90240 - acc: 0.6888 -- iter: 07744/10000
[A[ATraining Step: 436  | total loss: [1m[32m0.91444[0m[0m | time: 88.859s
[2K| Adam | epoch: 003 | loss: 0.91444 - acc: 0.6950 -- iter: 07808/10000
[A[ATraining Step: 437  | total loss: [1m[32m0.91240[0m[0m | time: 89.666s
[2K| Adam | epoch: 003 | loss: 0.91240 - acc: 0.6911 -- iter: 07872/10000
[A[ATraining Step: 438  | total loss: [1m[32m0.91113[0m[0m | time: 90.453s
[2K| Adam | epoch: 003 | loss: 0.91113 - acc: 0.6970 -- iter: 07936/10000
[A[ATraining Step: 439  | total loss: [1m[32m0.91727[0m[0m | time: 91.231s
[2K| Adam | epoch: 003 | loss: 0.91727 - acc: 0.6992 -- iter: 08000/10000
[A[ATraining Step: 440  | total loss: [1m[32m0.90999[0m[0m | time: 92.001s
[2K| Adam | epoch: 003 | loss: 0.90999 - acc: 0.7074 -- iter: 08064/10000
[A[ATraining Step: 441  | total loss: [1m[32m0.91138[0m[0m | time: 92.804s
[2K| Adam | epoch: 003 | loss: 0.91138 - acc: 0.7132 -- iter: 08128/10000
[A[ATraining Step: 442  | total loss: [1m[32m1.47487[0m[0m | time: 93.555s
[2K| Adam | epoch: 003 | loss: 1.47487 - acc: 0.6466 -- iter: 08192/10000
[A[ATraining Step: 443  | total loss: [1m[32m1.42315[0m[0m | time: 94.295s
[2K| Adam | epoch: 003 | loss: 1.42315 - acc: 0.6475 -- iter: 08256/10000
[A[ATraining Step: 444  | total loss: [1m[32m1.42778[0m[0m | time: 95.033s
[2K| Adam | epoch: 003 | loss: 1.42778 - acc: 0.6343 -- iter: 08320/10000
[A[ATraining Step: 445  | total loss: [1m[32m1.38629[0m[0m | time: 95.771s
[2K| Adam | epoch: 003 | loss: 1.38629 - acc: 0.6303 -- iter: 08384/10000
[A[ATraining Step: 446  | total loss: [1m[32m1.33848[0m[0m | time: 96.513s
[2K| Adam | epoch: 003 | loss: 1.33848 - acc: 0.6329 -- iter: 08448/10000
[A[ATraining Step: 447  | total loss: [1m[32m1.29524[0m[0m | time: 97.255s
[2K| Adam | epoch: 003 | loss: 1.29524 - acc: 0.6290 -- iter: 08512/10000
[A[ATraining Step: 448  | total loss: [1m[32m1.27923[0m[0m | time: 98.000s
[2K| Adam | epoch: 003 | loss: 1.27923 - acc: 0.6208 -- iter: 08576/10000
[A[ATraining Step: 449  | total loss: [1m[32m1.23859[0m[0m | time: 98.738s
[2K| Adam | epoch: 003 | loss: 1.23859 - acc: 0.6227 -- iter: 08640/10000
[A[ATraining Step: 450  | total loss: [1m[32m1.19790[0m[0m | time: 99.476s
[2K| Adam | epoch: 003 | loss: 1.19790 - acc: 0.6308 -- iter: 08704/10000
[A[ATraining Step: 451  | total loss: [1m[32m1.15903[0m[0m | time: 100.222s
[2K| Adam | epoch: 003 | loss: 1.15903 - acc: 0.6396 -- iter: 08768/10000
[A[ATraining Step: 452  | total loss: [1m[32m1.13458[0m[0m | time: 100.966s
[2K| Adam | epoch: 003 | loss: 1.13458 - acc: 0.6428 -- iter: 08832/10000
[A[ATraining Step: 453  | total loss: [1m[32m1.12316[0m[0m | time: 101.711s
[2K| Adam | epoch: 003 | loss: 1.12316 - acc: 0.6442 -- iter: 08896/10000
[A[ATraining Step: 454  | total loss: [1m[32m1.08794[0m[0m | time: 102.480s
[2K| Adam | epoch: 003 | loss: 1.08794 - acc: 0.6563 -- iter: 08960/10000
[A[ATraining Step: 455  | total loss: [1m[32m1.05026[0m[0m | time: 103.220s
[2K| Adam | epoch: 003 | loss: 1.05026 - acc: 0.6704 -- iter: 09024/10000
[A[ATraining Step: 456  | total loss: [1m[32m1.03749[0m[0m | time: 103.944s
[2K| Adam | epoch: 003 | loss: 1.03749 - acc: 0.6721 -- iter: 09088/10000
[A[ATraining Step: 457  | total loss: [1m[32m1.02005[0m[0m | time: 104.658s
[2K| Adam | epoch: 003 | loss: 1.02005 - acc: 0.6689 -- iter: 09152/10000
[A[ATraining Step: 458  | total loss: [1m[32m1.00441[0m[0m | time: 105.372s
[2K| Adam | epoch: 003 | loss: 1.00441 - acc: 0.6645 -- iter: 09216/10000
[A[ATraining Step: 459  | total loss: [1m[32m0.99607[0m[0m | time: 106.088s
[2K| Adam | epoch: 003 | loss: 0.99607 - acc: 0.6637 -- iter: 09280/10000
[A[ATraining Step: 460  | total loss: [1m[32m0.98253[0m[0m | time: 106.829s
[2K| Adam | epoch: 003 | loss: 0.98253 - acc: 0.6723 -- iter: 09344/10000
[A[ATraining Step: 461  | total loss: [1m[32m0.98548[0m[0m | time: 107.571s
[2K| Adam | epoch: 003 | loss: 0.98548 - acc: 0.6723 -- iter: 09408/10000
[A[ATraining Step: 462  | total loss: [1m[32m0.96992[0m[0m | time: 108.308s
[2K| Adam | epoch: 003 | loss: 0.96992 - acc: 0.6832 -- iter: 09472/10000
[A[ATraining Step: 463  | total loss: [1m[32m0.96799[0m[0m | time: 109.048s
[2K| Adam | epoch: 003 | loss: 0.96799 - acc: 0.6883 -- iter: 09536/10000
[A[ATraining Step: 464  | total loss: [1m[32m0.98728[0m[0m | time: 109.786s
[2K| Adam | epoch: 003 | loss: 0.98728 - acc: 0.6851 -- iter: 09600/10000
[A[ATraining Step: 465  | total loss: [1m[32m0.99113[0m[0m | time: 110.530s
[2K| Adam | epoch: 003 | loss: 0.99113 - acc: 0.6807 -- iter: 09664/10000
[A[ATraining Step: 466  | total loss: [1m[32m0.99359[0m[0m | time: 111.271s
[2K| Adam | epoch: 003 | loss: 0.99359 - acc: 0.6829 -- iter: 09728/10000
[A[ATraining Step: 467  | total loss: [1m[32m0.97417[0m[0m | time: 112.024s
[2K| Adam | epoch: 003 | loss: 0.97417 - acc: 0.6959 -- iter: 09792/10000
[A[ATraining Step: 468  | total loss: [1m[32m0.94429[0m[0m | time: 112.787s
[2K| Adam | epoch: 003 | loss: 0.94429 - acc: 0.6997 -- iter: 09856/10000
[A[ATraining Step: 469  | total loss: [1m[32m0.92225[0m[0m | time: 113.528s
[2K| Adam | epoch: 003 | loss: 0.92225 - acc: 0.7079 -- iter: 09920/10000
[A[ATraining Step: 470  | total loss: [1m[32m0.93868[0m[0m | time: 114.270s
[2K| Adam | epoch: 003 | loss: 0.93868 - acc: 0.6933 -- iter: 09984/10000
[A[ATraining Step: 471  | total loss: [1m[32m0.92126[0m[0m | time: 116.893s
[2K| Adam | epoch: 003 | loss: 0.92126 - acc: 0.6912 | val_loss: 1.40698 - val_acc: 0.4814 -- iter: 10000/10000
--
Training Step: 472  | total loss: [1m[32m0.93269[0m[0m | time: 0.707s
[2K| Adam | epoch: 004 | loss: 0.93269 - acc: 0.6830 -- iter: 00064/10000
[A[ATraining Step: 473  | total loss: [1m[32m0.91223[0m[0m | time: 1.055s
[2K| Adam | epoch: 004 | loss: 0.91223 - acc: 0.6881 -- iter: 00128/10000
[A[ATraining Step: 474  | total loss: [1m[32m0.88869[0m[0m | time: 1.409s
[2K| Adam | epoch: 004 | loss: 0.88869 - acc: 0.6943 -- iter: 00192/10000
[A[ATraining Step: 475  | total loss: [1m[32m0.87256[0m[0m | time: 2.152s
[2K| Adam | epoch: 004 | loss: 0.87256 - acc: 0.6874 -- iter: 00256/10000
[A[ATraining Step: 476  | total loss: [1m[32m0.89250[0m[0m | time: 2.890s
[2K| Adam | epoch: 004 | loss: 0.89250 - acc: 0.6733 -- iter: 00320/10000
[A[ATraining Step: 477  | total loss: [1m[32m0.90536[0m[0m | time: 3.637s
[2K| Adam | epoch: 004 | loss: 0.90536 - acc: 0.6732 -- iter: 00384/10000
[A[ATraining Step: 478  | total loss: [1m[32m0.91735[0m[0m | time: 4.372s
[2K| Adam | epoch: 004 | loss: 0.91735 - acc: 0.6652 -- iter: 00448/10000
[A[ATraining Step: 479  | total loss: [1m[32m0.89984[0m[0m | time: 5.128s
[2K| Adam | epoch: 004 | loss: 0.89984 - acc: 0.6722 -- iter: 00512/10000
[A[ATraining Step: 480  | total loss: [1m[32m0.89044[0m[0m | time: 5.886s
[2K| Adam | epoch: 004 | loss: 0.89044 - acc: 0.6753 -- iter: 00576/10000
[A[ATraining Step: 481  | total loss: [1m[32m0.90708[0m[0m | time: 6.598s
[2K| Adam | epoch: 004 | loss: 0.90708 - acc: 0.6749 -- iter: 00640/10000
[A[ATraining Step: 482  | total loss: [1m[32m0.90491[0m[0m | time: 7.343s
[2K| Adam | epoch: 004 | loss: 0.90491 - acc: 0.6715 -- iter: 00704/10000
[A[ATraining Step: 483  | total loss: [1m[32m0.88766[0m[0m | time: 8.087s
[2K| Adam | epoch: 004 | loss: 0.88766 - acc: 0.6809 -- iter: 00768/10000
[A[ATraining Step: 484  | total loss: [1m[32m0.88152[0m[0m | time: 8.829s
[2K| Adam | epoch: 004 | loss: 0.88152 - acc: 0.6847 -- iter: 00832/10000
[A[ATraining Step: 485  | total loss: [1m[32m0.87565[0m[0m | time: 9.580s
[2K| Adam | epoch: 004 | loss: 0.87565 - acc: 0.6850 -- iter: 00896/10000
[A[ATraining Step: 486  | total loss: [1m[32m0.89400[0m[0m | time: 10.372s
[2K| Adam | epoch: 004 | loss: 0.89400 - acc: 0.6774 -- iter: 00960/10000
[A[ATraining Step: 487  | total loss: [1m[32m0.88885[0m[0m | time: 11.149s
[2K| Adam | epoch: 004 | loss: 0.88885 - acc: 0.6831 -- iter: 01024/10000
[A[ATraining Step: 488  | total loss: [1m[32m0.90195[0m[0m | time: 11.931s
[2K| Adam | epoch: 004 | loss: 0.90195 - acc: 0.6789 -- iter: 01088/10000
[A[ATraining Step: 489  | total loss: [1m[32m0.90484[0m[0m | time: 12.698s
[2K| Adam | epoch: 004 | loss: 0.90484 - acc: 0.6860 -- iter: 01152/10000
[A[ATraining Step: 490  | total loss: [1m[32m0.91091[0m[0m | time: 13.494s
[2K| Adam | epoch: 004 | loss: 0.91091 - acc: 0.6908 -- iter: 01216/10000
[A[ATraining Step: 491  | total loss: [1m[32m0.92261[0m[0m | time: 14.274s
[2K| Adam | epoch: 004 | loss: 0.92261 - acc: 0.6842 -- iter: 01280/10000
[A[ATraining Step: 492  | total loss: [1m[32m0.92238[0m[0m | time: 15.079s
[2K| Adam | epoch: 004 | loss: 0.92238 - acc: 0.6814 -- iter: 01344/10000
[A[ATraining Step: 493  | total loss: [1m[32m0.95777[0m[0m | time: 15.882s
[2K| Adam | epoch: 004 | loss: 0.95777 - acc: 0.6680 -- iter: 01408/10000
[A[ATraining Step: 494  | total loss: [1m[32m0.94450[0m[0m | time: 16.655s
[2K| Adam | epoch: 004 | loss: 0.94450 - acc: 0.6668 -- iter: 01472/10000
[A[ATraining Step: 495  | total loss: [1m[32m0.91065[0m[0m | time: 17.466s
[2K| Adam | epoch: 004 | loss: 0.91065 - acc: 0.6782 -- iter: 01536/10000
[A[ATraining Step: 496  | total loss: [1m[32m0.90146[0m[0m | time: 18.226s
[2K| Adam | epoch: 004 | loss: 0.90146 - acc: 0.6839 -- iter: 01600/10000
[A[ATraining Step: 497  | total loss: [1m[32m0.90360[0m[0m | time: 18.993s
[2K| Adam | epoch: 004 | loss: 0.90360 - acc: 0.6842 -- iter: 01664/10000
[A[ATraining Step: 498  | total loss: [1m[32m0.89059[0m[0m | time: 19.776s
[2K| Adam | epoch: 004 | loss: 0.89059 - acc: 0.6908 -- iter: 01728/10000
[A[ATraining Step: 499  | total loss: [1m[32m0.90902[0m[0m | time: 20.588s
[2K| Adam | epoch: 004 | loss: 0.90902 - acc: 0.6905 -- iter: 01792/10000
[A[ATraining Step: 500  | total loss: [1m[32m0.87889[0m[0m | time: 23.842s
[2K| Adam | epoch: 004 | loss: 0.87889 - acc: 0.7011 | val_loss: 1.39008 - val_acc: 0.5043 -- iter: 01856/10000
--
Training Step: 501  | total loss: [1m[32m0.90041[0m[0m | time: 24.967s
[2K| Adam | epoch: 004 | loss: 0.90041 - acc: 0.6966 -- iter: 01920/10000
[A[ATraining Step: 502  | total loss: [1m[32m0.90183[0m[0m | time: 26.281s
[2K| Adam | epoch: 004 | loss: 0.90183 - acc: 0.7035 -- iter: 01984/10000
[A[ATraining Step: 503  | total loss: [1m[32m0.89814[0m[0m | time: 27.280s
[2K| Adam | epoch: 004 | loss: 0.89814 - acc: 0.7050 -- iter: 02048/10000
[A[ATraining Step: 504  | total loss: [1m[32m0.89391[0m[0m | time: 28.241s
[2K| Adam | epoch: 004 | loss: 0.89391 - acc: 0.6970 -- iter: 02112/10000
[A[ATraining Step: 505  | total loss: [1m[32m0.87163[0m[0m | time: 29.174s
[2K| Adam | epoch: 004 | loss: 0.87163 - acc: 0.7070 -- iter: 02176/10000
[A[ATraining Step: 506  | total loss: [1m[32m0.86249[0m[0m | time: 30.079s
[2K| Adam | epoch: 004 | loss: 0.86249 - acc: 0.7066 -- iter: 02240/10000
[A[ATraining Step: 507  | total loss: [1m[32m0.86758[0m[0m | time: 30.988s
[2K| Adam | epoch: 004 | loss: 0.86758 - acc: 0.6985 -- iter: 02304/10000
[A[ATraining Step: 508  | total loss: [1m[32m0.85569[0m[0m | time: 31.842s
[2K| Adam | epoch: 004 | loss: 0.85569 - acc: 0.7036 -- iter: 02368/10000
[A[ATraining Step: 509  | total loss: [1m[32m0.86612[0m[0m | time: 32.682s
[2K| Adam | epoch: 004 | loss: 0.86612 - acc: 0.6989 -- iter: 02432/10000
[A[ATraining Step: 510  | total loss: [1m[32m0.88529[0m[0m | time: 33.497s
[2K| Adam | epoch: 004 | loss: 0.88529 - acc: 0.6884 -- iter: 02496/10000
[A[ATraining Step: 511  | total loss: [1m[32m0.90085[0m[0m | time: 34.316s
[2K| Adam | epoch: 004 | loss: 0.90085 - acc: 0.6820 -- iter: 02560/10000
[A[ATraining Step: 512  | total loss: [1m[32m0.89086[0m[0m | time: 35.122s
[2K| Adam | epoch: 004 | loss: 0.89086 - acc: 0.6826 -- iter: 02624/10000
[A[ATraining Step: 513  | total loss: [1m[32m0.88354[0m[0m | time: 35.990s
[2K| Adam | epoch: 004 | loss: 0.88354 - acc: 0.6784 -- iter: 02688/10000
[A[ATraining Step: 514  | total loss: [1m[32m0.87266[0m[0m | time: 36.884s
[2K| Adam | epoch: 004 | loss: 0.87266 - acc: 0.6840 -- iter: 02752/10000
[A[ATraining Step: 515  | total loss: [1m[32m0.86008[0m[0m | time: 37.682s
[2K| Adam | epoch: 004 | loss: 0.86008 - acc: 0.6828 -- iter: 02816/10000
[A[ATraining Step: 516  | total loss: [1m[32m0.86539[0m[0m | time: 38.457s
[2K| Adam | epoch: 004 | loss: 0.86539 - acc: 0.6786 -- iter: 02880/10000
[A[ATraining Step: 517  | total loss: [1m[32m0.89488[0m[0m | time: 39.305s
[2K| Adam | epoch: 004 | loss: 0.89488 - acc: 0.6732 -- iter: 02944/10000
[A[ATraining Step: 518  | total loss: [1m[32m0.87712[0m[0m | time: 40.114s
[2K| Adam | epoch: 004 | loss: 0.87712 - acc: 0.6856 -- iter: 03008/10000
[A[ATraining Step: 519  | total loss: [1m[32m0.90112[0m[0m | time: 41.012s
[2K| Adam | epoch: 004 | loss: 0.90112 - acc: 0.6717 -- iter: 03072/10000
[A[ATraining Step: 520  | total loss: [1m[32m0.89160[0m[0m | time: 41.956s
[2K| Adam | epoch: 004 | loss: 0.89160 - acc: 0.6764 -- iter: 03136/10000
[A[ATraining Step: 521  | total loss: [1m[32m0.88797[0m[0m | time: 42.897s
[2K| Adam | epoch: 004 | loss: 0.88797 - acc: 0.6791 -- iter: 03200/10000
[A[ATraining Step: 522  | total loss: [1m[32m0.88164[0m[0m | time: 43.857s
[2K| Adam | epoch: 004 | loss: 0.88164 - acc: 0.6815 -- iter: 03264/10000
[A[ATraining Step: 523  | total loss: [1m[32m0.87788[0m[0m | time: 44.787s
[2K| Adam | epoch: 004 | loss: 0.87788 - acc: 0.6836 -- iter: 03328/10000
[A[ATraining Step: 524  | total loss: [1m[32m0.86599[0m[0m | time: 45.777s
[2K| Adam | epoch: 004 | loss: 0.86599 - acc: 0.6872 -- iter: 03392/10000
[A[ATraining Step: 525  | total loss: [1m[32m0.86003[0m[0m | time: 46.735s
[2K| Adam | epoch: 004 | loss: 0.86003 - acc: 0.6825 -- iter: 03456/10000
[A[ATraining Step: 526  | total loss: [1m[32m0.87348[0m[0m | time: 47.685s
[2K| Adam | epoch: 004 | loss: 0.87348 - acc: 0.6768 -- iter: 03520/10000
[A[ATraining Step: 527  | total loss: [1m[32m0.88523[0m[0m | time: 48.598s
[2K| Adam | epoch: 004 | loss: 0.88523 - acc: 0.6700 -- iter: 03584/10000
[A[ATraining Step: 528  | total loss: [1m[32m0.88967[0m[0m | time: 49.497s
[2K| Adam | epoch: 004 | loss: 0.88967 - acc: 0.6733 -- iter: 03648/10000
[A[ATraining Step: 529  | total loss: [1m[32m0.91342[0m[0m | time: 50.371s
[2K| Adam | epoch: 004 | loss: 0.91342 - acc: 0.6669 -- iter: 03712/10000
[A[ATraining Step: 530  | total loss: [1m[32m0.89338[0m[0m | time: 51.272s
[2K| Adam | epoch: 004 | loss: 0.89338 - acc: 0.6768 -- iter: 03776/10000
[A[ATraining Step: 531  | total loss: [1m[32m0.90703[0m[0m | time: 52.163s
[2K| Adam | epoch: 004 | loss: 0.90703 - acc: 0.6701 -- iter: 03840/10000
[A[ATraining Step: 532  | total loss: [1m[32m0.89928[0m[0m | time: 53.113s
[2K| Adam | epoch: 004 | loss: 0.89928 - acc: 0.6781 -- iter: 03904/10000
[A[ATraining Step: 533  | total loss: [1m[32m0.90066[0m[0m | time: 54.002s
[2K| Adam | epoch: 004 | loss: 0.90066 - acc: 0.6806 -- iter: 03968/10000
[A[ATraining Step: 534  | total loss: [1m[32m0.89204[0m[0m | time: 54.870s
[2K| Adam | epoch: 004 | loss: 0.89204 - acc: 0.6859 -- iter: 04032/10000
[A[ATraining Step: 535  | total loss: [1m[32m0.88930[0m[0m | time: 55.761s
[2K| Adam | epoch: 004 | loss: 0.88930 - acc: 0.6892 -- iter: 04096/10000
[A[ATraining Step: 536  | total loss: [1m[32m0.87175[0m[0m | time: 56.614s
[2K| Adam | epoch: 004 | loss: 0.87175 - acc: 0.6969 -- iter: 04160/10000
[A[ATraining Step: 537  | total loss: [1m[32m0.85781[0m[0m | time: 57.441s
[2K| Adam | epoch: 004 | loss: 0.85781 - acc: 0.7006 -- iter: 04224/10000
[A[ATraining Step: 538  | total loss: [1m[32m0.84223[0m[0m | time: 58.281s
[2K| Adam | epoch: 004 | loss: 0.84223 - acc: 0.7087 -- iter: 04288/10000
[A[ATraining Step: 539  | total loss: [1m[32m0.85097[0m[0m | time: 59.104s
[2K| Adam | epoch: 004 | loss: 0.85097 - acc: 0.7081 -- iter: 04352/10000
[A[ATraining Step: 540  | total loss: [1m[32m0.83028[0m[0m | time: 59.940s
[2K| Adam | epoch: 004 | loss: 0.83028 - acc: 0.7201 -- iter: 04416/10000
[A[ATraining Step: 541  | total loss: [1m[32m0.82211[0m[0m | time: 60.859s
[2K| Adam | epoch: 004 | loss: 0.82211 - acc: 0.7215 -- iter: 04480/10000
[A[ATraining Step: 542  | total loss: [1m[32m0.81209[0m[0m | time: 61.765s
[2K| Adam | epoch: 004 | loss: 0.81209 - acc: 0.7228 -- iter: 04544/10000
[A[ATraining Step: 543  | total loss: [1m[32m0.82407[0m[0m | time: 62.703s
[2K| Adam | epoch: 004 | loss: 0.82407 - acc: 0.7224 -- iter: 04608/10000
[A[ATraining Step: 544  | total loss: [1m[32m0.80993[0m[0m | time: 63.596s
[2K| Adam | epoch: 004 | loss: 0.80993 - acc: 0.7267 -- iter: 04672/10000
[A[ATraining Step: 545  | total loss: [1m[32m0.81699[0m[0m | time: 64.546s
[2K| Adam | epoch: 004 | loss: 0.81699 - acc: 0.7306 -- iter: 04736/10000
[A[ATraining Step: 546  | total loss: [1m[32m0.82166[0m[0m | time: 65.490s
[2K| Adam | epoch: 004 | loss: 0.82166 - acc: 0.7279 -- iter: 04800/10000
[A[ATraining Step: 547  | total loss: [1m[32m0.82470[0m[0m | time: 66.391s
[2K| Adam | epoch: 004 | loss: 0.82470 - acc: 0.7301 -- iter: 04864/10000
[A[ATraining Step: 548  | total loss: [1m[32m0.82293[0m[0m | time: 67.255s
[2K| Adam | epoch: 004 | loss: 0.82293 - acc: 0.7274 -- iter: 04928/10000
[A[ATraining Step: 549  | total loss: [1m[32m0.82687[0m[0m | time: 68.120s
[2K| Adam | epoch: 004 | loss: 0.82687 - acc: 0.7234 -- iter: 04992/10000
[A[ATraining Step: 550  | total loss: [1m[32m0.86130[0m[0m | time: 68.947s
[2K| Adam | epoch: 004 | loss: 0.86130 - acc: 0.7151 -- iter: 05056/10000
[A[ATraining Step: 551  | total loss: [1m[32m0.85872[0m[0m | time: 69.770s
[2K| Adam | epoch: 004 | loss: 0.85872 - acc: 0.7092 -- iter: 05120/10000
[A[ATraining Step: 552  | total loss: [1m[32m0.88215[0m[0m | time: 70.649s
[2K| Adam | epoch: 004 | loss: 0.88215 - acc: 0.6961 -- iter: 05184/10000
[A[ATraining Step: 553  | total loss: [1m[32m0.87803[0m[0m | time: 71.479s
[2K| Adam | epoch: 004 | loss: 0.87803 - acc: 0.7000 -- iter: 05248/10000
[A[ATraining Step: 554  | total loss: [1m[32m0.90201[0m[0m | time: 72.288s
[2K| Adam | epoch: 004 | loss: 0.90201 - acc: 0.6925 -- iter: 05312/10000
[A[ATraining Step: 555  | total loss: [1m[32m0.90923[0m[0m | time: 73.109s
[2K| Adam | epoch: 004 | loss: 0.90923 - acc: 0.6966 -- iter: 05376/10000
[A[ATraining Step: 556  | total loss: [1m[32m0.90095[0m[0m | time: 73.922s
[2K| Adam | epoch: 004 | loss: 0.90095 - acc: 0.6973 -- iter: 05440/10000
[A[ATraining Step: 557  | total loss: [1m[32m0.90373[0m[0m | time: 74.750s
[2K| Adam | epoch: 004 | loss: 0.90373 - acc: 0.7010 -- iter: 05504/10000
[A[ATraining Step: 558  | total loss: [1m[32m0.90833[0m[0m | time: 75.583s
[2K| Adam | epoch: 004 | loss: 0.90833 - acc: 0.6903 -- iter: 05568/10000
[A[ATraining Step: 559  | total loss: [1m[32m0.90742[0m[0m | time: 76.393s
[2K| Adam | epoch: 004 | loss: 0.90742 - acc: 0.6947 -- iter: 05632/10000
[A[ATraining Step: 560  | total loss: [1m[32m0.90946[0m[0m | time: 77.230s
[2K| Adam | epoch: 004 | loss: 0.90946 - acc: 0.6940 -- iter: 05696/10000
[A[ATraining Step: 561  | total loss: [1m[32m0.90509[0m[0m | time: 78.038s
[2K| Adam | epoch: 004 | loss: 0.90509 - acc: 0.6964 -- iter: 05760/10000
[A[ATraining Step: 562  | total loss: [1m[32m0.91788[0m[0m | time: 78.856s
[2K| Adam | epoch: 004 | loss: 0.91788 - acc: 0.6909 -- iter: 05824/10000
[A[ATraining Step: 563  | total loss: [1m[32m0.92570[0m[0m | time: 79.662s
[2K| Adam | epoch: 004 | loss: 0.92570 - acc: 0.6921 -- iter: 05888/10000
[A[ATraining Step: 564  | total loss: [1m[32m0.92013[0m[0m | time: 80.465s
[2K| Adam | epoch: 004 | loss: 0.92013 - acc: 0.6916 -- iter: 05952/10000
[A[ATraining Step: 565  | total loss: [1m[32m0.92140[0m[0m | time: 81.273s
[2K| Adam | epoch: 004 | loss: 0.92140 - acc: 0.6943 -- iter: 06016/10000
[A[ATraining Step: 566  | total loss: [1m[32m0.91702[0m[0m | time: 82.082s
[2K| Adam | epoch: 004 | loss: 0.91702 - acc: 0.6890 -- iter: 06080/10000
[A[ATraining Step: 567  | total loss: [1m[32m0.91267[0m[0m | time: 82.888s
[2K| Adam | epoch: 004 | loss: 0.91267 - acc: 0.6951 -- iter: 06144/10000
[A[ATraining Step: 568  | total loss: [1m[32m0.92614[0m[0m | time: 83.689s
[2K| Adam | epoch: 004 | loss: 0.92614 - acc: 0.6834 -- iter: 06208/10000
[A[ATraining Step: 569  | total loss: [1m[32m0.90929[0m[0m | time: 84.491s
[2K| Adam | epoch: 004 | loss: 0.90929 - acc: 0.6916 -- iter: 06272/10000
[A[ATraining Step: 570  | total loss: [1m[32m0.90710[0m[0m | time: 85.328s
[2K| Adam | epoch: 004 | loss: 0.90710 - acc: 0.6881 -- iter: 06336/10000
[A[ATraining Step: 571  | total loss: [1m[32m0.90490[0m[0m | time: 86.150s
[2K| Adam | epoch: 004 | loss: 0.90490 - acc: 0.6911 -- iter: 06400/10000
[A[ATraining Step: 572  | total loss: [1m[32m0.89843[0m[0m | time: 86.976s
[2K| Adam | epoch: 004 | loss: 0.89843 - acc: 0.6876 -- iter: 06464/10000
[A[ATraining Step: 573  | total loss: [1m[32m0.88749[0m[0m | time: 87.769s
[2K| Adam | epoch: 004 | loss: 0.88749 - acc: 0.6908 -- iter: 06528/10000
[A[ATraining Step: 574  | total loss: [1m[32m0.86720[0m[0m | time: 88.541s
[2K| Adam | epoch: 004 | loss: 0.86720 - acc: 0.6920 -- iter: 06592/10000
[A[ATraining Step: 575  | total loss: [1m[32m0.87184[0m[0m | time: 89.321s
[2K| Adam | epoch: 004 | loss: 0.87184 - acc: 0.6915 -- iter: 06656/10000
[A[ATraining Step: 576  | total loss: [1m[32m0.86820[0m[0m | time: 90.101s
[2K| Adam | epoch: 004 | loss: 0.86820 - acc: 0.6943 -- iter: 06720/10000
[A[ATraining Step: 577  | total loss: [1m[32m0.87915[0m[0m | time: 90.877s
[2K| Adam | epoch: 004 | loss: 0.87915 - acc: 0.6920 -- iter: 06784/10000
[A[ATraining Step: 578  | total loss: [1m[32m0.85185[0m[0m | time: 91.660s
[2K| Adam | epoch: 004 | loss: 0.85185 - acc: 0.7025 -- iter: 06848/10000
[A[ATraining Step: 579  | total loss: [1m[32m0.84443[0m[0m | time: 92.471s
[2K| Adam | epoch: 004 | loss: 0.84443 - acc: 0.7041 -- iter: 06912/10000
[A[ATraining Step: 580  | total loss: [1m[32m0.85131[0m[0m | time: 93.390s
[2K| Adam | epoch: 004 | loss: 0.85131 - acc: 0.7025 -- iter: 06976/10000
[A[ATraining Step: 581  | total loss: [1m[32m0.86128[0m[0m | time: 94.276s
[2K| Adam | epoch: 004 | loss: 0.86128 - acc: 0.7010 -- iter: 07040/10000
[A[ATraining Step: 582  | total loss: [1m[32m0.84248[0m[0m | time: 95.295s
[2K| Adam | epoch: 004 | loss: 0.84248 - acc: 0.7074 -- iter: 07104/10000
[A[ATraining Step: 583  | total loss: [1m[32m0.83235[0m[0m | time: 96.330s
[2K| Adam | epoch: 004 | loss: 0.83235 - acc: 0.7117 -- iter: 07168/10000
[A[ATraining Step: 584  | total loss: [1m[32m0.83619[0m[0m | time: 97.338s
[2K| Adam | epoch: 004 | loss: 0.83619 - acc: 0.7093 -- iter: 07232/10000
[A[ATraining Step: 585  | total loss: [1m[32m0.84042[0m[0m | time: 98.383s
[2K| Adam | epoch: 004 | loss: 0.84042 - acc: 0.7118 -- iter: 07296/10000
[A[ATraining Step: 586  | total loss: [1m[32m0.83428[0m[0m | time: 99.360s
[2K| Adam | epoch: 004 | loss: 0.83428 - acc: 0.7172 -- iter: 07360/10000
[A[ATraining Step: 587  | total loss: [1m[32m0.83194[0m[0m | time: 100.306s
[2K| Adam | epoch: 004 | loss: 0.83194 - acc: 0.7095 -- iter: 07424/10000
[A[ATraining Step: 588  | total loss: [1m[32m0.83561[0m[0m | time: 101.158s
[2K| Adam | epoch: 004 | loss: 0.83561 - acc: 0.7042 -- iter: 07488/10000
[A[ATraining Step: 589  | total loss: [1m[32m0.82940[0m[0m | time: 101.993s
[2K| Adam | epoch: 004 | loss: 0.82940 - acc: 0.7072 -- iter: 07552/10000
[A[ATraining Step: 590  | total loss: [1m[32m0.80791[0m[0m | time: 102.819s
[2K| Adam | epoch: 004 | loss: 0.80791 - acc: 0.7146 -- iter: 07616/10000
[A[ATraining Step: 591  | total loss: [1m[32m0.80576[0m[0m | time: 103.612s
[2K| Adam | epoch: 004 | loss: 0.80576 - acc: 0.7119 -- iter: 07680/10000
[A[ATraining Step: 592  | total loss: [1m[32m0.79242[0m[0m | time: 104.494s
[2K| Adam | epoch: 004 | loss: 0.79242 - acc: 0.7157 -- iter: 07744/10000
[A[ATraining Step: 593  | total loss: [1m[32m0.79431[0m[0m | time: 105.324s
[2K| Adam | epoch: 004 | loss: 0.79431 - acc: 0.7145 -- iter: 07808/10000
[A[ATraining Step: 594  | total loss: [1m[32m0.80639[0m[0m | time: 106.170s
[2K| Adam | epoch: 004 | loss: 0.80639 - acc: 0.7086 -- iter: 07872/10000
[A[ATraining Step: 595  | total loss: [1m[32m0.80597[0m[0m | time: 107.045s
[2K| Adam | epoch: 004 | loss: 0.80597 - acc: 0.7143 -- iter: 07936/10000
[A[ATraining Step: 596  | total loss: [1m[32m0.80329[0m[0m | time: 107.929s
[2K| Adam | epoch: 004 | loss: 0.80329 - acc: 0.7132 -- iter: 08000/10000
[A[ATraining Step: 597  | total loss: [1m[32m0.82244[0m[0m | time: 108.875s
[2K| Adam | epoch: 004 | loss: 0.82244 - acc: 0.7106 -- iter: 08064/10000
[A[ATraining Step: 598  | total loss: [1m[32m0.82229[0m[0m | time: 109.783s
[2K| Adam | epoch: 004 | loss: 0.82229 - acc: 0.7068 -- iter: 08128/10000
[A[ATraining Step: 599  | total loss: [1m[32m0.82603[0m[0m | time: 110.662s
[2K| Adam | epoch: 004 | loss: 0.82603 - acc: 0.7064 -- iter: 08192/10000
[A[ATraining Step: 600  | total loss: [1m[32m1.33802[0m[0m | time: 114.004s
[2K| Adam | epoch: 004 | loss: 1.33802 - acc: 0.6483 | val_loss: 1.67624 - val_acc: 0.4457 -- iter: 08256/10000
--
Training Step: 601  | total loss: [1m[32m1.29300[0m[0m | time: 114.880s
[2K| Adam | epoch: 004 | loss: 1.29300 - acc: 0.6569 -- iter: 08320/10000
[A[ATraining Step: 602  | total loss: [1m[32m1.27527[0m[0m | time: 115.820s
[2K| Adam | epoch: 004 | loss: 1.27527 - acc: 0.6506 -- iter: 08384/10000
[A[ATraining Step: 603  | total loss: [1m[32m1.24997[0m[0m | time: 116.704s
[2K| Adam | epoch: 004 | loss: 1.24997 - acc: 0.6527 -- iter: 08448/10000
[A[ATraining Step: 604  | total loss: [1m[32m1.19971[0m[0m | time: 117.583s
[2K| Adam | epoch: 004 | loss: 1.19971 - acc: 0.6624 -- iter: 08512/10000
[A[ATraining Step: 605  | total loss: [1m[32m1.16589[0m[0m | time: 118.487s
[2K| Adam | epoch: 004 | loss: 1.16589 - acc: 0.6696 -- iter: 08576/10000
[A[ATraining Step: 606  | total loss: [1m[32m1.13922[0m[0m | time: 119.382s
[2K| Adam | epoch: 004 | loss: 1.13922 - acc: 0.6761 -- iter: 08640/10000
[A[ATraining Step: 607  | total loss: [1m[32m1.07840[0m[0m | time: 120.272s
[2K| Adam | epoch: 004 | loss: 1.07840 - acc: 0.6944 -- iter: 08704/10000
[A[ATraining Step: 608  | total loss: [1m[32m1.05617[0m[0m | time: 121.200s
[2K| Adam | epoch: 004 | loss: 1.05617 - acc: 0.6906 -- iter: 08768/10000
[A[ATraining Step: 609  | total loss: [1m[32m1.04905[0m[0m | time: 122.086s
[2K| Adam | epoch: 004 | loss: 1.04905 - acc: 0.6903 -- iter: 08832/10000
[A[ATraining Step: 610  | total loss: [1m[32m1.04727[0m[0m | time: 123.089s
[2K| Adam | epoch: 004 | loss: 1.04727 - acc: 0.6822 -- iter: 08896/10000
[A[ATraining Step: 611  | total loss: [1m[32m1.02546[0m[0m | time: 124.126s
[2K| Adam | epoch: 004 | loss: 1.02546 - acc: 0.6780 -- iter: 08960/10000
[A[ATraining Step: 612  | total loss: [1m[32m0.98613[0m[0m | time: 125.104s
[2K| Adam | epoch: 004 | loss: 0.98613 - acc: 0.6837 -- iter: 09024/10000
[A[ATraining Step: 613  | total loss: [1m[32m0.98755[0m[0m | time: 126.163s
[2K| Adam | epoch: 004 | loss: 0.98755 - acc: 0.6809 -- iter: 09088/10000
[A[ATraining Step: 614  | total loss: [1m[32m0.98245[0m[0m | time: 127.302s
[2K| Adam | epoch: 004 | loss: 0.98245 - acc: 0.6753 -- iter: 09152/10000
[A[ATraining Step: 615  | total loss: [1m[32m0.93844[0m[0m | time: 128.473s
[2K| Adam | epoch: 004 | loss: 0.93844 - acc: 0.6922 -- iter: 09216/10000
[A[ATraining Step: 616  | total loss: [1m[32m0.94701[0m[0m | time: 129.549s
[2K| Adam | epoch: 004 | loss: 0.94701 - acc: 0.6855 -- iter: 09280/10000
[A[ATraining Step: 617  | total loss: [1m[32m0.92896[0m[0m | time: 130.553s
[2K| Adam | epoch: 004 | loss: 0.92896 - acc: 0.6935 -- iter: 09344/10000
[A[ATraining Step: 618  | total loss: [1m[32m0.92961[0m[0m | time: 131.516s
[2K| Adam | epoch: 004 | loss: 0.92961 - acc: 0.6866 -- iter: 09408/10000
[A[ATraining Step: 619  | total loss: [1m[32m0.91442[0m[0m | time: 132.433s
[2K| Adam | epoch: 004 | loss: 0.91442 - acc: 0.6898 -- iter: 09472/10000
[A[ATraining Step: 620  | total loss: [1m[32m0.91837[0m[0m | time: 133.344s
[2K| Adam | epoch: 004 | loss: 0.91837 - acc: 0.6943 -- iter: 09536/10000
[A[ATraining Step: 621  | total loss: [1m[32m0.92365[0m[0m | time: 134.244s
[2K| Adam | epoch: 004 | loss: 0.92365 - acc: 0.6874 -- iter: 09600/10000
[A[ATraining Step: 622  | total loss: [1m[32m0.91369[0m[0m | time: 135.120s
[2K| Adam | epoch: 004 | loss: 0.91369 - acc: 0.6952 -- iter: 09664/10000
[A[ATraining Step: 623  | total loss: [1m[32m0.91478[0m[0m | time: 136.063s
[2K| Adam | epoch: 004 | loss: 0.91478 - acc: 0.6960 -- iter: 09728/10000
[A[ATraining Step: 624  | total loss: [1m[32m0.92843[0m[0m | time: 137.060s
[2K| Adam | epoch: 004 | loss: 0.92843 - acc: 0.6904 -- iter: 09792/10000
[A[ATraining Step: 625  | total loss: [1m[32m0.90956[0m[0m | time: 137.983s
[2K| Adam | epoch: 004 | loss: 0.90956 - acc: 0.6948 -- iter: 09856/10000
[A[ATraining Step: 626  | total loss: [1m[32m0.88936[0m[0m | time: 138.958s
[2K| Adam | epoch: 004 | loss: 0.88936 - acc: 0.6988 -- iter: 09920/10000
[A[ATraining Step: 627  | total loss: [1m[32m0.89149[0m[0m | time: 140.023s
[2K| Adam | epoch: 004 | loss: 0.89149 - acc: 0.6899 -- iter: 09984/10000
[A[ATraining Step: 628  | total loss: [1m[32m0.87961[0m[0m | time: 145.039s
[2K| Adam | epoch: 004 | loss: 0.87961 - acc: 0.6881 | val_loss: 1.38440 - val_acc: 0.5157 -- iter: 10000/10000
--
Training Step: 629  | total loss: [1m[32m0.88550[0m[0m | time: 1.437s
[2K| Adam | epoch: 005 | loss: 0.88550 - acc: 0.6849 -- iter: 00064/10000
[A[ATraining Step: 630  | total loss: [1m[32m0.88845[0m[0m | time: 3.051s
[2K| Adam | epoch: 005 | loss: 0.88845 - acc: 0.6836 -- iter: 00128/10000
[A[ATraining Step: 631  | total loss: [1m[32m0.86508[0m[0m | time: 3.846s
[2K| Adam | epoch: 005 | loss: 0.86508 - acc: 0.6933 -- iter: 00192/10000
[A[ATraining Step: 632  | total loss: [1m[32m0.83029[0m[0m | time: 4.707s
[2K| Adam | epoch: 005 | loss: 0.83029 - acc: 0.7053 -- iter: 00256/10000
[A[ATraining Step: 633  | total loss: [1m[32m0.80240[0m[0m | time: 6.252s
[2K| Adam | epoch: 005 | loss: 0.80240 - acc: 0.7222 -- iter: 00320/10000
[A[ATraining Step: 634  | total loss: [1m[32m0.80170[0m[0m | time: 7.703s
[2K| Adam | epoch: 005 | loss: 0.80170 - acc: 0.7250 -- iter: 00384/10000
[A[ATraining Step: 635  | total loss: [1m[32m0.80387[0m[0m | time: 9.223s
[2K| Adam | epoch: 005 | loss: 0.80387 - acc: 0.7259 -- iter: 00448/10000
[A[ATraining Step: 636  | total loss: [1m[32m0.80455[0m[0m | time: 10.742s
[2K| Adam | epoch: 005 | loss: 0.80455 - acc: 0.7237 -- iter: 00512/10000
[A[ATraining Step: 637  | total loss: [1m[32m0.79755[0m[0m | time: 12.232s
[2K| Adam | epoch: 005 | loss: 0.79755 - acc: 0.7232 -- iter: 00576/10000
[A[ATraining Step: 638  | total loss: [1m[32m0.79034[0m[0m | time: 13.700s
[2K| Adam | epoch: 005 | loss: 0.79034 - acc: 0.7212 -- iter: 00640/10000
[A[ATraining Step: 639  | total loss: [1m[32m0.79652[0m[0m | time: 15.096s
[2K| Adam | epoch: 005 | loss: 0.79652 - acc: 0.7225 -- iter: 00704/10000
[A[ATraining Step: 640  | total loss: [1m[32m0.76600[0m[0m | time: 16.426s
[2K| Adam | epoch: 005 | loss: 0.76600 - acc: 0.7346 -- iter: 00768/10000
[A[ATraining Step: 641  | total loss: [1m[32m0.78609[0m[0m | time: 17.690s
[2K| Adam | epoch: 005 | loss: 0.78609 - acc: 0.7283 -- iter: 00832/10000
[A[ATraining Step: 642  | total loss: [1m[32m0.79326[0m[0m | time: 18.900s
[2K| Adam | epoch: 005 | loss: 0.79326 - acc: 0.7258 -- iter: 00896/10000
[A[ATraining Step: 643  | total loss: [1m[32m0.80151[0m[0m | time: 20.171s
[2K| Adam | epoch: 005 | loss: 0.80151 - acc: 0.7267 -- iter: 00960/10000
[A[ATraining Step: 644  | total loss: [1m[32m0.80378[0m[0m | time: 21.364s
[2K| Adam | epoch: 005 | loss: 0.80378 - acc: 0.7118 -- iter: 01024/10000
[A[ATraining Step: 645  | total loss: [1m[32m0.80674[0m[0m | time: 22.363s
[2K| Adam | epoch: 005 | loss: 0.80674 - acc: 0.7156 -- iter: 01088/10000
[A[ATraining Step: 646  | total loss: [1m[32m0.81417[0m[0m | time: 23.299s
[2K| Adam | epoch: 005 | loss: 0.81417 - acc: 0.7066 -- iter: 01152/10000
[A[ATraining Step: 647  | total loss: [1m[32m0.80746[0m[0m | time: 24.188s
[2K| Adam | epoch: 005 | loss: 0.80746 - acc: 0.7109 -- iter: 01216/10000
[A[ATraining Step: 648  | total loss: [1m[32m0.79412[0m[0m | time: 25.068s
[2K| Adam | epoch: 005 | loss: 0.79412 - acc: 0.7164 -- iter: 01280/10000
[A[ATraining Step: 649  | total loss: [1m[32m0.79996[0m[0m | time: 25.913s
[2K| Adam | epoch: 005 | loss: 0.79996 - acc: 0.7104 -- iter: 01344/10000
[A[ATraining Step: 650  | total loss: [1m[32m0.80570[0m[0m | time: 26.752s
[2K| Adam | epoch: 005 | loss: 0.80570 - acc: 0.7050 -- iter: 01408/10000
[A[ATraining Step: 651  | total loss: [1m[32m0.80774[0m[0m | time: 27.562s
[2K| Adam | epoch: 005 | loss: 0.80774 - acc: 0.7001 -- iter: 01472/10000
[A[ATraining Step: 652  | total loss: [1m[32m0.78032[0m[0m | time: 28.366s
[2K| Adam | epoch: 005 | loss: 0.78032 - acc: 0.7098 -- iter: 01536/10000
[A[ATraining Step: 653  | total loss: [1m[32m0.78443[0m[0m | time: 29.176s
[2K| Adam | epoch: 005 | loss: 0.78443 - acc: 0.7075 -- iter: 01600/10000
[A[ATraining Step: 654  | total loss: [1m[32m0.80696[0m[0m | time: 29.958s
[2K| Adam | epoch: 005 | loss: 0.80696 - acc: 0.7087 -- iter: 01664/10000
[A[ATraining Step: 655  | total loss: [1m[32m0.78928[0m[0m | time: 30.874s
[2K| Adam | epoch: 005 | loss: 0.78928 - acc: 0.7237 -- iter: 01728/10000
[A[ATraining Step: 656  | total loss: [1m[32m0.80417[0m[0m | time: 31.671s
[2K| Adam | epoch: 005 | loss: 0.80417 - acc: 0.7279 -- iter: 01792/10000
[A[ATraining Step: 657  | total loss: [1m[32m0.80696[0m[0m | time: 32.523s
[2K| Adam | epoch: 005 | loss: 0.80696 - acc: 0.7301 -- iter: 01856/10000
[A[ATraining Step: 658  | total loss: [1m[32m0.81685[0m[0m | time: 33.510s
[2K| Adam | epoch: 005 | loss: 0.81685 - acc: 0.7274 -- iter: 01920/10000
[A[ATraining Step: 659  | total loss: [1m[32m0.82178[0m[0m | time: 34.414s
[2K| Adam | epoch: 005 | loss: 0.82178 - acc: 0.7250 -- iter: 01984/10000
[A[ATraining Step: 660  | total loss: [1m[32m0.83743[0m[0m | time: 35.403s
[2K| Adam | epoch: 005 | loss: 0.83743 - acc: 0.7212 -- iter: 02048/10000
[A[ATraining Step: 661  | total loss: [1m[32m0.83541[0m[0m | time: 36.404s
[2K| Adam | epoch: 005 | loss: 0.83541 - acc: 0.7241 -- iter: 02112/10000
[A[ATraining Step: 662  | total loss: [1m[32m0.82681[0m[0m | time: 37.404s
[2K| Adam | epoch: 005 | loss: 0.82681 - acc: 0.7220 -- iter: 02176/10000
[A[ATraining Step: 663  | total loss: [1m[32m0.83867[0m[0m | time: 38.351s
[2K| Adam | epoch: 005 | loss: 0.83867 - acc: 0.7139 -- iter: 02240/10000
[A[ATraining Step: 664  | total loss: [1m[32m0.84135[0m[0m | time: 39.318s
[2K| Adam | epoch: 005 | loss: 0.84135 - acc: 0.7081 -- iter: 02304/10000
[A[ATraining Step: 665  | total loss: [1m[32m0.83520[0m[0m | time: 40.320s
[2K| Adam | epoch: 005 | loss: 0.83520 - acc: 0.7061 -- iter: 02368/10000
[A[ATraining Step: 666  | total loss: [1m[32m0.83486[0m[0m | time: 41.227s
[2K| Adam | epoch: 005 | loss: 0.83486 - acc: 0.7073 -- iter: 02432/10000
[A[ATraining Step: 667  | total loss: [1m[32m0.83479[0m[0m | time: 42.188s
[2K| Adam | epoch: 005 | loss: 0.83479 - acc: 0.6991 -- iter: 02496/10000
[A[ATraining Step: 668  | total loss: [1m[32m0.84585[0m[0m | time: 43.100s
[2K| Adam | epoch: 005 | loss: 0.84585 - acc: 0.6979 -- iter: 02560/10000
[A[ATraining Step: 669  | total loss: [1m[32m0.83534[0m[0m | time: 44.057s
[2K| Adam | epoch: 005 | loss: 0.83534 - acc: 0.7031 -- iter: 02624/10000
[A[ATraining Step: 670  | total loss: [1m[32m0.86683[0m[0m | time: 44.979s
[2K| Adam | epoch: 005 | loss: 0.86683 - acc: 0.6906 -- iter: 02688/10000
[A[ATraining Step: 671  | total loss: [1m[32m0.84436[0m[0m | time: 45.895s
[2K| Adam | epoch: 005 | loss: 0.84436 - acc: 0.6950 -- iter: 02752/10000
[A[ATraining Step: 672  | total loss: [1m[32m0.86980[0m[0m | time: 46.855s
[2K| Adam | epoch: 005 | loss: 0.86980 - acc: 0.6880 -- iter: 02816/10000
[A[ATraining Step: 673  | total loss: [1m[32m0.85806[0m[0m | time: 47.778s
[2K| Adam | epoch: 005 | loss: 0.85806 - acc: 0.6926 -- iter: 02880/10000
[A[ATraining Step: 674  | total loss: [1m[32m0.84818[0m[0m | time: 48.672s
[2K| Adam | epoch: 005 | loss: 0.84818 - acc: 0.6953 -- iter: 02944/10000
[A[ATraining Step: 675  | total loss: [1m[32m0.83510[0m[0m | time: 49.600s
[2K| Adam | epoch: 005 | loss: 0.83510 - acc: 0.6992 -- iter: 03008/10000
[A[ATraining Step: 676  | total loss: [1m[32m0.82493[0m[0m | time: 50.573s
[2K| Adam | epoch: 005 | loss: 0.82493 - acc: 0.7074 -- iter: 03072/10000
[A[ATraining Step: 677  | total loss: [1m[32m0.84097[0m[0m | time: 51.479s
[2K| Adam | epoch: 005 | loss: 0.84097 - acc: 0.7023 -- iter: 03136/10000
[A[ATraining Step: 678  | total loss: [1m[32m0.83227[0m[0m | time: 52.378s
[2K| Adam | epoch: 005 | loss: 0.83227 - acc: 0.7086 -- iter: 03200/10000
[A[ATraining Step: 679  | total loss: [1m[32m0.82427[0m[0m | time: 53.201s
[2K| Adam | epoch: 005 | loss: 0.82427 - acc: 0.7159 -- iter: 03264/10000
[A[ATraining Step: 680  | total loss: [1m[32m0.83541[0m[0m | time: 54.022s
[2K| Adam | epoch: 005 | loss: 0.83541 - acc: 0.7162 -- iter: 03328/10000
[A[ATraining Step: 681  | total loss: [1m[32m0.82767[0m[0m | time: 54.824s
[2K| Adam | epoch: 005 | loss: 0.82767 - acc: 0.7149 -- iter: 03392/10000
[A[ATraining Step: 682  | total loss: [1m[32m0.80760[0m[0m | time: 55.669s
[2K| Adam | epoch: 005 | loss: 0.80760 - acc: 0.7199 -- iter: 03456/10000
[A[ATraining Step: 683  | total loss: [1m[32m0.79734[0m[0m | time: 56.505s
[2K| Adam | epoch: 005 | loss: 0.79734 - acc: 0.7182 -- iter: 03520/10000
[A[ATraining Step: 684  | total loss: [1m[32m0.79426[0m[0m | time: 57.304s
[2K| Adam | epoch: 005 | loss: 0.79426 - acc: 0.7167 -- iter: 03584/10000
[A[ATraining Step: 685  | total loss: [1m[32m0.79633[0m[0m | time: 58.097s
[2K| Adam | epoch: 005 | loss: 0.79633 - acc: 0.7154 -- iter: 03648/10000
[A[ATraining Step: 686  | total loss: [1m[32m0.81391[0m[0m | time: 58.885s
[2K| Adam | epoch: 005 | loss: 0.81391 - acc: 0.7048 -- iter: 03712/10000
[A[ATraining Step: 687  | total loss: [1m[32m0.82216[0m[0m | time: 59.663s
[2K| Adam | epoch: 005 | loss: 0.82216 - acc: 0.7015 -- iter: 03776/10000
[A[ATraining Step: 688  | total loss: [1m[32m0.81675[0m[0m | time: 60.453s
[2K| Adam | epoch: 005 | loss: 0.81675 - acc: 0.7016 -- iter: 03840/10000
[A[ATraining Step: 689  | total loss: [1m[32m0.83009[0m[0m | time: 61.217s
[2K| Adam | epoch: 005 | loss: 0.83009 - acc: 0.7002 -- iter: 03904/10000
[A[ATraining Step: 690  | total loss: [1m[32m0.81106[0m[0m | time: 61.994s
[2K| Adam | epoch: 005 | loss: 0.81106 - acc: 0.7068 -- iter: 03968/10000
[A[ATraining Step: 691  | total loss: [1m[32m0.79361[0m[0m | time: 62.783s
[2K| Adam | epoch: 005 | loss: 0.79361 - acc: 0.7111 -- iter: 04032/10000
[A[ATraining Step: 692  | total loss: [1m[32m0.81222[0m[0m | time: 63.560s
[2K| Adam | epoch: 005 | loss: 0.81222 - acc: 0.7056 -- iter: 04096/10000
[A[ATraining Step: 693  | total loss: [1m[32m0.79797[0m[0m | time: 64.337s
[2K| Adam | epoch: 005 | loss: 0.79797 - acc: 0.7116 -- iter: 04160/10000
[A[ATraining Step: 694  | total loss: [1m[32m0.81315[0m[0m | time: 65.099s
[2K| Adam | epoch: 005 | loss: 0.81315 - acc: 0.7123 -- iter: 04224/10000
[A[ATraining Step: 695  | total loss: [1m[32m0.82370[0m[0m | time: 65.860s
[2K| Adam | epoch: 005 | loss: 0.82370 - acc: 0.7067 -- iter: 04288/10000
[A[ATraining Step: 696  | total loss: [1m[32m0.83014[0m[0m | time: 66.609s
[2K| Adam | epoch: 005 | loss: 0.83014 - acc: 0.7032 -- iter: 04352/10000
[A[ATraining Step: 697  | total loss: [1m[32m0.82732[0m[0m | time: 67.337s
[2K| Adam | epoch: 005 | loss: 0.82732 - acc: 0.7032 -- iter: 04416/10000
[A[ATraining Step: 698  | total loss: [1m[32m0.82760[0m[0m | time: 68.088s
[2K| Adam | epoch: 005 | loss: 0.82760 - acc: 0.7032 -- iter: 04480/10000
[A[ATraining Step: 699  | total loss: [1m[32m0.82250[0m[0m | time: 68.876s
[2K| Adam | epoch: 005 | loss: 0.82250 - acc: 0.7079 -- iter: 04544/10000
[A[ATraining Step: 700  | total loss: [1m[32m0.84014[0m[0m | time: 71.703s
[2K| Adam | epoch: 005 | loss: 0.84014 - acc: 0.6996 | val_loss: 1.70136 - val_acc: 0.3929 -- iter: 04608/10000
--
Training Step: 701  | total loss: [1m[32m0.85254[0m[0m | time: 72.471s
[2K| Adam | epoch: 005 | loss: 0.85254 - acc: 0.6937 -- iter: 04672/10000
[A[ATraining Step: 702  | total loss: [1m[32m0.87226[0m[0m | time: 73.298s
[2K| Adam | epoch: 005 | loss: 0.87226 - acc: 0.6868 -- iter: 04736/10000
[A[ATraining Step: 703  | total loss: [1m[32m0.84935[0m[0m | time: 74.080s
[2K| Adam | epoch: 005 | loss: 0.84935 - acc: 0.6900 -- iter: 04800/10000
[A[ATraining Step: 704  | total loss: [1m[32m0.85188[0m[0m | time: 74.869s
[2K| Adam | epoch: 005 | loss: 0.85188 - acc: 0.6835 -- iter: 04864/10000
[A[ATraining Step: 705  | total loss: [1m[32m0.85471[0m[0m | time: 75.642s
[2K| Adam | epoch: 005 | loss: 0.85471 - acc: 0.6855 -- iter: 04928/10000
[A[ATraining Step: 706  | total loss: [1m[32m0.84499[0m[0m | time: 76.471s
[2K| Adam | epoch: 005 | loss: 0.84499 - acc: 0.6857 -- iter: 04992/10000
[A[ATraining Step: 707  | total loss: [1m[32m0.83517[0m[0m | time: 77.261s
[2K| Adam | epoch: 005 | loss: 0.83517 - acc: 0.6906 -- iter: 05056/10000
[A[ATraining Step: 708  | total loss: [1m[32m0.82253[0m[0m | time: 78.126s
[2K| Adam | epoch: 005 | loss: 0.82253 - acc: 0.6965 -- iter: 05120/10000
[A[ATraining Step: 709  | total loss: [1m[32m0.81945[0m[0m | time: 79.001s
[2K| Adam | epoch: 005 | loss: 0.81945 - acc: 0.7018 -- iter: 05184/10000
[A[ATraining Step: 710  | total loss: [1m[32m0.82532[0m[0m | time: 79.850s
[2K| Adam | epoch: 005 | loss: 0.82532 - acc: 0.7051 -- iter: 05248/10000
[A[ATraining Step: 711  | total loss: [1m[32m0.82202[0m[0m | time: 80.776s
[2K| Adam | epoch: 005 | loss: 0.82202 - acc: 0.7096 -- iter: 05312/10000
[A[ATraining Step: 712  | total loss: [1m[32m0.81114[0m[0m | time: 81.653s
[2K| Adam | epoch: 005 | loss: 0.81114 - acc: 0.7136 -- iter: 05376/10000
[A[ATraining Step: 713  | total loss: [1m[32m0.80206[0m[0m | time: 82.537s
[2K| Adam | epoch: 005 | loss: 0.80206 - acc: 0.7188 -- iter: 05440/10000
[A[ATraining Step: 714  | total loss: [1m[32m0.78418[0m[0m | time: 83.394s
[2K| Adam | epoch: 005 | loss: 0.78418 - acc: 0.7251 -- iter: 05504/10000
[A[ATraining Step: 715  | total loss: [1m[32m0.77991[0m[0m | time: 84.240s
[2K| Adam | epoch: 005 | loss: 0.77991 - acc: 0.7291 -- iter: 05568/10000
[A[ATraining Step: 716  | total loss: [1m[32m0.78937[0m[0m | time: 85.052s
[2K| Adam | epoch: 005 | loss: 0.78937 - acc: 0.7281 -- iter: 05632/10000
[A[ATraining Step: 717  | total loss: [1m[32m0.80486[0m[0m | time: 85.859s
[2K| Adam | epoch: 005 | loss: 0.80486 - acc: 0.7240 -- iter: 05696/10000
[A[ATraining Step: 718  | total loss: [1m[32m0.80596[0m[0m | time: 86.664s
[2K| Adam | epoch: 005 | loss: 0.80596 - acc: 0.7251 -- iter: 05760/10000
[A[ATraining Step: 719  | total loss: [1m[32m0.80752[0m[0m | time: 87.461s
[2K| Adam | epoch: 005 | loss: 0.80752 - acc: 0.7197 -- iter: 05824/10000
[A[ATraining Step: 720  | total loss: [1m[32m0.81407[0m[0m | time: 88.267s
[2K| Adam | epoch: 005 | loss: 0.81407 - acc: 0.7181 -- iter: 05888/10000
[A[ATraining Step: 721  | total loss: [1m[32m0.82050[0m[0m | time: 89.050s
[2K| Adam | epoch: 005 | loss: 0.82050 - acc: 0.7213 -- iter: 05952/10000
[A[ATraining Step: 722  | total loss: [1m[32m0.81535[0m[0m | time: 89.825s
[2K| Adam | epoch: 005 | loss: 0.81535 - acc: 0.7163 -- iter: 06016/10000
[A[ATraining Step: 723  | total loss: [1m[32m0.81510[0m[0m | time: 90.618s
[2K| Adam | epoch: 005 | loss: 0.81510 - acc: 0.7228 -- iter: 06080/10000
[A[ATraining Step: 724  | total loss: [1m[32m0.80637[0m[0m | time: 91.383s
[2K| Adam | epoch: 005 | loss: 0.80637 - acc: 0.7240 -- iter: 06144/10000
[A[ATraining Step: 725  | total loss: [1m[32m0.78426[0m[0m | time: 92.159s
[2K| Adam | epoch: 005 | loss: 0.78426 - acc: 0.7328 -- iter: 06208/10000
[A[ATraining Step: 726  | total loss: [1m[32m0.78265[0m[0m | time: 92.929s
[2K| Adam | epoch: 005 | loss: 0.78265 - acc: 0.7267 -- iter: 06272/10000
[A[ATraining Step: 727  | total loss: [1m[32m0.77995[0m[0m | time: 93.665s
[2K| Adam | epoch: 005 | loss: 0.77995 - acc: 0.7228 -- iter: 06336/10000
[A[ATraining Step: 728  | total loss: [1m[32m0.78431[0m[0m | time: 94.429s
[2K| Adam | epoch: 005 | loss: 0.78431 - acc: 0.7240 -- iter: 06400/10000
[A[ATraining Step: 729  | total loss: [1m[32m0.80003[0m[0m | time: 95.202s
[2K| Adam | epoch: 005 | loss: 0.80003 - acc: 0.7125 -- iter: 06464/10000
[A[ATraining Step: 730  | total loss: [1m[32m0.78932[0m[0m | time: 95.977s
[2K| Adam | epoch: 005 | loss: 0.78932 - acc: 0.7163 -- iter: 06528/10000
[A[ATraining Step: 731  | total loss: [1m[32m0.80559[0m[0m | time: 96.749s
[2K| Adam | epoch: 005 | loss: 0.80559 - acc: 0.7071 -- iter: 06592/10000
[A[ATraining Step: 732  | total loss: [1m[32m0.80380[0m[0m | time: 97.525s
[2K| Adam | epoch: 005 | loss: 0.80380 - acc: 0.7036 -- iter: 06656/10000
[A[ATraining Step: 733  | total loss: [1m[32m0.80627[0m[0m | time: 98.308s
[2K| Adam | epoch: 005 | loss: 0.80627 - acc: 0.7051 -- iter: 06720/10000
[A[ATraining Step: 734  | total loss: [1m[32m0.81650[0m[0m | time: 99.116s
[2K| Adam | epoch: 005 | loss: 0.81650 - acc: 0.7002 -- iter: 06784/10000
[A[ATraining Step: 735  | total loss: [1m[32m0.81854[0m[0m | time: 99.919s
[2K| Adam | epoch: 005 | loss: 0.81854 - acc: 0.6958 -- iter: 06848/10000
[A[ATraining Step: 736  | total loss: [1m[32m0.78915[0m[0m | time: 100.752s
[2K| Adam | epoch: 005 | loss: 0.78915 - acc: 0.7091 -- iter: 06912/10000
[A[ATraining Step: 737  | total loss: [1m[32m0.80317[0m[0m | time: 101.555s
[2K| Adam | epoch: 005 | loss: 0.80317 - acc: 0.7069 -- iter: 06976/10000
[A[ATraining Step: 738  | total loss: [1m[32m0.80877[0m[0m | time: 102.367s
[2K| Adam | epoch: 005 | loss: 0.80877 - acc: 0.7081 -- iter: 07040/10000
[A[ATraining Step: 739  | total loss: [1m[32m0.79934[0m[0m | time: 103.198s
[2K| Adam | epoch: 005 | loss: 0.79934 - acc: 0.7076 -- iter: 07104/10000
[A[ATraining Step: 740  | total loss: [1m[32m0.78754[0m[0m | time: 104.013s
[2K| Adam | epoch: 005 | loss: 0.78754 - acc: 0.7071 -- iter: 07168/10000
[A[ATraining Step: 741  | total loss: [1m[32m0.80020[0m[0m | time: 104.876s
[2K| Adam | epoch: 005 | loss: 0.80020 - acc: 0.7036 -- iter: 07232/10000
[A[ATraining Step: 742  | total loss: [1m[32m0.78194[0m[0m | time: 105.766s
[2K| Adam | epoch: 005 | loss: 0.78194 - acc: 0.7083 -- iter: 07296/10000
[A[ATraining Step: 743  | total loss: [1m[32m0.79695[0m[0m | time: 106.669s
[2K| Adam | epoch: 005 | loss: 0.79695 - acc: 0.7031 -- iter: 07360/10000
[A[ATraining Step: 744  | total loss: [1m[32m0.78758[0m[0m | time: 107.545s
[2K| Adam | epoch: 005 | loss: 0.78758 - acc: 0.7093 -- iter: 07424/10000
[A[ATraining Step: 745  | total loss: [1m[32m0.79987[0m[0m | time: 108.431s
[2K| Adam | epoch: 005 | loss: 0.79987 - acc: 0.7040 -- iter: 07488/10000
[A[ATraining Step: 746  | total loss: [1m[32m0.79096[0m[0m | time: 109.281s
[2K| Adam | epoch: 005 | loss: 0.79096 - acc: 0.7102 -- iter: 07552/10000
[A[ATraining Step: 747  | total loss: [1m[32m0.79399[0m[0m | time: 110.142s
[2K| Adam | epoch: 005 | loss: 0.79399 - acc: 0.7157 -- iter: 07616/10000
[A[ATraining Step: 748  | total loss: [1m[32m0.79711[0m[0m | time: 110.969s
[2K| Adam | epoch: 005 | loss: 0.79711 - acc: 0.7191 -- iter: 07680/10000
[A[ATraining Step: 749  | total loss: [1m[32m0.80387[0m[0m | time: 111.776s
[2K| Adam | epoch: 005 | loss: 0.80387 - acc: 0.7269 -- iter: 07744/10000
[A[ATraining Step: 750  | total loss: [1m[32m0.79121[0m[0m | time: 112.576s
[2K| Adam | epoch: 005 | loss: 0.79121 - acc: 0.7324 -- iter: 07808/10000
[A[ATraining Step: 751  | total loss: [1m[32m0.78212[0m[0m | time: 113.356s
[2K| Adam | epoch: 005 | loss: 0.78212 - acc: 0.7388 -- iter: 07872/10000
[A[ATraining Step: 752  | total loss: [1m[32m0.77376[0m[0m | time: 114.149s
[2K| Adam | epoch: 005 | loss: 0.77376 - acc: 0.7399 -- iter: 07936/10000
[A[ATraining Step: 753  | total loss: [1m[32m0.78946[0m[0m | time: 114.940s
[2K| Adam | epoch: 005 | loss: 0.78946 - acc: 0.7409 -- iter: 08000/10000
[A[ATraining Step: 754  | total loss: [1m[32m0.77788[0m[0m | time: 115.852s
[2K| Adam | epoch: 005 | loss: 0.77788 - acc: 0.7512 -- iter: 08064/10000
[A[ATraining Step: 755  | total loss: [1m[32m0.78129[0m[0m | time: 116.775s
[2K| Adam | epoch: 005 | loss: 0.78129 - acc: 0.7495 -- iter: 08128/10000
[A[ATraining Step: 756  | total loss: [1m[32m0.79201[0m[0m | time: 117.648s
[2K| Adam | epoch: 005 | loss: 0.79201 - acc: 0.7449 -- iter: 08192/10000
[A[ATraining Step: 757  | total loss: [1m[32m0.77209[0m[0m | time: 118.560s
[2K| Adam | epoch: 005 | loss: 0.77209 - acc: 0.7501 -- iter: 08256/10000
[A[ATraining Step: 758  | total loss: [1m[32m1.45248[0m[0m | time: 119.428s
[2K| Adam | epoch: 005 | loss: 1.45248 - acc: 0.6829 -- iter: 08320/10000
[A[ATraining Step: 759  | total loss: [1m[32m1.38377[0m[0m | time: 120.291s
[2K| Adam | epoch: 005 | loss: 1.38377 - acc: 0.6865 -- iter: 08384/10000
[A[ATraining Step: 760  | total loss: [1m[32m1.31102[0m[0m | time: 121.104s
[2K| Adam | epoch: 005 | loss: 1.31102 - acc: 0.6928 -- iter: 08448/10000
[A[ATraining Step: 761  | total loss: [1m[32m1.26246[0m[0m | time: 121.902s
[2K| Adam | epoch: 005 | loss: 1.26246 - acc: 0.6970 -- iter: 08512/10000
[A[ATraining Step: 762  | total loss: [1m[32m1.24745[0m[0m | time: 122.697s
[2K| Adam | epoch: 005 | loss: 1.24745 - acc: 0.6929 -- iter: 08576/10000
[A[ATraining Step: 763  | total loss: [1m[32m1.18360[0m[0m | time: 123.461s
[2K| Adam | epoch: 005 | loss: 1.18360 - acc: 0.7017 -- iter: 08640/10000
[A[ATraining Step: 764  | total loss: [1m[32m1.15403[0m[0m | time: 124.231s
[2K| Adam | epoch: 005 | loss: 1.15403 - acc: 0.6941 -- iter: 08704/10000
[A[ATraining Step: 765  | total loss: [1m[32m1.11365[0m[0m | time: 125.001s
[2K| Adam | epoch: 005 | loss: 1.11365 - acc: 0.6965 -- iter: 08768/10000
[A[ATraining Step: 766  | total loss: [1m[32m1.08067[0m[0m | time: 125.778s
[2K| Adam | epoch: 005 | loss: 1.08067 - acc: 0.6972 -- iter: 08832/10000
[A[ATraining Step: 767  | total loss: [1m[32m1.05331[0m[0m | time: 126.549s
[2K| Adam | epoch: 005 | loss: 1.05331 - acc: 0.7009 -- iter: 08896/10000
[A[ATraining Step: 768  | total loss: [1m[32m1.01171[0m[0m | time: 127.321s
[2K| Adam | epoch: 005 | loss: 1.01171 - acc: 0.7058 -- iter: 08960/10000
[A[ATraining Step: 769  | total loss: [1m[32m0.98889[0m[0m | time: 128.097s
[2K| Adam | epoch: 005 | loss: 0.98889 - acc: 0.7196 -- iter: 09024/10000
[A[ATraining Step: 770  | total loss: [1m[32m0.97114[0m[0m | time: 128.872s
[2K| Adam | epoch: 005 | loss: 0.97114 - acc: 0.7242 -- iter: 09088/10000
[A[ATraining Step: 771  | total loss: [1m[32m0.96623[0m[0m | time: 129.642s
[2K| Adam | epoch: 005 | loss: 0.96623 - acc: 0.7143 -- iter: 09152/10000
[A[ATraining Step: 772  | total loss: [1m[32m0.96801[0m[0m | time: 130.413s
[2K| Adam | epoch: 005 | loss: 0.96801 - acc: 0.7054 -- iter: 09216/10000
[A[ATraining Step: 773  | total loss: [1m[32m0.94229[0m[0m | time: 131.161s
[2K| Adam | epoch: 005 | loss: 0.94229 - acc: 0.7098 -- iter: 09280/10000
[A[ATraining Step: 774  | total loss: [1m[32m0.90393[0m[0m | time: 131.904s
[2K| Adam | epoch: 005 | loss: 0.90393 - acc: 0.7201 -- iter: 09344/10000
[A[ATraining Step: 775  | total loss: [1m[32m0.90456[0m[0m | time: 132.620s
[2K| Adam | epoch: 005 | loss: 0.90456 - acc: 0.7153 -- iter: 09408/10000
[A[ATraining Step: 776  | total loss: [1m[32m0.90580[0m[0m | time: 133.360s
[2K| Adam | epoch: 005 | loss: 0.90580 - acc: 0.7078 -- iter: 09472/10000
[A[ATraining Step: 777  | total loss: [1m[32m0.89336[0m[0m | time: 134.102s
[2K| Adam | epoch: 005 | loss: 0.89336 - acc: 0.7105 -- iter: 09536/10000
[A[ATraining Step: 778  | total loss: [1m[32m0.90698[0m[0m | time: 134.849s
[2K| Adam | epoch: 005 | loss: 0.90698 - acc: 0.7035 -- iter: 09600/10000
[A[ATraining Step: 779  | total loss: [1m[32m0.90402[0m[0m | time: 135.602s
[2K| Adam | epoch: 005 | loss: 0.90402 - acc: 0.7003 -- iter: 09664/10000
[A[ATraining Step: 780  | total loss: [1m[32m0.90815[0m[0m | time: 136.345s
[2K| Adam | epoch: 005 | loss: 0.90815 - acc: 0.6912 -- iter: 09728/10000
[A[ATraining Step: 781  | total loss: [1m[32m0.88604[0m[0m | time: 137.091s
[2K| Adam | epoch: 005 | loss: 0.88604 - acc: 0.6909 -- iter: 09792/10000
[A[ATraining Step: 782  | total loss: [1m[32m0.87145[0m[0m | time: 137.831s
[2K| Adam | epoch: 005 | loss: 0.87145 - acc: 0.6921 -- iter: 09856/10000
[A[ATraining Step: 783  | total loss: [1m[32m0.86077[0m[0m | time: 138.577s
[2K| Adam | epoch: 005 | loss: 0.86077 - acc: 0.6901 -- iter: 09920/10000
[A[ATraining Step: 784  | total loss: [1m[32m0.83137[0m[0m | time: 139.342s
[2K| Adam | epoch: 005 | loss: 0.83137 - acc: 0.6992 -- iter: 09984/10000
[A[ATraining Step: 785  | total loss: [1m[32m0.82972[0m[0m | time: 142.053s
[2K| Adam | epoch: 005 | loss: 0.82972 - acc: 0.6996 | val_loss: 1.34077 - val_acc: 0.5514 -- iter: 10000/10000
--
Training Step: 786  | total loss: [1m[32m0.81752[0m[0m | time: 0.742s
[2K| Adam | epoch: 006 | loss: 0.81752 - acc: 0.7124 -- iter: 00064/10000
[A[ATraining Step: 787  | total loss: [1m[32m0.82584[0m[0m | time: 1.514s
[2K| Adam | epoch: 006 | loss: 0.82584 - acc: 0.7115 -- iter: 00128/10000
[A[ATraining Step: 788  | total loss: [1m[32m0.82694[0m[0m | time: 2.285s
[2K| Adam | epoch: 006 | loss: 0.82694 - acc: 0.7138 -- iter: 00192/10000
[A[ATraining Step: 789  | total loss: [1m[32m0.83249[0m[0m | time: 2.653s
[2K| Adam | epoch: 006 | loss: 0.83249 - acc: 0.7127 -- iter: 00256/10000
[A[ATraining Step: 790  | total loss: [1m[32m0.84113[0m[0m | time: 2.993s
[2K| Adam | epoch: 006 | loss: 0.84113 - acc: 0.7164 -- iter: 00320/10000
[A[ATraining Step: 791  | total loss: [1m[32m0.84502[0m[0m | time: 3.740s
[2K| Adam | epoch: 006 | loss: 0.84502 - acc: 0.7073 -- iter: 00384/10000
[A[ATraining Step: 792  | total loss: [1m[32m0.82798[0m[0m | time: 4.511s
[2K| Adam | epoch: 006 | loss: 0.82798 - acc: 0.7147 -- iter: 00448/10000
[A[ATraining Step: 793  | total loss: [1m[32m0.86563[0m[0m | time: 5.278s
[2K| Adam | epoch: 006 | loss: 0.86563 - acc: 0.7057 -- iter: 00512/10000
[A[ATraining Step: 794  | total loss: [1m[32m0.87069[0m[0m | time: 6.052s
[2K| Adam | epoch: 006 | loss: 0.87069 - acc: 0.6992 -- iter: 00576/10000
[A[ATraining Step: 795  | total loss: [1m[32m0.87065[0m[0m | time: 6.831s
[2K| Adam | epoch: 006 | loss: 0.87065 - acc: 0.7074 -- iter: 00640/10000
[A[ATraining Step: 796  | total loss: [1m[32m0.85101[0m[0m | time: 7.607s
[2K| Adam | epoch: 006 | loss: 0.85101 - acc: 0.7132 -- iter: 00704/10000
[A[ATraining Step: 797  | total loss: [1m[32m0.87094[0m[0m | time: 8.370s
[2K| Adam | epoch: 006 | loss: 0.87094 - acc: 0.7107 -- iter: 00768/10000
[A[ATraining Step: 798  | total loss: [1m[32m0.87033[0m[0m | time: 9.145s
[2K| Adam | epoch: 006 | loss: 0.87033 - acc: 0.7084 -- iter: 00832/10000
[A[ATraining Step: 799  | total loss: [1m[32m0.84878[0m[0m | time: 9.910s
[2K| Adam | epoch: 006 | loss: 0.84878 - acc: 0.7156 -- iter: 00896/10000
[A[ATraining Step: 800  | total loss: [1m[32m0.83662[0m[0m | time: 12.658s
[2K| Adam | epoch: 006 | loss: 0.83662 - acc: 0.7175 | val_loss: 1.66858 - val_acc: 0.4400 -- iter: 00960/10000
--
Training Step: 801  | total loss: [1m[32m0.82457[0m[0m | time: 13.398s
[2K| Adam | epoch: 006 | loss: 0.82457 - acc: 0.7239 -- iter: 01024/10000
[A[ATraining Step: 802  | total loss: [1m[32m0.80589[0m[0m | time: 14.168s
[2K| Adam | epoch: 006 | loss: 0.80589 - acc: 0.7281 -- iter: 01088/10000
[A[ATraining Step: 803  | total loss: [1m[32m0.78355[0m[0m | time: 14.940s
[2K| Adam | epoch: 006 | loss: 0.78355 - acc: 0.7318 -- iter: 01152/10000
[A[ATraining Step: 804  | total loss: [1m[32m0.79062[0m[0m | time: 15.714s
[2K| Adam | epoch: 006 | loss: 0.79062 - acc: 0.7289 -- iter: 01216/10000
[A[ATraining Step: 805  | total loss: [1m[32m0.78901[0m[0m | time: 16.489s
[2K| Adam | epoch: 006 | loss: 0.78901 - acc: 0.7264 -- iter: 01280/10000
[A[ATraining Step: 806  | total loss: [1m[32m0.77463[0m[0m | time: 17.236s
[2K| Adam | epoch: 006 | loss: 0.77463 - acc: 0.7272 -- iter: 01344/10000
[A[ATraining Step: 807  | total loss: [1m[32m0.78378[0m[0m | time: 17.977s
[2K| Adam | epoch: 006 | loss: 0.78378 - acc: 0.7295 -- iter: 01408/10000
[A[ATraining Step: 808  | total loss: [1m[32m0.80497[0m[0m | time: 18.756s
[2K| Adam | epoch: 006 | loss: 0.80497 - acc: 0.7221 -- iter: 01472/10000
[A[ATraining Step: 809  | total loss: [1m[32m0.80754[0m[0m | time: 19.500s
[2K| Adam | epoch: 006 | loss: 0.80754 - acc: 0.7187 -- iter: 01536/10000
[A[ATraining Step: 810  | total loss: [1m[32m0.79226[0m[0m | time: 20.244s
[2K| Adam | epoch: 006 | loss: 0.79226 - acc: 0.7218 -- iter: 01600/10000
[A[ATraining Step: 811  | total loss: [1m[32m0.77734[0m[0m | time: 20.984s
[2K| Adam | epoch: 006 | loss: 0.77734 - acc: 0.7246 -- iter: 01664/10000
[A[ATraining Step: 812  | total loss: [1m[32m0.78342[0m[0m | time: 21.728s
[2K| Adam | epoch: 006 | loss: 0.78342 - acc: 0.7272 -- iter: 01728/10000
[A[ATraining Step: 813  | total loss: [1m[32m0.77749[0m[0m | time: 22.466s
[2K| Adam | epoch: 006 | loss: 0.77749 - acc: 0.7294 -- iter: 01792/10000
[A[ATraining Step: 814  | total loss: [1m[32m0.78745[0m[0m | time: 23.214s
[2K| Adam | epoch: 006 | loss: 0.78745 - acc: 0.7315 -- iter: 01856/10000
[A[ATraining Step: 815  | total loss: [1m[32m0.77730[0m[0m | time: 23.963s
[2K| Adam | epoch: 006 | loss: 0.77730 - acc: 0.7318 -- iter: 01920/10000
[A[ATraining Step: 816  | total loss: [1m[32m0.77093[0m[0m | time: 24.709s
[2K| Adam | epoch: 006 | loss: 0.77093 - acc: 0.7352 -- iter: 01984/10000
[A[ATraining Step: 817  | total loss: [1m[32m0.76550[0m[0m | time: 25.448s
[2K| Adam | epoch: 006 | loss: 0.76550 - acc: 0.7398 -- iter: 02048/10000
[A[ATraining Step: 818  | total loss: [1m[32m0.76010[0m[0m | time: 26.192s
[2K| Adam | epoch: 006 | loss: 0.76010 - acc: 0.7392 -- iter: 02112/10000
[A[ATraining Step: 819  | total loss: [1m[32m0.75740[0m[0m | time: 26.938s
[2K| Adam | epoch: 006 | loss: 0.75740 - acc: 0.7372 -- iter: 02176/10000
[A[ATraining Step: 820  | total loss: [1m[32m0.76169[0m[0m | time: 27.683s
[2K| Adam | epoch: 006 | loss: 0.76169 - acc: 0.7291 -- iter: 02240/10000
[A[ATraining Step: 821  | total loss: [1m[32m0.78379[0m[0m | time: 28.443s
[2K| Adam | epoch: 006 | loss: 0.78379 - acc: 0.7187 -- iter: 02304/10000
[A[ATraining Step: 822  | total loss: [1m[32m0.76715[0m[0m | time: 29.188s
[2K| Adam | epoch: 006 | loss: 0.76715 - acc: 0.7234 -- iter: 02368/10000
[A[ATraining Step: 823  | total loss: [1m[32m0.78589[0m[0m | time: 29.938s
[2K| Adam | epoch: 006 | loss: 0.78589 - acc: 0.7198 -- iter: 02432/10000
[A[ATraining Step: 824  | total loss: [1m[32m0.76884[0m[0m | time: 30.709s
[2K| Adam | epoch: 006 | loss: 0.76884 - acc: 0.7197 -- iter: 02496/10000
[A[ATraining Step: 825  | total loss: [1m[32m0.74880[0m[0m | time: 31.485s
[2K| Adam | epoch: 006 | loss: 0.74880 - acc: 0.7290 -- iter: 02560/10000
[A[ATraining Step: 826  | total loss: [1m[32m0.75402[0m[0m | time: 32.263s
[2K| Adam | epoch: 006 | loss: 0.75402 - acc: 0.7248 -- iter: 02624/10000
[A[ATraining Step: 827  | total loss: [1m[32m0.78370[0m[0m | time: 33.033s
[2K| Adam | epoch: 006 | loss: 0.78370 - acc: 0.7195 -- iter: 02688/10000
[A[ATraining Step: 828  | total loss: [1m[32m0.78905[0m[0m | time: 33.805s
[2K| Adam | epoch: 006 | loss: 0.78905 - acc: 0.7101 -- iter: 02752/10000
[A[ATraining Step: 829  | total loss: [1m[32m0.79715[0m[0m | time: 34.574s
[2K| Adam | epoch: 006 | loss: 0.79715 - acc: 0.7031 -- iter: 02816/10000
[A[ATraining Step: 830  | total loss: [1m[32m0.80008[0m[0m | time: 35.350s
[2K| Adam | epoch: 006 | loss: 0.80008 - acc: 0.7063 -- iter: 02880/10000
[A[ATraining Step: 831  | total loss: [1m[32m0.80886[0m[0m | time: 36.125s
[2K| Adam | epoch: 006 | loss: 0.80886 - acc: 0.7106 -- iter: 02944/10000
[A[ATraining Step: 832  | total loss: [1m[32m0.78948[0m[0m | time: 36.907s
[2K| Adam | epoch: 006 | loss: 0.78948 - acc: 0.7177 -- iter: 03008/10000
[A[ATraining Step: 833  | total loss: [1m[32m0.78143[0m[0m | time: 37.681s
[2K| Adam | epoch: 006 | loss: 0.78143 - acc: 0.7225 -- iter: 03072/10000
[A[ATraining Step: 834  | total loss: [1m[32m0.79933[0m[0m | time: 38.455s
[2K| Adam | epoch: 006 | loss: 0.79933 - acc: 0.7174 -- iter: 03136/10000
[A[ATraining Step: 835  | total loss: [1m[32m0.82478[0m[0m | time: 39.204s
[2K| Adam | epoch: 006 | loss: 0.82478 - acc: 0.7191 -- iter: 03200/10000
[A[ATraining Step: 836  | total loss: [1m[32m0.83664[0m[0m | time: 39.946s
[2K| Adam | epoch: 006 | loss: 0.83664 - acc: 0.7191 -- iter: 03264/10000
[A[ATraining Step: 837  | total loss: [1m[32m0.82932[0m[0m | time: 40.687s
[2K| Adam | epoch: 006 | loss: 0.82932 - acc: 0.7144 -- iter: 03328/10000
[A[ATraining Step: 838  | total loss: [1m[32m0.84361[0m[0m | time: 41.435s
[2K| Adam | epoch: 006 | loss: 0.84361 - acc: 0.7085 -- iter: 03392/10000
[A[ATraining Step: 839  | total loss: [1m[32m0.85865[0m[0m | time: 42.182s
[2K| Adam | epoch: 006 | loss: 0.85865 - acc: 0.7002 -- iter: 03456/10000
[A[ATraining Step: 840  | total loss: [1m[32m0.85156[0m[0m | time: 42.922s
[2K| Adam | epoch: 006 | loss: 0.85156 - acc: 0.6989 -- iter: 03520/10000
[A[ATraining Step: 841  | total loss: [1m[32m0.84183[0m[0m | time: 43.667s
[2K| Adam | epoch: 006 | loss: 0.84183 - acc: 0.6978 -- iter: 03584/10000
[A[ATraining Step: 842  | total loss: [1m[32m0.83533[0m[0m | time: 44.410s
[2K| Adam | epoch: 006 | loss: 0.83533 - acc: 0.6968 -- iter: 03648/10000
[A[ATraining Step: 843  | total loss: [1m[32m0.85353[0m[0m | time: 45.153s
[2K| Adam | epoch: 006 | loss: 0.85353 - acc: 0.6896 -- iter: 03712/10000
[A[ATraining Step: 844  | total loss: [1m[32m0.84639[0m[0m | time: 45.893s
[2K| Adam | epoch: 006 | loss: 0.84639 - acc: 0.6909 -- iter: 03776/10000
[A[ATraining Step: 845  | total loss: [1m[32m0.85703[0m[0m | time: 46.640s
[2K| Adam | epoch: 006 | loss: 0.85703 - acc: 0.6937 -- iter: 03840/10000
[A[ATraining Step: 846  | total loss: [1m[32m0.83524[0m[0m | time: 47.378s
[2K| Adam | epoch: 006 | loss: 0.83524 - acc: 0.6993 -- iter: 03904/10000
[A[ATraining Step: 847  | total loss: [1m[32m0.83741[0m[0m | time: 48.139s
[2K| Adam | epoch: 006 | loss: 0.83741 - acc: 0.7013 -- iter: 03968/10000
[A[ATraining Step: 848  | total loss: [1m[32m0.86162[0m[0m | time: 48.889s
[2K| Adam | epoch: 006 | loss: 0.86162 - acc: 0.6983 -- iter: 04032/10000
[A[ATraining Step: 849  | total loss: [1m[32m0.84059[0m[0m | time: 49.635s
[2K| Adam | epoch: 006 | loss: 0.84059 - acc: 0.7051 -- iter: 04096/10000
[A[ATraining Step: 850  | total loss: [1m[32m0.85455[0m[0m | time: 50.379s
[2K| Adam | epoch: 006 | loss: 0.85455 - acc: 0.7033 -- iter: 04160/10000
[A[ATraining Step: 851  | total loss: [1m[32m0.85959[0m[0m | time: 51.123s
[2K| Adam | epoch: 006 | loss: 0.85959 - acc: 0.6986 -- iter: 04224/10000
[A[ATraining Step: 852  | total loss: [1m[32m0.85077[0m[0m | time: 51.865s
[2K| Adam | epoch: 006 | loss: 0.85077 - acc: 0.6991 -- iter: 04288/10000
[A[ATraining Step: 853  | total loss: [1m[32m0.82438[0m[0m | time: 52.611s
[2K| Adam | epoch: 006 | loss: 0.82438 - acc: 0.7088 -- iter: 04352/10000
[A[ATraining Step: 854  | total loss: [1m[32m0.84550[0m[0m | time: 53.357s
[2K| Adam | epoch: 006 | loss: 0.84550 - acc: 0.7098 -- iter: 04416/10000
[A[ATraining Step: 855  | total loss: [1m[32m0.83144[0m[0m | time: 54.106s
[2K| Adam | epoch: 006 | loss: 0.83144 - acc: 0.7092 -- iter: 04480/10000
[A[ATraining Step: 856  | total loss: [1m[32m0.81665[0m[0m | time: 54.848s
[2K| Adam | epoch: 006 | loss: 0.81665 - acc: 0.7101 -- iter: 04544/10000
[A[ATraining Step: 857  | total loss: [1m[32m0.79019[0m[0m | time: 55.589s
[2K| Adam | epoch: 006 | loss: 0.79019 - acc: 0.7188 -- iter: 04608/10000
[A[ATraining Step: 858  | total loss: [1m[32m0.80954[0m[0m | time: 56.333s
[2K| Adam | epoch: 006 | loss: 0.80954 - acc: 0.7079 -- iter: 04672/10000
[A[ATraining Step: 859  | total loss: [1m[32m0.81294[0m[0m | time: 57.071s
[2K| Adam | epoch: 006 | loss: 0.81294 - acc: 0.7058 -- iter: 04736/10000
[A[ATraining Step: 860  | total loss: [1m[32m0.82645[0m[0m | time: 57.820s
[2K| Adam | epoch: 006 | loss: 0.82645 - acc: 0.6993 -- iter: 04800/10000
[A[ATraining Step: 861  | total loss: [1m[32m0.83078[0m[0m | time: 58.594s
[2K| Adam | epoch: 006 | loss: 0.83078 - acc: 0.6997 -- iter: 04864/10000
[A[ATraining Step: 862  | total loss: [1m[32m0.82803[0m[0m | time: 59.333s
[2K| Adam | epoch: 006 | loss: 0.82803 - acc: 0.7016 -- iter: 04928/10000
[A[ATraining Step: 863  | total loss: [1m[32m0.81508[0m[0m | time: 60.089s
[2K| Adam | epoch: 006 | loss: 0.81508 - acc: 0.7127 -- iter: 04992/10000
[A[ATraining Step: 864  | total loss: [1m[32m0.85450[0m[0m | time: 60.839s
[2K| Adam | epoch: 006 | loss: 0.85450 - acc: 0.7070 -- iter: 05056/10000
[A[ATraining Step: 865  | total loss: [1m[32m0.85573[0m[0m | time: 61.615s
[2K| Adam | epoch: 006 | loss: 0.85573 - acc: 0.7113 -- iter: 05120/10000
[A[ATraining Step: 866  | total loss: [1m[32m0.83871[0m[0m | time: 62.411s
[2K| Adam | epoch: 006 | loss: 0.83871 - acc: 0.7183 -- iter: 05184/10000
[A[ATraining Step: 867  | total loss: [1m[32m0.82289[0m[0m | time: 63.250s
[2K| Adam | epoch: 006 | loss: 0.82289 - acc: 0.7168 -- iter: 05248/10000
[A[ATraining Step: 868  | total loss: [1m[32m0.81037[0m[0m | time: 64.089s
[2K| Adam | epoch: 006 | loss: 0.81037 - acc: 0.7201 -- iter: 05312/10000
[A[ATraining Step: 869  | total loss: [1m[32m0.79642[0m[0m | time: 64.929s
[2K| Adam | epoch: 006 | loss: 0.79642 - acc: 0.7215 -- iter: 05376/10000
[A[ATraining Step: 870  | total loss: [1m[32m0.80732[0m[0m | time: 65.783s
[2K| Adam | epoch: 006 | loss: 0.80732 - acc: 0.7135 -- iter: 05440/10000
[A[ATraining Step: 871  | total loss: [1m[32m0.78853[0m[0m | time: 66.626s
[2K| Adam | epoch: 006 | loss: 0.78853 - acc: 0.7187 -- iter: 05504/10000
[A[ATraining Step: 872  | total loss: [1m[32m0.75350[0m[0m | time: 67.435s
[2K| Adam | epoch: 006 | loss: 0.75350 - acc: 0.7421 -- iter: 05568/10000
[A[ATraining Step: 873  | total loss: [1m[32m0.73418[0m[0m | time: 68.228s
[2K| Adam | epoch: 006 | loss: 0.73418 - acc: 0.7429 -- iter: 05632/10000
[A[ATraining Step: 874  | total loss: [1m[32m0.72639[0m[0m | time: 69.029s
[2K| Adam | epoch: 006 | loss: 0.72639 - acc: 0.7467 -- iter: 05696/10000
[A[ATraining Step: 875  | total loss: [1m[32m0.71461[0m[0m | time: 69.806s
[2K| Adam | epoch: 006 | loss: 0.71461 - acc: 0.7533 -- iter: 05760/10000
[A[ATraining Step: 876  | total loss: [1m[32m0.72468[0m[0m | time: 70.647s
[2K| Adam | epoch: 006 | loss: 0.72468 - acc: 0.7514 -- iter: 05824/10000
[A[ATraining Step: 877  | total loss: [1m[32m0.72102[0m[0m | time: 71.452s
[2K| Adam | epoch: 006 | loss: 0.72102 - acc: 0.7497 -- iter: 05888/10000
[A[ATraining Step: 878  | total loss: [1m[32m0.74128[0m[0m | time: 72.254s
[2K| Adam | epoch: 006 | loss: 0.74128 - acc: 0.7357 -- iter: 05952/10000
[A[ATraining Step: 879  | total loss: [1m[32m0.73441[0m[0m | time: 73.026s
[2K| Adam | epoch: 006 | loss: 0.73441 - acc: 0.7371 -- iter: 06016/10000
[A[ATraining Step: 880  | total loss: [1m[32m0.76295[0m[0m | time: 73.795s
[2K| Adam | epoch: 006 | loss: 0.76295 - acc: 0.7243 -- iter: 06080/10000
[A[ATraining Step: 881  | total loss: [1m[32m0.76488[0m[0m | time: 74.569s
[2K| Adam | epoch: 006 | loss: 0.76488 - acc: 0.7269 -- iter: 06144/10000
[A[ATraining Step: 882  | total loss: [1m[32m0.79079[0m[0m | time: 75.334s
[2K| Adam | epoch: 006 | loss: 0.79079 - acc: 0.7152 -- iter: 06208/10000
[A[ATraining Step: 883  | total loss: [1m[32m0.79715[0m[0m | time: 76.146s
[2K| Adam | epoch: 006 | loss: 0.79715 - acc: 0.7186 -- iter: 06272/10000
[A[ATraining Step: 884  | total loss: [1m[32m0.80195[0m[0m | time: 76.919s
[2K| Adam | epoch: 006 | loss: 0.80195 - acc: 0.7202 -- iter: 06336/10000
[A[ATraining Step: 885  | total loss: [1m[32m0.79409[0m[0m | time: 77.691s
[2K| Adam | epoch: 006 | loss: 0.79409 - acc: 0.7201 -- iter: 06400/10000
[A[ATraining Step: 886  | total loss: [1m[32m0.77668[0m[0m | time: 78.475s
[2K| Adam | epoch: 006 | loss: 0.77668 - acc: 0.7231 -- iter: 06464/10000
[A[ATraining Step: 887  | total loss: [1m[32m0.75564[0m[0m | time: 79.253s
[2K| Adam | epoch: 006 | loss: 0.75564 - acc: 0.7320 -- iter: 06528/10000
[A[ATraining Step: 888  | total loss: [1m[32m0.75688[0m[0m | time: 80.051s
[2K| Adam | epoch: 006 | loss: 0.75688 - acc: 0.7385 -- iter: 06592/10000
[A[ATraining Step: 889  | total loss: [1m[32m0.76416[0m[0m | time: 81.099s
[2K| Adam | epoch: 006 | loss: 0.76416 - acc: 0.7350 -- iter: 06656/10000
[A[ATraining Step: 890  | total loss: [1m[32m0.78434[0m[0m | time: 82.232s
[2K| Adam | epoch: 006 | loss: 0.78434 - acc: 0.7286 -- iter: 06720/10000
[A[ATraining Step: 891  | total loss: [1m[32m0.77620[0m[0m | time: 83.060s
[2K| Adam | epoch: 006 | loss: 0.77620 - acc: 0.7261 -- iter: 06784/10000
[A[ATraining Step: 892  | total loss: [1m[32m0.77230[0m[0m | time: 84.024s
[2K| Adam | epoch: 006 | loss: 0.77230 - acc: 0.7332 -- iter: 06848/10000
[A[ATraining Step: 893  | total loss: [1m[32m0.76536[0m[0m | time: 85.085s
[2K| Adam | epoch: 006 | loss: 0.76536 - acc: 0.7349 -- iter: 06912/10000
[A[ATraining Step: 894  | total loss: [1m[32m0.77093[0m[0m | time: 86.079s
[2K| Adam | epoch: 006 | loss: 0.77093 - acc: 0.7364 -- iter: 06976/10000
[A[ATraining Step: 895  | total loss: [1m[32m0.76544[0m[0m | time: 87.145s
[2K| Adam | epoch: 006 | loss: 0.76544 - acc: 0.7393 -- iter: 07040/10000
[A[ATraining Step: 896  | total loss: [1m[32m0.76888[0m[0m | time: 88.192s
[2K| Adam | epoch: 006 | loss: 0.76888 - acc: 0.7404 -- iter: 07104/10000
[A[ATraining Step: 897  | total loss: [1m[32m0.77944[0m[0m | time: 89.168s
[2K| Adam | epoch: 006 | loss: 0.77944 - acc: 0.7335 -- iter: 07168/10000
[A[ATraining Step: 898  | total loss: [1m[32m0.77819[0m[0m | time: 90.253s
[2K| Adam | epoch: 006 | loss: 0.77819 - acc: 0.7289 -- iter: 07232/10000
[A[ATraining Step: 899  | total loss: [1m[32m0.76461[0m[0m | time: 91.341s
[2K| Adam | epoch: 006 | loss: 0.76461 - acc: 0.7295 -- iter: 07296/10000
[A[ATraining Step: 900  | total loss: [1m[32m0.74662[0m[0m | time: 97.119s
[2K| Adam | epoch: 006 | loss: 0.74662 - acc: 0.7331 | val_loss: 1.60766 - val_acc: 0.4757 -- iter: 07360/10000
--
Training Step: 901  | total loss: [1m[32m0.74156[0m[0m | time: 98.718s
[2K| Adam | epoch: 006 | loss: 0.74156 - acc: 0.7348 -- iter: 07424/10000
[A[ATraining Step: 902  | total loss: [1m[32m0.74096[0m[0m | time: 99.987s
[2K| Adam | epoch: 006 | loss: 0.74096 - acc: 0.7394 -- iter: 07488/10000
[A[ATraining Step: 903  | total loss: [1m[32m0.73946[0m[0m | time: 101.224s
[2K| Adam | epoch: 006 | loss: 0.73946 - acc: 0.7389 -- iter: 07552/10000
[A[ATraining Step: 904  | total loss: [1m[32m0.72631[0m[0m | time: 102.617s
[2K| Adam | epoch: 006 | loss: 0.72631 - acc: 0.7431 -- iter: 07616/10000
[A[ATraining Step: 905  | total loss: [1m[32m0.74145[0m[0m | time: 103.878s
[2K| Adam | epoch: 006 | loss: 0.74145 - acc: 0.7376 -- iter: 07680/10000
[A[ATraining Step: 906  | total loss: [1m[32m0.73747[0m[0m | time: 104.982s
[2K| Adam | epoch: 006 | loss: 0.73747 - acc: 0.7466 -- iter: 07744/10000
[A[ATraining Step: 907  | total loss: [1m[32m0.74016[0m[0m | time: 106.097s
[2K| Adam | epoch: 006 | loss: 0.74016 - acc: 0.7454 -- iter: 07808/10000
[A[ATraining Step: 908  | total loss: [1m[32m0.73044[0m[0m | time: 107.085s
[2K| Adam | epoch: 006 | loss: 0.73044 - acc: 0.7537 -- iter: 07872/10000
[A[ATraining Step: 909  | total loss: [1m[32m0.74958[0m[0m | time: 108.035s
[2K| Adam | epoch: 006 | loss: 0.74958 - acc: 0.7408 -- iter: 07936/10000
[A[ATraining Step: 910  | total loss: [1m[32m0.73165[0m[0m | time: 108.966s
[2K| Adam | epoch: 006 | loss: 0.73165 - acc: 0.7480 -- iter: 08000/10000
[A[ATraining Step: 911  | total loss: [1m[32m0.72530[0m[0m | time: 109.833s
[2K| Adam | epoch: 006 | loss: 0.72530 - acc: 0.7497 -- iter: 08064/10000
[A[ATraining Step: 912  | total loss: [1m[32m0.73505[0m[0m | time: 110.739s
[2K| Adam | epoch: 006 | loss: 0.73505 - acc: 0.7529 -- iter: 08128/10000
[A[ATraining Step: 913  | total loss: [1m[32m0.73561[0m[0m | time: 111.669s
[2K| Adam | epoch: 006 | loss: 0.73561 - acc: 0.7557 -- iter: 08192/10000
[A[ATraining Step: 914  | total loss: [1m[32m0.74531[0m[0m | time: 112.610s
[2K| Adam | epoch: 006 | loss: 0.74531 - acc: 0.7552 -- iter: 08256/10000
[A[ATraining Step: 915  | total loss: [1m[32m0.75490[0m[0m | time: 113.466s
[2K| Adam | epoch: 006 | loss: 0.75490 - acc: 0.7546 -- iter: 08320/10000
[A[ATraining Step: 916  | total loss: [1m[32m1.40865[0m[0m | time: 114.357s
[2K| Adam | epoch: 006 | loss: 1.40865 - acc: 0.6948 -- iter: 08384/10000
[A[ATraining Step: 917  | total loss: [1m[32m1.33051[0m[0m | time: 115.269s
[2K| Adam | epoch: 006 | loss: 1.33051 - acc: 0.6972 -- iter: 08448/10000
[A[ATraining Step: 918  | total loss: [1m[32m1.29207[0m[0m | time: 116.135s
[2K| Adam | epoch: 006 | loss: 1.29207 - acc: 0.6962 -- iter: 08512/10000
[A[ATraining Step: 919  | total loss: [1m[32m1.23787[0m[0m | time: 116.986s
[2K| Adam | epoch: 006 | loss: 1.23787 - acc: 0.7000 -- iter: 08576/10000
[A[ATraining Step: 920  | total loss: [1m[32m1.17977[0m[0m | time: 117.836s
[2K| Adam | epoch: 006 | loss: 1.17977 - acc: 0.7050 -- iter: 08640/10000
[A[ATraining Step: 921  | total loss: [1m[32m1.12191[0m[0m | time: 118.705s
[2K| Adam | epoch: 006 | loss: 1.12191 - acc: 0.7111 -- iter: 08704/10000
[A[ATraining Step: 922  | total loss: [1m[32m1.10453[0m[0m | time: 119.506s
[2K| Adam | epoch: 006 | loss: 1.10453 - acc: 0.7056 -- iter: 08768/10000
[A[ATraining Step: 923  | total loss: [1m[32m1.07396[0m[0m | time: 120.348s
[2K| Adam | epoch: 006 | loss: 1.07396 - acc: 0.7007 -- iter: 08832/10000
[A[ATraining Step: 924  | total loss: [1m[32m1.03405[0m[0m | time: 121.199s
[2K| Adam | epoch: 006 | loss: 1.03405 - acc: 0.7025 -- iter: 08896/10000
[A[ATraining Step: 925  | total loss: [1m[32m1.00884[0m[0m | time: 122.034s
[2K| Adam | epoch: 006 | loss: 1.00884 - acc: 0.7072 -- iter: 08960/10000
[A[ATraining Step: 926  | total loss: [1m[32m0.98915[0m[0m | time: 122.887s
[2K| Adam | epoch: 006 | loss: 0.98915 - acc: 0.7053 -- iter: 09024/10000
[A[ATraining Step: 927  | total loss: [1m[32m0.96263[0m[0m | time: 123.721s
[2K| Adam | epoch: 006 | loss: 0.96263 - acc: 0.7113 -- iter: 09088/10000
[A[ATraining Step: 928  | total loss: [1m[32m0.93529[0m[0m | time: 124.519s
[2K| Adam | epoch: 006 | loss: 0.93529 - acc: 0.7120 -- iter: 09152/10000
[A[ATraining Step: 929  | total loss: [1m[32m0.92554[0m[0m | time: 125.327s
[2K| Adam | epoch: 006 | loss: 0.92554 - acc: 0.7127 -- iter: 09216/10000
[A[ATraining Step: 930  | total loss: [1m[32m0.92119[0m[0m | time: 126.133s
[2K| Adam | epoch: 006 | loss: 0.92119 - acc: 0.7086 -- iter: 09280/10000
[A[ATraining Step: 931  | total loss: [1m[32m0.90143[0m[0m | time: 126.980s
[2K| Adam | epoch: 006 | loss: 0.90143 - acc: 0.7065 -- iter: 09344/10000
[A[ATraining Step: 932  | total loss: [1m[32m0.89350[0m[0m | time: 127.772s
[2K| Adam | epoch: 006 | loss: 0.89350 - acc: 0.7015 -- iter: 09408/10000
[A[ATraining Step: 933  | total loss: [1m[32m0.91940[0m[0m | time: 128.652s
[2K| Adam | epoch: 006 | loss: 0.91940 - acc: 0.6970 -- iter: 09472/10000
[A[ATraining Step: 934  | total loss: [1m[32m0.94478[0m[0m | time: 129.470s
[2K| Adam | epoch: 006 | loss: 0.94478 - acc: 0.6851 -- iter: 09536/10000
[A[ATraining Step: 935  | total loss: [1m[32m0.95653[0m[0m | time: 130.483s
[2K| Adam | epoch: 006 | loss: 0.95653 - acc: 0.6744 -- iter: 09600/10000
[A[ATraining Step: 936  | total loss: [1m[32m0.94095[0m[0m | time: 131.377s
[2K| Adam | epoch: 006 | loss: 0.94095 - acc: 0.6804 -- iter: 09664/10000
[A[ATraining Step: 937  | total loss: [1m[32m0.92013[0m[0m | time: 132.305s
[2K| Adam | epoch: 006 | loss: 0.92013 - acc: 0.6905 -- iter: 09728/10000
[A[ATraining Step: 938  | total loss: [1m[32m0.89452[0m[0m | time: 133.250s
[2K| Adam | epoch: 006 | loss: 0.89452 - acc: 0.6964 -- iter: 09792/10000
[A[ATraining Step: 939  | total loss: [1m[32m0.88562[0m[0m | time: 134.187s
[2K| Adam | epoch: 006 | loss: 0.88562 - acc: 0.6955 -- iter: 09856/10000
[A[ATraining Step: 940  | total loss: [1m[32m0.84345[0m[0m | time: 135.102s
[2K| Adam | epoch: 006 | loss: 0.84345 - acc: 0.7104 -- iter: 09920/10000
[A[ATraining Step: 941  | total loss: [1m[32m0.85361[0m[0m | time: 136.039s
[2K| Adam | epoch: 006 | loss: 0.85361 - acc: 0.7128 -- iter: 09984/10000
[A[ATraining Step: 942  | total loss: [1m[32m0.81855[0m[0m | time: 139.520s
[2K| Adam | epoch: 006 | loss: 0.81855 - acc: 0.7227 | val_loss: 1.54712 - val_acc: 0.4600 -- iter: 10000/10000
--
Training Step: 943  | total loss: [1m[32m0.82689[0m[0m | time: 0.893s
[2K| Adam | epoch: 007 | loss: 0.82689 - acc: 0.7208 -- iter: 00064/10000
[A[ATraining Step: 944  | total loss: [1m[32m0.81938[0m[0m | time: 1.778s
[2K| Adam | epoch: 007 | loss: 0.81938 - acc: 0.7284 -- iter: 00128/10000
[A[ATraining Step: 945  | total loss: [1m[32m0.81305[0m[0m | time: 2.677s
[2K| Adam | epoch: 007 | loss: 0.81305 - acc: 0.7259 -- iter: 00192/10000
[A[ATraining Step: 946  | total loss: [1m[32m0.80856[0m[0m | time: 3.559s
[2K| Adam | epoch: 007 | loss: 0.80856 - acc: 0.7267 -- iter: 00256/10000
[A[ATraining Step: 947  | total loss: [1m[32m0.79870[0m[0m | time: 3.972s
[2K| Adam | epoch: 007 | loss: 0.79870 - acc: 0.7259 -- iter: 00320/10000
[A[ATraining Step: 948  | total loss: [1m[32m0.81596[0m[0m | time: 4.340s
[2K| Adam | epoch: 007 | loss: 0.81596 - acc: 0.7158 -- iter: 00384/10000
[A[ATraining Step: 949  | total loss: [1m[32m0.82052[0m[0m | time: 5.155s
[2K| Adam | epoch: 007 | loss: 0.82052 - acc: 0.7067 -- iter: 00448/10000
[A[ATraining Step: 950  | total loss: [1m[32m0.80214[0m[0m | time: 6.009s
[2K| Adam | epoch: 007 | loss: 0.80214 - acc: 0.7142 -- iter: 00512/10000
[A[ATraining Step: 951  | total loss: [1m[32m0.78213[0m[0m | time: 6.853s
[2K| Adam | epoch: 007 | loss: 0.78213 - acc: 0.7271 -- iter: 00576/10000
[A[ATraining Step: 952  | total loss: [1m[32m0.76166[0m[0m | time: 7.666s
[2K| Adam | epoch: 007 | loss: 0.76166 - acc: 0.7310 -- iter: 00640/10000
[A[ATraining Step: 953  | total loss: [1m[32m0.76993[0m[0m | time: 8.468s
[2K| Adam | epoch: 007 | loss: 0.76993 - acc: 0.7220 -- iter: 00704/10000
[A[ATraining Step: 954  | total loss: [1m[32m0.76965[0m[0m | time: 9.290s
[2K| Adam | epoch: 007 | loss: 0.76965 - acc: 0.7232 -- iter: 00768/10000
[A[ATraining Step: 955  | total loss: [1m[32m0.79284[0m[0m | time: 10.095s
[2K| Adam | epoch: 007 | loss: 0.79284 - acc: 0.7134 -- iter: 00832/10000
[A[ATraining Step: 956  | total loss: [1m[32m0.78145[0m[0m | time: 10.915s
[2K| Adam | epoch: 007 | loss: 0.78145 - acc: 0.7233 -- iter: 00896/10000
[A[ATraining Step: 957  | total loss: [1m[32m0.77510[0m[0m | time: 11.716s
[2K| Adam | epoch: 007 | loss: 0.77510 - acc: 0.7369 -- iter: 00960/10000
[A[ATraining Step: 958  | total loss: [1m[32m0.77937[0m[0m | time: 12.516s
[2K| Adam | epoch: 007 | loss: 0.77937 - acc: 0.7382 -- iter: 01024/10000
[A[ATraining Step: 959  | total loss: [1m[32m0.79824[0m[0m | time: 13.313s
[2K| Adam | epoch: 007 | loss: 0.79824 - acc: 0.7316 -- iter: 01088/10000
[A[ATraining Step: 960  | total loss: [1m[32m0.79661[0m[0m | time: 14.113s
[2K| Adam | epoch: 007 | loss: 0.79661 - acc: 0.7334 -- iter: 01152/10000
[A[ATraining Step: 961  | total loss: [1m[32m0.80318[0m[0m | time: 14.921s
[2K| Adam | epoch: 007 | loss: 0.80318 - acc: 0.7288 -- iter: 01216/10000
[A[ATraining Step: 962  | total loss: [1m[32m0.81409[0m[0m | time: 15.714s
[2K| Adam | epoch: 007 | loss: 0.81409 - acc: 0.7200 -- iter: 01280/10000
[A[ATraining Step: 963  | total loss: [1m[32m0.80012[0m[0m | time: 16.521s
[2K| Adam | epoch: 007 | loss: 0.80012 - acc: 0.7277 -- iter: 01344/10000
[A[ATraining Step: 964  | total loss: [1m[32m0.77160[0m[0m | time: 17.323s
[2K| Adam | epoch: 007 | loss: 0.77160 - acc: 0.7284 -- iter: 01408/10000
[A[ATraining Step: 965  | total loss: [1m[32m0.76026[0m[0m | time: 18.121s
[2K| Adam | epoch: 007 | loss: 0.76026 - acc: 0.7352 -- iter: 01472/10000
[A[ATraining Step: 966  | total loss: [1m[32m0.75039[0m[0m | time: 18.952s
[2K| Adam | epoch: 007 | loss: 0.75039 - acc: 0.7367 -- iter: 01536/10000
[A[ATraining Step: 967  | total loss: [1m[32m0.76902[0m[0m | time: 19.753s
[2K| Adam | epoch: 007 | loss: 0.76902 - acc: 0.7318 -- iter: 01600/10000
[A[ATraining Step: 968  | total loss: [1m[32m0.74876[0m[0m | time: 20.560s
[2K| Adam | epoch: 007 | loss: 0.74876 - acc: 0.7398 -- iter: 01664/10000
[A[ATraining Step: 969  | total loss: [1m[32m0.73977[0m[0m | time: 21.367s
[2K| Adam | epoch: 007 | loss: 0.73977 - acc: 0.7424 -- iter: 01728/10000
[A[ATraining Step: 970  | total loss: [1m[32m0.73221[0m[0m | time: 22.180s
[2K| Adam | epoch: 007 | loss: 0.73221 - acc: 0.7401 -- iter: 01792/10000
[A[ATraining Step: 971  | total loss: [1m[32m0.72627[0m[0m | time: 22.983s
[2K| Adam | epoch: 007 | loss: 0.72627 - acc: 0.7457 -- iter: 01856/10000
[A[ATraining Step: 972  | total loss: [1m[32m0.73065[0m[0m | time: 23.788s
[2K| Adam | epoch: 007 | loss: 0.73065 - acc: 0.7415 -- iter: 01920/10000
[A[ATraining Step: 973  | total loss: [1m[32m0.71745[0m[0m | time: 24.597s
[2K| Adam | epoch: 007 | loss: 0.71745 - acc: 0.7423 -- iter: 01984/10000
[A[ATraining Step: 974  | total loss: [1m[32m0.71438[0m[0m | time: 25.402s
[2K| Adam | epoch: 007 | loss: 0.71438 - acc: 0.7400 -- iter: 02048/10000
[A[ATraining Step: 975  | total loss: [1m[32m0.72902[0m[0m | time: 26.215s
[2K| Adam | epoch: 007 | loss: 0.72902 - acc: 0.7363 -- iter: 02112/10000
[A[ATraining Step: 976  | total loss: [1m[32m0.73651[0m[0m | time: 27.019s
[2K| Adam | epoch: 007 | loss: 0.73651 - acc: 0.7439 -- iter: 02176/10000
[A[ATraining Step: 977  | total loss: [1m[32m0.75639[0m[0m | time: 27.820s
[2K| Adam | epoch: 007 | loss: 0.75639 - acc: 0.7445 -- iter: 02240/10000
[A[ATraining Step: 978  | total loss: [1m[32m0.77534[0m[0m | time: 28.636s
[2K| Adam | epoch: 007 | loss: 0.77534 - acc: 0.7451 -- iter: 02304/10000
[A[ATraining Step: 979  | total loss: [1m[32m0.77982[0m[0m | time: 29.436s
[2K| Adam | epoch: 007 | loss: 0.77982 - acc: 0.7393 -- iter: 02368/10000
[A[ATraining Step: 980  | total loss: [1m[32m0.77315[0m[0m | time: 30.222s
[2K| Adam | epoch: 007 | loss: 0.77315 - acc: 0.7388 -- iter: 02432/10000
[A[ATraining Step: 981  | total loss: [1m[32m0.76465[0m[0m | time: 30.987s
[2K| Adam | epoch: 007 | loss: 0.76465 - acc: 0.7493 -- iter: 02496/10000
[A[ATraining Step: 982  | total loss: [1m[32m0.74791[0m[0m | time: 31.751s
[2K| Adam | epoch: 007 | loss: 0.74791 - acc: 0.7478 -- iter: 02560/10000
[A[ATraining Step: 983  | total loss: [1m[32m0.73571[0m[0m | time: 32.515s
[2K| Adam | epoch: 007 | loss: 0.73571 - acc: 0.7527 -- iter: 02624/10000
[A[ATraining Step: 984  | total loss: [1m[32m0.73119[0m[0m | time: 33.293s
[2K| Adam | epoch: 007 | loss: 0.73119 - acc: 0.7524 -- iter: 02688/10000
[A[ATraining Step: 985  | total loss: [1m[32m0.73416[0m[0m | time: 34.052s
[2K| Adam | epoch: 007 | loss: 0.73416 - acc: 0.7506 -- iter: 02752/10000
[A[ATraining Step: 986  | total loss: [1m[32m0.73643[0m[0m | time: 34.817s
[2K| Adam | epoch: 007 | loss: 0.73643 - acc: 0.7521 -- iter: 02816/10000
[A[ATraining Step: 987  | total loss: [1m[32m0.73285[0m[0m | time: 35.578s
[2K| Adam | epoch: 007 | loss: 0.73285 - acc: 0.7472 -- iter: 02880/10000
[A[ATraining Step: 988  | total loss: [1m[32m0.76715[0m[0m | time: 36.347s
[2K| Adam | epoch: 007 | loss: 0.76715 - acc: 0.7256 -- iter: 02944/10000
[A[ATraining Step: 989  | total loss: [1m[32m0.76847[0m[0m | time: 37.130s
[2K| Adam | epoch: 007 | loss: 0.76847 - acc: 0.7203 -- iter: 03008/10000
[A[ATraining Step: 990  | total loss: [1m[32m0.75931[0m[0m | time: 37.904s
[2K| Adam | epoch: 007 | loss: 0.75931 - acc: 0.7232 -- iter: 03072/10000
[A[ATraining Step: 991  | total loss: [1m[32m0.75850[0m[0m | time: 38.701s
[2K| Adam | epoch: 007 | loss: 0.75850 - acc: 0.7244 -- iter: 03136/10000
[A[ATraining Step: 992  | total loss: [1m[32m0.74947[0m[0m | time: 39.450s
[2K| Adam | epoch: 007 | loss: 0.74947 - acc: 0.7269 -- iter: 03200/10000
[A[ATraining Step: 993  | total loss: [1m[32m0.76987[0m[0m | time: 40.227s
[2K| Adam | epoch: 007 | loss: 0.76987 - acc: 0.7323 -- iter: 03264/10000
[A[ATraining Step: 994  | total loss: [1m[32m0.74426[0m[0m | time: 40.994s
[2K| Adam | epoch: 007 | loss: 0.74426 - acc: 0.7497 -- iter: 03328/10000
[A[ATraining Step: 995  | total loss: [1m[32m0.75081[0m[0m | time: 41.759s
[2K| Adam | epoch: 007 | loss: 0.75081 - acc: 0.7420 -- iter: 03392/10000
[A[ATraining Step: 996  | total loss: [1m[32m0.74222[0m[0m | time: 42.533s
[2K| Adam | epoch: 007 | loss: 0.74222 - acc: 0.7412 -- iter: 03456/10000
[A[ATraining Step: 997  | total loss: [1m[32m0.74124[0m[0m | time: 43.327s
[2K| Adam | epoch: 007 | loss: 0.74124 - acc: 0.7374 -- iter: 03520/10000
[A[ATraining Step: 998  | total loss: [1m[32m0.73119[0m[0m | time: 44.120s
[2K| Adam | epoch: 007 | loss: 0.73119 - acc: 0.7355 -- iter: 03584/10000
[A[ATraining Step: 999  | total loss: [1m[32m0.70877[0m[0m | time: 44.917s
[2K| Adam | epoch: 007 | loss: 0.70877 - acc: 0.7370 -- iter: 03648/10000
[A[ATraining Step: 1000  | total loss: [1m[32m0.71374[0m[0m | time: 47.747s
[2K| Adam | epoch: 007 | loss: 0.71374 - acc: 0.7336 | val_loss: 1.35114 - val_acc: 0.4929 -- iter: 03712/10000
--
Training Step: 1001  | total loss: [1m[32m0.70815[0m[0m | time: 48.534s
[2K| Adam | epoch: 007 | loss: 0.70815 - acc: 0.7368 -- iter: 03776/10000
[A[ATraining Step: 1002  | total loss: [1m[32m0.71185[0m[0m | time: 49.348s
[2K| Adam | epoch: 007 | loss: 0.71185 - acc: 0.7381 -- iter: 03840/10000
[A[ATraining Step: 1003  | total loss: [1m[32m0.72061[0m[0m | time: 50.160s
[2K| Adam | epoch: 007 | loss: 0.72061 - acc: 0.7393 -- iter: 03904/10000
[A[ATraining Step: 1004  | total loss: [1m[32m0.73481[0m[0m | time: 50.967s
[2K| Adam | epoch: 007 | loss: 0.73481 - acc: 0.7326 -- iter: 03968/10000
[A[ATraining Step: 1005  | total loss: [1m[32m0.74119[0m[0m | time: 51.769s
[2K| Adam | epoch: 007 | loss: 0.74119 - acc: 0.7296 -- iter: 04032/10000
[A[ATraining Step: 1006  | total loss: [1m[32m0.76185[0m[0m | time: 52.565s
[2K| Adam | epoch: 007 | loss: 0.76185 - acc: 0.7207 -- iter: 04096/10000
[A[ATraining Step: 1007  | total loss: [1m[32m0.76830[0m[0m | time: 53.345s
[2K| Adam | epoch: 007 | loss: 0.76830 - acc: 0.7174 -- iter: 04160/10000
[A[ATraining Step: 1008  | total loss: [1m[32m0.74697[0m[0m | time: 54.122s
[2K| Adam | epoch: 007 | loss: 0.74697 - acc: 0.7285 -- iter: 04224/10000
[A[ATraining Step: 1009  | total loss: [1m[32m0.73457[0m[0m | time: 54.887s
[2K| Adam | epoch: 007 | loss: 0.73457 - acc: 0.7353 -- iter: 04288/10000
[A[ATraining Step: 1010  | total loss: [1m[32m0.72377[0m[0m | time: 55.653s
[2K| Adam | epoch: 007 | loss: 0.72377 - acc: 0.7399 -- iter: 04352/10000
[A[ATraining Step: 1011  | total loss: [1m[32m0.71749[0m[0m | time: 56.425s
[2K| Adam | epoch: 007 | loss: 0.71749 - acc: 0.7440 -- iter: 04416/10000
[A[ATraining Step: 1012  | total loss: [1m[32m0.72467[0m[0m | time: 57.191s
[2K| Adam | epoch: 007 | loss: 0.72467 - acc: 0.7368 -- iter: 04480/10000
[A[ATraining Step: 1013  | total loss: [1m[32m0.71417[0m[0m | time: 57.955s
[2K| Adam | epoch: 007 | loss: 0.71417 - acc: 0.7366 -- iter: 04544/10000
[A[ATraining Step: 1014  | total loss: [1m[32m0.68924[0m[0m | time: 58.735s
[2K| Adam | epoch: 007 | loss: 0.68924 - acc: 0.7504 -- iter: 04608/10000
[A[ATraining Step: 1015  | total loss: [1m[32m0.68752[0m[0m | time: 59.505s
[2K| Adam | epoch: 007 | loss: 0.68752 - acc: 0.7504 -- iter: 04672/10000
[A[ATraining Step: 1016  | total loss: [1m[32m0.68012[0m[0m | time: 60.268s
[2K| Adam | epoch: 007 | loss: 0.68012 - acc: 0.7503 -- iter: 04736/10000
[A[ATraining Step: 1017  | total loss: [1m[32m0.66958[0m[0m | time: 61.024s
[2K| Adam | epoch: 007 | loss: 0.66958 - acc: 0.7534 -- iter: 04800/10000
[A[ATraining Step: 1018  | total loss: [1m[32m0.68165[0m[0m | time: 61.789s
[2K| Adam | epoch: 007 | loss: 0.68165 - acc: 0.7562 -- iter: 04864/10000
[A[ATraining Step: 1019  | total loss: [1m[32m0.69789[0m[0m | time: 62.551s
[2K| Adam | epoch: 007 | loss: 0.69789 - acc: 0.7493 -- iter: 04928/10000
[A[ATraining Step: 1020  | total loss: [1m[32m0.70821[0m[0m | time: 63.320s
[2K| Adam | epoch: 007 | loss: 0.70821 - acc: 0.7463 -- iter: 04992/10000
[A[ATraining Step: 1021  | total loss: [1m[32m0.71054[0m[0m | time: 64.091s
[2K| Adam | epoch: 007 | loss: 0.71054 - acc: 0.7482 -- iter: 05056/10000
[A[ATraining Step: 1022  | total loss: [1m[32m0.70814[0m[0m | time: 64.867s
[2K| Adam | epoch: 007 | loss: 0.70814 - acc: 0.7406 -- iter: 05120/10000
[A[ATraining Step: 1023  | total loss: [1m[32m0.70138[0m[0m | time: 65.636s
[2K| Adam | epoch: 007 | loss: 0.70138 - acc: 0.7431 -- iter: 05184/10000
[A[ATraining Step: 1024  | total loss: [1m[32m0.70744[0m[0m | time: 66.406s
[2K| Adam | epoch: 007 | loss: 0.70744 - acc: 0.7453 -- iter: 05248/10000
[A[ATraining Step: 1025  | total loss: [1m[32m0.70271[0m[0m | time: 67.170s
[2K| Adam | epoch: 007 | loss: 0.70271 - acc: 0.7442 -- iter: 05312/10000
[A[ATraining Step: 1026  | total loss: [1m[32m0.72575[0m[0m | time: 67.932s
[2K| Adam | epoch: 007 | loss: 0.72575 - acc: 0.7370 -- iter: 05376/10000
[A[ATraining Step: 1027  | total loss: [1m[32m0.70337[0m[0m | time: 68.716s
[2K| Adam | epoch: 007 | loss: 0.70337 - acc: 0.7446 -- iter: 05440/10000
[A[ATraining Step: 1028  | total loss: [1m[32m0.70753[0m[0m | time: 69.488s
[2K| Adam | epoch: 007 | loss: 0.70753 - acc: 0.7451 -- iter: 05504/10000
[A[ATraining Step: 1029  | total loss: [1m[32m0.72048[0m[0m | time: 70.252s
[2K| Adam | epoch: 007 | loss: 0.72048 - acc: 0.7331 -- iter: 05568/10000
[A[ATraining Step: 1030  | total loss: [1m[32m0.73540[0m[0m | time: 71.016s
[2K| Adam | epoch: 007 | loss: 0.73540 - acc: 0.7285 -- iter: 05632/10000
[A[ATraining Step: 1031  | total loss: [1m[32m0.76473[0m[0m | time: 71.777s
[2K| Adam | epoch: 007 | loss: 0.76473 - acc: 0.7244 -- iter: 05696/10000
[A[ATraining Step: 1032  | total loss: [1m[32m0.74832[0m[0m | time: 72.542s
[2K| Adam | epoch: 007 | loss: 0.74832 - acc: 0.7301 -- iter: 05760/10000
[A[ATraining Step: 1033  | total loss: [1m[32m0.74172[0m[0m | time: 73.308s
[2K| Adam | epoch: 007 | loss: 0.74172 - acc: 0.7305 -- iter: 05824/10000
[A[ATraining Step: 1034  | total loss: [1m[32m0.76983[0m[0m | time: 74.078s
[2K| Adam | epoch: 007 | loss: 0.76983 - acc: 0.7231 -- iter: 05888/10000
[A[ATraining Step: 1035  | total loss: [1m[32m0.76179[0m[0m | time: 74.860s
[2K| Adam | epoch: 007 | loss: 0.76179 - acc: 0.7211 -- iter: 05952/10000
[A[ATraining Step: 1036  | total loss: [1m[32m0.77434[0m[0m | time: 75.637s
[2K| Adam | epoch: 007 | loss: 0.77434 - acc: 0.7256 -- iter: 06016/10000
[A[ATraining Step: 1037  | total loss: [1m[32m0.75414[0m[0m | time: 76.417s
[2K| Adam | epoch: 007 | loss: 0.75414 - acc: 0.7311 -- iter: 06080/10000
[A[ATraining Step: 1038  | total loss: [1m[32m0.75697[0m[0m | time: 77.187s
[2K| Adam | epoch: 007 | loss: 0.75697 - acc: 0.7268 -- iter: 06144/10000
[A[ATraining Step: 1039  | total loss: [1m[32m0.75596[0m[0m | time: 77.954s
[2K| Adam | epoch: 007 | loss: 0.75596 - acc: 0.7353 -- iter: 06208/10000
[A[ATraining Step: 1040  | total loss: [1m[32m0.73775[0m[0m | time: 78.743s
[2K| Adam | epoch: 007 | loss: 0.73775 - acc: 0.7446 -- iter: 06272/10000
[A[ATraining Step: 1041  | total loss: [1m[32m0.73275[0m[0m | time: 79.510s
[2K| Adam | epoch: 007 | loss: 0.73275 - acc: 0.7467 -- iter: 06336/10000
[A[ATraining Step: 1042  | total loss: [1m[32m0.74525[0m[0m | time: 80.277s
[2K| Adam | epoch: 007 | loss: 0.74525 - acc: 0.7408 -- iter: 06400/10000
[A[ATraining Step: 1043  | total loss: [1m[32m0.73834[0m[0m | time: 81.041s
[2K| Adam | epoch: 007 | loss: 0.73834 - acc: 0.7402 -- iter: 06464/10000
[A[ATraining Step: 1044  | total loss: [1m[32m0.74403[0m[0m | time: 81.804s
[2K| Adam | epoch: 007 | loss: 0.74403 - acc: 0.7443 -- iter: 06528/10000
[A[ATraining Step: 1045  | total loss: [1m[32m0.77299[0m[0m | time: 82.543s
[2K| Adam | epoch: 007 | loss: 0.77299 - acc: 0.7308 -- iter: 06592/10000
[A[ATraining Step: 1046  | total loss: [1m[32m0.78300[0m[0m | time: 83.273s
[2K| Adam | epoch: 007 | loss: 0.78300 - acc: 0.7249 -- iter: 06656/10000
[A[ATraining Step: 1047  | total loss: [1m[32m0.77865[0m[0m | time: 84.007s
[2K| Adam | epoch: 007 | loss: 0.77865 - acc: 0.7227 -- iter: 06720/10000
[A[ATraining Step: 1048  | total loss: [1m[32m0.76465[0m[0m | time: 84.748s
[2K| Adam | epoch: 007 | loss: 0.76465 - acc: 0.7301 -- iter: 06784/10000
[A[ATraining Step: 1049  | total loss: [1m[32m0.74308[0m[0m | time: 85.494s
[2K| Adam | epoch: 007 | loss: 0.74308 - acc: 0.7368 -- iter: 06848/10000
[A[ATraining Step: 1050  | total loss: [1m[32m0.75164[0m[0m | time: 86.235s
[2K| Adam | epoch: 007 | loss: 0.75164 - acc: 0.7272 -- iter: 06912/10000
[A[ATraining Step: 1051  | total loss: [1m[32m0.74074[0m[0m | time: 86.975s
[2K| Adam | epoch: 007 | loss: 0.74074 - acc: 0.7248 -- iter: 06976/10000
[A[ATraining Step: 1052  | total loss: [1m[32m0.73755[0m[0m | time: 87.708s
[2K| Adam | epoch: 007 | loss: 0.73755 - acc: 0.7273 -- iter: 07040/10000
[A[ATraining Step: 1053  | total loss: [1m[32m0.76754[0m[0m | time: 88.448s
[2K| Adam | epoch: 007 | loss: 0.76754 - acc: 0.7218 -- iter: 07104/10000
[A[ATraining Step: 1054  | total loss: [1m[32m0.77410[0m[0m | time: 89.219s
[2K| Adam | epoch: 007 | loss: 0.77410 - acc: 0.7168 -- iter: 07168/10000
[A[ATraining Step: 1055  | total loss: [1m[32m0.77528[0m[0m | time: 89.952s
[2K| Adam | epoch: 007 | loss: 0.77528 - acc: 0.7123 -- iter: 07232/10000
[A[ATraining Step: 1056  | total loss: [1m[32m0.75630[0m[0m | time: 90.691s
[2K| Adam | epoch: 007 | loss: 0.75630 - acc: 0.7145 -- iter: 07296/10000
[A[ATraining Step: 1057  | total loss: [1m[32m0.75182[0m[0m | time: 91.433s
[2K| Adam | epoch: 007 | loss: 0.75182 - acc: 0.7212 -- iter: 07360/10000
[A[ATraining Step: 1058  | total loss: [1m[32m0.75555[0m[0m | time: 92.197s
[2K| Adam | epoch: 007 | loss: 0.75555 - acc: 0.7240 -- iter: 07424/10000
[A[ATraining Step: 1059  | total loss: [1m[32m0.76165[0m[0m | time: 92.957s
[2K| Adam | epoch: 007 | loss: 0.76165 - acc: 0.7220 -- iter: 07488/10000
[A[ATraining Step: 1060  | total loss: [1m[32m0.74982[0m[0m | time: 93.725s
[2K| Adam | epoch: 007 | loss: 0.74982 - acc: 0.7248 -- iter: 07552/10000
[A[ATraining Step: 1061  | total loss: [1m[32m0.76002[0m[0m | time: 94.495s
[2K| Adam | epoch: 007 | loss: 0.76002 - acc: 0.7320 -- iter: 07616/10000
[A[ATraining Step: 1062  | total loss: [1m[32m0.75012[0m[0m | time: 95.260s
[2K| Adam | epoch: 007 | loss: 0.75012 - acc: 0.7369 -- iter: 07680/10000
[A[ATraining Step: 1063  | total loss: [1m[32m0.75250[0m[0m | time: 96.031s
[2K| Adam | epoch: 007 | loss: 0.75250 - acc: 0.7413 -- iter: 07744/10000
[A[ATraining Step: 1064  | total loss: [1m[32m0.75334[0m[0m | time: 96.796s
[2K| Adam | epoch: 007 | loss: 0.75334 - acc: 0.7391 -- iter: 07808/10000
[A[ATraining Step: 1065  | total loss: [1m[32m0.74586[0m[0m | time: 97.563s
[2K| Adam | epoch: 007 | loss: 0.74586 - acc: 0.7386 -- iter: 07872/10000
[A[ATraining Step: 1066  | total loss: [1m[32m0.74550[0m[0m | time: 98.324s
[2K| Adam | epoch: 007 | loss: 0.74550 - acc: 0.7366 -- iter: 07936/10000
[A[ATraining Step: 1067  | total loss: [1m[32m0.74157[0m[0m | time: 99.124s
[2K| Adam | epoch: 007 | loss: 0.74157 - acc: 0.7348 -- iter: 08000/10000
[A[ATraining Step: 1068  | total loss: [1m[32m0.73227[0m[0m | time: 99.907s
[2K| Adam | epoch: 007 | loss: 0.73227 - acc: 0.7364 -- iter: 08064/10000
[A[ATraining Step: 1069  | total loss: [1m[32m0.74617[0m[0m | time: 100.670s
[2K| Adam | epoch: 007 | loss: 0.74617 - acc: 0.7330 -- iter: 08128/10000
[A[ATraining Step: 1070  | total loss: [1m[32m0.75690[0m[0m | time: 101.432s
[2K| Adam | epoch: 007 | loss: 0.75690 - acc: 0.7285 -- iter: 08192/10000
[A[ATraining Step: 1071  | total loss: [1m[32m0.74309[0m[0m | time: 102.198s
[2K| Adam | epoch: 007 | loss: 0.74309 - acc: 0.7322 -- iter: 08256/10000
[A[ATraining Step: 1072  | total loss: [1m[32m0.74597[0m[0m | time: 102.939s
[2K| Adam | epoch: 007 | loss: 0.74597 - acc: 0.7402 -- iter: 08320/10000
[A[ATraining Step: 1073  | total loss: [1m[32m0.75404[0m[0m | time: 103.678s
[2K| Adam | epoch: 007 | loss: 0.75404 - acc: 0.7443 -- iter: 08384/10000
[A[ATraining Step: 1074  | total loss: [1m[32m1.33597[0m[0m | time: 104.411s
[2K| Adam | epoch: 007 | loss: 1.33597 - acc: 0.6824 -- iter: 08448/10000
[A[ATraining Step: 1075  | total loss: [1m[32m1.27052[0m[0m | time: 105.151s
[2K| Adam | epoch: 007 | loss: 1.27052 - acc: 0.6938 -- iter: 08512/10000
[A[ATraining Step: 1076  | total loss: [1m[32m1.22956[0m[0m | time: 105.887s
[2K| Adam | epoch: 007 | loss: 1.22956 - acc: 0.7010 -- iter: 08576/10000
[A[ATraining Step: 1077  | total loss: [1m[32m1.18988[0m[0m | time: 106.628s
[2K| Adam | epoch: 007 | loss: 1.18988 - acc: 0.7012 -- iter: 08640/10000
[A[ATraining Step: 1078  | total loss: [1m[32m1.13291[0m[0m | time: 107.368s
[2K| Adam | epoch: 007 | loss: 1.13291 - acc: 0.7092 -- iter: 08704/10000
[A[ATraining Step: 1079  | total loss: [1m[32m1.09569[0m[0m | time: 108.106s
[2K| Adam | epoch: 007 | loss: 1.09569 - acc: 0.7149 -- iter: 08768/10000
[A[ATraining Step: 1080  | total loss: [1m[32m1.05477[0m[0m | time: 108.860s
[2K| Adam | epoch: 007 | loss: 1.05477 - acc: 0.7215 -- iter: 08832/10000
[A[ATraining Step: 1081  | total loss: [1m[32m1.04351[0m[0m | time: 109.610s
[2K| Adam | epoch: 007 | loss: 1.04351 - acc: 0.7103 -- iter: 08896/10000
[A[ATraining Step: 1082  | total loss: [1m[32m1.01364[0m[0m | time: 110.341s
[2K| Adam | epoch: 007 | loss: 1.01364 - acc: 0.7111 -- iter: 08960/10000
[A[ATraining Step: 1083  | total loss: [1m[32m0.99096[0m[0m | time: 111.072s
[2K| Adam | epoch: 007 | loss: 0.99096 - acc: 0.7119 -- iter: 09024/10000
[A[ATraining Step: 1084  | total loss: [1m[32m0.97329[0m[0m | time: 111.807s
[2K| Adam | epoch: 007 | loss: 0.97329 - acc: 0.7079 -- iter: 09088/10000
[A[ATraining Step: 1085  | total loss: [1m[32m0.94039[0m[0m | time: 112.545s
[2K| Adam | epoch: 007 | loss: 0.94039 - acc: 0.7059 -- iter: 09152/10000
[A[ATraining Step: 1086  | total loss: [1m[32m0.90655[0m[0m | time: 113.320s
[2K| Adam | epoch: 007 | loss: 0.90655 - acc: 0.7087 -- iter: 09216/10000
[A[ATraining Step: 1087  | total loss: [1m[32m0.90581[0m[0m | time: 114.082s
[2K| Adam | epoch: 007 | loss: 0.90581 - acc: 0.7082 -- iter: 09280/10000
[A[ATraining Step: 1088  | total loss: [1m[32m0.88488[0m[0m | time: 114.848s
[2K| Adam | epoch: 007 | loss: 0.88488 - acc: 0.7170 -- iter: 09344/10000
[A[ATraining Step: 1089  | total loss: [1m[32m0.87056[0m[0m | time: 115.617s
[2K| Adam | epoch: 007 | loss: 0.87056 - acc: 0.7094 -- iter: 09408/10000
[A[ATraining Step: 1090  | total loss: [1m[32m0.85334[0m[0m | time: 116.380s
[2K| Adam | epoch: 007 | loss: 0.85334 - acc: 0.7166 -- iter: 09472/10000
[A[ATraining Step: 1091  | total loss: [1m[32m0.84916[0m[0m | time: 117.142s
[2K| Adam | epoch: 007 | loss: 0.84916 - acc: 0.7199 -- iter: 09536/10000
[A[ATraining Step: 1092  | total loss: [1m[32m0.83053[0m[0m | time: 117.917s
[2K| Adam | epoch: 007 | loss: 0.83053 - acc: 0.7182 -- iter: 09600/10000
[A[ATraining Step: 1093  | total loss: [1m[32m0.80570[0m[0m | time: 118.696s
[2K| Adam | epoch: 007 | loss: 0.80570 - acc: 0.7277 -- iter: 09664/10000
[A[ATraining Step: 1094  | total loss: [1m[32m0.79858[0m[0m | time: 119.469s
[2K| Adam | epoch: 007 | loss: 0.79858 - acc: 0.7315 -- iter: 09728/10000
[A[ATraining Step: 1095  | total loss: [1m[32m0.77785[0m[0m | time: 120.227s
[2K| Adam | epoch: 007 | loss: 0.77785 - acc: 0.7442 -- iter: 09792/10000
[A[ATraining Step: 1096  | total loss: [1m[32m0.78855[0m[0m | time: 120.998s
[2K| Adam | epoch: 007 | loss: 0.78855 - acc: 0.7433 -- iter: 09856/10000
[A[ATraining Step: 1097  | total loss: [1m[32m0.78191[0m[0m | time: 121.772s
[2K| Adam | epoch: 007 | loss: 0.78191 - acc: 0.7408 -- iter: 09920/10000
[A[ATraining Step: 1098  | total loss: [1m[32m0.79231[0m[0m | time: 122.543s
[2K| Adam | epoch: 007 | loss: 0.79231 - acc: 0.7417 -- iter: 09984/10000
[A[ATraining Step: 1099  | total loss: [1m[32m0.76613[0m[0m | time: 125.284s
[2K| Adam | epoch: 007 | loss: 0.76613 - acc: 0.7472 | val_loss: 1.84048 - val_acc: 0.3629 -- iter: 10000/10000
--
Training Step: 1100  | total loss: [1m[32m0.78215[0m[0m | time: 2.716s
[2K| Adam | epoch: 008 | loss: 0.78215 - acc: 0.7381 | val_loss: 1.75273 - val_acc: 0.3743 -- iter: 00064/10000
--
Training Step: 1101  | total loss: [1m[32m0.77088[0m[0m | time: 3.473s
[2K| Adam | epoch: 008 | loss: 0.77088 - acc: 0.7346 -- iter: 00128/10000
[A[ATraining Step: 1102  | total loss: [1m[32m0.74218[0m[0m | time: 4.239s
[2K| Adam | epoch: 008 | loss: 0.74218 - acc: 0.7471 -- iter: 00192/10000
[A[ATraining Step: 1103  | total loss: [1m[32m0.73815[0m[0m | time: 5.009s
[2K| Adam | epoch: 008 | loss: 0.73815 - acc: 0.7427 -- iter: 00256/10000
[A[ATraining Step: 1104  | total loss: [1m[32m0.75205[0m[0m | time: 5.777s
[2K| Adam | epoch: 008 | loss: 0.75205 - acc: 0.7372 -- iter: 00320/10000
[A[ATraining Step: 1105  | total loss: [1m[32m0.74196[0m[0m | time: 6.136s
[2K| Adam | epoch: 008 | loss: 0.74196 - acc: 0.7338 -- iter: 00384/10000
[A[ATraining Step: 1106  | total loss: [1m[32m0.76543[0m[0m | time: 6.494s
[2K| Adam | epoch: 008 | loss: 0.76543 - acc: 0.7292 -- iter: 00448/10000
[A[ATraining Step: 1107  | total loss: [1m[32m0.75884[0m[0m | time: 7.259s
[2K| Adam | epoch: 008 | loss: 0.75884 - acc: 0.7312 -- iter: 00512/10000
[A[ATraining Step: 1108  | total loss: [1m[32m0.73987[0m[0m | time: 8.026s
[2K| Adam | epoch: 008 | loss: 0.73987 - acc: 0.7316 -- iter: 00576/10000
[A[ATraining Step: 1109  | total loss: [1m[32m0.74027[0m[0m | time: 8.794s
[2K| Adam | epoch: 008 | loss: 0.74027 - acc: 0.7318 -- iter: 00640/10000
[A[ATraining Step: 1110  | total loss: [1m[32m0.72959[0m[0m | time: 9.560s
[2K| Adam | epoch: 008 | loss: 0.72959 - acc: 0.7337 -- iter: 00704/10000
[A[ATraining Step: 1111  | total loss: [1m[32m0.72274[0m[0m | time: 10.325s
[2K| Adam | epoch: 008 | loss: 0.72274 - acc: 0.7369 -- iter: 00768/10000
[A[ATraining Step: 1112  | total loss: [1m[32m0.69499[0m[0m | time: 11.086s
[2K| Adam | epoch: 008 | loss: 0.69499 - acc: 0.7491 -- iter: 00832/10000
[A[ATraining Step: 1113  | total loss: [1m[32m0.70846[0m[0m | time: 11.830s
[2K| Adam | epoch: 008 | loss: 0.70846 - acc: 0.7429 -- iter: 00896/10000
[A[ATraining Step: 1114  | total loss: [1m[32m0.71204[0m[0m | time: 12.576s
[2K| Adam | epoch: 008 | loss: 0.71204 - acc: 0.7452 -- iter: 00960/10000
[A[ATraining Step: 1115  | total loss: [1m[32m0.69611[0m[0m | time: 13.334s
[2K| Adam | epoch: 008 | loss: 0.69611 - acc: 0.7519 -- iter: 01024/10000
[A[ATraining Step: 1116  | total loss: [1m[32m0.68357[0m[0m | time: 14.078s
[2K| Adam | epoch: 008 | loss: 0.68357 - acc: 0.7564 -- iter: 01088/10000
[A[ATraining Step: 1117  | total loss: [1m[32m0.68910[0m[0m | time: 14.812s
[2K| Adam | epoch: 008 | loss: 0.68910 - acc: 0.7558 -- iter: 01152/10000
[A[ATraining Step: 1118  | total loss: [1m[32m0.70218[0m[0m | time: 15.553s
[2K| Adam | epoch: 008 | loss: 0.70218 - acc: 0.7490 -- iter: 01216/10000
[A[ATraining Step: 1119  | total loss: [1m[32m0.71177[0m[0m | time: 16.286s
[2K| Adam | epoch: 008 | loss: 0.71177 - acc: 0.7506 -- iter: 01280/10000
[A[ATraining Step: 1120  | total loss: [1m[32m0.73418[0m[0m | time: 17.016s
[2K| Adam | epoch: 008 | loss: 0.73418 - acc: 0.7428 -- iter: 01344/10000
[A[ATraining Step: 1121  | total loss: [1m[32m0.71392[0m[0m | time: 17.723s
[2K| Adam | epoch: 008 | loss: 0.71392 - acc: 0.7435 -- iter: 01408/10000
[A[ATraining Step: 1122  | total loss: [1m[32m0.71747[0m[0m | time: 18.460s
[2K| Adam | epoch: 008 | loss: 0.71747 - acc: 0.7426 -- iter: 01472/10000
[A[ATraining Step: 1123  | total loss: [1m[32m0.71055[0m[0m | time: 19.229s
[2K| Adam | epoch: 008 | loss: 0.71055 - acc: 0.7417 -- iter: 01536/10000
[A[ATraining Step: 1124  | total loss: [1m[32m0.71501[0m[0m | time: 19.991s
[2K| Adam | epoch: 008 | loss: 0.71501 - acc: 0.7394 -- iter: 01600/10000
[A[ATraining Step: 1125  | total loss: [1m[32m0.72265[0m[0m | time: 20.753s
[2K| Adam | epoch: 008 | loss: 0.72265 - acc: 0.7343 -- iter: 01664/10000
[A[ATraining Step: 1126  | total loss: [1m[32m0.72590[0m[0m | time: 21.519s
[2K| Adam | epoch: 008 | loss: 0.72590 - acc: 0.7358 -- iter: 01728/10000
[A[ATraining Step: 1127  | total loss: [1m[32m0.71826[0m[0m | time: 22.286s
[2K| Adam | epoch: 008 | loss: 0.71826 - acc: 0.7419 -- iter: 01792/10000
[A[ATraining Step: 1128  | total loss: [1m[32m0.69500[0m[0m | time: 23.047s
[2K| Adam | epoch: 008 | loss: 0.69500 - acc: 0.7537 -- iter: 01856/10000
[A[ATraining Step: 1129  | total loss: [1m[32m0.70793[0m[0m | time: 23.841s
[2K| Adam | epoch: 008 | loss: 0.70793 - acc: 0.7439 -- iter: 01920/10000
[A[ATraining Step: 1130  | total loss: [1m[32m0.69789[0m[0m | time: 24.607s
[2K| Adam | epoch: 008 | loss: 0.69789 - acc: 0.7477 -- iter: 01984/10000
[A[ATraining Step: 1131  | total loss: [1m[32m0.67956[0m[0m | time: 25.382s
[2K| Adam | epoch: 008 | loss: 0.67956 - acc: 0.7510 -- iter: 02048/10000
[A[ATraining Step: 1132  | total loss: [1m[32m0.69209[0m[0m | time: 26.148s
[2K| Adam | epoch: 008 | loss: 0.69209 - acc: 0.7494 -- iter: 02112/10000
[A[ATraining Step: 1133  | total loss: [1m[32m0.67545[0m[0m | time: 26.921s
[2K| Adam | epoch: 008 | loss: 0.67545 - acc: 0.7541 -- iter: 02176/10000
[A[ATraining Step: 1134  | total loss: [1m[32m0.66234[0m[0m | time: 27.693s
[2K| Adam | epoch: 008 | loss: 0.66234 - acc: 0.7584 -- iter: 02240/10000
[A[ATraining Step: 1135  | total loss: [1m[32m0.66966[0m[0m | time: 28.453s
[2K| Adam | epoch: 008 | loss: 0.66966 - acc: 0.7482 -- iter: 02304/10000
[A[ATraining Step: 1136  | total loss: [1m[32m0.68047[0m[0m | time: 29.222s
[2K| Adam | epoch: 008 | loss: 0.68047 - acc: 0.7484 -- iter: 02368/10000
[A[ATraining Step: 1137  | total loss: [1m[32m0.68233[0m[0m | time: 29.990s
[2K| Adam | epoch: 008 | loss: 0.68233 - acc: 0.7470 -- iter: 02432/10000
[A[ATraining Step: 1138  | total loss: [1m[32m0.70218[0m[0m | time: 30.755s
[2K| Adam | epoch: 008 | loss: 0.70218 - acc: 0.7519 -- iter: 02496/10000
[A[ATraining Step: 1139  | total loss: [1m[32m0.72853[0m[0m | time: 31.518s
[2K| Adam | epoch: 008 | loss: 0.72853 - acc: 0.7486 -- iter: 02560/10000
[A[ATraining Step: 1140  | total loss: [1m[32m0.73053[0m[0m | time: 32.283s
[2K| Adam | epoch: 008 | loss: 0.73053 - acc: 0.7488 -- iter: 02624/10000
[A[ATraining Step: 1141  | total loss: [1m[32m0.71826[0m[0m | time: 33.054s
[2K| Adam | epoch: 008 | loss: 0.71826 - acc: 0.7567 -- iter: 02688/10000
[A[ATraining Step: 1142  | total loss: [1m[32m0.71993[0m[0m | time: 33.849s
[2K| Adam | epoch: 008 | loss: 0.71993 - acc: 0.7576 -- iter: 02752/10000
[A[ATraining Step: 1143  | total loss: [1m[32m0.72604[0m[0m | time: 34.614s
[2K| Adam | epoch: 008 | loss: 0.72604 - acc: 0.7537 -- iter: 02816/10000
[A[ATraining Step: 1144  | total loss: [1m[32m0.74600[0m[0m | time: 35.379s
[2K| Adam | epoch: 008 | loss: 0.74600 - acc: 0.7424 -- iter: 02880/10000
[A[ATraining Step: 1145  | total loss: [1m[32m0.74996[0m[0m | time: 36.157s
[2K| Adam | epoch: 008 | loss: 0.74996 - acc: 0.7400 -- iter: 02944/10000
[A[ATraining Step: 1146  | total loss: [1m[32m0.73734[0m[0m | time: 36.922s
[2K| Adam | epoch: 008 | loss: 0.73734 - acc: 0.7520 -- iter: 03008/10000
[A[ATraining Step: 1147  | total loss: [1m[32m0.75363[0m[0m | time: 37.663s
[2K| Adam | epoch: 008 | loss: 0.75363 - acc: 0.7455 -- iter: 03072/10000
[A[ATraining Step: 1148  | total loss: [1m[32m0.74861[0m[0m | time: 38.400s
[2K| Adam | epoch: 008 | loss: 0.74861 - acc: 0.7460 -- iter: 03136/10000
[A[ATraining Step: 1149  | total loss: [1m[32m0.73121[0m[0m | time: 39.138s
[2K| Adam | epoch: 008 | loss: 0.73121 - acc: 0.7495 -- iter: 03200/10000
[A[ATraining Step: 1150  | total loss: [1m[32m0.72883[0m[0m | time: 39.871s
[2K| Adam | epoch: 008 | loss: 0.72883 - acc: 0.7480 -- iter: 03264/10000
[A[ATraining Step: 1151  | total loss: [1m[32m0.73525[0m[0m | time: 40.606s
[2K| Adam | epoch: 008 | loss: 0.73525 - acc: 0.7498 -- iter: 03328/10000
[A[ATraining Step: 1152  | total loss: [1m[32m0.75570[0m[0m | time: 41.344s
[2K| Adam | epoch: 008 | loss: 0.75570 - acc: 0.7451 -- iter: 03392/10000
[A[ATraining Step: 1153  | total loss: [1m[32m0.76741[0m[0m | time: 42.084s
[2K| Adam | epoch: 008 | loss: 0.76741 - acc: 0.7362 -- iter: 03456/10000
[A[ATraining Step: 1154  | total loss: [1m[32m0.75613[0m[0m | time: 42.828s
[2K| Adam | epoch: 008 | loss: 0.75613 - acc: 0.7329 -- iter: 03520/10000
[A[ATraining Step: 1155  | total loss: [1m[32m0.74127[0m[0m | time: 43.575s
[2K| Adam | epoch: 008 | loss: 0.74127 - acc: 0.7362 -- iter: 03584/10000
[A[ATraining Step: 1156  | total loss: [1m[32m0.76979[0m[0m | time: 44.287s
[2K| Adam | epoch: 008 | loss: 0.76979 - acc: 0.7376 -- iter: 03648/10000
[A[ATraining Step: 1157  | total loss: [1m[32m0.76176[0m[0m | time: 45.051s
[2K| Adam | epoch: 008 | loss: 0.76176 - acc: 0.7435 -- iter: 03712/10000
[A[ATraining Step: 1158  | total loss: [1m[32m0.75790[0m[0m | time: 45.818s
[2K| Adam | epoch: 008 | loss: 0.75790 - acc: 0.7426 -- iter: 03776/10000
[A[ATraining Step: 1159  | total loss: [1m[32m0.75267[0m[0m | time: 46.588s
[2K| Adam | epoch: 008 | loss: 0.75267 - acc: 0.7433 -- iter: 03840/10000
[A[ATraining Step: 1160  | total loss: [1m[32m0.74489[0m[0m | time: 47.362s
[2K| Adam | epoch: 008 | loss: 0.74489 - acc: 0.7455 -- iter: 03904/10000
[A[ATraining Step: 1161  | total loss: [1m[32m0.75270[0m[0m | time: 48.139s
[2K| Adam | epoch: 008 | loss: 0.75270 - acc: 0.7429 -- iter: 03968/10000
[A[ATraining Step: 1162  | total loss: [1m[32m0.73962[0m[0m | time: 48.912s
[2K| Adam | epoch: 008 | loss: 0.73962 - acc: 0.7498 -- iter: 04032/10000
[A[ATraining Step: 1163  | total loss: [1m[32m0.74074[0m[0m | time: 49.679s
[2K| Adam | epoch: 008 | loss: 0.74074 - acc: 0.7452 -- iter: 04096/10000
[A[ATraining Step: 1164  | total loss: [1m[32m0.71879[0m[0m | time: 50.443s
[2K| Adam | epoch: 008 | loss: 0.71879 - acc: 0.7535 -- iter: 04160/10000
[A[ATraining Step: 1165  | total loss: [1m[32m0.74094[0m[0m | time: 51.206s
[2K| Adam | epoch: 008 | loss: 0.74094 - acc: 0.7422 -- iter: 04224/10000
[A[ATraining Step: 1166  | total loss: [1m[32m0.73945[0m[0m | time: 51.975s
[2K| Adam | epoch: 008 | loss: 0.73945 - acc: 0.7383 -- iter: 04288/10000
[A[ATraining Step: 1167  | total loss: [1m[32m0.74173[0m[0m | time: 52.739s
[2K| Adam | epoch: 008 | loss: 0.74173 - acc: 0.7394 -- iter: 04352/10000
[A[ATraining Step: 1168  | total loss: [1m[32m0.74131[0m[0m | time: 53.520s
[2K| Adam | epoch: 008 | loss: 0.74131 - acc: 0.7389 -- iter: 04416/10000
[A[ATraining Step: 1169  | total loss: [1m[32m0.70257[0m[0m | time: 54.287s
[2K| Adam | epoch: 008 | loss: 0.70257 - acc: 0.7510 -- iter: 04480/10000
[A[ATraining Step: 1170  | total loss: [1m[32m0.69721[0m[0m | time: 55.054s
[2K| Adam | epoch: 008 | loss: 0.69721 - acc: 0.7603 -- iter: 04544/10000
[A[ATraining Step: 1171  | total loss: [1m[32m0.69990[0m[0m | time: 55.818s
[2K| Adam | epoch: 008 | loss: 0.69990 - acc: 0.7592 -- iter: 04608/10000
[A[ATraining Step: 1172  | total loss: [1m[32m0.71466[0m[0m | time: 56.583s
[2K| Adam | epoch: 008 | loss: 0.71466 - acc: 0.7536 -- iter: 04672/10000
[A[ATraining Step: 1173  | total loss: [1m[32m0.73641[0m[0m | time: 57.345s
[2K| Adam | epoch: 008 | loss: 0.73641 - acc: 0.7501 -- iter: 04736/10000
[A[ATraining Step: 1174  | total loss: [1m[32m0.73038[0m[0m | time: 58.111s
[2K| Adam | epoch: 008 | loss: 0.73038 - acc: 0.7517 -- iter: 04800/10000
[A[ATraining Step: 1175  | total loss: [1m[32m0.74125[0m[0m | time: 58.887s
[2K| Adam | epoch: 008 | loss: 0.74125 - acc: 0.7421 -- iter: 04864/10000
[A[ATraining Step: 1176  | total loss: [1m[32m0.73337[0m[0m | time: 59.656s
[2K| Adam | epoch: 008 | loss: 0.73337 - acc: 0.7429 -- iter: 04928/10000
[A[ATraining Step: 1177  | total loss: [1m[32m0.72586[0m[0m | time: 60.415s
[2K| Adam | epoch: 008 | loss: 0.72586 - acc: 0.7452 -- iter: 04992/10000
[A[ATraining Step: 1178  | total loss: [1m[32m0.71791[0m[0m | time: 61.189s
[2K| Adam | epoch: 008 | loss: 0.71791 - acc: 0.7457 -- iter: 05056/10000
[A[ATraining Step: 1179  | total loss: [1m[32m0.73187[0m[0m | time: 61.951s
[2K| Adam | epoch: 008 | loss: 0.73187 - acc: 0.7383 -- iter: 05120/10000
[A[ATraining Step: 1180  | total loss: [1m[32m0.72387[0m[0m | time: 62.712s
[2K| Adam | epoch: 008 | loss: 0.72387 - acc: 0.7395 -- iter: 05184/10000
[A[ATraining Step: 1181  | total loss: [1m[32m0.71560[0m[0m | time: 63.493s
[2K| Adam | epoch: 008 | loss: 0.71560 - acc: 0.7374 -- iter: 05248/10000
[A[ATraining Step: 1182  | total loss: [1m[32m0.71065[0m[0m | time: 64.252s
[2K| Adam | epoch: 008 | loss: 0.71065 - acc: 0.7340 -- iter: 05312/10000
[A[ATraining Step: 1183  | total loss: [1m[32m0.71459[0m[0m | time: 65.020s
[2K| Adam | epoch: 008 | loss: 0.71459 - acc: 0.7340 -- iter: 05376/10000
[A[ATraining Step: 1184  | total loss: [1m[32m0.69376[0m[0m | time: 65.784s
[2K| Adam | epoch: 008 | loss: 0.69376 - acc: 0.7372 -- iter: 05440/10000
[A[ATraining Step: 1185  | total loss: [1m[32m0.70875[0m[0m | time: 66.546s
[2K| Adam | epoch: 008 | loss: 0.70875 - acc: 0.7306 -- iter: 05504/10000
[A[ATraining Step: 1186  | total loss: [1m[32m0.69219[0m[0m | time: 67.311s
[2K| Adam | epoch: 008 | loss: 0.69219 - acc: 0.7357 -- iter: 05568/10000
[A[ATraining Step: 1187  | total loss: [1m[32m0.70929[0m[0m | time: 68.076s
[2K| Adam | epoch: 008 | loss: 0.70929 - acc: 0.7262 -- iter: 05632/10000
[A[ATraining Step: 1188  | total loss: [1m[32m0.70096[0m[0m | time: 68.836s
[2K| Adam | epoch: 008 | loss: 0.70096 - acc: 0.7317 -- iter: 05696/10000
[A[ATraining Step: 1189  | total loss: [1m[32m0.70244[0m[0m | time: 69.602s
[2K| Adam | epoch: 008 | loss: 0.70244 - acc: 0.7288 -- iter: 05760/10000
[A[ATraining Step: 1190  | total loss: [1m[32m0.72682[0m[0m | time: 70.370s
[2K| Adam | epoch: 008 | loss: 0.72682 - acc: 0.7278 -- iter: 05824/10000
[A[ATraining Step: 1191  | total loss: [1m[32m0.70785[0m[0m | time: 71.145s
[2K| Adam | epoch: 008 | loss: 0.70785 - acc: 0.7379 -- iter: 05888/10000
[A[ATraining Step: 1192  | total loss: [1m[32m0.71567[0m[0m | time: 71.913s
[2K| Adam | epoch: 008 | loss: 0.71567 - acc: 0.7375 -- iter: 05952/10000
[A[ATraining Step: 1193  | total loss: [1m[32m0.70804[0m[0m | time: 72.684s
[2K| Adam | epoch: 008 | loss: 0.70804 - acc: 0.7450 -- iter: 06016/10000
[A[ATraining Step: 1194  | total loss: [1m[32m0.73131[0m[0m | time: 73.465s
[2K| Adam | epoch: 008 | loss: 0.73131 - acc: 0.7455 -- iter: 06080/10000
[A[ATraining Step: 1195  | total loss: [1m[32m0.71645[0m[0m | time: 74.230s
[2K| Adam | epoch: 008 | loss: 0.71645 - acc: 0.7553 -- iter: 06144/10000
[A[ATraining Step: 1196  | total loss: [1m[32m0.69098[0m[0m | time: 74.991s
[2K| Adam | epoch: 008 | loss: 0.69098 - acc: 0.7657 -- iter: 06208/10000
[A[ATraining Step: 1197  | total loss: [1m[32m0.67588[0m[0m | time: 75.749s
[2K| Adam | epoch: 008 | loss: 0.67588 - acc: 0.7735 -- iter: 06272/10000
[A[ATraining Step: 1198  | total loss: [1m[32m0.67188[0m[0m | time: 76.505s
[2K| Adam | epoch: 008 | loss: 0.67188 - acc: 0.7712 -- iter: 06336/10000
[A[ATraining Step: 1199  | total loss: [1m[32m0.69276[0m[0m | time: 77.272s
[2K| Adam | epoch: 008 | loss: 0.69276 - acc: 0.7675 -- iter: 06400/10000
[A[ATraining Step: 1200  | total loss: [1m[32m0.68768[0m[0m | time: 80.007s
[2K| Adam | epoch: 008 | loss: 0.68768 - acc: 0.7720 | val_loss: 1.44924 - val_acc: 0.4943 -- iter: 06464/10000
--
Training Step: 1201  | total loss: [1m[32m0.69665[0m[0m | time: 80.748s
[2K| Adam | epoch: 008 | loss: 0.69665 - acc: 0.7698 -- iter: 06528/10000
[A[ATraining Step: 1202  | total loss: [1m[32m0.71403[0m[0m | time: 81.523s
[2K| Adam | epoch: 008 | loss: 0.71403 - acc: 0.7569 -- iter: 06592/10000
[A[ATraining Step: 1203  | total loss: [1m[32m0.71384[0m[0m | time: 82.308s
[2K| Adam | epoch: 008 | loss: 0.71384 - acc: 0.7562 -- iter: 06656/10000
[A[ATraining Step: 1204  | total loss: [1m[32m0.71985[0m[0m | time: 83.044s
[2K| Adam | epoch: 008 | loss: 0.71985 - acc: 0.7587 -- iter: 06720/10000
[A[ATraining Step: 1205  | total loss: [1m[32m0.76033[0m[0m | time: 83.838s
[2K| Adam | epoch: 008 | loss: 0.76033 - acc: 0.7453 -- iter: 06784/10000
[A[ATraining Step: 1206  | total loss: [1m[32m0.77910[0m[0m | time: 84.600s
[2K| Adam | epoch: 008 | loss: 0.77910 - acc: 0.7427 -- iter: 06848/10000
[A[ATraining Step: 1207  | total loss: [1m[32m0.76822[0m[0m | time: 85.366s
[2K| Adam | epoch: 008 | loss: 0.76822 - acc: 0.7465 -- iter: 06912/10000
[A[ATraining Step: 1208  | total loss: [1m[32m0.75256[0m[0m | time: 86.128s
[2K| Adam | epoch: 008 | loss: 0.75256 - acc: 0.7469 -- iter: 06976/10000
[A[ATraining Step: 1209  | total loss: [1m[32m0.74345[0m[0m | time: 86.894s
[2K| Adam | epoch: 008 | loss: 0.74345 - acc: 0.7503 -- iter: 07040/10000
[A[ATraining Step: 1210  | total loss: [1m[32m0.74666[0m[0m | time: 87.658s
[2K| Adam | epoch: 008 | loss: 0.74666 - acc: 0.7487 -- iter: 07104/10000
[A[ATraining Step: 1211  | total loss: [1m[32m0.74217[0m[0m | time: 88.420s
[2K| Adam | epoch: 008 | loss: 0.74217 - acc: 0.7504 -- iter: 07168/10000
[A[ATraining Step: 1212  | total loss: [1m[32m0.72782[0m[0m | time: 89.187s
[2K| Adam | epoch: 008 | loss: 0.72782 - acc: 0.7551 -- iter: 07232/10000
[A[ATraining Step: 1213  | total loss: [1m[32m0.72229[0m[0m | time: 89.963s
[2K| Adam | epoch: 008 | loss: 0.72229 - acc: 0.7530 -- iter: 07296/10000
[A[ATraining Step: 1214  | total loss: [1m[32m0.73063[0m[0m | time: 90.718s
[2K| Adam | epoch: 008 | loss: 0.73063 - acc: 0.7496 -- iter: 07360/10000
[A[ATraining Step: 1215  | total loss: [1m[32m0.72913[0m[0m | time: 91.490s
[2K| Adam | epoch: 008 | loss: 0.72913 - acc: 0.7559 -- iter: 07424/10000
[A[ATraining Step: 1216  | total loss: [1m[32m0.71026[0m[0m | time: 92.256s
[2K| Adam | epoch: 008 | loss: 0.71026 - acc: 0.7600 -- iter: 07488/10000
[A[ATraining Step: 1217  | total loss: [1m[32m0.71159[0m[0m | time: 93.032s
[2K| Adam | epoch: 008 | loss: 0.71159 - acc: 0.7590 -- iter: 07552/10000
[A[ATraining Step: 1218  | total loss: [1m[32m0.70774[0m[0m | time: 93.838s
[2K| Adam | epoch: 008 | loss: 0.70774 - acc: 0.7549 -- iter: 07616/10000
[A[ATraining Step: 1219  | total loss: [1m[32m0.72652[0m[0m | time: 94.603s
[2K| Adam | epoch: 008 | loss: 0.72652 - acc: 0.7435 -- iter: 07680/10000
[A[ATraining Step: 1220  | total loss: [1m[32m0.72186[0m[0m | time: 95.372s
[2K| Adam | epoch: 008 | loss: 0.72186 - acc: 0.7488 -- iter: 07744/10000
[A[ATraining Step: 1221  | total loss: [1m[32m0.70681[0m[0m | time: 96.133s
[2K| Adam | epoch: 008 | loss: 0.70681 - acc: 0.7458 -- iter: 07808/10000
[A[ATraining Step: 1222  | total loss: [1m[32m0.69900[0m[0m | time: 96.902s
[2K| Adam | epoch: 008 | loss: 0.69900 - acc: 0.7494 -- iter: 07872/10000
[A[ATraining Step: 1223  | total loss: [1m[32m0.69302[0m[0m | time: 97.627s
[2K| Adam | epoch: 008 | loss: 0.69302 - acc: 0.7604 -- iter: 07936/10000
[A[ATraining Step: 1224  | total loss: [1m[32m0.70384[0m[0m | time: 98.388s
[2K| Adam | epoch: 008 | loss: 0.70384 - acc: 0.7531 -- iter: 08000/10000
[A[ATraining Step: 1225  | total loss: [1m[32m0.70925[0m[0m | time: 99.148s
[2K| Adam | epoch: 008 | loss: 0.70925 - acc: 0.7450 -- iter: 08064/10000
[A[ATraining Step: 1226  | total loss: [1m[32m0.72173[0m[0m | time: 99.906s
[2K| Adam | epoch: 008 | loss: 0.72173 - acc: 0.7486 -- iter: 08128/10000
[A[ATraining Step: 1227  | total loss: [1m[32m0.73247[0m[0m | time: 100.671s
[2K| Adam | epoch: 008 | loss: 0.73247 - acc: 0.7409 -- iter: 08192/10000
[A[ATraining Step: 1228  | total loss: [1m[32m0.73238[0m[0m | time: 101.436s
[2K| Adam | epoch: 008 | loss: 0.73238 - acc: 0.7418 -- iter: 08256/10000
[A[ATraining Step: 1229  | total loss: [1m[32m0.73422[0m[0m | time: 102.196s
[2K| Adam | epoch: 008 | loss: 0.73422 - acc: 0.7489 -- iter: 08320/10000
[A[ATraining Step: 1230  | total loss: [1m[32m0.73087[0m[0m | time: 102.967s
[2K| Adam | epoch: 008 | loss: 0.73087 - acc: 0.7459 -- iter: 08384/10000
[A[ATraining Step: 1231  | total loss: [1m[32m0.73883[0m[0m | time: 103.760s
[2K| Adam | epoch: 008 | loss: 0.73883 - acc: 0.7400 -- iter: 08448/10000
[A[ATraining Step: 1232  | total loss: [1m[32m1.36463[0m[0m | time: 104.529s
[2K| Adam | epoch: 008 | loss: 1.36463 - acc: 0.6754 -- iter: 08512/10000
[A[ATraining Step: 1233  | total loss: [1m[32m1.30529[0m[0m | time: 105.305s
[2K| Adam | epoch: 008 | loss: 1.30529 - acc: 0.6797 -- iter: 08576/10000
[A[ATraining Step: 1234  | total loss: [1m[32m1.24102[0m[0m | time: 106.076s
[2K| Adam | epoch: 008 | loss: 1.24102 - acc: 0.6821 -- iter: 08640/10000
[A[ATraining Step: 1235  | total loss: [1m[32m1.19303[0m[0m | time: 106.843s
[2K| Adam | epoch: 008 | loss: 1.19303 - acc: 0.6904 -- iter: 08704/10000
[A[ATraining Step: 1236  | total loss: [1m[32m1.14819[0m[0m | time: 107.616s
[2K| Adam | epoch: 008 | loss: 1.14819 - acc: 0.7011 -- iter: 08768/10000
[A[ATraining Step: 1237  | total loss: [1m[32m1.10364[0m[0m | time: 108.388s
[2K| Adam | epoch: 008 | loss: 1.10364 - acc: 0.6982 -- iter: 08832/10000
[A[ATraining Step: 1238  | total loss: [1m[32m1.06433[0m[0m | time: 109.153s
[2K| Adam | epoch: 008 | loss: 1.06433 - acc: 0.7096 -- iter: 08896/10000
[A[ATraining Step: 1239  | total loss: [1m[32m1.03153[0m[0m | time: 109.917s
[2K| Adam | epoch: 008 | loss: 1.03153 - acc: 0.7136 -- iter: 08960/10000
[A[ATraining Step: 1240  | total loss: [1m[32m1.00094[0m[0m | time: 110.678s
[2K| Adam | epoch: 008 | loss: 1.00094 - acc: 0.7220 -- iter: 09024/10000
[A[ATraining Step: 1241  | total loss: [1m[32m0.98203[0m[0m | time: 111.466s
[2K| Adam | epoch: 008 | loss: 0.98203 - acc: 0.7138 -- iter: 09088/10000
[A[ATraining Step: 1242  | total loss: [1m[32m0.94540[0m[0m | time: 112.261s
[2K| Adam | epoch: 008 | loss: 0.94540 - acc: 0.7206 -- iter: 09152/10000
[A[ATraining Step: 1243  | total loss: [1m[32m0.92647[0m[0m | time: 113.061s
[2K| Adam | epoch: 008 | loss: 0.92647 - acc: 0.7173 -- iter: 09216/10000
[A[ATraining Step: 1244  | total loss: [1m[32m0.89962[0m[0m | time: 113.886s
[2K| Adam | epoch: 008 | loss: 0.89962 - acc: 0.7221 -- iter: 09280/10000
[A[ATraining Step: 1245  | total loss: [1m[32m0.89249[0m[0m | time: 114.672s
[2K| Adam | epoch: 008 | loss: 0.89249 - acc: 0.7202 -- iter: 09344/10000
[A[ATraining Step: 1246  | total loss: [1m[32m0.87587[0m[0m | time: 115.470s
[2K| Adam | epoch: 008 | loss: 0.87587 - acc: 0.7232 -- iter: 09408/10000
[A[ATraining Step: 1247  | total loss: [1m[32m0.86005[0m[0m | time: 116.266s
[2K| Adam | epoch: 008 | loss: 0.86005 - acc: 0.7259 -- iter: 09472/10000
[A[ATraining Step: 1248  | total loss: [1m[32m0.84909[0m[0m | time: 117.061s
[2K| Adam | epoch: 008 | loss: 0.84909 - acc: 0.7236 -- iter: 09536/10000
[A[ATraining Step: 1249  | total loss: [1m[32m0.84378[0m[0m | time: 117.823s
[2K| Adam | epoch: 008 | loss: 0.84378 - acc: 0.7200 -- iter: 09600/10000
[A[ATraining Step: 1250  | total loss: [1m[32m0.81474[0m[0m | time: 118.584s
[2K| Adam | epoch: 008 | loss: 0.81474 - acc: 0.7308 -- iter: 09664/10000
[A[ATraining Step: 1251  | total loss: [1m[32m0.79671[0m[0m | time: 119.352s
[2K| Adam | epoch: 008 | loss: 0.79671 - acc: 0.7265 -- iter: 09728/10000
[A[ATraining Step: 1252  | total loss: [1m[32m0.78242[0m[0m | time: 120.144s
[2K| Adam | epoch: 008 | loss: 0.78242 - acc: 0.7288 -- iter: 09792/10000
[A[ATraining Step: 1253  | total loss: [1m[32m0.78794[0m[0m | time: 120.791s
[2K| Adam | epoch: 008 | loss: 0.78794 - acc: 0.7262 -- iter: 09856/10000
[A[ATraining Step: 1254  | total loss: [1m[32m0.76164[0m[0m | time: 121.621s
[2K| Adam | epoch: 008 | loss: 0.76164 - acc: 0.7411 -- iter: 09920/10000
[A[ATraining Step: 1255  | total loss: [1m[32m0.75057[0m[0m | time: 122.399s
[2K| Adam | epoch: 008 | loss: 0.75057 - acc: 0.7483 -- iter: 09984/10000
[A[ATraining Step: 1256  | total loss: [1m[32m0.75148[0m[0m | time: 125.255s
[2K| Adam | epoch: 008 | loss: 0.75148 - acc: 0.7500 | val_loss: 1.60861 - val_acc: 0.4829 -- iter: 10000/10000
--
Training Step: 1257  | total loss: [1m[32m0.73057[0m[0m | time: 0.742s
[2K| Adam | epoch: 009 | loss: 0.73057 - acc: 0.7609 -- iter: 00064/10000
[A[ATraining Step: 1258  | total loss: [1m[32m0.71102[0m[0m | time: 1.517s
[2K| Adam | epoch: 009 | loss: 0.71102 - acc: 0.7692 -- iter: 00128/10000
[A[ATraining Step: 1259  | total loss: [1m[32m0.70187[0m[0m | time: 2.283s
[2K| Adam | epoch: 009 | loss: 0.70187 - acc: 0.7704 -- iter: 00192/10000
[A[ATraining Step: 1260  | total loss: [1m[32m0.70670[0m[0m | time: 3.044s
[2K| Adam | epoch: 009 | loss: 0.70670 - acc: 0.7653 -- iter: 00256/10000
[A[ATraining Step: 1261  | total loss: [1m[32m0.71972[0m[0m | time: 3.809s
[2K| Adam | epoch: 009 | loss: 0.71972 - acc: 0.7684 -- iter: 00320/10000
[A[ATraining Step: 1262  | total loss: [1m[32m0.69992[0m[0m | time: 4.570s
[2K| Adam | epoch: 009 | loss: 0.69992 - acc: 0.7713 -- iter: 00384/10000
[A[ATraining Step: 1263  | total loss: [1m[32m0.68314[0m[0m | time: 4.962s
[2K| Adam | epoch: 009 | loss: 0.68314 - acc: 0.7738 -- iter: 00448/10000
[A[ATraining Step: 1264  | total loss: [1m[32m0.66097[0m[0m | time: 5.429s
[2K| Adam | epoch: 009 | loss: 0.66097 - acc: 0.7777 -- iter: 00512/10000
[A[ATraining Step: 1265  | total loss: [1m[32m0.66397[0m[0m | time: 6.389s
[2K| Adam | epoch: 009 | loss: 0.66397 - acc: 0.7812 -- iter: 00576/10000
[A[ATraining Step: 1266  | total loss: [1m[32m0.64890[0m[0m | time: 7.200s
[2K| Adam | epoch: 009 | loss: 0.64890 - acc: 0.7827 -- iter: 00640/10000
[A[ATraining Step: 1267  | total loss: [1m[32m0.66823[0m[0m | time: 8.080s
[2K| Adam | epoch: 009 | loss: 0.66823 - acc: 0.7763 -- iter: 00704/10000
[A[ATraining Step: 1268  | total loss: [1m[32m0.64528[0m[0m | time: 8.983s
[2K| Adam | epoch: 009 | loss: 0.64528 - acc: 0.7800 -- iter: 00768/10000
[A[ATraining Step: 1269  | total loss: [1m[32m0.63501[0m[0m | time: 9.911s
[2K| Adam | epoch: 009 | loss: 0.63501 - acc: 0.7863 -- iter: 00832/10000
[A[ATraining Step: 1270  | total loss: [1m[32m0.65915[0m[0m | time: 10.750s
[2K| Adam | epoch: 009 | loss: 0.65915 - acc: 0.7811 -- iter: 00896/10000
[A[ATraining Step: 1271  | total loss: [1m[32m0.70269[0m[0m | time: 11.589s
[2K| Adam | epoch: 009 | loss: 0.70269 - acc: 0.7655 -- iter: 00960/10000
[A[ATraining Step: 1272  | total loss: [1m[32m0.71645[0m[0m | time: 12.437s
[2K| Adam | epoch: 009 | loss: 0.71645 - acc: 0.7562 -- iter: 01024/10000
[A[ATraining Step: 1273  | total loss: [1m[32m0.72191[0m[0m | time: 13.259s
[2K| Adam | epoch: 009 | loss: 0.72191 - acc: 0.7587 -- iter: 01088/10000
[A[ATraining Step: 1274  | total loss: [1m[32m0.72272[0m[0m | time: 14.072s
[2K| Adam | epoch: 009 | loss: 0.72272 - acc: 0.7578 -- iter: 01152/10000
[A[ATraining Step: 1275  | total loss: [1m[32m0.71851[0m[0m | time: 14.866s
[2K| Adam | epoch: 009 | loss: 0.71851 - acc: 0.7617 -- iter: 01216/10000
[A[ATraining Step: 1276  | total loss: [1m[32m0.69944[0m[0m | time: 15.661s
[2K| Adam | epoch: 009 | loss: 0.69944 - acc: 0.7668 -- iter: 01280/10000
[A[ATraining Step: 1277  | total loss: [1m[32m0.69769[0m[0m | time: 16.465s
[2K| Adam | epoch: 009 | loss: 0.69769 - acc: 0.7557 -- iter: 01344/10000
[A[ATraining Step: 1278  | total loss: [1m[32m0.69294[0m[0m | time: 17.255s
[2K| Adam | epoch: 009 | loss: 0.69294 - acc: 0.7630 -- iter: 01408/10000
[A[ATraining Step: 1279  | total loss: [1m[32m0.67702[0m[0m | time: 18.068s
[2K| Adam | epoch: 009 | loss: 0.67702 - acc: 0.7632 -- iter: 01472/10000
[A[ATraining Step: 1280  | total loss: [1m[32m0.70480[0m[0m | time: 18.861s
[2K| Adam | epoch: 009 | loss: 0.70480 - acc: 0.7557 -- iter: 01536/10000
[A[ATraining Step: 1281  | total loss: [1m[32m0.68466[0m[0m | time: 19.667s
[2K| Adam | epoch: 009 | loss: 0.68466 - acc: 0.7551 -- iter: 01600/10000
[A[ATraining Step: 1282  | total loss: [1m[32m0.68616[0m[0m | time: 20.466s
[2K| Adam | epoch: 009 | loss: 0.68616 - acc: 0.7499 -- iter: 01664/10000
[A[ATraining Step: 1283  | total loss: [1m[32m0.69165[0m[0m | time: 21.267s
[2K| Adam | epoch: 009 | loss: 0.69165 - acc: 0.7546 -- iter: 01728/10000
[A[ATraining Step: 1284  | total loss: [1m[32m0.68655[0m[0m | time: 22.056s
[2K| Adam | epoch: 009 | loss: 0.68655 - acc: 0.7541 -- iter: 01792/10000
[A[ATraining Step: 1285  | total loss: [1m[32m0.70416[0m[0m | time: 22.831s
[2K| Adam | epoch: 009 | loss: 0.70416 - acc: 0.7522 -- iter: 01856/10000
[A[ATraining Step: 1286  | total loss: [1m[32m0.70620[0m[0m | time: 23.593s
[2K| Adam | epoch: 009 | loss: 0.70620 - acc: 0.7566 -- iter: 01920/10000
[A[ATraining Step: 1287  | total loss: [1m[32m0.68398[0m[0m | time: 24.362s
[2K| Adam | epoch: 009 | loss: 0.68398 - acc: 0.7638 -- iter: 01984/10000
[A[ATraining Step: 1288  | total loss: [1m[32m0.67468[0m[0m | time: 25.128s
[2K| Adam | epoch: 009 | loss: 0.67468 - acc: 0.7718 -- iter: 02048/10000
[A[ATraining Step: 1289  | total loss: [1m[32m0.67126[0m[0m | time: 25.942s
[2K| Adam | epoch: 009 | loss: 0.67126 - acc: 0.7790 -- iter: 02112/10000
[A[ATraining Step: 1290  | total loss: [1m[32m0.67356[0m[0m | time: 26.739s
[2K| Adam | epoch: 009 | loss: 0.67356 - acc: 0.7808 -- iter: 02176/10000
[A[ATraining Step: 1291  | total loss: [1m[32m0.66873[0m[0m | time: 27.525s
[2K| Adam | epoch: 009 | loss: 0.66873 - acc: 0.7871 -- iter: 02240/10000
[A[ATraining Step: 1292  | total loss: [1m[32m0.66883[0m[0m | time: 28.334s
[2K| Adam | epoch: 009 | loss: 0.66883 - acc: 0.7802 -- iter: 02304/10000
[A[ATraining Step: 1293  | total loss: [1m[32m0.66284[0m[0m | time: 29.116s
[2K| Adam | epoch: 009 | loss: 0.66284 - acc: 0.7803 -- iter: 02368/10000
[A[ATraining Step: 1294  | total loss: [1m[32m0.65719[0m[0m | time: 29.928s
[2K| Adam | epoch: 009 | loss: 0.65719 - acc: 0.7789 -- iter: 02432/10000
[A[ATraining Step: 1295  | total loss: [1m[32m0.66654[0m[0m | time: 30.749s
[2K| Adam | epoch: 009 | loss: 0.66654 - acc: 0.7791 -- iter: 02496/10000
[A[ATraining Step: 1296  | total loss: [1m[32m0.68195[0m[0m | time: 31.562s
[2K| Adam | epoch: 009 | loss: 0.68195 - acc: 0.7731 -- iter: 02560/10000
[A[ATraining Step: 1297  | total loss: [1m[32m0.71243[0m[0m | time: 32.392s
[2K| Adam | epoch: 009 | loss: 0.71243 - acc: 0.7551 -- iter: 02624/10000
[A[ATraining Step: 1298  | total loss: [1m[32m0.70380[0m[0m | time: 33.234s
[2K| Adam | epoch: 009 | loss: 0.70380 - acc: 0.7515 -- iter: 02688/10000
[A[ATraining Step: 1299  | total loss: [1m[32m0.70740[0m[0m | time: 34.111s
[2K| Adam | epoch: 009 | loss: 0.70740 - acc: 0.7451 -- iter: 02752/10000
[A[ATraining Step: 1300  | total loss: [1m[32m0.69974[0m[0m | time: 37.280s
[2K| Adam | epoch: 009 | loss: 0.69974 - acc: 0.7487 | val_loss: 1.80578 - val_acc: 0.4557 -- iter: 02816/10000
--
Training Step: 1301  | total loss: [1m[32m0.70762[0m[0m | time: 38.155s
[2K| Adam | epoch: 009 | loss: 0.70762 - acc: 0.7379 -- iter: 02880/10000
[A[ATraining Step: 1302  | total loss: [1m[32m0.69157[0m[0m | time: 39.031s
[2K| Adam | epoch: 009 | loss: 0.69157 - acc: 0.7438 -- iter: 02944/10000
[A[ATraining Step: 1303  | total loss: [1m[32m0.70458[0m[0m | time: 39.893s
[2K| Adam | epoch: 009 | loss: 0.70458 - acc: 0.7475 -- iter: 03008/10000
[A[ATraining Step: 1304  | total loss: [1m[32m0.69535[0m[0m | time: 40.748s
[2K| Adam | epoch: 009 | loss: 0.69535 - acc: 0.7509 -- iter: 03072/10000
[A[ATraining Step: 1305  | total loss: [1m[32m0.68981[0m[0m | time: 41.567s
[2K| Adam | epoch: 009 | loss: 0.68981 - acc: 0.7602 -- iter: 03136/10000
[A[ATraining Step: 1306  | total loss: [1m[32m0.68127[0m[0m | time: 42.375s
[2K| Adam | epoch: 009 | loss: 0.68127 - acc: 0.7686 -- iter: 03200/10000
[A[ATraining Step: 1307  | total loss: [1m[32m0.66658[0m[0m | time: 43.187s
[2K| Adam | epoch: 009 | loss: 0.66658 - acc: 0.7729 -- iter: 03264/10000
[A[ATraining Step: 1308  | total loss: [1m[32m0.66630[0m[0m | time: 43.966s
[2K| Adam | epoch: 009 | loss: 0.66630 - acc: 0.7738 -- iter: 03328/10000
[A[ATraining Step: 1309  | total loss: [1m[32m0.66398[0m[0m | time: 44.798s
[2K| Adam | epoch: 009 | loss: 0.66398 - acc: 0.7636 -- iter: 03392/10000
[A[ATraining Step: 1310  | total loss: [1m[32m0.69668[0m[0m | time: 45.619s
[2K| Adam | epoch: 009 | loss: 0.69668 - acc: 0.7513 -- iter: 03456/10000
[A[ATraining Step: 1311  | total loss: [1m[32m0.68866[0m[0m | time: 46.447s
[2K| Adam | epoch: 009 | loss: 0.68866 - acc: 0.7512 -- iter: 03520/10000
[A[ATraining Step: 1312  | total loss: [1m[32m0.67807[0m[0m | time: 47.282s
[2K| Adam | epoch: 009 | loss: 0.67807 - acc: 0.7495 -- iter: 03584/10000
[A[ATraining Step: 1313  | total loss: [1m[32m0.68918[0m[0m | time: 48.121s
[2K| Adam | epoch: 009 | loss: 0.68918 - acc: 0.7433 -- iter: 03648/10000
[A[ATraining Step: 1314  | total loss: [1m[32m0.70239[0m[0m | time: 48.919s
[2K| Adam | epoch: 009 | loss: 0.70239 - acc: 0.7377 -- iter: 03712/10000
[A[ATraining Step: 1315  | total loss: [1m[32m0.67700[0m[0m | time: 49.715s
[2K| Adam | epoch: 009 | loss: 0.67700 - acc: 0.7499 -- iter: 03776/10000
[A[ATraining Step: 1316  | total loss: [1m[32m0.68733[0m[0m | time: 50.537s
[2K| Adam | epoch: 009 | loss: 0.68733 - acc: 0.7436 -- iter: 03840/10000
[A[ATraining Step: 1317  | total loss: [1m[32m0.66466[0m[0m | time: 51.301s
[2K| Adam | epoch: 009 | loss: 0.66466 - acc: 0.7490 -- iter: 03904/10000
[A[ATraining Step: 1318  | total loss: [1m[32m0.68465[0m[0m | time: 52.112s
[2K| Adam | epoch: 009 | loss: 0.68465 - acc: 0.7475 -- iter: 03968/10000
[A[ATraining Step: 1319  | total loss: [1m[32m0.71099[0m[0m | time: 52.926s
[2K| Adam | epoch: 009 | loss: 0.71099 - acc: 0.7384 -- iter: 04032/10000
[A[ATraining Step: 1320  | total loss: [1m[32m0.71986[0m[0m | time: 53.744s
[2K| Adam | epoch: 009 | loss: 0.71986 - acc: 0.7395 -- iter: 04096/10000
[A[ATraining Step: 1321  | total loss: [1m[32m0.71700[0m[0m | time: 54.570s
[2K| Adam | epoch: 009 | loss: 0.71700 - acc: 0.7453 -- iter: 04160/10000
[A[ATraining Step: 1322  | total loss: [1m[32m0.69614[0m[0m | time: 55.392s
[2K| Adam | epoch: 009 | loss: 0.69614 - acc: 0.7567 -- iter: 04224/10000
[A[ATraining Step: 1323  | total loss: [1m[32m0.68950[0m[0m | time: 56.212s
[2K| Adam | epoch: 009 | loss: 0.68950 - acc: 0.7623 -- iter: 04288/10000
[A[ATraining Step: 1324  | total loss: [1m[32m0.67866[0m[0m | time: 57.036s
[2K| Adam | epoch: 009 | loss: 0.67866 - acc: 0.7673 -- iter: 04352/10000
[A[ATraining Step: 1325  | total loss: [1m[32m0.66126[0m[0m | time: 57.891s
[2K| Adam | epoch: 009 | loss: 0.66126 - acc: 0.7702 -- iter: 04416/10000
[A[ATraining Step: 1326  | total loss: [1m[32m0.65137[0m[0m | time: 58.729s
[2K| Adam | epoch: 009 | loss: 0.65137 - acc: 0.7713 -- iter: 04480/10000
[A[ATraining Step: 1327  | total loss: [1m[32m0.65823[0m[0m | time: 59.555s
[2K| Adam | epoch: 009 | loss: 0.65823 - acc: 0.7692 -- iter: 04544/10000
[A[ATraining Step: 1328  | total loss: [1m[32m0.66239[0m[0m | time: 60.371s
[2K| Adam | epoch: 009 | loss: 0.66239 - acc: 0.7673 -- iter: 04608/10000
[A[ATraining Step: 1329  | total loss: [1m[32m0.64702[0m[0m | time: 61.182s
[2K| Adam | epoch: 009 | loss: 0.64702 - acc: 0.7702 -- iter: 04672/10000
[A[ATraining Step: 1330  | total loss: [1m[32m0.65646[0m[0m | time: 61.986s
[2K| Adam | epoch: 009 | loss: 0.65646 - acc: 0.7667 -- iter: 04736/10000
[A[ATraining Step: 1331  | total loss: [1m[32m0.64095[0m[0m | time: 62.792s
[2K| Adam | epoch: 009 | loss: 0.64095 - acc: 0.7759 -- iter: 04800/10000
[A[ATraining Step: 1332  | total loss: [1m[32m0.65714[0m[0m | time: 63.587s
[2K| Adam | epoch: 009 | loss: 0.65714 - acc: 0.7749 -- iter: 04864/10000
[A[ATraining Step: 1333  | total loss: [1m[32m0.67397[0m[0m | time: 64.394s
[2K| Adam | epoch: 009 | loss: 0.67397 - acc: 0.7740 -- iter: 04928/10000
[A[ATraining Step: 1334  | total loss: [1m[32m0.67890[0m[0m | time: 65.204s
[2K| Adam | epoch: 009 | loss: 0.67890 - acc: 0.7778 -- iter: 04992/10000
[A[ATraining Step: 1335  | total loss: [1m[32m0.67264[0m[0m | time: 66.006s
[2K| Adam | epoch: 009 | loss: 0.67264 - acc: 0.7766 -- iter: 05056/10000
[A[ATraining Step: 1336  | total loss: [1m[32m0.68680[0m[0m | time: 66.808s
[2K| Adam | epoch: 009 | loss: 0.68680 - acc: 0.7677 -- iter: 05120/10000
[A[ATraining Step: 1337  | total loss: [1m[32m0.66970[0m[0m | time: 67.612s
[2K| Adam | epoch: 009 | loss: 0.66970 - acc: 0.7706 -- iter: 05184/10000
[A[ATraining Step: 1338  | total loss: [1m[32m0.66628[0m[0m | time: 68.446s
[2K| Adam | epoch: 009 | loss: 0.66628 - acc: 0.7639 -- iter: 05248/10000
[A[ATraining Step: 1339  | total loss: [1m[32m0.67322[0m[0m | time: 69.249s
[2K| Adam | epoch: 009 | loss: 0.67322 - acc: 0.7640 -- iter: 05312/10000
[A[ATraining Step: 1340  | total loss: [1m[32m0.65261[0m[0m | time: 70.068s
[2K| Adam | epoch: 009 | loss: 0.65261 - acc: 0.7704 -- iter: 05376/10000
[A[ATraining Step: 1341  | total loss: [1m[32m0.66728[0m[0m | time: 70.887s
[2K| Adam | epoch: 009 | loss: 0.66728 - acc: 0.7653 -- iter: 05440/10000
[A[ATraining Step: 1342  | total loss: [1m[32m0.68213[0m[0m | time: 71.735s
[2K| Adam | epoch: 009 | loss: 0.68213 - acc: 0.7575 -- iter: 05504/10000
[A[ATraining Step: 1343  | total loss: [1m[32m0.68094[0m[0m | time: 72.562s
[2K| Adam | epoch: 009 | loss: 0.68094 - acc: 0.7536 -- iter: 05568/10000
[A[ATraining Step: 1344  | total loss: [1m[32m0.69110[0m[0m | time: 73.380s
[2K| Adam | epoch: 009 | loss: 0.69110 - acc: 0.7486 -- iter: 05632/10000
[A[ATraining Step: 1345  | total loss: [1m[32m0.68769[0m[0m | time: 74.206s
[2K| Adam | epoch: 009 | loss: 0.68769 - acc: 0.7472 -- iter: 05696/10000
[A[ATraining Step: 1346  | total loss: [1m[32m0.65873[0m[0m | time: 75.021s
[2K| Adam | epoch: 009 | loss: 0.65873 - acc: 0.7631 -- iter: 05760/10000
[A[ATraining Step: 1347  | total loss: [1m[32m0.65371[0m[0m | time: 75.847s
[2K| Adam | epoch: 009 | loss: 0.65371 - acc: 0.7711 -- iter: 05824/10000
[A[ATraining Step: 1348  | total loss: [1m[32m0.66525[0m[0m | time: 76.660s
[2K| Adam | epoch: 009 | loss: 0.66525 - acc: 0.7628 -- iter: 05888/10000
[A[ATraining Step: 1349  | total loss: [1m[32m0.67180[0m[0m | time: 77.450s
[2K| Adam | epoch: 009 | loss: 0.67180 - acc: 0.7599 -- iter: 05952/10000
[A[ATraining Step: 1350  | total loss: [1m[32m0.67808[0m[0m | time: 78.246s
[2K| Adam | epoch: 009 | loss: 0.67808 - acc: 0.7574 -- iter: 06016/10000
[A[ATraining Step: 1351  | total loss: [1m[32m0.67028[0m[0m | time: 79.029s
[2K| Adam | epoch: 009 | loss: 0.67028 - acc: 0.7566 -- iter: 06080/10000
[A[ATraining Step: 1352  | total loss: [1m[32m0.66256[0m[0m | time: 79.769s
[2K| Adam | epoch: 009 | loss: 0.66256 - acc: 0.7607 -- iter: 06144/10000
[A[ATraining Step: 1353  | total loss: [1m[32m0.65344[0m[0m | time: 80.540s
[2K| Adam | epoch: 009 | loss: 0.65344 - acc: 0.7690 -- iter: 06208/10000
[A[ATraining Step: 1354  | total loss: [1m[32m0.67075[0m[0m | time: 81.322s
[2K| Adam | epoch: 009 | loss: 0.67075 - acc: 0.7624 -- iter: 06272/10000
[A[ATraining Step: 1355  | total loss: [1m[32m0.69471[0m[0m | time: 82.092s
[2K| Adam | epoch: 009 | loss: 0.69471 - acc: 0.7502 -- iter: 06336/10000
[A[ATraining Step: 1356  | total loss: [1m[32m0.69003[0m[0m | time: 82.866s
[2K| Adam | epoch: 009 | loss: 0.69003 - acc: 0.7518 -- iter: 06400/10000
[A[ATraining Step: 1357  | total loss: [1m[32m0.67827[0m[0m | time: 83.632s
[2K| Adam | epoch: 009 | loss: 0.67827 - acc: 0.7516 -- iter: 06464/10000
[A[ATraining Step: 1358  | total loss: [1m[32m0.66160[0m[0m | time: 84.373s
[2K| Adam | epoch: 009 | loss: 0.66160 - acc: 0.7561 -- iter: 06528/10000
[A[ATraining Step: 1359  | total loss: [1m[32m0.63945[0m[0m | time: 85.146s
[2K| Adam | epoch: 009 | loss: 0.63945 - acc: 0.7680 -- iter: 06592/10000
[A[ATraining Step: 1360  | total loss: [1m[32m0.67262[0m[0m | time: 85.917s
[2K| Adam | epoch: 009 | loss: 0.67262 - acc: 0.7615 -- iter: 06656/10000
[A[ATraining Step: 1361  | total loss: [1m[32m0.65404[0m[0m | time: 86.688s
[2K| Adam | epoch: 009 | loss: 0.65404 - acc: 0.7697 -- iter: 06720/10000
[A[ATraining Step: 1362  | total loss: [1m[32m0.65032[0m[0m | time: 87.443s
[2K| Adam | epoch: 009 | loss: 0.65032 - acc: 0.7740 -- iter: 06784/10000
[A[ATraining Step: 1363  | total loss: [1m[32m0.65382[0m[0m | time: 88.258s
[2K| Adam | epoch: 009 | loss: 0.65382 - acc: 0.7700 -- iter: 06848/10000
[A[ATraining Step: 1364  | total loss: [1m[32m0.66321[0m[0m | time: 89.081s
[2K| Adam | epoch: 009 | loss: 0.66321 - acc: 0.7649 -- iter: 06912/10000
[A[ATraining Step: 1365  | total loss: [1m[32m0.66072[0m[0m | time: 89.906s
[2K| Adam | epoch: 009 | loss: 0.66072 - acc: 0.7634 -- iter: 06976/10000
[A[ATraining Step: 1366  | total loss: [1m[32m0.66016[0m[0m | time: 90.734s
[2K| Adam | epoch: 009 | loss: 0.66016 - acc: 0.7590 -- iter: 07040/10000
[A[ATraining Step: 1367  | total loss: [1m[32m0.66667[0m[0m | time: 91.558s
[2K| Adam | epoch: 009 | loss: 0.66667 - acc: 0.7534 -- iter: 07104/10000
[A[ATraining Step: 1368  | total loss: [1m[32m0.64876[0m[0m | time: 92.388s
[2K| Adam | epoch: 009 | loss: 0.64876 - acc: 0.7593 -- iter: 07168/10000
[A[ATraining Step: 1369  | total loss: [1m[32m0.66009[0m[0m | time: 93.211s
[2K| Adam | epoch: 009 | loss: 0.66009 - acc: 0.7552 -- iter: 07232/10000
[A[ATraining Step: 1370  | total loss: [1m[32m0.67173[0m[0m | time: 94.024s
[2K| Adam | epoch: 009 | loss: 0.67173 - acc: 0.7500 -- iter: 07296/10000
[A[ATraining Step: 1371  | total loss: [1m[32m0.66694[0m[0m | time: 94.828s
[2K| Adam | epoch: 009 | loss: 0.66694 - acc: 0.7500 -- iter: 07360/10000
[A[ATraining Step: 1372  | total loss: [1m[32m0.67716[0m[0m | time: 95.631s
[2K| Adam | epoch: 009 | loss: 0.67716 - acc: 0.7438 -- iter: 07424/10000
[A[ATraining Step: 1373  | total loss: [1m[32m0.68057[0m[0m | time: 96.426s
[2K| Adam | epoch: 009 | loss: 0.68057 - acc: 0.7413 -- iter: 07488/10000
[A[ATraining Step: 1374  | total loss: [1m[32m0.69597[0m[0m | time: 97.231s
[2K| Adam | epoch: 009 | loss: 0.69597 - acc: 0.7343 -- iter: 07552/10000
[A[ATraining Step: 1375  | total loss: [1m[32m0.72432[0m[0m | time: 98.051s
[2K| Adam | epoch: 009 | loss: 0.72432 - acc: 0.7265 -- iter: 07616/10000
[A[ATraining Step: 1376  | total loss: [1m[32m0.71334[0m[0m | time: 98.849s
[2K| Adam | epoch: 009 | loss: 0.71334 - acc: 0.7273 -- iter: 07680/10000
[A[ATraining Step: 1377  | total loss: [1m[32m0.70521[0m[0m | time: 99.655s
[2K| Adam | epoch: 009 | loss: 0.70521 - acc: 0.7311 -- iter: 07744/10000
[A[ATraining Step: 1378  | total loss: [1m[32m0.69567[0m[0m | time: 100.425s
[2K| Adam | epoch: 009 | loss: 0.69567 - acc: 0.7377 -- iter: 07808/10000
[A[ATraining Step: 1379  | total loss: [1m[32m0.69030[0m[0m | time: 101.196s
[2K| Adam | epoch: 009 | loss: 0.69030 - acc: 0.7421 -- iter: 07872/10000
[A[ATraining Step: 1380  | total loss: [1m[32m0.69564[0m[0m | time: 101.959s
[2K| Adam | epoch: 009 | loss: 0.69564 - acc: 0.7460 -- iter: 07936/10000
[A[ATraining Step: 1381  | total loss: [1m[32m0.75471[0m[0m | time: 102.734s
[2K| Adam | epoch: 009 | loss: 0.75471 - acc: 0.7292 -- iter: 08000/10000
[A[ATraining Step: 1382  | total loss: [1m[32m0.72939[0m[0m | time: 103.531s
[2K| Adam | epoch: 009 | loss: 0.72939 - acc: 0.7391 -- iter: 08064/10000
[A[ATraining Step: 1383  | total loss: [1m[32m0.72901[0m[0m | time: 104.336s
[2K| Adam | epoch: 009 | loss: 0.72901 - acc: 0.7417 -- iter: 08128/10000
[A[ATraining Step: 1384  | total loss: [1m[32m0.74797[0m[0m | time: 105.125s
[2K| Adam | epoch: 009 | loss: 0.74797 - acc: 0.7316 -- iter: 08192/10000
[A[ATraining Step: 1385  | total loss: [1m[32m0.74683[0m[0m | time: 105.913s
[2K| Adam | epoch: 009 | loss: 0.74683 - acc: 0.7288 -- iter: 08256/10000
[A[ATraining Step: 1386  | total loss: [1m[32m0.73585[0m[0m | time: 106.692s
[2K| Adam | epoch: 009 | loss: 0.73585 - acc: 0.7309 -- iter: 08320/10000
[A[ATraining Step: 1387  | total loss: [1m[32m0.72083[0m[0m | time: 107.477s
[2K| Adam | epoch: 009 | loss: 0.72083 - acc: 0.7344 -- iter: 08384/10000
[A[ATraining Step: 1388  | total loss: [1m[32m0.70331[0m[0m | time: 108.279s
[2K| Adam | epoch: 009 | loss: 0.70331 - acc: 0.7375 -- iter: 08448/10000
[A[ATraining Step: 1389  | total loss: [1m[32m0.69530[0m[0m | time: 109.055s
[2K| Adam | epoch: 009 | loss: 0.69530 - acc: 0.7356 -- iter: 08512/10000
[A[ATraining Step: 1390  | total loss: [1m[32m1.48669[0m[0m | time: 109.833s
[2K| Adam | epoch: 009 | loss: 1.48669 - acc: 0.6730 -- iter: 08576/10000
[A[ATraining Step: 1391  | total loss: [1m[32m1.42373[0m[0m | time: 110.606s
[2K| Adam | epoch: 009 | loss: 1.42373 - acc: 0.6713 -- iter: 08640/10000
[A[ATraining Step: 1392  | total loss: [1m[32m1.34736[0m[0m | time: 111.380s
[2K| Adam | epoch: 009 | loss: 1.34736 - acc: 0.6745 -- iter: 08704/10000
[A[ATraining Step: 1393  | total loss: [1m[32m1.28056[0m[0m | time: 112.119s
[2K| Adam | epoch: 009 | loss: 1.28056 - acc: 0.6774 -- iter: 08768/10000
[A[ATraining Step: 1394  | total loss: [1m[32m1.24658[0m[0m | time: 112.889s
[2K| Adam | epoch: 009 | loss: 1.24658 - acc: 0.6784 -- iter: 08832/10000
[A[ATraining Step: 1395  | total loss: [1m[32m1.19248[0m[0m | time: 113.665s
[2K| Adam | epoch: 009 | loss: 1.19248 - acc: 0.6871 -- iter: 08896/10000
[A[ATraining Step: 1396  | total loss: [1m[32m1.12655[0m[0m | time: 114.456s
[2K| Adam | epoch: 009 | loss: 1.12655 - acc: 0.6934 -- iter: 08960/10000
[A[ATraining Step: 1397  | total loss: [1m[32m1.06456[0m[0m | time: 115.270s
[2K| Adam | epoch: 009 | loss: 1.06456 - acc: 0.7037 -- iter: 09024/10000
[A[ATraining Step: 1398  | total loss: [1m[32m1.02111[0m[0m | time: 116.071s
[2K| Adam | epoch: 009 | loss: 1.02111 - acc: 0.7068 -- iter: 09088/10000
[A[ATraining Step: 1399  | total loss: [1m[32m0.96919[0m[0m | time: 116.872s
[2K| Adam | epoch: 009 | loss: 0.96919 - acc: 0.7189 -- iter: 09152/10000
[A[ATraining Step: 1400  | total loss: [1m[32m0.93515[0m[0m | time: 119.828s
[2K| Adam | epoch: 009 | loss: 0.93515 - acc: 0.7252 | val_loss: 1.98914 - val_acc: 0.4257 -- iter: 09216/10000
--
Training Step: 1401  | total loss: [1m[32m0.89322[0m[0m | time: 120.601s
[2K| Adam | epoch: 009 | loss: 0.89322 - acc: 0.7339 -- iter: 09280/10000
[A[ATraining Step: 1402  | total loss: [1m[32m0.85958[0m[0m | time: 121.408s
[2K| Adam | epoch: 009 | loss: 0.85958 - acc: 0.7386 -- iter: 09344/10000
[A[ATraining Step: 1403  | total loss: [1m[32m0.84678[0m[0m | time: 122.214s
[2K| Adam | epoch: 009 | loss: 0.84678 - acc: 0.7413 -- iter: 09408/10000
[A[ATraining Step: 1404  | total loss: [1m[32m0.79881[0m[0m | time: 123.018s
[2K| Adam | epoch: 009 | loss: 0.79881 - acc: 0.7610 -- iter: 09472/10000
[A[ATraining Step: 1405  | total loss: [1m[32m0.76588[0m[0m | time: 123.827s
[2K| Adam | epoch: 009 | loss: 0.76588 - acc: 0.7724 -- iter: 09536/10000
[A[ATraining Step: 1406  | total loss: [1m[32m0.74464[0m[0m | time: 124.624s
[2K| Adam | epoch: 009 | loss: 0.74464 - acc: 0.7764 -- iter: 09600/10000
[A[ATraining Step: 1407  | total loss: [1m[32m0.74259[0m[0m | time: 125.403s
[2K| Adam | epoch: 009 | loss: 0.74259 - acc: 0.7690 -- iter: 09664/10000
[A[ATraining Step: 1408  | total loss: [1m[32m0.75758[0m[0m | time: 126.171s
[2K| Adam | epoch: 009 | loss: 0.75758 - acc: 0.7640 -- iter: 09728/10000
[A[ATraining Step: 1409  | total loss: [1m[32m0.73927[0m[0m | time: 126.944s
[2K| Adam | epoch: 009 | loss: 0.73927 - acc: 0.7657 -- iter: 09792/10000
[A[ATraining Step: 1410  | total loss: [1m[32m0.71857[0m[0m | time: 127.725s
[2K| Adam | epoch: 009 | loss: 0.71857 - acc: 0.7626 -- iter: 09856/10000
[A[ATraining Step: 1411  | total loss: [1m[32m0.69687[0m[0m | time: 128.534s
[2K| Adam | epoch: 009 | loss: 0.69687 - acc: 0.7645 -- iter: 09920/10000
[A[ATraining Step: 1412  | total loss: [1m[32m0.69702[0m[0m | time: 129.305s
[2K| Adam | epoch: 009 | loss: 0.69702 - acc: 0.7630 -- iter: 09984/10000
[A[ATraining Step: 1413  | total loss: [1m[32m0.68530[0m[0m | time: 132.118s
[2K| Adam | epoch: 009 | loss: 0.68530 - acc: 0.7617 | val_loss: 2.20140 - val_acc: 0.3857 -- iter: 10000/10000
--
Training Step: 1414  | total loss: [1m[32m0.68356[0m[0m | time: 0.747s
[2K| Adam | epoch: 010 | loss: 0.68356 - acc: 0.7590 -- iter: 00064/10000
[A[ATraining Step: 1415  | total loss: [1m[32m0.66189[0m[0m | time: 1.526s
[2K| Adam | epoch: 010 | loss: 0.66189 - acc: 0.7690 -- iter: 00128/10000
[A[ATraining Step: 1416  | total loss: [1m[32m0.65159[0m[0m | time: 2.323s
[2K| Adam | epoch: 010 | loss: 0.65159 - acc: 0.7702 -- iter: 00192/10000
[A[ATraining Step: 1417  | total loss: [1m[32m0.63229[0m[0m | time: 3.105s
[2K| Adam | epoch: 010 | loss: 0.63229 - acc: 0.7776 -- iter: 00256/10000
[A[ATraining Step: 1418  | total loss: [1m[32m0.64323[0m[0m | time: 3.890s
[2K| Adam | epoch: 010 | loss: 0.64323 - acc: 0.7717 -- iter: 00320/10000
[A[ATraining Step: 1419  | total loss: [1m[32m0.62548[0m[0m | time: 4.641s
[2K| Adam | epoch: 010 | loss: 0.62548 - acc: 0.7742 -- iter: 00384/10000
[A[ATraining Step: 1420  | total loss: [1m[32m0.60918[0m[0m | time: 5.455s
[2K| Adam | epoch: 010 | loss: 0.60918 - acc: 0.7827 -- iter: 00448/10000
[A[ATraining Step: 1421  | total loss: [1m[32m0.60620[0m[0m | time: 5.854s
[2K| Adam | epoch: 010 | loss: 0.60620 - acc: 0.7795 -- iter: 00512/10000
[A[ATraining Step: 1422  | total loss: [1m[32m0.60655[0m[0m | time: 6.249s
[2K| Adam | epoch: 010 | loss: 0.60655 - acc: 0.7828 -- iter: 00576/10000
[A[ATraining Step: 1423  | total loss: [1m[32m0.61305[0m[0m | time: 7.065s
[2K| Adam | epoch: 010 | loss: 0.61305 - acc: 0.7670 -- iter: 00640/10000
[A[ATraining Step: 1424  | total loss: [1m[32m0.62561[0m[0m | time: 7.894s
[2K| Adam | epoch: 010 | loss: 0.62561 - acc: 0.7653 -- iter: 00704/10000
[A[ATraining Step: 1425  | total loss: [1m[32m0.63019[0m[0m | time: 8.720s
[2K| Adam | epoch: 010 | loss: 0.63019 - acc: 0.7638 -- iter: 00768/10000
[A[ATraining Step: 1426  | total loss: [1m[32m0.63689[0m[0m | time: 9.540s
[2K| Adam | epoch: 010 | loss: 0.63689 - acc: 0.7624 -- iter: 00832/10000
[A[ATraining Step: 1427  | total loss: [1m[32m0.62080[0m[0m | time: 10.368s
[2K| Adam | epoch: 010 | loss: 0.62080 - acc: 0.7674 -- iter: 00896/10000
[A[ATraining Step: 1428  | total loss: [1m[32m0.60908[0m[0m | time: 11.155s
[2K| Adam | epoch: 010 | loss: 0.60908 - acc: 0.7719 -- iter: 00960/10000
[A[ATraining Step: 1429  | total loss: [1m[32m0.63178[0m[0m | time: 11.976s
[2K| Adam | epoch: 010 | loss: 0.63178 - acc: 0.7619 -- iter: 01024/10000
[A[ATraining Step: 1430  | total loss: [1m[32m0.63688[0m[0m | time: 12.797s
[2K| Adam | epoch: 010 | loss: 0.63688 - acc: 0.7560 -- iter: 01088/10000
[A[ATraining Step: 1431  | total loss: [1m[32m0.65194[0m[0m | time: 13.620s
[2K| Adam | epoch: 010 | loss: 0.65194 - acc: 0.7492 -- iter: 01152/10000
[A[ATraining Step: 1432  | total loss: [1m[32m0.64711[0m[0m | time: 14.432s
[2K| Adam | epoch: 010 | loss: 0.64711 - acc: 0.7571 -- iter: 01216/10000
[A[ATraining Step: 1433  | total loss: [1m[32m0.63563[0m[0m | time: 15.253s
[2K| Adam | epoch: 010 | loss: 0.63563 - acc: 0.7611 -- iter: 01280/10000
[A[ATraining Step: 1434  | total loss: [1m[32m0.63677[0m[0m | time: 16.090s
[2K| Adam | epoch: 010 | loss: 0.63677 - acc: 0.7662 -- iter: 01344/10000
[A[ATraining Step: 1435  | total loss: [1m[32m0.62397[0m[0m | time: 16.900s
[2K| Adam | epoch: 010 | loss: 0.62397 - acc: 0.7771 -- iter: 01408/10000
[A[ATraining Step: 1436  | total loss: [1m[32m0.62308[0m[0m | time: 17.683s
[2K| Adam | epoch: 010 | loss: 0.62308 - acc: 0.7775 -- iter: 01472/10000
[A[ATraining Step: 1437  | total loss: [1m[32m0.63120[0m[0m | time: 18.452s
[2K| Adam | epoch: 010 | loss: 0.63120 - acc: 0.7732 -- iter: 01536/10000
[A[ATraining Step: 1438  | total loss: [1m[32m0.64518[0m[0m | time: 19.228s
[2K| Adam | epoch: 010 | loss: 0.64518 - acc: 0.7724 -- iter: 01600/10000
[A[ATraining Step: 1439  | total loss: [1m[32m0.67096[0m[0m | time: 20.000s
[2K| Adam | epoch: 010 | loss: 0.67096 - acc: 0.7686 -- iter: 01664/10000
[A[ATraining Step: 1440  | total loss: [1m[32m0.66967[0m[0m | time: 20.772s
[2K| Adam | epoch: 010 | loss: 0.66967 - acc: 0.7668 -- iter: 01728/10000
[A[ATraining Step: 1441  | total loss: [1m[32m0.68335[0m[0m | time: 21.538s
[2K| Adam | epoch: 010 | loss: 0.68335 - acc: 0.7557 -- iter: 01792/10000
[A[ATraining Step: 1442  | total loss: [1m[32m0.66968[0m[0m | time: 22.307s
[2K| Adam | epoch: 010 | loss: 0.66968 - acc: 0.7598 -- iter: 01856/10000
[A[ATraining Step: 1443  | total loss: [1m[32m0.65695[0m[0m | time: 23.084s
[2K| Adam | epoch: 010 | loss: 0.65695 - acc: 0.7651 -- iter: 01920/10000
[A[ATraining Step: 1444  | total loss: [1m[32m0.65821[0m[0m | time: 23.851s
[2K| Adam | epoch: 010 | loss: 0.65821 - acc: 0.7573 -- iter: 01984/10000
[A[ATraining Step: 1445  | total loss: [1m[32m0.65456[0m[0m | time: 24.622s
[2K| Adam | epoch: 010 | loss: 0.65456 - acc: 0.7566 -- iter: 02048/10000
[A[ATraining Step: 1446  | total loss: [1m[32m0.65380[0m[0m | time: 25.394s
[2K| Adam | epoch: 010 | loss: 0.65380 - acc: 0.7544 -- iter: 02112/10000
[A[ATraining Step: 1447  | total loss: [1m[32m0.64449[0m[0m | time: 26.197s
[2K| Adam | epoch: 010 | loss: 0.64449 - acc: 0.7524 -- iter: 02176/10000
[A[ATraining Step: 1448  | total loss: [1m[32m0.65394[0m[0m | time: 26.979s
[2K| Adam | epoch: 010 | loss: 0.65394 - acc: 0.7459 -- iter: 02240/10000
[A[ATraining Step: 1449  | total loss: [1m[32m0.63688[0m[0m | time: 27.772s
[2K| Adam | epoch: 010 | loss: 0.63688 - acc: 0.7557 -- iter: 02304/10000
[A[ATraining Step: 1450  | total loss: [1m[32m0.66116[0m[0m | time: 28.603s
[2K| Adam | epoch: 010 | loss: 0.66116 - acc: 0.7489 -- iter: 02368/10000
[A[ATraining Step: 1451  | total loss: [1m[32m0.65495[0m[0m | time: 29.439s
[2K| Adam | epoch: 010 | loss: 0.65495 - acc: 0.7396 -- iter: 02432/10000
[A[ATraining Step: 1452  | total loss: [1m[32m0.65083[0m[0m | time: 30.262s
[2K| Adam | epoch: 010 | loss: 0.65083 - acc: 0.7422 -- iter: 02496/10000
[A[ATraining Step: 1453  | total loss: [1m[32m0.63982[0m[0m | time: 31.096s
[2K| Adam | epoch: 010 | loss: 0.63982 - acc: 0.7492 -- iter: 02560/10000
[A[ATraining Step: 1454  | total loss: [1m[32m0.64383[0m[0m | time: 31.916s
[2K| Adam | epoch: 010 | loss: 0.64383 - acc: 0.7493 -- iter: 02624/10000
[A[ATraining Step: 1455  | total loss: [1m[32m0.63933[0m[0m | time: 32.727s
[2K| Adam | epoch: 010 | loss: 0.63933 - acc: 0.7572 -- iter: 02688/10000
[A[ATraining Step: 1456  | total loss: [1m[32m0.62086[0m[0m | time: 33.525s
[2K| Adam | epoch: 010 | loss: 0.62086 - acc: 0.7705 -- iter: 02752/10000
[A[ATraining Step: 1457  | total loss: [1m[32m0.61067[0m[0m | time: 34.344s
[2K| Adam | epoch: 010 | loss: 0.61067 - acc: 0.7779 -- iter: 02816/10000
[A[ATraining Step: 1458  | total loss: [1m[32m0.64900[0m[0m | time: 35.142s
[2K| Adam | epoch: 010 | loss: 0.64900 - acc: 0.7766 -- iter: 02880/10000
[A[ATraining Step: 1459  | total loss: [1m[32m0.65485[0m[0m | time: 35.977s
[2K| Adam | epoch: 010 | loss: 0.65485 - acc: 0.7724 -- iter: 02944/10000
[A[ATraining Step: 1460  | total loss: [1m[32m0.64723[0m[0m | time: 36.789s
[2K| Adam | epoch: 010 | loss: 0.64723 - acc: 0.7717 -- iter: 03008/10000
[A[ATraining Step: 1461  | total loss: [1m[32m0.66470[0m[0m | time: 37.607s
[2K| Adam | epoch: 010 | loss: 0.66470 - acc: 0.7649 -- iter: 03072/10000
[A[ATraining Step: 1462  | total loss: [1m[32m0.66281[0m[0m | time: 38.427s
[2K| Adam | epoch: 010 | loss: 0.66281 - acc: 0.7649 -- iter: 03136/10000
[A[ATraining Step: 1463  | total loss: [1m[32m0.66647[0m[0m | time: 39.249s
[2K| Adam | epoch: 010 | loss: 0.66647 - acc: 0.7588 -- iter: 03200/10000
[A[ATraining Step: 1464  | total loss: [1m[32m0.67191[0m[0m | time: 40.036s
[2K| Adam | epoch: 010 | loss: 0.67191 - acc: 0.7594 -- iter: 03264/10000
[A[ATraining Step: 1465  | total loss: [1m[32m0.68009[0m[0m | time: 40.846s
[2K| Adam | epoch: 010 | loss: 0.68009 - acc: 0.7601 -- iter: 03328/10000
[A[ATraining Step: 1466  | total loss: [1m[32m0.67210[0m[0m | time: 41.670s
[2K| Adam | epoch: 010 | loss: 0.67210 - acc: 0.7591 -- iter: 03392/10000
[A[ATraining Step: 1467  | total loss: [1m[32m0.67846[0m[0m | time: 42.493s
[2K| Adam | epoch: 010 | loss: 0.67846 - acc: 0.7535 -- iter: 03456/10000
[A[ATraining Step: 1468  | total loss: [1m[32m0.67217[0m[0m | time: 43.312s
[2K| Adam | epoch: 010 | loss: 0.67217 - acc: 0.7531 -- iter: 03520/10000
[A[ATraining Step: 1469  | total loss: [1m[32m0.66079[0m[0m | time: 44.127s
[2K| Adam | epoch: 010 | loss: 0.66079 - acc: 0.7559 -- iter: 03584/10000
[A[ATraining Step: 1470  | total loss: [1m[32m0.64939[0m[0m | time: 44.942s
[2K| Adam | epoch: 010 | loss: 0.64939 - acc: 0.7585 -- iter: 03648/10000
[A[ATraining Step: 1471  | total loss: [1m[32m0.64414[0m[0m | time: 45.777s
[2K| Adam | epoch: 010 | loss: 0.64414 - acc: 0.7639 -- iter: 03712/10000
[A[ATraining Step: 1472  | total loss: [1m[32m0.65311[0m[0m | time: 46.592s
[2K| Adam | epoch: 010 | loss: 0.65311 - acc: 0.7531 -- iter: 03776/10000
[A[ATraining Step: 1473  | total loss: [1m[32m0.66020[0m[0m | time: 47.371s
[2K| Adam | epoch: 010 | loss: 0.66020 - acc: 0.7528 -- iter: 03840/10000
[A[ATraining Step: 1474  | total loss: [1m[32m0.66295[0m[0m | time: 48.145s
[2K| Adam | epoch: 010 | loss: 0.66295 - acc: 0.7478 -- iter: 03904/10000
[A[ATraining Step: 1475  | total loss: [1m[32m0.66144[0m[0m | time: 48.954s
[2K| Adam | epoch: 010 | loss: 0.66144 - acc: 0.7480 -- iter: 03968/10000
[A[ATraining Step: 1476  | total loss: [1m[32m0.66870[0m[0m | time: 49.760s
[2K| Adam | epoch: 010 | loss: 0.66870 - acc: 0.7451 -- iter: 04032/10000
[A[ATraining Step: 1477  | total loss: [1m[32m0.65728[0m[0m | time: 50.572s
[2K| Adam | epoch: 010 | loss: 0.65728 - acc: 0.7472 -- iter: 04096/10000
[A[ATraining Step: 1478  | total loss: [1m[32m0.64281[0m[0m | time: 51.403s
[2K| Adam | epoch: 010 | loss: 0.64281 - acc: 0.7506 -- iter: 04160/10000
[A[ATraining Step: 1479  | total loss: [1m[32m0.64608[0m[0m | time: 52.244s
[2K| Adam | epoch: 010 | loss: 0.64608 - acc: 0.7443 -- iter: 04224/10000
[A[ATraining Step: 1480  | total loss: [1m[32m0.64187[0m[0m | time: 53.074s
[2K| Adam | epoch: 010 | loss: 0.64187 - acc: 0.7511 -- iter: 04288/10000
[A[ATraining Step: 1481  | total loss: [1m[32m0.63138[0m[0m | time: 53.897s
[2K| Adam | epoch: 010 | loss: 0.63138 - acc: 0.7604 -- iter: 04352/10000
[A[ATraining Step: 1482  | total loss: [1m[32m0.64520[0m[0m | time: 54.708s
[2K| Adam | epoch: 010 | loss: 0.64520 - acc: 0.7624 -- iter: 04416/10000
[A[ATraining Step: 1483  | total loss: [1m[32m0.65836[0m[0m | time: 55.512s
[2K| Adam | epoch: 010 | loss: 0.65836 - acc: 0.7706 -- iter: 04480/10000
[A[ATraining Step: 1484  | total loss: [1m[32m0.66165[0m[0m | time: 56.381s
[2K| Adam | epoch: 010 | loss: 0.66165 - acc: 0.7732 -- iter: 04544/10000
[A[ATraining Step: 1485  | total loss: [1m[32m0.66905[0m[0m | time: 57.179s
[2K| Adam | epoch: 010 | loss: 0.66905 - acc: 0.7693 -- iter: 04608/10000
[A[ATraining Step: 1486  | total loss: [1m[32m0.64670[0m[0m | time: 57.972s
[2K| Adam | epoch: 010 | loss: 0.64670 - acc: 0.7768 -- iter: 04672/10000
[A[ATraining Step: 1487  | total loss: [1m[32m0.66978[0m[0m | time: 58.759s
[2K| Adam | epoch: 010 | loss: 0.66978 - acc: 0.7741 -- iter: 04736/10000
[A[ATraining Step: 1488  | total loss: [1m[32m0.69200[0m[0m | time: 59.542s
[2K| Adam | epoch: 010 | loss: 0.69200 - acc: 0.7623 -- iter: 04800/10000
[A[ATraining Step: 1489  | total loss: [1m[32m0.67883[0m[0m | time: 60.326s
[2K| Adam | epoch: 010 | loss: 0.67883 - acc: 0.7673 -- iter: 04864/10000
[A[ATraining Step: 1490  | total loss: [1m[32m0.68584[0m[0m | time: 61.114s
[2K| Adam | epoch: 010 | loss: 0.68584 - acc: 0.7625 -- iter: 04928/10000
[A[ATraining Step: 1491  | total loss: [1m[32m0.69664[0m[0m | time: 61.907s
[2K| Adam | epoch: 010 | loss: 0.69664 - acc: 0.7518 -- iter: 04992/10000
[A[ATraining Step: 1492  | total loss: [1m[32m0.72043[0m[0m | time: 62.711s
[2K| Adam | epoch: 010 | loss: 0.72043 - acc: 0.7423 -- iter: 05056/10000
[A[ATraining Step: 1493  | total loss: [1m[32m0.70823[0m[0m | time: 63.512s
[2K| Adam | epoch: 010 | loss: 0.70823 - acc: 0.7462 -- iter: 05120/10000
[A[ATraining Step: 1494  | total loss: [1m[32m0.70966[0m[0m | time: 64.363s
[2K| Adam | epoch: 010 | loss: 0.70966 - acc: 0.7434 -- iter: 05184/10000
[A[ATraining Step: 1495  | total loss: [1m[32m0.69511[0m[0m | time: 65.230s
[2K| Adam | epoch: 010 | loss: 0.69511 - acc: 0.7441 -- iter: 05248/10000
[A[ATraining Step: 1496  | total loss: [1m[32m0.68111[0m[0m | time: 66.105s
[2K| Adam | epoch: 010 | loss: 0.68111 - acc: 0.7447 -- iter: 05312/10000
[A[ATraining Step: 1497  | total loss: [1m[32m0.67219[0m[0m | time: 66.989s
[2K| Adam | epoch: 010 | loss: 0.67219 - acc: 0.7499 -- iter: 05376/10000
[A[ATraining Step: 1498  | total loss: [1m[32m0.66498[0m[0m | time: 67.852s
[2K| Adam | epoch: 010 | loss: 0.66498 - acc: 0.7515 -- iter: 05440/10000
[A[ATraining Step: 1499  | total loss: [1m[32m0.65217[0m[0m | time: 68.753s
[2K| Adam | epoch: 010 | loss: 0.65217 - acc: 0.7560 -- iter: 05504/10000
[A[ATraining Step: 1500  | total loss: [1m[32m0.66262[0m[0m | time: 73.186s
[2K| Adam | epoch: 010 | loss: 0.66262 - acc: 0.7523 | val_loss: 2.04854 - val_acc: 0.4429 -- iter: 05568/10000
--
Training Step: 1501  | total loss: [1m[32m0.66267[0m[0m | time: 74.043s
[2K| Adam | epoch: 010 | loss: 0.66267 - acc: 0.7583 -- iter: 05632/10000
[A[ATraining Step: 1502  | total loss: [1m[32m0.66353[0m[0m | time: 74.923s
[2K| Adam | epoch: 010 | loss: 0.66353 - acc: 0.7590 -- iter: 05696/10000
[A[ATraining Step: 1503  | total loss: [1m[32m0.68233[0m[0m | time: 75.965s
[2K| Adam | epoch: 010 | loss: 0.68233 - acc: 0.7566 -- iter: 05760/10000
[A[ATraining Step: 1504  | total loss: [1m[32m0.69130[0m[0m | time: 77.002s
[2K| Adam | epoch: 010 | loss: 0.69130 - acc: 0.7544 -- iter: 05824/10000
[A[ATraining Step: 1505  | total loss: [1m[32m0.67929[0m[0m | time: 77.858s
[2K| Adam | epoch: 010 | loss: 0.67929 - acc: 0.7680 -- iter: 05888/10000
[A[ATraining Step: 1506  | total loss: [1m[32m0.66154[0m[0m | time: 78.816s
[2K| Adam | epoch: 010 | loss: 0.66154 - acc: 0.7709 -- iter: 05952/10000
[A[ATraining Step: 1507  | total loss: [1m[32m0.66340[0m[0m | time: 79.827s
[2K| Adam | epoch: 010 | loss: 0.66340 - acc: 0.7672 -- iter: 06016/10000
[A[ATraining Step: 1508  | total loss: [1m[32m0.65267[0m[0m | time: 80.754s
[2K| Adam | epoch: 010 | loss: 0.65267 - acc: 0.7608 -- iter: 06080/10000
[A[ATraining Step: 1509  | total loss: [1m[32m0.64778[0m[0m | time: 81.707s
[2K| Adam | epoch: 010 | loss: 0.64778 - acc: 0.7675 -- iter: 06144/10000
[A[ATraining Step: 1510  | total loss: [1m[32m0.65447[0m[0m | time: 82.599s
[2K| Adam | epoch: 010 | loss: 0.65447 - acc: 0.7642 -- iter: 06208/10000
[A[ATraining Step: 1511  | total loss: [1m[32m0.67351[0m[0m | time: 83.533s
[2K| Adam | epoch: 010 | loss: 0.67351 - acc: 0.7550 -- iter: 06272/10000
[A[ATraining Step: 1512  | total loss: [1m[32m0.68637[0m[0m | time: 84.570s
[2K| Adam | epoch: 010 | loss: 0.68637 - acc: 0.7482 -- iter: 06336/10000
[A[ATraining Step: 1513  | total loss: [1m[32m0.66597[0m[0m | time: 85.499s
[2K| Adam | epoch: 010 | loss: 0.66597 - acc: 0.7578 -- iter: 06400/10000
[A[ATraining Step: 1514  | total loss: [1m[32m0.66342[0m[0m | time: 86.432s
[2K| Adam | epoch: 010 | loss: 0.66342 - acc: 0.7586 -- iter: 06464/10000
[A[ATraining Step: 1515  | total loss: [1m[32m0.65783[0m[0m | time: 87.309s
[2K| Adam | epoch: 010 | loss: 0.65783 - acc: 0.7593 -- iter: 06528/10000
[A[ATraining Step: 1516  | total loss: [1m[32m0.66705[0m[0m | time: 88.165s
[2K| Adam | epoch: 010 | loss: 0.66705 - acc: 0.7630 -- iter: 06592/10000
[A[ATraining Step: 1517  | total loss: [1m[32m0.67244[0m[0m | time: 89.074s
[2K| Adam | epoch: 010 | loss: 0.67244 - acc: 0.7586 -- iter: 06656/10000
[A[ATraining Step: 1518  | total loss: [1m[32m0.67022[0m[0m | time: 89.945s
[2K| Adam | epoch: 010 | loss: 0.67022 - acc: 0.7656 -- iter: 06720/10000
[A[ATraining Step: 1519  | total loss: [1m[32m0.67768[0m[0m | time: 90.785s
[2K| Adam | epoch: 010 | loss: 0.67768 - acc: 0.7624 -- iter: 06784/10000
[A[ATraining Step: 1520  | total loss: [1m[32m0.68433[0m[0m | time: 91.701s
[2K| Adam | epoch: 010 | loss: 0.68433 - acc: 0.7643 -- iter: 06848/10000
[A[ATraining Step: 1521  | total loss: [1m[32m0.67727[0m[0m | time: 92.644s
[2K| Adam | epoch: 010 | loss: 0.67727 - acc: 0.7707 -- iter: 06912/10000
[A[ATraining Step: 1522  | total loss: [1m[32m0.67709[0m[0m | time: 93.508s
[2K| Adam | epoch: 010 | loss: 0.67709 - acc: 0.7702 -- iter: 06976/10000
[A[ATraining Step: 1523  | total loss: [1m[32m0.69961[0m[0m | time: 94.338s
[2K| Adam | epoch: 010 | loss: 0.69961 - acc: 0.7713 -- iter: 07040/10000
[A[ATraining Step: 1524  | total loss: [1m[32m0.69304[0m[0m | time: 95.161s
[2K| Adam | epoch: 010 | loss: 0.69304 - acc: 0.7692 -- iter: 07104/10000
[A[ATraining Step: 1525  | total loss: [1m[32m0.67586[0m[0m | time: 96.029s
[2K| Adam | epoch: 010 | loss: 0.67586 - acc: 0.7719 -- iter: 07168/10000
[A[ATraining Step: 1526  | total loss: [1m[32m0.66867[0m[0m | time: 96.858s
[2K| Adam | epoch: 010 | loss: 0.66867 - acc: 0.7713 -- iter: 07232/10000
[A[ATraining Step: 1527  | total loss: [1m[32m0.65526[0m[0m | time: 97.633s
[2K| Adam | epoch: 010 | loss: 0.65526 - acc: 0.7676 -- iter: 07296/10000
[A[ATraining Step: 1528  | total loss: [1m[32m0.65297[0m[0m | time: 98.412s
[2K| Adam | epoch: 010 | loss: 0.65297 - acc: 0.7627 -- iter: 07360/10000
[A[ATraining Step: 1529  | total loss: [1m[32m0.64830[0m[0m | time: 99.261s
[2K| Adam | epoch: 010 | loss: 0.64830 - acc: 0.7568 -- iter: 07424/10000
[A[ATraining Step: 1530  | total loss: [1m[32m0.64758[0m[0m | time: 100.115s
[2K| Adam | epoch: 010 | loss: 0.64758 - acc: 0.7623 -- iter: 07488/10000
[A[ATraining Step: 1531  | total loss: [1m[32m0.62947[0m[0m | time: 100.993s
[2K| Adam | epoch: 010 | loss: 0.62947 - acc: 0.7689 -- iter: 07552/10000
[A[ATraining Step: 1532  | total loss: [1m[32m0.62602[0m[0m | time: 102.028s
[2K| Adam | epoch: 010 | loss: 0.62602 - acc: 0.7608 -- iter: 07616/10000
[A[ATraining Step: 1533  | total loss: [1m[32m0.60898[0m[0m | time: 103.141s
[2K| Adam | epoch: 010 | loss: 0.60898 - acc: 0.7660 -- iter: 07680/10000
[A[ATraining Step: 1534  | total loss: [1m[32m0.59200[0m[0m | time: 104.079s
[2K| Adam | epoch: 010 | loss: 0.59200 - acc: 0.7737 -- iter: 07744/10000
[A[ATraining Step: 1535  | total loss: [1m[32m0.59311[0m[0m | time: 105.078s
[2K| Adam | epoch: 010 | loss: 0.59311 - acc: 0.7776 -- iter: 07808/10000
[A[ATraining Step: 1536  | total loss: [1m[32m0.59396[0m[0m | time: 105.969s
[2K| Adam | epoch: 010 | loss: 0.59396 - acc: 0.7795 -- iter: 07872/10000
[A[ATraining Step: 1537  | total loss: [1m[32m0.61582[0m[0m | time: 106.860s
[2K| Adam | epoch: 010 | loss: 0.61582 - acc: 0.7750 -- iter: 07936/10000
[A[ATraining Step: 1538  | total loss: [1m[32m0.60608[0m[0m | time: 107.856s
[2K| Adam | epoch: 010 | loss: 0.60608 - acc: 0.7850 -- iter: 08000/10000
[A[ATraining Step: 1539  | total loss: [1m[32m0.62464[0m[0m | time: 108.731s
[2K| Adam | epoch: 010 | loss: 0.62464 - acc: 0.7846 -- iter: 08064/10000
[A[ATraining Step: 1540  | total loss: [1m[32m0.61154[0m[0m | time: 109.654s
[2K| Adam | epoch: 010 | loss: 0.61154 - acc: 0.7890 -- iter: 08128/10000
[A[ATraining Step: 1541  | total loss: [1m[32m0.61715[0m[0m | time: 110.605s
[2K| Adam | epoch: 010 | loss: 0.61715 - acc: 0.7913 -- iter: 08192/10000
[A[ATraining Step: 1542  | total loss: [1m[32m0.61967[0m[0m | time: 111.489s
[2K| Adam | epoch: 010 | loss: 0.61967 - acc: 0.7856 -- iter: 08256/10000
[A[ATraining Step: 1543  | total loss: [1m[32m0.62628[0m[0m | time: 112.367s
[2K| Adam | epoch: 010 | loss: 0.62628 - acc: 0.7852 -- iter: 08320/10000
[A[ATraining Step: 1544  | total loss: [1m[32m0.64076[0m[0m | time: 113.239s
[2K| Adam | epoch: 010 | loss: 0.64076 - acc: 0.7817 -- iter: 08384/10000
[A[ATraining Step: 1545  | total loss: [1m[32m0.62789[0m[0m | time: 114.253s
[2K| Adam | epoch: 010 | loss: 0.62789 - acc: 0.7848 -- iter: 08448/10000
[A[ATraining Step: 1546  | total loss: [1m[32m0.64962[0m[0m | time: 115.188s
[2K| Adam | epoch: 010 | loss: 0.64962 - acc: 0.7782 -- iter: 08512/10000
[A[ATraining Step: 1547  | total loss: [1m[32m0.67548[0m[0m | time: 116.083s
[2K| Adam | epoch: 010 | loss: 0.67548 - acc: 0.7613 -- iter: 08576/10000
[A[ATraining Step: 1548  | total loss: [1m[32m1.55560[0m[0m | time: 116.983s
[2K| Adam | epoch: 010 | loss: 1.55560 - acc: 0.6945 -- iter: 08640/10000
[A[ATraining Step: 1549  | total loss: [1m[32m1.45289[0m[0m | time: 117.875s
[2K| Adam | epoch: 010 | loss: 1.45289 - acc: 0.7063 -- iter: 08704/10000
[A[ATraining Step: 1550  | total loss: [1m[32m1.35865[0m[0m | time: 118.743s
[2K| Adam | epoch: 010 | loss: 1.35865 - acc: 0.7185 -- iter: 08768/10000
[A[ATraining Step: 1551  | total loss: [1m[32m1.26160[0m[0m | time: 119.567s
[2K| Adam | epoch: 010 | loss: 1.26160 - acc: 0.7295 -- iter: 08832/10000
[A[ATraining Step: 1552  | total loss: [1m[32m1.21022[0m[0m | time: 120.412s
[2K| Adam | epoch: 010 | loss: 1.21022 - acc: 0.7237 -- iter: 08896/10000
[A[ATraining Step: 1553  | total loss: [1m[32m1.16291[0m[0m | time: 121.255s
[2K| Adam | epoch: 010 | loss: 1.16291 - acc: 0.7263 -- iter: 08960/10000
[A[ATraining Step: 1554  | total loss: [1m[32m1.12910[0m[0m | time: 122.128s
[2K| Adam | epoch: 010 | loss: 1.12910 - acc: 0.7225 -- iter: 09024/10000
[A[ATraining Step: 1555  | total loss: [1m[32m1.08093[0m[0m | time: 123.029s
[2K| Adam | epoch: 010 | loss: 1.08093 - acc: 0.7283 -- iter: 09088/10000
[A[ATraining Step: 1556  | total loss: [1m[32m1.04494[0m[0m | time: 123.883s
[2K| Adam | epoch: 010 | loss: 1.04494 - acc: 0.7289 -- iter: 09152/10000
[A[ATraining Step: 1557  | total loss: [1m[32m0.99570[0m[0m | time: 124.781s
[2K| Adam | epoch: 010 | loss: 0.99570 - acc: 0.7326 -- iter: 09216/10000
[A[ATraining Step: 1558  | total loss: [1m[32m0.95148[0m[0m | time: 125.557s
[2K| Adam | epoch: 010 | loss: 0.95148 - acc: 0.7390 -- iter: 09280/10000
[A[ATraining Step: 1559  | total loss: [1m[32m0.93448[0m[0m | time: 126.468s
[2K| Adam | epoch: 010 | loss: 0.93448 - acc: 0.7354 -- iter: 09344/10000
[A[ATraining Step: 1560  | total loss: [1m[32m0.89379[0m[0m | time: 127.481s
[2K| Adam | epoch: 010 | loss: 0.89379 - acc: 0.7400 -- iter: 09408/10000
[A[ATraining Step: 1561  | total loss: [1m[32m0.87332[0m[0m | time: 128.430s
[2K| Adam | epoch: 010 | loss: 0.87332 - acc: 0.7457 -- iter: 09472/10000
[A[ATraining Step: 1562  | total loss: [1m[32m0.84746[0m[0m | time: 129.389s
[2K| Adam | epoch: 010 | loss: 0.84746 - acc: 0.7555 -- iter: 09536/10000
[A[ATraining Step: 1563  | total loss: [1m[32m0.82640[0m[0m | time: 130.293s
[2K| Adam | epoch: 010 | loss: 0.82640 - acc: 0.7565 -- iter: 09600/10000
[A[ATraining Step: 1564  | total loss: [1m[32m0.81210[0m[0m | time: 131.269s
[2K| Adam | epoch: 010 | loss: 0.81210 - acc: 0.7543 -- iter: 09664/10000
[A[ATraining Step: 1565  | total loss: [1m[32m0.78467[0m[0m | time: 132.288s
[2K| Adam | epoch: 010 | loss: 0.78467 - acc: 0.7570 -- iter: 09728/10000
[A[ATraining Step: 1566  | total loss: [1m[32m0.77499[0m[0m | time: 133.335s
[2K| Adam | epoch: 010 | loss: 0.77499 - acc: 0.7563 -- iter: 09792/10000
[A[ATraining Step: 1567  | total loss: [1m[32m0.76852[0m[0m | time: 134.346s
[2K| Adam | epoch: 010 | loss: 0.76852 - acc: 0.7604 -- iter: 09856/10000
[A[ATraining Step: 1568  | total loss: [1m[32m0.75025[0m[0m | time: 135.463s
[2K| Adam | epoch: 010 | loss: 0.75025 - acc: 0.7624 -- iter: 09920/10000
[A[ATraining Step: 1569  | total loss: [1m[32m0.74089[0m[0m | time: 136.546s
[2K| Adam | epoch: 010 | loss: 0.74089 - acc: 0.7643 -- iter: 09984/10000
[A[ATraining Step: 1570  | total loss: [1m[32m0.73155[0m[0m | time: 140.371s
[2K| Adam | epoch: 010 | loss: 0.73155 - acc: 0.7598 | val_loss: 1.84983 - val_acc: 0.4214 -- iter: 10000/10000
--
Training Step: 1571  | total loss: [1m[32m0.72643[0m[0m | time: 0.928s
[2K| Adam | epoch: 011 | loss: 0.72643 - acc: 0.7557 -- iter: 00064/10000
[A[ATraining Step: 1572  | total loss: [1m[32m0.70252[0m[0m | time: 1.899s
[2K| Adam | epoch: 011 | loss: 0.70252 - acc: 0.7551 -- iter: 00128/10000
[A[ATraining Step: 1573  | total loss: [1m[32m0.69665[0m[0m | time: 2.817s
[2K| Adam | epoch: 011 | loss: 0.69665 - acc: 0.7515 -- iter: 00192/10000
[A[ATraining Step: 1574  | total loss: [1m[32m0.66456[0m[0m | time: 3.755s
[2K| Adam | epoch: 011 | loss: 0.66456 - acc: 0.7638 -- iter: 00256/10000
[A[ATraining Step: 1575  | total loss: [1m[32m0.66167[0m[0m | time: 4.700s
[2K| Adam | epoch: 011 | loss: 0.66167 - acc: 0.7593 -- iter: 00320/10000
[A[ATraining Step: 1576  | total loss: [1m[32m0.66121[0m[0m | time: 5.619s
[2K| Adam | epoch: 011 | loss: 0.66121 - acc: 0.7615 -- iter: 00384/10000
[A[ATraining Step: 1577  | total loss: [1m[32m0.65169[0m[0m | time: 6.511s
[2K| Adam | epoch: 011 | loss: 0.65169 - acc: 0.7604 -- iter: 00448/10000
[A[ATraining Step: 1578  | total loss: [1m[32m0.64455[0m[0m | time: 7.416s
[2K| Adam | epoch: 011 | loss: 0.64455 - acc: 0.7718 -- iter: 00512/10000
[A[ATraining Step: 1579  | total loss: [1m[32m0.63833[0m[0m | time: 7.811s
[2K| Adam | epoch: 011 | loss: 0.63833 - acc: 0.7759 -- iter: 00576/10000
[A[ATraining Step: 1580  | total loss: [1m[32m0.62061[0m[0m | time: 8.210s
[2K| Adam | epoch: 011 | loss: 0.62061 - acc: 0.7670 -- iter: 00640/10000
[A[ATraining Step: 1581  | total loss: [1m[32m0.61650[0m[0m | time: 9.094s
[2K| Adam | epoch: 011 | loss: 0.61650 - acc: 0.7716 -- iter: 00704/10000
[A[ATraining Step: 1582  | total loss: [1m[32m0.63430[0m[0m | time: 9.964s
[2K| Adam | epoch: 011 | loss: 0.63430 - acc: 0.7726 -- iter: 00768/10000
[A[ATraining Step: 1583  | total loss: [1m[32m0.64016[0m[0m | time: 10.834s
[2K| Adam | epoch: 011 | loss: 0.64016 - acc: 0.7687 -- iter: 00832/10000
[A[ATraining Step: 1584  | total loss: [1m[32m0.64058[0m[0m | time: 11.721s
[2K| Adam | epoch: 011 | loss: 0.64058 - acc: 0.7669 -- iter: 00896/10000
[A[ATraining Step: 1585  | total loss: [1m[32m0.65003[0m[0m | time: 12.590s
[2K| Adam | epoch: 011 | loss: 0.65003 - acc: 0.7667 -- iter: 00960/10000
[A[ATraining Step: 1586  | total loss: [1m[32m0.66206[0m[0m | time: 13.428s
[2K| Adam | epoch: 011 | loss: 0.66206 - acc: 0.7666 -- iter: 01024/10000
[A[ATraining Step: 1587  | total loss: [1m[32m0.65274[0m[0m | time: 14.283s
[2K| Adam | epoch: 011 | loss: 0.65274 - acc: 0.7712 -- iter: 01088/10000
[A[ATraining Step: 1588  | total loss: [1m[32m0.63642[0m[0m | time: 15.119s
[2K| Adam | epoch: 011 | loss: 0.63642 - acc: 0.7753 -- iter: 01152/10000
[A[ATraining Step: 1589  | total loss: [1m[32m0.62763[0m[0m | time: 15.978s
[2K| Adam | epoch: 011 | loss: 0.62763 - acc: 0.7759 -- iter: 01216/10000
[A[ATraining Step: 1590  | total loss: [1m[32m0.65116[0m[0m | time: 16.811s
[2K| Adam | epoch: 011 | loss: 0.65116 - acc: 0.7671 -- iter: 01280/10000
[A[ATraining Step: 1591  | total loss: [1m[32m0.65560[0m[0m | time: 17.639s
[2K| Adam | epoch: 011 | loss: 0.65560 - acc: 0.7638 -- iter: 01344/10000
[A[ATraining Step: 1592  | total loss: [1m[32m0.66600[0m[0m | time: 18.463s
[2K| Adam | epoch: 011 | loss: 0.66600 - acc: 0.7578 -- iter: 01408/10000
[A[ATraining Step: 1593  | total loss: [1m[32m0.66722[0m[0m | time: 19.309s
[2K| Adam | epoch: 011 | loss: 0.66722 - acc: 0.7570 -- iter: 01472/10000
[A[ATraining Step: 1594  | total loss: [1m[32m0.67312[0m[0m | time: 20.298s
[2K| Adam | epoch: 011 | loss: 0.67312 - acc: 0.7532 -- iter: 01536/10000
[A[ATraining Step: 1595  | total loss: [1m[32m0.67356[0m[0m | time: 21.214s
[2K| Adam | epoch: 011 | loss: 0.67356 - acc: 0.7560 -- iter: 01600/10000
[A[ATraining Step: 1596  | total loss: [1m[32m0.67968[0m[0m | time: 22.115s
[2K| Adam | epoch: 011 | loss: 0.67968 - acc: 0.7538 -- iter: 01664/10000
[A[ATraining Step: 1597  | total loss: [1m[32m0.68114[0m[0m | time: 22.985s
[2K| Adam | epoch: 011 | loss: 0.68114 - acc: 0.7472 -- iter: 01728/10000
[A[ATraining Step: 1598  | total loss: [1m[32m0.69048[0m[0m | time: 23.853s
[2K| Adam | epoch: 011 | loss: 0.69048 - acc: 0.7459 -- iter: 01792/10000
[A[ATraining Step: 1599  | total loss: [1m[32m0.68065[0m[0m | time: 24.736s
[2K| Adam | epoch: 011 | loss: 0.68065 - acc: 0.7510 -- iter: 01856/10000
[A[ATraining Step: 1600  | total loss: [1m[32m0.66866[0m[0m | time: 27.910s
[2K| Adam | epoch: 011 | loss: 0.66866 - acc: 0.7540 | val_loss: 1.90428 - val_acc: 0.4171 -- iter: 01920/10000
--
Training Step: 1601  | total loss: [1m[32m0.66325[0m[0m | time: 28.756s
[2K| Adam | epoch: 011 | loss: 0.66325 - acc: 0.7536 -- iter: 01984/10000
[A[ATraining Step: 1602  | total loss: [1m[32m0.66081[0m[0m | time: 29.673s
[2K| Adam | epoch: 011 | loss: 0.66081 - acc: 0.7548 -- iter: 02048/10000
[A[ATraining Step: 1603  | total loss: [1m[32m0.67569[0m[0m | time: 30.566s
[2K| Adam | epoch: 011 | loss: 0.67569 - acc: 0.7403 -- iter: 02112/10000
[A[ATraining Step: 1604  | total loss: [1m[32m0.66891[0m[0m | time: 31.436s
[2K| Adam | epoch: 011 | loss: 0.66891 - acc: 0.7506 -- iter: 02176/10000
[A[ATraining Step: 1605  | total loss: [1m[32m0.66871[0m[0m | time: 32.304s
[2K| Adam | epoch: 011 | loss: 0.66871 - acc: 0.7521 -- iter: 02240/10000
[A[ATraining Step: 1606  | total loss: [1m[32m0.66547[0m[0m | time: 33.210s
[2K| Adam | epoch: 011 | loss: 0.66547 - acc: 0.7566 -- iter: 02304/10000
[A[ATraining Step: 1607  | total loss: [1m[32m0.66208[0m[0m | time: 34.094s
[2K| Adam | epoch: 011 | loss: 0.66208 - acc: 0.7591 -- iter: 02368/10000
[A[ATraining Step: 1608  | total loss: [1m[32m0.66924[0m[0m | time: 34.964s
[2K| Adam | epoch: 011 | loss: 0.66924 - acc: 0.7550 -- iter: 02432/10000
[A[ATraining Step: 1609  | total loss: [1m[32m0.66066[0m[0m | time: 35.858s
[2K| Adam | epoch: 011 | loss: 0.66066 - acc: 0.7670 -- iter: 02496/10000
[A[ATraining Step: 1610  | total loss: [1m[32m0.66113[0m[0m | time: 36.724s
[2K| Adam | epoch: 011 | loss: 0.66113 - acc: 0.7700 -- iter: 02560/10000
[A[ATraining Step: 1611  | total loss: [1m[32m0.66164[0m[0m | time: 37.599s
[2K| Adam | epoch: 011 | loss: 0.66164 - acc: 0.7680 -- iter: 02624/10000
[A[ATraining Step: 1612  | total loss: [1m[32m0.66302[0m[0m | time: 38.447s
[2K| Adam | epoch: 011 | loss: 0.66302 - acc: 0.7646 -- iter: 02688/10000
[A[ATraining Step: 1613  | total loss: [1m[32m0.66094[0m[0m | time: 39.288s
[2K| Adam | epoch: 011 | loss: 0.66094 - acc: 0.7601 -- iter: 02752/10000
[A[ATraining Step: 1614  | total loss: [1m[32m0.63923[0m[0m | time: 40.111s
[2K| Adam | epoch: 011 | loss: 0.63923 - acc: 0.7669 -- iter: 02816/10000
[A[ATraining Step: 1615  | total loss: [1m[32m0.62971[0m[0m | time: 40.972s
[2K| Adam | epoch: 011 | loss: 0.62971 - acc: 0.7699 -- iter: 02880/10000
[A[ATraining Step: 1616  | total loss: [1m[32m0.64667[0m[0m | time: 41.832s
[2K| Adam | epoch: 011 | loss: 0.64667 - acc: 0.7648 -- iter: 02944/10000
[A[ATraining Step: 1617  | total loss: [1m[32m0.65078[0m[0m | time: 42.665s
[2K| Adam | epoch: 011 | loss: 0.65078 - acc: 0.7648 -- iter: 03008/10000
[A[ATraining Step: 1618  | total loss: [1m[32m0.65364[0m[0m | time: 43.509s
[2K| Adam | epoch: 011 | loss: 0.65364 - acc: 0.7618 -- iter: 03072/10000
[A[ATraining Step: 1619  | total loss: [1m[32m0.65334[0m[0m | time: 44.360s
[2K| Adam | epoch: 011 | loss: 0.65334 - acc: 0.7669 -- iter: 03136/10000
[A[ATraining Step: 1620  | total loss: [1m[32m0.64666[0m[0m | time: 45.196s
[2K| Adam | epoch: 011 | loss: 0.64666 - acc: 0.7683 -- iter: 03200/10000
[A[ATraining Step: 1621  | total loss: [1m[32m0.63299[0m[0m | time: 46.067s
[2K| Adam | epoch: 011 | loss: 0.63299 - acc: 0.7743 -- iter: 03264/10000
[A[ATraining Step: 1622  | total loss: [1m[32m0.64208[0m[0m | time: 46.911s
[2K| Adam | epoch: 011 | loss: 0.64208 - acc: 0.7703 -- iter: 03328/10000
[A[ATraining Step: 1623  | total loss: [1m[32m0.63895[0m[0m | time: 47.782s
[2K| Adam | epoch: 011 | loss: 0.63895 - acc: 0.7745 -- iter: 03392/10000
[A[ATraining Step: 1624  | total loss: [1m[32m0.62641[0m[0m | time: 48.618s
[2K| Adam | epoch: 011 | loss: 0.62641 - acc: 0.7783 -- iter: 03456/10000
[A[ATraining Step: 1625  | total loss: [1m[32m0.64605[0m[0m | time: 49.484s
[2K| Adam | epoch: 011 | loss: 0.64605 - acc: 0.7708 -- iter: 03520/10000
[A[ATraining Step: 1626  | total loss: [1m[32m0.67782[0m[0m | time: 50.342s
[2K| Adam | epoch: 011 | loss: 0.67782 - acc: 0.7547 -- iter: 03584/10000
[A[ATraining Step: 1627  | total loss: [1m[32m0.67669[0m[0m | time: 51.220s
[2K| Adam | epoch: 011 | loss: 0.67669 - acc: 0.7511 -- iter: 03648/10000
[A[ATraining Step: 1628  | total loss: [1m[32m0.67358[0m[0m | time: 52.074s
[2K| Adam | epoch: 011 | loss: 0.67358 - acc: 0.7494 -- iter: 03712/10000
[A[ATraining Step: 1629  | total loss: [1m[32m0.67683[0m[0m | time: 52.908s
[2K| Adam | epoch: 011 | loss: 0.67683 - acc: 0.7448 -- iter: 03776/10000
[A[ATraining Step: 1630  | total loss: [1m[32m0.66995[0m[0m | time: 53.783s
[2K| Adam | epoch: 011 | loss: 0.66995 - acc: 0.7469 -- iter: 03840/10000
[A[ATraining Step: 1631  | total loss: [1m[32m0.65833[0m[0m | time: 54.655s
[2K| Adam | epoch: 011 | loss: 0.65833 - acc: 0.7487 -- iter: 03904/10000
[A[ATraining Step: 1632  | total loss: [1m[32m0.66238[0m[0m | time: 55.564s
[2K| Adam | epoch: 011 | loss: 0.66238 - acc: 0.7473 -- iter: 03968/10000
[A[ATraining Step: 1633  | total loss: [1m[32m0.66390[0m[0m | time: 56.434s
[2K| Adam | epoch: 011 | loss: 0.66390 - acc: 0.7429 -- iter: 04032/10000
[A[ATraining Step: 1634  | total loss: [1m[32m0.67129[0m[0m | time: 57.290s
[2K| Adam | epoch: 011 | loss: 0.67129 - acc: 0.7405 -- iter: 04096/10000
[A[ATraining Step: 1635  | total loss: [1m[32m0.66713[0m[0m | time: 58.144s
[2K| Adam | epoch: 011 | loss: 0.66713 - acc: 0.7461 -- iter: 04160/10000
[A[ATraining Step: 1636  | total loss: [1m[32m0.65916[0m[0m | time: 59.022s
[2K| Adam | epoch: 011 | loss: 0.65916 - acc: 0.7449 -- iter: 04224/10000
[A[ATraining Step: 1637  | total loss: [1m[32m0.65948[0m[0m | time: 59.918s
[2K| Adam | epoch: 011 | loss: 0.65948 - acc: 0.7486 -- iter: 04288/10000
[A[ATraining Step: 1638  | total loss: [1m[32m0.67243[0m[0m | time: 60.797s
[2K| Adam | epoch: 011 | loss: 0.67243 - acc: 0.7471 -- iter: 04352/10000
[A[ATraining Step: 1639  | total loss: [1m[32m0.66265[0m[0m | time: 61.637s
[2K| Adam | epoch: 011 | loss: 0.66265 - acc: 0.7521 -- iter: 04416/10000
[A[ATraining Step: 1640  | total loss: [1m[32m0.63949[0m[0m | time: 62.501s
[2K| Adam | epoch: 011 | loss: 0.63949 - acc: 0.7597 -- iter: 04480/10000
[A[ATraining Step: 1641  | total loss: [1m[32m0.63847[0m[0m | time: 63.347s
[2K| Adam | epoch: 011 | loss: 0.63847 - acc: 0.7572 -- iter: 04544/10000
[A[ATraining Step: 1642  | total loss: [1m[32m0.65925[0m[0m | time: 64.190s
[2K| Adam | epoch: 011 | loss: 0.65925 - acc: 0.7471 -- iter: 04608/10000
[A[ATraining Step: 1643  | total loss: [1m[32m0.65610[0m[0m | time: 65.027s
[2K| Adam | epoch: 011 | loss: 0.65610 - acc: 0.7521 -- iter: 04672/10000
[A[ATraining Step: 1644  | total loss: [1m[32m0.67628[0m[0m | time: 65.915s
[2K| Adam | epoch: 011 | loss: 0.67628 - acc: 0.7409 -- iter: 04736/10000
[A[ATraining Step: 1645  | total loss: [1m[32m0.65943[0m[0m | time: 66.750s
[2K| Adam | epoch: 011 | loss: 0.65943 - acc: 0.7434 -- iter: 04800/10000
[A[ATraining Step: 1646  | total loss: [1m[32m0.65094[0m[0m | time: 67.599s
[2K| Adam | epoch: 011 | loss: 0.65094 - acc: 0.7487 -- iter: 04864/10000
[A[ATraining Step: 1647  | total loss: [1m[32m0.63544[0m[0m | time: 68.438s
[2K| Adam | epoch: 011 | loss: 0.63544 - acc: 0.7551 -- iter: 04928/10000
[A[ATraining Step: 1648  | total loss: [1m[32m0.62265[0m[0m | time: 69.274s
[2K| Adam | epoch: 011 | loss: 0.62265 - acc: 0.7593 -- iter: 04992/10000
[A[ATraining Step: 1649  | total loss: [1m[32m0.60784[0m[0m | time: 70.154s
[2K| Adam | epoch: 011 | loss: 0.60784 - acc: 0.7631 -- iter: 05056/10000
[A[ATraining Step: 1650  | total loss: [1m[32m0.60165[0m[0m | time: 71.002s
[2K| Adam | epoch: 011 | loss: 0.60165 - acc: 0.7664 -- iter: 05120/10000
[A[ATraining Step: 1651  | total loss: [1m[32m0.59691[0m[0m | time: 71.842s
[2K| Adam | epoch: 011 | loss: 0.59691 - acc: 0.7648 -- iter: 05184/10000
[A[ATraining Step: 1652  | total loss: [1m[32m0.60278[0m[0m | time: 72.704s
[2K| Adam | epoch: 011 | loss: 0.60278 - acc: 0.7649 -- iter: 05248/10000
[A[ATraining Step: 1653  | total loss: [1m[32m0.58226[0m[0m | time: 73.557s
[2K| Adam | epoch: 011 | loss: 0.58226 - acc: 0.7728 -- iter: 05312/10000
[A[ATraining Step: 1654  | total loss: [1m[32m0.60897[0m[0m | time: 74.423s
[2K| Adam | epoch: 011 | loss: 0.60897 - acc: 0.7705 -- iter: 05376/10000
[A[ATraining Step: 1655  | total loss: [1m[32m0.59913[0m[0m | time: 75.297s
[2K| Adam | epoch: 011 | loss: 0.59913 - acc: 0.7747 -- iter: 05440/10000
[A[ATraining Step: 1656  | total loss: [1m[32m0.63003[0m[0m | time: 76.224s
[2K| Adam | epoch: 011 | loss: 0.63003 - acc: 0.7660 -- iter: 05504/10000
[A[ATraining Step: 1657  | total loss: [1m[32m0.63284[0m[0m | time: 77.087s
[2K| Adam | epoch: 011 | loss: 0.63284 - acc: 0.7691 -- iter: 05568/10000
[A[ATraining Step: 1658  | total loss: [1m[32m0.63651[0m[0m | time: 77.967s
[2K| Adam | epoch: 011 | loss: 0.63651 - acc: 0.7672 -- iter: 05632/10000
[A[ATraining Step: 1659  | total loss: [1m[32m0.63826[0m[0m | time: 78.847s
[2K| Adam | epoch: 011 | loss: 0.63826 - acc: 0.7654 -- iter: 05696/10000
[A[ATraining Step: 1660  | total loss: [1m[32m0.65330[0m[0m | time: 79.719s
[2K| Adam | epoch: 011 | loss: 0.65330 - acc: 0.7592 -- iter: 05760/10000
[A[ATraining Step: 1661  | total loss: [1m[32m0.64580[0m[0m | time: 80.592s
[2K| Adam | epoch: 011 | loss: 0.64580 - acc: 0.7583 -- iter: 05824/10000
[A[ATraining Step: 1662  | total loss: [1m[32m0.64892[0m[0m | time: 81.499s
[2K| Adam | epoch: 011 | loss: 0.64892 - acc: 0.7590 -- iter: 05888/10000
[A[ATraining Step: 1663  | total loss: [1m[32m0.64952[0m[0m | time: 82.375s
[2K| Adam | epoch: 011 | loss: 0.64952 - acc: 0.7612 -- iter: 05952/10000
[A[ATraining Step: 1664  | total loss: [1m[32m0.64095[0m[0m | time: 83.254s
[2K| Adam | epoch: 011 | loss: 0.64095 - acc: 0.7554 -- iter: 06016/10000
[A[ATraining Step: 1665  | total loss: [1m[32m0.67196[0m[0m | time: 84.145s
[2K| Adam | epoch: 011 | loss: 0.67196 - acc: 0.7424 -- iter: 06080/10000
[A[ATraining Step: 1666  | total loss: [1m[32m0.66135[0m[0m | time: 85.006s
[2K| Adam | epoch: 011 | loss: 0.66135 - acc: 0.7478 -- iter: 06144/10000
[A[ATraining Step: 1667  | total loss: [1m[32m0.66404[0m[0m | time: 85.884s
[2K| Adam | epoch: 011 | loss: 0.66404 - acc: 0.7449 -- iter: 06208/10000
[A[ATraining Step: 1668  | total loss: [1m[32m0.66403[0m[0m | time: 86.737s
[2K| Adam | epoch: 011 | loss: 0.66403 - acc: 0.7423 -- iter: 06272/10000
[A[ATraining Step: 1669  | total loss: [1m[32m0.65846[0m[0m | time: 87.575s
[2K| Adam | epoch: 011 | loss: 0.65846 - acc: 0.7384 -- iter: 06336/10000
[A[ATraining Step: 1670  | total loss: [1m[32m0.65528[0m[0m | time: 88.417s
[2K| Adam | epoch: 011 | loss: 0.65528 - acc: 0.7427 -- iter: 06400/10000
[A[ATraining Step: 1671  | total loss: [1m[32m0.63097[0m[0m | time: 89.297s
[2K| Adam | epoch: 011 | loss: 0.63097 - acc: 0.7575 -- iter: 06464/10000
[A[ATraining Step: 1672  | total loss: [1m[32m0.63610[0m[0m | time: 90.177s
[2K| Adam | epoch: 011 | loss: 0.63610 - acc: 0.7599 -- iter: 06528/10000
[A[ATraining Step: 1673  | total loss: [1m[32m0.64546[0m[0m | time: 91.017s
[2K| Adam | epoch: 011 | loss: 0.64546 - acc: 0.7511 -- iter: 06592/10000
[A[ATraining Step: 1674  | total loss: [1m[32m0.62534[0m[0m | time: 91.866s
[2K| Adam | epoch: 011 | loss: 0.62534 - acc: 0.7509 -- iter: 06656/10000
[A[ATraining Step: 1675  | total loss: [1m[32m0.62628[0m[0m | time: 92.728s
[2K| Adam | epoch: 011 | loss: 0.62628 - acc: 0.7571 -- iter: 06720/10000
[A[ATraining Step: 1676  | total loss: [1m[32m0.63183[0m[0m | time: 93.572s
[2K| Adam | epoch: 011 | loss: 0.63183 - acc: 0.7580 -- iter: 06784/10000
[A[ATraining Step: 1677  | total loss: [1m[32m0.64331[0m[0m | time: 94.441s
[2K| Adam | epoch: 011 | loss: 0.64331 - acc: 0.7493 -- iter: 06848/10000
[A[ATraining Step: 1678  | total loss: [1m[32m0.63363[0m[0m | time: 95.279s
[2K| Adam | epoch: 011 | loss: 0.63363 - acc: 0.7525 -- iter: 06912/10000
[A[ATraining Step: 1679  | total loss: [1m[32m0.63122[0m[0m | time: 96.183s
[2K| Adam | epoch: 011 | loss: 0.63122 - acc: 0.7523 -- iter: 06976/10000
[A[ATraining Step: 1680  | total loss: [1m[32m0.62738[0m[0m | time: 97.095s
[2K| Adam | epoch: 011 | loss: 0.62738 - acc: 0.7567 -- iter: 07040/10000
[A[ATraining Step: 1681  | total loss: [1m[32m0.63689[0m[0m | time: 97.992s
[2K| Adam | epoch: 011 | loss: 0.63689 - acc: 0.7623 -- iter: 07104/10000
[A[ATraining Step: 1682  | total loss: [1m[32m0.63959[0m[0m | time: 98.906s
[2K| Adam | epoch: 011 | loss: 0.63959 - acc: 0.7673 -- iter: 07168/10000
[A[ATraining Step: 1683  | total loss: [1m[32m0.63783[0m[0m | time: 99.792s
[2K| Adam | epoch: 011 | loss: 0.63783 - acc: 0.7703 -- iter: 07232/10000
[A[ATraining Step: 1684  | total loss: [1m[32m0.64031[0m[0m | time: 100.677s
[2K| Adam | epoch: 011 | loss: 0.64031 - acc: 0.7683 -- iter: 07296/10000
[A[ATraining Step: 1685  | total loss: [1m[32m0.64538[0m[0m | time: 101.569s
[2K| Adam | epoch: 011 | loss: 0.64538 - acc: 0.7727 -- iter: 07360/10000
[A[ATraining Step: 1686  | total loss: [1m[32m0.64414[0m[0m | time: 102.461s
[2K| Adam | epoch: 011 | loss: 0.64414 - acc: 0.7704 -- iter: 07424/10000
[A[ATraining Step: 1687  | total loss: [1m[32m0.64141[0m[0m | time: 103.346s
[2K| Adam | epoch: 011 | loss: 0.64141 - acc: 0.7731 -- iter: 07488/10000
[A[ATraining Step: 1688  | total loss: [1m[32m0.63737[0m[0m | time: 104.225s
[2K| Adam | epoch: 011 | loss: 0.63737 - acc: 0.7739 -- iter: 07552/10000
[A[ATraining Step: 1689  | total loss: [1m[32m0.64918[0m[0m | time: 105.147s
[2K| Adam | epoch: 011 | loss: 0.64918 - acc: 0.7621 -- iter: 07616/10000
[A[ATraining Step: 1690  | total loss: [1m[32m0.65153[0m[0m | time: 106.089s
[2K| Adam | epoch: 011 | loss: 0.65153 - acc: 0.7578 -- iter: 07680/10000
[A[ATraining Step: 1691  | total loss: [1m[32m0.66010[0m[0m | time: 106.976s
[2K| Adam | epoch: 011 | loss: 0.66010 - acc: 0.7586 -- iter: 07744/10000
[A[ATraining Step: 1692  | total loss: [1m[32m0.65136[0m[0m | time: 107.827s
[2K| Adam | epoch: 011 | loss: 0.65136 - acc: 0.7608 -- iter: 07808/10000
[A[ATraining Step: 1693  | total loss: [1m[32m0.64343[0m[0m | time: 108.674s
[2K| Adam | epoch: 011 | loss: 0.64343 - acc: 0.7644 -- iter: 07872/10000
[A[ATraining Step: 1694  | total loss: [1m[32m0.65684[0m[0m | time: 109.503s
[2K| Adam | epoch: 011 | loss: 0.65684 - acc: 0.7505 -- iter: 07936/10000
[A[ATraining Step: 1695  | total loss: [1m[32m0.64996[0m[0m | time: 110.337s
[2K| Adam | epoch: 011 | loss: 0.64996 - acc: 0.7520 -- iter: 08000/10000
[A[ATraining Step: 1696  | total loss: [1m[32m0.66331[0m[0m | time: 111.173s
[2K| Adam | epoch: 011 | loss: 0.66331 - acc: 0.7471 -- iter: 08064/10000
[A[ATraining Step: 1697  | total loss: [1m[32m0.65565[0m[0m | time: 112.031s
[2K| Adam | epoch: 011 | loss: 0.65565 - acc: 0.7443 -- iter: 08128/10000
[A[ATraining Step: 1698  | total loss: [1m[32m0.65394[0m[0m | time: 112.864s
[2K| Adam | epoch: 011 | loss: 0.65394 - acc: 0.7464 -- iter: 08192/10000
[A[ATraining Step: 1699  | total loss: [1m[32m0.66473[0m[0m | time: 113.701s
[2K| Adam | epoch: 011 | loss: 0.66473 - acc: 0.7483 -- iter: 08256/10000
[A[ATraining Step: 1700  | total loss: [1m[32m0.65316[0m[0m | time: 116.751s
[2K| Adam | epoch: 011 | loss: 0.65316 - acc: 0.7563 | val_loss: 2.18249 - val_acc: 0.3971 -- iter: 08320/10000
--
Training Step: 1701  | total loss: [1m[32m0.64432[0m[0m | time: 117.557s
[2K| Adam | epoch: 011 | loss: 0.64432 - acc: 0.7635 -- iter: 08384/10000
[A[ATraining Step: 1702  | total loss: [1m[32m0.63987[0m[0m | time: 118.402s
[2K| Adam | epoch: 011 | loss: 0.63987 - acc: 0.7700 -- iter: 08448/10000
[A[ATraining Step: 1703  | total loss: [1m[32m0.63624[0m[0m | time: 119.255s
[2K| Adam | epoch: 011 | loss: 0.63624 - acc: 0.7664 -- iter: 08512/10000
[A[ATraining Step: 1704  | total loss: [1m[32m0.63725[0m[0m | time: 120.103s
[2K| Adam | epoch: 011 | loss: 0.63725 - acc: 0.7741 -- iter: 08576/10000
[A[ATraining Step: 1705  | total loss: [1m[32m0.62892[0m[0m | time: 120.951s
[2K| Adam | epoch: 011 | loss: 0.62892 - acc: 0.7811 -- iter: 08640/10000
[A[ATraining Step: 1706  | total loss: [1m[32m1.44068[0m[0m | time: 121.742s
[2K| Adam | epoch: 011 | loss: 1.44068 - acc: 0.7139 -- iter: 08704/10000
[A[ATraining Step: 1707  | total loss: [1m[32m1.36737[0m[0m | time: 122.590s
[2K| Adam | epoch: 011 | loss: 1.36737 - acc: 0.7238 -- iter: 08768/10000
[A[ATraining Step: 1708  | total loss: [1m[32m1.28024[0m[0m | time: 123.431s
[2K| Adam | epoch: 011 | loss: 1.28024 - acc: 0.7295 -- iter: 08832/10000
[A[ATraining Step: 1709  | total loss: [1m[32m1.21289[0m[0m | time: 124.317s
[2K| Adam | epoch: 011 | loss: 1.21289 - acc: 0.7316 -- iter: 08896/10000
[A[ATraining Step: 1710  | total loss: [1m[32m1.16523[0m[0m | time: 125.197s
[2K| Adam | epoch: 011 | loss: 1.16523 - acc: 0.7225 -- iter: 08960/10000
[A[ATraining Step: 1711  | total loss: [1m[32m1.09328[0m[0m | time: 126.117s
[2K| Adam | epoch: 011 | loss: 1.09328 - acc: 0.7299 -- iter: 09024/10000
[A[ATraining Step: 1712  | total loss: [1m[32m1.07711[0m[0m | time: 127.004s
[2K| Adam | epoch: 011 | loss: 1.07711 - acc: 0.7179 -- iter: 09088/10000
[A[ATraining Step: 1713  | total loss: [1m[32m1.03233[0m[0m | time: 127.875s
[2K| Adam | epoch: 011 | loss: 1.03233 - acc: 0.7226 -- iter: 09152/10000
[A[ATraining Step: 1714  | total loss: [1m[32m0.98090[0m[0m | time: 128.753s
[2K| Adam | epoch: 011 | loss: 0.98090 - acc: 0.7332 -- iter: 09216/10000
[A[ATraining Step: 1715  | total loss: [1m[32m0.94722[0m[0m | time: 129.636s
[2K| Adam | epoch: 011 | loss: 0.94722 - acc: 0.7349 -- iter: 09280/10000
[A[ATraining Step: 1716  | total loss: [1m[32m0.90631[0m[0m | time: 130.524s
[2K| Adam | epoch: 011 | loss: 0.90631 - acc: 0.7442 -- iter: 09344/10000
[A[ATraining Step: 1717  | total loss: [1m[32m0.87893[0m[0m | time: 131.383s
[2K| Adam | epoch: 011 | loss: 0.87893 - acc: 0.7526 -- iter: 09408/10000
[A[ATraining Step: 1718  | total loss: [1m[32m0.86583[0m[0m | time: 132.268s
[2K| Adam | epoch: 011 | loss: 0.86583 - acc: 0.7586 -- iter: 09472/10000
[A[ATraining Step: 1719  | total loss: [1m[32m0.84477[0m[0m | time: 133.106s
[2K| Adam | epoch: 011 | loss: 0.84477 - acc: 0.7593 -- iter: 09536/10000
[A[ATraining Step: 1720  | total loss: [1m[32m0.81387[0m[0m | time: 133.956s
[2K| Adam | epoch: 011 | loss: 0.81387 - acc: 0.7693 -- iter: 09600/10000
[A[ATraining Step: 1721  | total loss: [1m[32m0.78169[0m[0m | time: 134.830s
[2K| Adam | epoch: 011 | loss: 0.78169 - acc: 0.7736 -- iter: 09664/10000
[A[ATraining Step: 1722  | total loss: [1m[32m0.75645[0m[0m | time: 135.708s
[2K| Adam | epoch: 011 | loss: 0.75645 - acc: 0.7775 -- iter: 09728/10000
[A[ATraining Step: 1723  | total loss: [1m[32m0.77929[0m[0m | time: 137.193s
[2K| Adam | epoch: 011 | loss: 0.77929 - acc: 0.7669 -- iter: 09792/10000
[A[ATraining Step: 1724  | total loss: [1m[32m0.76009[0m[0m | time: 138.106s
[2K| Adam | epoch: 011 | loss: 0.76009 - acc: 0.7746 -- iter: 09856/10000
[A[ATraining Step: 1725  | total loss: [1m[32m0.75349[0m[0m | time: 139.063s
[2K| Adam | epoch: 011 | loss: 0.75349 - acc: 0.7722 -- iter: 09920/10000
[A[ATraining Step: 1726  | total loss: [1m[32m0.73940[0m[0m | time: 140.005s
[2K| Adam | epoch: 011 | loss: 0.73940 - acc: 0.7715 -- iter: 09984/10000
[A[ATraining Step: 1727  | total loss: [1m[32m0.71487[0m[0m | time: 143.411s
[2K| Adam | epoch: 011 | loss: 0.71487 - acc: 0.7740 | val_loss: 1.64645 - val_acc: 0.4486 -- iter: 10000/10000
--
Training Step: 1728  | total loss: [1m[32m0.71574[0m[0m | time: 0.899s
[2K| Adam | epoch: 012 | loss: 0.71574 - acc: 0.7732 -- iter: 00064/10000
[A[ATraining Step: 1729  | total loss: [1m[32m0.71321[0m[0m | time: 1.836s
[2K| Adam | epoch: 012 | loss: 0.71321 - acc: 0.7740 -- iter: 00128/10000
[A[ATraining Step: 1730  | total loss: [1m[32m0.70967[0m[0m | time: 2.793s
[2K| Adam | epoch: 012 | loss: 0.70967 - acc: 0.7685 -- iter: 00192/10000
[A[ATraining Step: 1731  | total loss: [1m[32m0.69720[0m[0m | time: 3.712s
[2K| Adam | epoch: 012 | loss: 0.69720 - acc: 0.7698 -- iter: 00256/10000
[A[ATraining Step: 1732  | total loss: [1m[32m0.67779[0m[0m | time: 4.600s
[2K| Adam | epoch: 012 | loss: 0.67779 - acc: 0.7756 -- iter: 00320/10000
[A[ATraining Step: 1733  | total loss: [1m[32m0.66894[0m[0m | time: 5.507s
[2K| Adam | epoch: 012 | loss: 0.66894 - acc: 0.7777 -- iter: 00384/10000
[A[ATraining Step: 1734  | total loss: [1m[32m0.65868[0m[0m | time: 6.401s
[2K| Adam | epoch: 012 | loss: 0.65868 - acc: 0.7812 -- iter: 00448/10000
[A[ATraining Step: 1735  | total loss: [1m[32m0.66873[0m[0m | time: 7.272s
[2K| Adam | epoch: 012 | loss: 0.66873 - acc: 0.7781 -- iter: 00512/10000
[A[ATraining Step: 1736  | total loss: [1m[32m0.66357[0m[0m | time: 8.119s
[2K| Adam | epoch: 012 | loss: 0.66357 - acc: 0.7800 -- iter: 00576/10000
[A[ATraining Step: 1737  | total loss: [1m[32m0.65575[0m[0m | time: 8.528s
[2K| Adam | epoch: 012 | loss: 0.65575 - acc: 0.7785 -- iter: 00640/10000
[A[ATraining Step: 1738  | total loss: [1m[32m0.62903[0m[0m | time: 8.930s
[2K| Adam | epoch: 012 | loss: 0.62903 - acc: 0.7944 -- iter: 00704/10000
[A[ATraining Step: 1739  | total loss: [1m[32m0.59861[0m[0m | time: 9.740s
[2K| Adam | epoch: 012 | loss: 0.59861 - acc: 0.8087 -- iter: 00768/10000
[A[ATraining Step: 1740  | total loss: [1m[32m0.60004[0m[0m | time: 10.592s
[2K| Adam | epoch: 012 | loss: 0.60004 - acc: 0.7997 -- iter: 00832/10000
[A[ATraining Step: 1741  | total loss: [1m[32m0.60190[0m[0m | time: 11.443s
[2K| Adam | epoch: 012 | loss: 0.60190 - acc: 0.7885 -- iter: 00896/10000
[A[ATraining Step: 1742  | total loss: [1m[32m0.61508[0m[0m | time: 12.355s
[2K| Adam | epoch: 012 | loss: 0.61508 - acc: 0.7831 -- iter: 00960/10000
[A[ATraining Step: 1743  | total loss: [1m[32m0.61100[0m[0m | time: 13.248s
[2K| Adam | epoch: 012 | loss: 0.61100 - acc: 0.7767 -- iter: 01024/10000
[A[ATraining Step: 1744  | total loss: [1m[32m0.63569[0m[0m | time: 14.182s
[2K| Adam | epoch: 012 | loss: 0.63569 - acc: 0.7693 -- iter: 01088/10000
[A[ATraining Step: 1745  | total loss: [1m[32m0.63334[0m[0m | time: 15.109s
[2K| Adam | epoch: 012 | loss: 0.63334 - acc: 0.7736 -- iter: 01152/10000
[A[ATraining Step: 1746  | total loss: [1m[32m0.64015[0m[0m | time: 16.096s
[2K| Adam | epoch: 012 | loss: 0.64015 - acc: 0.7713 -- iter: 01216/10000
[A[ATraining Step: 1747  | total loss: [1m[32m0.62746[0m[0m | time: 17.083s
[2K| Adam | epoch: 012 | loss: 0.62746 - acc: 0.7707 -- iter: 01280/10000
[A[ATraining Step: 1748  | total loss: [1m[32m0.63909[0m[0m | time: 18.061s
[2K| Adam | epoch: 012 | loss: 0.63909 - acc: 0.7593 -- iter: 01344/10000
[A[ATraining Step: 1749  | total loss: [1m[32m0.63791[0m[0m | time: 19.049s
[2K| Adam | epoch: 012 | loss: 0.63791 - acc: 0.7630 -- iter: 01408/10000
[A[ATraining Step: 1750  | total loss: [1m[32m0.65326[0m[0m | time: 20.034s
[2K| Adam | epoch: 012 | loss: 0.65326 - acc: 0.7555 -- iter: 01472/10000
[A[ATraining Step: 1751  | total loss: [1m[32m0.65526[0m[0m | time: 21.023s
[2K| Adam | epoch: 012 | loss: 0.65526 - acc: 0.7518 -- iter: 01536/10000
[A[ATraining Step: 1752  | total loss: [1m[32m0.64793[0m[0m | time: 21.983s
[2K| Adam | epoch: 012 | loss: 0.64793 - acc: 0.7563 -- iter: 01600/10000
[A[ATraining Step: 1753  | total loss: [1m[32m0.64663[0m[0m | time: 22.942s
[2K| Adam | epoch: 012 | loss: 0.64663 - acc: 0.7572 -- iter: 01664/10000
[A[ATraining Step: 1754  | total loss: [1m[32m0.63571[0m[0m | time: 23.879s
[2K| Adam | epoch: 012 | loss: 0.63571 - acc: 0.7596 -- iter: 01728/10000
[A[ATraining Step: 1755  | total loss: [1m[32m0.64095[0m[0m | time: 24.782s
[2K| Adam | epoch: 012 | loss: 0.64095 - acc: 0.7634 -- iter: 01792/10000
[A[ATraining Step: 1756  | total loss: [1m[32m0.62409[0m[0m | time: 25.697s
[2K| Adam | epoch: 012 | loss: 0.62409 - acc: 0.7714 -- iter: 01856/10000
[A[ATraining Step: 1757  | total loss: [1m[32m0.63364[0m[0m | time: 26.575s
[2K| Adam | epoch: 012 | loss: 0.63364 - acc: 0.7739 -- iter: 01920/10000
[A[ATraining Step: 1758  | total loss: [1m[32m0.64414[0m[0m | time: 27.442s
[2K| Adam | epoch: 012 | loss: 0.64414 - acc: 0.7716 -- iter: 01984/10000
[A[ATraining Step: 1759  | total loss: [1m[32m0.65121[0m[0m | time: 28.308s
[2K| Adam | epoch: 012 | loss: 0.65121 - acc: 0.7678 -- iter: 02048/10000
[A[ATraining Step: 1760  | total loss: [1m[32m0.65318[0m[0m | time: 29.136s
[2K| Adam | epoch: 012 | loss: 0.65318 - acc: 0.7707 -- iter: 02112/10000
[A[ATraining Step: 1761  | total loss: [1m[32m0.67022[0m[0m | time: 29.963s
[2K| Adam | epoch: 012 | loss: 0.67022 - acc: 0.7640 -- iter: 02176/10000
[A[ATraining Step: 1762  | total loss: [1m[32m0.67852[0m[0m | time: 30.793s
[2K| Adam | epoch: 012 | loss: 0.67852 - acc: 0.7657 -- iter: 02240/10000
[A[ATraining Step: 1763  | total loss: [1m[32m0.66884[0m[0m | time: 31.626s
[2K| Adam | epoch: 012 | loss: 0.66884 - acc: 0.7688 -- iter: 02304/10000
[A[ATraining Step: 1764  | total loss: [1m[32m0.66347[0m[0m | time: 32.487s
[2K| Adam | epoch: 012 | loss: 0.66347 - acc: 0.7748 -- iter: 02368/10000
[A[ATraining Step: 1765  | total loss: [1m[32m0.66414[0m[0m | time: 33.326s
[2K| Adam | epoch: 012 | loss: 0.66414 - acc: 0.7692 -- iter: 02432/10000
[A[ATraining Step: 1766  | total loss: [1m[32m0.65348[0m[0m | time: 34.167s
[2K| Adam | epoch: 012 | loss: 0.65348 - acc: 0.7625 -- iter: 02496/10000
[A[ATraining Step: 1767  | total loss: [1m[32m0.63294[0m[0m | time: 34.992s
[2K| Adam | epoch: 012 | loss: 0.63294 - acc: 0.7644 -- iter: 02560/10000
[A[ATraining Step: 1768  | total loss: [1m[32m0.61543[0m[0m | time: 35.849s
[2K| Adam | epoch: 012 | loss: 0.61543 - acc: 0.7645 -- iter: 02624/10000
[A[ATraining Step: 1769  | total loss: [1m[32m0.62512[0m[0m | time: 36.708s
[2K| Adam | epoch: 012 | loss: 0.62512 - acc: 0.7600 -- iter: 02688/10000
[A[ATraining Step: 1770  | total loss: [1m[32m0.63831[0m[0m | time: 37.560s
[2K| Adam | epoch: 012 | loss: 0.63831 - acc: 0.7543 -- iter: 02752/10000
[A[ATraining Step: 1771  | total loss: [1m[32m0.66612[0m[0m | time: 38.431s
[2K| Adam | epoch: 012 | loss: 0.66612 - acc: 0.7429 -- iter: 02816/10000
[A[ATraining Step: 1772  | total loss: [1m[32m0.65662[0m[0m | time: 39.305s
[2K| Adam | epoch: 012 | loss: 0.65662 - acc: 0.7483 -- iter: 02880/10000
[A[ATraining Step: 1773  | total loss: [1m[32m0.65785[0m[0m | time: 40.209s
[2K| Adam | epoch: 012 | loss: 0.65785 - acc: 0.7563 -- iter: 02944/10000
[A[ATraining Step: 1774  | total loss: [1m[32m0.65056[0m[0m | time: 41.072s
[2K| Adam | epoch: 012 | loss: 0.65056 - acc: 0.7572 -- iter: 03008/10000
[A[ATraining Step: 1775  | total loss: [1m[32m0.66696[0m[0m | time: 41.917s
[2K| Adam | epoch: 012 | loss: 0.66696 - acc: 0.7581 -- iter: 03072/10000
[A[ATraining Step: 1776  | total loss: [1m[32m0.65068[0m[0m | time: 42.798s
[2K| Adam | epoch: 012 | loss: 0.65068 - acc: 0.7604 -- iter: 03136/10000
[A[ATraining Step: 1777  | total loss: [1m[32m0.65505[0m[0m | time: 43.635s
[2K| Adam | epoch: 012 | loss: 0.65505 - acc: 0.7640 -- iter: 03200/10000
[A[ATraining Step: 1778  | total loss: [1m[32m0.64913[0m[0m | time: 44.465s
[2K| Adam | epoch: 012 | loss: 0.64913 - acc: 0.7704 -- iter: 03264/10000
[A[ATraining Step: 1779  | total loss: [1m[32m0.67188[0m[0m | time: 45.298s
[2K| Adam | epoch: 012 | loss: 0.67188 - acc: 0.7684 -- iter: 03328/10000
[A[ATraining Step: 1780  | total loss: [1m[32m0.66974[0m[0m | time: 46.130s
[2K| Adam | epoch: 012 | loss: 0.66974 - acc: 0.7759 -- iter: 03392/10000
[A[ATraining Step: 1781  | total loss: [1m[32m0.66132[0m[0m | time: 46.962s
[2K| Adam | epoch: 012 | loss: 0.66132 - acc: 0.7796 -- iter: 03456/10000
[A[ATraining Step: 1782  | total loss: [1m[32m0.65092[0m[0m | time: 47.797s
[2K| Adam | epoch: 012 | loss: 0.65092 - acc: 0.7813 -- iter: 03520/10000
[A[ATraining Step: 1783  | total loss: [1m[32m0.63573[0m[0m | time: 48.629s
[2K| Adam | epoch: 012 | loss: 0.63573 - acc: 0.7782 -- iter: 03584/10000
[A[ATraining Step: 1784  | total loss: [1m[32m0.63599[0m[0m | time: 49.451s
[2K| Adam | epoch: 012 | loss: 0.63599 - acc: 0.7801 -- iter: 03648/10000
[A[ATraining Step: 1785  | total loss: [1m[32m0.62803[0m[0m | time: 50.278s
[2K| Adam | epoch: 012 | loss: 0.62803 - acc: 0.7833 -- iter: 03712/10000
[A[ATraining Step: 1786  | total loss: [1m[32m0.62626[0m[0m | time: 51.106s
[2K| Adam | epoch: 012 | loss: 0.62626 - acc: 0.7768 -- iter: 03776/10000
[A[ATraining Step: 1787  | total loss: [1m[32m0.61767[0m[0m | time: 51.928s
[2K| Adam | epoch: 012 | loss: 0.61767 - acc: 0.7742 -- iter: 03840/10000
[A[ATraining Step: 1788  | total loss: [1m[32m0.60415[0m[0m | time: 52.789s
[2K| Adam | epoch: 012 | loss: 0.60415 - acc: 0.7749 -- iter: 03904/10000
[A[ATraining Step: 1789  | total loss: [1m[32m0.61806[0m[0m | time: 53.658s
[2K| Adam | epoch: 012 | loss: 0.61806 - acc: 0.7646 -- iter: 03968/10000
[A[ATraining Step: 1790  | total loss: [1m[32m0.62097[0m[0m | time: 54.505s
[2K| Adam | epoch: 012 | loss: 0.62097 - acc: 0.7631 -- iter: 04032/10000
[A[ATraining Step: 1791  | total loss: [1m[32m0.62683[0m[0m | time: 55.325s
[2K| Adam | epoch: 012 | loss: 0.62683 - acc: 0.7681 -- iter: 04096/10000
[A[ATraining Step: 1792  | total loss: [1m[32m0.62746[0m[0m | time: 56.181s
[2K| Adam | epoch: 012 | loss: 0.62746 - acc: 0.7647 -- iter: 04160/10000
[A[ATraining Step: 1793  | total loss: [1m[32m0.62386[0m[0m | time: 57.050s
[2K| Adam | epoch: 012 | loss: 0.62386 - acc: 0.7632 -- iter: 04224/10000
[A[ATraining Step: 1794  | total loss: [1m[32m0.61944[0m[0m | time: 57.898s
[2K| Adam | epoch: 012 | loss: 0.61944 - acc: 0.7588 -- iter: 04288/10000
[A[ATraining Step: 1795  | total loss: [1m[32m0.61456[0m[0m | time: 58.769s
[2K| Adam | epoch: 012 | loss: 0.61456 - acc: 0.7657 -- iter: 04352/10000
[A[ATraining Step: 1796  | total loss: [1m[32m0.62126[0m[0m | time: 59.615s
[2K| Adam | epoch: 012 | loss: 0.62126 - acc: 0.7641 -- iter: 04416/10000
[A[ATraining Step: 1797  | total loss: [1m[32m0.62384[0m[0m | time: 60.464s
[2K| Adam | epoch: 012 | loss: 0.62384 - acc: 0.7674 -- iter: 04480/10000
[A[ATraining Step: 1798  | total loss: [1m[32m0.62771[0m[0m | time: 61.323s
[2K| Adam | epoch: 012 | loss: 0.62771 - acc: 0.7625 -- iter: 04544/10000
[A[ATraining Step: 1799  | total loss: [1m[32m0.62025[0m[0m | time: 62.216s
[2K| Adam | epoch: 012 | loss: 0.62025 - acc: 0.7644 -- iter: 04608/10000
[A[ATraining Step: 1800  | total loss: [1m[32m0.62195[0m[0m | time: 65.244s
[2K| Adam | epoch: 012 | loss: 0.62195 - acc: 0.7692 | val_loss: 2.33957 - val_acc: 0.3457 -- iter: 04672/10000
--
Training Step: 1801  | total loss: [1m[32m0.60584[0m[0m | time: 66.084s
[2K| Adam | epoch: 012 | loss: 0.60584 - acc: 0.7782 -- iter: 04736/10000
[A[ATraining Step: 1802  | total loss: [1m[32m0.59494[0m[0m | time: 66.942s
[2K| Adam | epoch: 012 | loss: 0.59494 - acc: 0.7754 -- iter: 04800/10000
[A[ATraining Step: 1803  | total loss: [1m[32m0.59603[0m[0m | time: 67.784s
[2K| Adam | epoch: 012 | loss: 0.59603 - acc: 0.7713 -- iter: 04864/10000
[A[ATraining Step: 1804  | total loss: [1m[32m0.58414[0m[0m | time: 68.677s
[2K| Adam | epoch: 012 | loss: 0.58414 - acc: 0.7692 -- iter: 04928/10000
[A[ATraining Step: 1805  | total loss: [1m[32m0.59001[0m[0m | time: 69.572s
[2K| Adam | epoch: 012 | loss: 0.59001 - acc: 0.7657 -- iter: 04992/10000
[A[ATraining Step: 1806  | total loss: [1m[32m0.60073[0m[0m | time: 70.484s
[2K| Adam | epoch: 012 | loss: 0.60073 - acc: 0.7657 -- iter: 05056/10000
[A[ATraining Step: 1807  | total loss: [1m[32m0.60695[0m[0m | time: 71.395s
[2K| Adam | epoch: 012 | loss: 0.60695 - acc: 0.7626 -- iter: 05120/10000
[A[ATraining Step: 1808  | total loss: [1m[32m0.62117[0m[0m | time: 72.341s
[2K| Adam | epoch: 012 | loss: 0.62117 - acc: 0.7660 -- iter: 05184/10000
[A[ATraining Step: 1809  | total loss: [1m[32m0.60342[0m[0m | time: 73.245s
[2K| Adam | epoch: 012 | loss: 0.60342 - acc: 0.7753 -- iter: 05248/10000
[A[ATraining Step: 1810  | total loss: [1m[32m0.61258[0m[0m | time: 74.128s
[2K| Adam | epoch: 012 | loss: 0.61258 - acc: 0.7822 -- iter: 05312/10000
[A[ATraining Step: 1811  | total loss: [1m[32m0.58885[0m[0m | time: 74.969s
[2K| Adam | epoch: 012 | loss: 0.58885 - acc: 0.7946 -- iter: 05376/10000
[A[ATraining Step: 1812  | total loss: [1m[32m0.59089[0m[0m | time: 75.812s
[2K| Adam | epoch: 012 | loss: 0.59089 - acc: 0.8011 -- iter: 05440/10000
[A[ATraining Step: 1813  | total loss: [1m[32m0.58794[0m[0m | time: 76.658s
[2K| Adam | epoch: 012 | loss: 0.58794 - acc: 0.8022 -- iter: 05504/10000
[A[ATraining Step: 1814  | total loss: [1m[32m0.60369[0m[0m | time: 77.496s
[2K| Adam | epoch: 012 | loss: 0.60369 - acc: 0.8001 -- iter: 05568/10000
[A[ATraining Step: 1815  | total loss: [1m[32m0.62170[0m[0m | time: 78.348s
[2K| Adam | epoch: 012 | loss: 0.62170 - acc: 0.7857 -- iter: 05632/10000
[A[ATraining Step: 1816  | total loss: [1m[32m0.61458[0m[0m | time: 79.215s
[2K| Adam | epoch: 012 | loss: 0.61458 - acc: 0.7853 -- iter: 05696/10000
[A[ATraining Step: 1817  | total loss: [1m[32m0.61337[0m[0m | time: 80.074s
[2K| Adam | epoch: 012 | loss: 0.61337 - acc: 0.7864 -- iter: 05760/10000
[A[ATraining Step: 1818  | total loss: [1m[32m0.60029[0m[0m | time: 80.938s
[2K| Adam | epoch: 012 | loss: 0.60029 - acc: 0.7922 -- iter: 05824/10000
[A[ATraining Step: 1819  | total loss: [1m[32m0.62547[0m[0m | time: 81.775s
[2K| Adam | epoch: 012 | loss: 0.62547 - acc: 0.7848 -- iter: 05888/10000
[A[ATraining Step: 1820  | total loss: [1m[32m0.62068[0m[0m | time: 82.702s
[2K| Adam | epoch: 012 | loss: 0.62068 - acc: 0.7892 -- iter: 05952/10000
[A[ATraining Step: 1821  | total loss: [1m[32m0.62591[0m[0m | time: 83.573s
[2K| Adam | epoch: 012 | loss: 0.62591 - acc: 0.7868 -- iter: 06016/10000
[A[ATraining Step: 1822  | total loss: [1m[32m0.61637[0m[0m | time: 84.438s
[2K| Adam | epoch: 012 | loss: 0.61637 - acc: 0.7941 -- iter: 06080/10000
[A[ATraining Step: 1823  | total loss: [1m[32m0.62089[0m[0m | time: 85.306s
[2K| Adam | epoch: 012 | loss: 0.62089 - acc: 0.7928 -- iter: 06144/10000
[A[ATraining Step: 1824  | total loss: [1m[32m0.62977[0m[0m | time: 86.173s
[2K| Adam | epoch: 012 | loss: 0.62977 - acc: 0.7932 -- iter: 06208/10000
[A[ATraining Step: 1825  | total loss: [1m[32m0.62010[0m[0m | time: 87.051s
[2K| Adam | epoch: 012 | loss: 0.62010 - acc: 0.7920 -- iter: 06272/10000
[A[ATraining Step: 1826  | total loss: [1m[32m0.60628[0m[0m | time: 87.931s
[2K| Adam | epoch: 012 | loss: 0.60628 - acc: 0.7909 -- iter: 06336/10000
[A[ATraining Step: 1827  | total loss: [1m[32m0.62799[0m[0m | time: 88.816s
[2K| Adam | epoch: 012 | loss: 0.62799 - acc: 0.7915 -- iter: 06400/10000
[A[ATraining Step: 1828  | total loss: [1m[32m0.62431[0m[0m | time: 89.679s
[2K| Adam | epoch: 012 | loss: 0.62431 - acc: 0.7889 -- iter: 06464/10000
[A[ATraining Step: 1829  | total loss: [1m[32m0.61887[0m[0m | time: 90.545s
[2K| Adam | epoch: 012 | loss: 0.61887 - acc: 0.7928 -- iter: 06528/10000
[A[ATraining Step: 1830  | total loss: [1m[32m0.59801[0m[0m | time: 91.435s
[2K| Adam | epoch: 012 | loss: 0.59801 - acc: 0.8011 -- iter: 06592/10000
[A[ATraining Step: 1831  | total loss: [1m[32m0.60002[0m[0m | time: 92.341s
[2K| Adam | epoch: 012 | loss: 0.60002 - acc: 0.7944 -- iter: 06656/10000
[A[ATraining Step: 1832  | total loss: [1m[32m0.61180[0m[0m | time: 93.213s
[2K| Adam | epoch: 012 | loss: 0.61180 - acc: 0.7868 -- iter: 06720/10000
[A[ATraining Step: 1833  | total loss: [1m[32m0.60703[0m[0m | time: 94.083s
[2K| Adam | epoch: 012 | loss: 0.60703 - acc: 0.7847 -- iter: 06784/10000
[A[ATraining Step: 1834  | total loss: [1m[32m0.62232[0m[0m | time: 94.950s
[2K| Adam | epoch: 012 | loss: 0.62232 - acc: 0.7765 -- iter: 06848/10000
[A[ATraining Step: 1835  | total loss: [1m[32m0.61481[0m[0m | time: 95.781s
[2K| Adam | epoch: 012 | loss: 0.61481 - acc: 0.7755 -- iter: 06912/10000
[A[ATraining Step: 1836  | total loss: [1m[32m0.60479[0m[0m | time: 96.585s
[2K| Adam | epoch: 012 | loss: 0.60479 - acc: 0.7776 -- iter: 06976/10000
[A[ATraining Step: 1837  | total loss: [1m[32m0.60869[0m[0m | time: 97.418s
[2K| Adam | epoch: 012 | loss: 0.60869 - acc: 0.7827 -- iter: 07040/10000
[A[ATraining Step: 1838  | total loss: [1m[32m0.59500[0m[0m | time: 98.253s
[2K| Adam | epoch: 012 | loss: 0.59500 - acc: 0.7919 -- iter: 07104/10000
[A[ATraining Step: 1839  | total loss: [1m[32m0.59302[0m[0m | time: 99.077s
[2K| Adam | epoch: 012 | loss: 0.59302 - acc: 0.7924 -- iter: 07168/10000
[A[ATraining Step: 1840  | total loss: [1m[32m0.60043[0m[0m | time: 99.913s
[2K| Adam | epoch: 012 | loss: 0.60043 - acc: 0.7866 -- iter: 07232/10000
[A[ATraining Step: 1841  | total loss: [1m[32m0.59929[0m[0m | time: 100.740s
[2K| Adam | epoch: 012 | loss: 0.59929 - acc: 0.7845 -- iter: 07296/10000
[A[ATraining Step: 1842  | total loss: [1m[32m0.58652[0m[0m | time: 101.570s
[2K| Adam | epoch: 012 | loss: 0.58652 - acc: 0.7889 -- iter: 07360/10000
[A[ATraining Step: 1843  | total loss: [1m[32m0.59894[0m[0m | time: 102.391s
[2K| Adam | epoch: 012 | loss: 0.59894 - acc: 0.7850 -- iter: 07424/10000
[A[ATraining Step: 1844  | total loss: [1m[32m0.60215[0m[0m | time: 103.188s
[2K| Adam | epoch: 012 | loss: 0.60215 - acc: 0.7893 -- iter: 07488/10000
[A[ATraining Step: 1845  | total loss: [1m[32m0.60877[0m[0m | time: 103.991s
[2K| Adam | epoch: 012 | loss: 0.60877 - acc: 0.7838 -- iter: 07552/10000
[A[ATraining Step: 1846  | total loss: [1m[32m0.62864[0m[0m | time: 104.821s
[2K| Adam | epoch: 012 | loss: 0.62864 - acc: 0.7820 -- iter: 07616/10000
[A[ATraining Step: 1847  | total loss: [1m[32m0.62395[0m[0m | time: 105.649s
[2K| Adam | epoch: 012 | loss: 0.62395 - acc: 0.7741 -- iter: 07680/10000
[A[ATraining Step: 1848  | total loss: [1m[32m0.62088[0m[0m | time: 106.467s
[2K| Adam | epoch: 012 | loss: 0.62088 - acc: 0.7764 -- iter: 07744/10000
[A[ATraining Step: 1849  | total loss: [1m[32m0.60437[0m[0m | time: 107.280s
[2K| Adam | epoch: 012 | loss: 0.60437 - acc: 0.7815 -- iter: 07808/10000
[A[ATraining Step: 1850  | total loss: [1m[32m0.60183[0m[0m | time: 108.098s
[2K| Adam | epoch: 012 | loss: 0.60183 - acc: 0.7862 -- iter: 07872/10000
[A[ATraining Step: 1851  | total loss: [1m[32m0.62001[0m[0m | time: 108.916s
[2K| Adam | epoch: 012 | loss: 0.62001 - acc: 0.7857 -- iter: 07936/10000
[A[ATraining Step: 1852  | total loss: [1m[32m0.62857[0m[0m | time: 109.730s
[2K| Adam | epoch: 012 | loss: 0.62857 - acc: 0.7899 -- iter: 08000/10000
[A[ATraining Step: 1853  | total loss: [1m[32m0.61880[0m[0m | time: 110.582s
[2K| Adam | epoch: 012 | loss: 0.61880 - acc: 0.7860 -- iter: 08064/10000
[A[ATraining Step: 1854  | total loss: [1m[32m0.62665[0m[0m | time: 111.436s
[2K| Adam | epoch: 012 | loss: 0.62665 - acc: 0.7761 -- iter: 08128/10000
[A[ATraining Step: 1855  | total loss: [1m[32m0.61972[0m[0m | time: 112.326s
[2K| Adam | epoch: 012 | loss: 0.61972 - acc: 0.7797 -- iter: 08192/10000
[A[ATraining Step: 1856  | total loss: [1m[32m0.60948[0m[0m | time: 113.187s
[2K| Adam | epoch: 012 | loss: 0.60948 - acc: 0.7877 -- iter: 08256/10000
[A[ATraining Step: 1857  | total loss: [1m[32m0.59516[0m[0m | time: 114.064s
[2K| Adam | epoch: 012 | loss: 0.59516 - acc: 0.7949 -- iter: 08320/10000
[A[ATraining Step: 1858  | total loss: [1m[32m0.60175[0m[0m | time: 114.939s
[2K| Adam | epoch: 012 | loss: 0.60175 - acc: 0.7951 -- iter: 08384/10000
[A[ATraining Step: 1859  | total loss: [1m[32m0.59942[0m[0m | time: 115.791s
[2K| Adam | epoch: 012 | loss: 0.59942 - acc: 0.7921 -- iter: 08448/10000
[A[ATraining Step: 1860  | total loss: [1m[32m0.61506[0m[0m | time: 116.650s
[2K| Adam | epoch: 012 | loss: 0.61506 - acc: 0.7848 -- iter: 08512/10000
[A[ATraining Step: 1861  | total loss: [1m[32m0.61386[0m[0m | time: 117.507s
[2K| Adam | epoch: 012 | loss: 0.61386 - acc: 0.7844 -- iter: 08576/10000
[A[ATraining Step: 1862  | total loss: [1m[32m0.60309[0m[0m | time: 118.357s
[2K| Adam | epoch: 012 | loss: 0.60309 - acc: 0.7872 -- iter: 08640/10000
[A[ATraining Step: 1863  | total loss: [1m[32m0.59772[0m[0m | time: 119.196s
[2K| Adam | epoch: 012 | loss: 0.59772 - acc: 0.7898 -- iter: 08704/10000
[A[ATraining Step: 1864  | total loss: [1m[32m0.58623[0m[0m | time: 120.054s
[2K| Adam | epoch: 012 | loss: 0.58623 - acc: 0.7983 -- iter: 08768/10000
[A[ATraining Step: 1865  | total loss: [1m[32m0.58372[0m[0m | time: 120.916s
[2K| Adam | epoch: 012 | loss: 0.58372 - acc: 0.7935 -- iter: 08832/10000
[A[ATraining Step: 1866  | total loss: [1m[32m0.59574[0m[0m | time: 121.776s
[2K| Adam | epoch: 012 | loss: 0.59574 - acc: 0.7922 -- iter: 08896/10000
[A[ATraining Step: 1867  | total loss: [1m[32m0.58936[0m[0m | time: 122.677s
[2K| Adam | epoch: 012 | loss: 0.58936 - acc: 0.7911 -- iter: 08960/10000
[A[ATraining Step: 1868  | total loss: [1m[32m0.57653[0m[0m | time: 123.553s
[2K| Adam | epoch: 012 | loss: 0.57653 - acc: 0.7933 -- iter: 09024/10000
[A[ATraining Step: 1869  | total loss: [1m[32m0.57191[0m[0m | time: 124.409s
[2K| Adam | epoch: 012 | loss: 0.57191 - acc: 0.7905 -- iter: 09088/10000
[A[ATraining Step: 1870  | total loss: [1m[32m0.56521[0m[0m | time: 125.269s
[2K| Adam | epoch: 012 | loss: 0.56521 - acc: 0.7896 -- iter: 09152/10000
[A[ATraining Step: 1871  | total loss: [1m[32m0.57169[0m[0m | time: 126.122s
[2K| Adam | epoch: 012 | loss: 0.57169 - acc: 0.7872 -- iter: 09216/10000
[A[ATraining Step: 1872  | total loss: [1m[32m0.57242[0m[0m | time: 126.981s
[2K| Adam | epoch: 012 | loss: 0.57242 - acc: 0.7913 -- iter: 09280/10000
[A[ATraining Step: 1873  | total loss: [1m[32m0.57583[0m[0m | time: 127.861s
[2K| Adam | epoch: 012 | loss: 0.57583 - acc: 0.7965 -- iter: 09344/10000
[A[ATraining Step: 1874  | total loss: [1m[32m0.58895[0m[0m | time: 128.741s
[2K| Adam | epoch: 012 | loss: 0.58895 - acc: 0.7888 -- iter: 09408/10000
[A[ATraining Step: 1875  | total loss: [1m[32m0.58280[0m[0m | time: 129.603s
[2K| Adam | epoch: 012 | loss: 0.58280 - acc: 0.7958 -- iter: 09472/10000
[A[ATraining Step: 1876  | total loss: [1m[32m0.56901[0m[0m | time: 130.435s
[2K| Adam | epoch: 012 | loss: 0.56901 - acc: 0.8022 -- iter: 09536/10000
[A[ATraining Step: 1877  | total loss: [1m[32m0.56114[0m[0m | time: 131.284s
[2K| Adam | epoch: 012 | loss: 0.56114 - acc: 0.8063 -- iter: 09600/10000
[A[ATraining Step: 1878  | total loss: [1m[32m0.59313[0m[0m | time: 132.159s
[2K| Adam | epoch: 012 | loss: 0.59313 - acc: 0.7976 -- iter: 09664/10000
[A[ATraining Step: 1879  | total loss: [1m[32m0.60774[0m[0m | time: 133.002s
[2K| Adam | epoch: 012 | loss: 0.60774 - acc: 0.7959 -- iter: 09728/10000
[A[ATraining Step: 1880  | total loss: [1m[32m0.60555[0m[0m | time: 133.856s
[2K| Adam | epoch: 012 | loss: 0.60555 - acc: 0.8007 -- iter: 09792/10000
[A[ATraining Step: 1881  | total loss: [1m[32m0.62628[0m[0m | time: 134.703s
[2K| Adam | epoch: 012 | loss: 0.62628 - acc: 0.8035 -- iter: 09856/10000
[A[ATraining Step: 1882  | total loss: [1m[32m0.61520[0m[0m | time: 135.571s
[2K| Adam | epoch: 012 | loss: 0.61520 - acc: 0.8075 -- iter: 09920/10000
[A[ATraining Step: 1883  | total loss: [1m[32m0.62050[0m[0m | time: 136.420s
[2K| Adam | epoch: 012 | loss: 0.62050 - acc: 0.8002 -- iter: 09984/10000
[A[ATraining Step: 1884  | total loss: [1m[32m0.59315[0m[0m | time: 139.438s
[2K| Adam | epoch: 012 | loss: 0.59315 - acc: 0.8030 | val_loss: 1.91171 - val_acc: 0.4314 -- iter: 10000/10000
--
Training Step: 1885  | total loss: [1m[32m0.59602[0m[0m | time: 0.821s
[2K| Adam | epoch: 013 | loss: 0.59602 - acc: 0.7946 -- iter: 00064/10000
[A[ATraining Step: 1886  | total loss: [1m[32m0.61179[0m[0m | time: 1.707s
[2K| Adam | epoch: 013 | loss: 0.61179 - acc: 0.7870 -- iter: 00128/10000
[A[ATraining Step: 1887  | total loss: [1m[32m0.62649[0m[0m | time: 2.616s
[2K| Adam | epoch: 013 | loss: 0.62649 - acc: 0.7833 -- iter: 00192/10000
[A[ATraining Step: 1888  | total loss: [1m[32m0.61892[0m[0m | time: 3.529s
[2K| Adam | epoch: 013 | loss: 0.61892 - acc: 0.7846 -- iter: 00256/10000
[A[ATraining Step: 1889  | total loss: [1m[32m0.60721[0m[0m | time: 4.425s
[2K| Adam | epoch: 013 | loss: 0.60721 - acc: 0.7874 -- iter: 00320/10000
[A[ATraining Step: 1890  | total loss: [1m[32m0.60446[0m[0m | time: 5.329s
[2K| Adam | epoch: 013 | loss: 0.60446 - acc: 0.7837 -- iter: 00384/10000
[A[ATraining Step: 1891  | total loss: [1m[32m0.60041[0m[0m | time: 6.233s
[2K| Adam | epoch: 013 | loss: 0.60041 - acc: 0.7866 -- iter: 00448/10000
[A[ATraining Step: 1892  | total loss: [1m[32m0.59681[0m[0m | time: 7.164s
[2K| Adam | epoch: 013 | loss: 0.59681 - acc: 0.7876 -- iter: 00512/10000
[A[ATraining Step: 1893  | total loss: [1m[32m0.58297[0m[0m | time: 8.085s
[2K| Adam | epoch: 013 | loss: 0.58297 - acc: 0.7854 -- iter: 00576/10000
[A[ATraining Step: 1894  | total loss: [1m[32m0.58360[0m[0m | time: 8.956s
[2K| Adam | epoch: 013 | loss: 0.58360 - acc: 0.7881 -- iter: 00640/10000
[A[ATraining Step: 1895  | total loss: [1m[32m0.60413[0m[0m | time: 9.399s
[2K| Adam | epoch: 013 | loss: 0.60413 - acc: 0.7905 -- iter: 00704/10000
[A[ATraining Step: 1896  | total loss: [1m[32m0.62562[0m[0m | time: 9.832s
[2K| Adam | epoch: 013 | loss: 0.62562 - acc: 0.7865 -- iter: 00768/10000
[A[ATraining Step: 1897  | total loss: [1m[32m0.64715[0m[0m | time: 10.702s
[2K| Adam | epoch: 013 | loss: 0.64715 - acc: 0.7641 -- iter: 00832/10000
[A[ATraining Step: 1898  | total loss: [1m[32m0.65436[0m[0m | time: 11.568s
[2K| Adam | epoch: 013 | loss: 0.65436 - acc: 0.7611 -- iter: 00896/10000
[A[ATraining Step: 1899  | total loss: [1m[32m0.64604[0m[0m | time: 12.442s
[2K| Adam | epoch: 013 | loss: 0.64604 - acc: 0.7663 -- iter: 00960/10000
[A[ATraining Step: 1900  | total loss: [1m[32m0.65992[0m[0m | time: 15.590s
[2K| Adam | epoch: 013 | loss: 0.65992 - acc: 0.7631 | val_loss: 2.29689 - val_acc: 0.4229 -- iter: 01024/10000
--
Training Step: 1901  | total loss: [1m[32m0.66804[0m[0m | time: 16.473s
[2K| Adam | epoch: 013 | loss: 0.66804 - acc: 0.7602 -- iter: 01088/10000
[A[ATraining Step: 1902  | total loss: [1m[32m0.64331[0m[0m | time: 17.495s
[2K| Adam | epoch: 013 | loss: 0.64331 - acc: 0.7701 -- iter: 01152/10000
[A[ATraining Step: 1903  | total loss: [1m[32m0.63923[0m[0m | time: 18.419s
[2K| Adam | epoch: 013 | loss: 0.63923 - acc: 0.7712 -- iter: 01216/10000
[A[ATraining Step: 1904  | total loss: [1m[32m0.63496[0m[0m | time: 19.339s
[2K| Adam | epoch: 013 | loss: 0.63496 - acc: 0.7629 -- iter: 01280/10000
[A[ATraining Step: 1905  | total loss: [1m[32m0.63142[0m[0m | time: 20.243s
[2K| Adam | epoch: 013 | loss: 0.63142 - acc: 0.7663 -- iter: 01344/10000
[A[ATraining Step: 1906  | total loss: [1m[32m0.62474[0m[0m | time: 21.157s
[2K| Adam | epoch: 013 | loss: 0.62474 - acc: 0.7678 -- iter: 01408/10000
[A[ATraining Step: 1907  | total loss: [1m[32m0.61083[0m[0m | time: 22.063s
[2K| Adam | epoch: 013 | loss: 0.61083 - acc: 0.7738 -- iter: 01472/10000
[A[ATraining Step: 1908  | total loss: [1m[32m0.61351[0m[0m | time: 22.973s
[2K| Adam | epoch: 013 | loss: 0.61351 - acc: 0.7745 -- iter: 01536/10000
[A[ATraining Step: 1909  | total loss: [1m[32m0.63379[0m[0m | time: 23.855s
[2K| Adam | epoch: 013 | loss: 0.63379 - acc: 0.7690 -- iter: 01600/10000
[A[ATraining Step: 1910  | total loss: [1m[32m0.63016[0m[0m | time: 24.749s
[2K| Adam | epoch: 013 | loss: 0.63016 - acc: 0.7686 -- iter: 01664/10000
[A[ATraining Step: 1911  | total loss: [1m[32m0.61585[0m[0m | time: 25.604s
[2K| Adam | epoch: 013 | loss: 0.61585 - acc: 0.7699 -- iter: 01728/10000
[A[ATraining Step: 1912  | total loss: [1m[32m0.63681[0m[0m | time: 26.480s
[2K| Adam | epoch: 013 | loss: 0.63681 - acc: 0.7617 -- iter: 01792/10000
[A[ATraining Step: 1913  | total loss: [1m[32m0.66476[0m[0m | time: 27.365s
[2K| Adam | epoch: 013 | loss: 0.66476 - acc: 0.7527 -- iter: 01856/10000
[A[ATraining Step: 1914  | total loss: [1m[32m0.65750[0m[0m | time: 28.240s
[2K| Adam | epoch: 013 | loss: 0.65750 - acc: 0.7524 -- iter: 01920/10000
[A[ATraining Step: 1915  | total loss: [1m[32m0.64028[0m[0m | time: 29.082s
[2K| Adam | epoch: 013 | loss: 0.64028 - acc: 0.7553 -- iter: 01984/10000
[A[ATraining Step: 1916  | total loss: [1m[32m0.64840[0m[0m | time: 29.938s
[2K| Adam | epoch: 013 | loss: 0.64840 - acc: 0.7563 -- iter: 02048/10000
[A[ATraining Step: 1917  | total loss: [1m[32m0.65588[0m[0m | time: 30.796s
[2K| Adam | epoch: 013 | loss: 0.65588 - acc: 0.7479 -- iter: 02112/10000
[A[ATraining Step: 1918  | total loss: [1m[32m0.64481[0m[0m | time: 31.633s
[2K| Adam | epoch: 013 | loss: 0.64481 - acc: 0.7543 -- iter: 02176/10000
[A[ATraining Step: 1919  | total loss: [1m[32m0.65805[0m[0m | time: 32.500s
[2K| Adam | epoch: 013 | loss: 0.65805 - acc: 0.7414 -- iter: 02240/10000
[A[ATraining Step: 1920  | total loss: [1m[32m0.68723[0m[0m | time: 33.406s
[2K| Adam | epoch: 013 | loss: 0.68723 - acc: 0.7407 -- iter: 02304/10000
[A[ATraining Step: 1921  | total loss: [1m[32m0.68316[0m[0m | time: 34.293s
[2K| Adam | epoch: 013 | loss: 0.68316 - acc: 0.7338 -- iter: 02368/10000
[A[ATraining Step: 1922  | total loss: [1m[32m0.66467[0m[0m | time: 35.154s
[2K| Adam | epoch: 013 | loss: 0.66467 - acc: 0.7386 -- iter: 02432/10000
[A[ATraining Step: 1923  | total loss: [1m[32m0.66157[0m[0m | time: 36.027s
[2K| Adam | epoch: 013 | loss: 0.66157 - acc: 0.7413 -- iter: 02496/10000
[A[ATraining Step: 1924  | total loss: [1m[32m0.66291[0m[0m | time: 36.886s
[2K| Adam | epoch: 013 | loss: 0.66291 - acc: 0.7453 -- iter: 02560/10000
[A[ATraining Step: 1925  | total loss: [1m[32m0.64981[0m[0m | time: 37.756s
[2K| Adam | epoch: 013 | loss: 0.64981 - acc: 0.7489 -- iter: 02624/10000
[A[ATraining Step: 1926  | total loss: [1m[32m0.64689[0m[0m | time: 38.626s
[2K| Adam | epoch: 013 | loss: 0.64689 - acc: 0.7537 -- iter: 02688/10000
[A[ATraining Step: 1927  | total loss: [1m[32m0.63940[0m[0m | time: 39.497s
[2K| Adam | epoch: 013 | loss: 0.63940 - acc: 0.7596 -- iter: 02752/10000
[A[ATraining Step: 1928  | total loss: [1m[32m0.62183[0m[0m | time: 40.376s
[2K| Adam | epoch: 013 | loss: 0.62183 - acc: 0.7695 -- iter: 02816/10000
[A[ATraining Step: 1929  | total loss: [1m[32m0.61899[0m[0m | time: 41.248s
[2K| Adam | epoch: 013 | loss: 0.61899 - acc: 0.7770 -- iter: 02880/10000
[A[ATraining Step: 1930  | total loss: [1m[32m0.61778[0m[0m | time: 42.109s
[2K| Adam | epoch: 013 | loss: 0.61778 - acc: 0.7789 -- iter: 02944/10000
[A[ATraining Step: 1931  | total loss: [1m[32m0.60183[0m[0m | time: 43.020s
[2K| Adam | epoch: 013 | loss: 0.60183 - acc: 0.7886 -- iter: 03008/10000
[A[ATraining Step: 1932  | total loss: [1m[32m0.59754[0m[0m | time: 43.873s
[2K| Adam | epoch: 013 | loss: 0.59754 - acc: 0.7878 -- iter: 03072/10000
[A[ATraining Step: 1933  | total loss: [1m[32m0.61669[0m[0m | time: 44.744s
[2K| Adam | epoch: 013 | loss: 0.61669 - acc: 0.7778 -- iter: 03136/10000
[A[ATraining Step: 1934  | total loss: [1m[32m0.63339[0m[0m | time: 45.652s
[2K| Adam | epoch: 013 | loss: 0.63339 - acc: 0.7766 -- iter: 03200/10000
[A[ATraining Step: 1935  | total loss: [1m[32m0.63694[0m[0m | time: 46.556s
[2K| Adam | epoch: 013 | loss: 0.63694 - acc: 0.7708 -- iter: 03264/10000
[A[ATraining Step: 1936  | total loss: [1m[32m0.66675[0m[0m | time: 47.480s
[2K| Adam | epoch: 013 | loss: 0.66675 - acc: 0.7640 -- iter: 03328/10000
[A[ATraining Step: 1937  | total loss: [1m[32m0.65508[0m[0m | time: 48.377s
[2K| Adam | epoch: 013 | loss: 0.65508 - acc: 0.7689 -- iter: 03392/10000
[A[ATraining Step: 1938  | total loss: [1m[32m0.65228[0m[0m | time: 49.283s
[2K| Adam | epoch: 013 | loss: 0.65228 - acc: 0.7779 -- iter: 03456/10000
[A[ATraining Step: 1939  | total loss: [1m[32m0.64687[0m[0m | time: 50.207s
[2K| Adam | epoch: 013 | loss: 0.64687 - acc: 0.7798 -- iter: 03520/10000
[A[ATraining Step: 1940  | total loss: [1m[32m0.62964[0m[0m | time: 51.178s
[2K| Adam | epoch: 013 | loss: 0.62964 - acc: 0.7846 -- iter: 03584/10000
[A[ATraining Step: 1941  | total loss: [1m[32m0.62811[0m[0m | time: 52.120s
[2K| Adam | epoch: 013 | loss: 0.62811 - acc: 0.7812 -- iter: 03648/10000
[A[ATraining Step: 1942  | total loss: [1m[32m0.62580[0m[0m | time: 53.139s
[2K| Adam | epoch: 013 | loss: 0.62580 - acc: 0.7843 -- iter: 03712/10000
[A[ATraining Step: 1943  | total loss: [1m[32m0.62415[0m[0m | time: 54.067s
[2K| Adam | epoch: 013 | loss: 0.62415 - acc: 0.7840 -- iter: 03776/10000
[A[ATraining Step: 1944  | total loss: [1m[32m0.61679[0m[0m | time: 55.012s
[2K| Adam | epoch: 013 | loss: 0.61679 - acc: 0.7837 -- iter: 03840/10000
[A[ATraining Step: 1945  | total loss: [1m[32m0.61397[0m[0m | time: 55.967s
[2K| Adam | epoch: 013 | loss: 0.61397 - acc: 0.7835 -- iter: 03904/10000
[A[ATraining Step: 1946  | total loss: [1m[32m0.61118[0m[0m | time: 56.907s
[2K| Adam | epoch: 013 | loss: 0.61118 - acc: 0.7879 -- iter: 03968/10000
[A[ATraining Step: 1947  | total loss: [1m[32m0.64015[0m[0m | time: 57.827s
[2K| Adam | epoch: 013 | loss: 0.64015 - acc: 0.7763 -- iter: 04032/10000
[A[ATraining Step: 1948  | total loss: [1m[32m0.63164[0m[0m | time: 58.770s
[2K| Adam | epoch: 013 | loss: 0.63164 - acc: 0.7784 -- iter: 04096/10000
[A[ATraining Step: 1949  | total loss: [1m[32m0.62365[0m[0m | time: 59.736s
[2K| Adam | epoch: 013 | loss: 0.62365 - acc: 0.7771 -- iter: 04160/10000
[A[ATraining Step: 1950  | total loss: [1m[32m0.60917[0m[0m | time: 60.700s
[2K| Adam | epoch: 013 | loss: 0.60917 - acc: 0.7838 -- iter: 04224/10000
[A[ATraining Step: 1951  | total loss: [1m[32m0.60701[0m[0m | time: 61.636s
[2K| Adam | epoch: 013 | loss: 0.60701 - acc: 0.7820 -- iter: 04288/10000
[A[ATraining Step: 1952  | total loss: [1m[32m0.59350[0m[0m | time: 62.543s
[2K| Adam | epoch: 013 | loss: 0.59350 - acc: 0.7850 -- iter: 04352/10000
[A[ATraining Step: 1953  | total loss: [1m[32m0.59698[0m[0m | time: 63.445s
[2K| Adam | epoch: 013 | loss: 0.59698 - acc: 0.7846 -- iter: 04416/10000
[A[ATraining Step: 1954  | total loss: [1m[32m0.60410[0m[0m | time: 64.347s
[2K| Adam | epoch: 013 | loss: 0.60410 - acc: 0.7765 -- iter: 04480/10000
[A[ATraining Step: 1955  | total loss: [1m[32m0.60374[0m[0m | time: 65.247s
[2K| Adam | epoch: 013 | loss: 0.60374 - acc: 0.7801 -- iter: 04544/10000
[A[ATraining Step: 1956  | total loss: [1m[32m0.60338[0m[0m | time: 66.153s
[2K| Adam | epoch: 013 | loss: 0.60338 - acc: 0.7771 -- iter: 04608/10000
[A[ATraining Step: 1957  | total loss: [1m[32m0.57928[0m[0m | time: 67.040s
[2K| Adam | epoch: 013 | loss: 0.57928 - acc: 0.7837 -- iter: 04672/10000
[A[ATraining Step: 1958  | total loss: [1m[32m0.56869[0m[0m | time: 67.943s
[2K| Adam | epoch: 013 | loss: 0.56869 - acc: 0.7929 -- iter: 04736/10000
[A[ATraining Step: 1959  | total loss: [1m[32m0.56932[0m[0m | time: 68.840s
[2K| Adam | epoch: 013 | loss: 0.56932 - acc: 0.7886 -- iter: 04800/10000
[A[ATraining Step: 1960  | total loss: [1m[32m0.56417[0m[0m | time: 69.726s
[2K| Adam | epoch: 013 | loss: 0.56417 - acc: 0.7910 -- iter: 04864/10000
[A[ATraining Step: 1961  | total loss: [1m[32m0.58644[0m[0m | time: 70.615s
[2K| Adam | epoch: 013 | loss: 0.58644 - acc: 0.7916 -- iter: 04928/10000
[A[ATraining Step: 1962  | total loss: [1m[32m0.60975[0m[0m | time: 71.511s
[2K| Adam | epoch: 013 | loss: 0.60975 - acc: 0.7827 -- iter: 04992/10000
[A[ATraining Step: 1963  | total loss: [1m[32m0.61442[0m[0m | time: 72.423s
[2K| Adam | epoch: 013 | loss: 0.61442 - acc: 0.7826 -- iter: 05056/10000
[A[ATraining Step: 1964  | total loss: [1m[32m0.65699[0m[0m | time: 73.395s
[2K| Adam | epoch: 013 | loss: 0.65699 - acc: 0.7746 -- iter: 05120/10000
[A[ATraining Step: 1965  | total loss: [1m[32m0.63810[0m[0m | time: 74.321s
[2K| Adam | epoch: 013 | loss: 0.63810 - acc: 0.7815 -- iter: 05184/10000
[A[ATraining Step: 1966  | total loss: [1m[32m0.63429[0m[0m | time: 75.271s
[2K| Adam | epoch: 013 | loss: 0.63429 - acc: 0.7800 -- iter: 05248/10000
[A[ATraining Step: 1967  | total loss: [1m[32m0.64381[0m[0m | time: 76.201s
[2K| Adam | epoch: 013 | loss: 0.64381 - acc: 0.7801 -- iter: 05312/10000
[A[ATraining Step: 1968  | total loss: [1m[32m0.63466[0m[0m | time: 77.141s
[2K| Adam | epoch: 013 | loss: 0.63466 - acc: 0.7849 -- iter: 05376/10000
[A[ATraining Step: 1969  | total loss: [1m[32m0.62682[0m[0m | time: 78.074s
[2K| Adam | epoch: 013 | loss: 0.62682 - acc: 0.7861 -- iter: 05440/10000
[A[ATraining Step: 1970  | total loss: [1m[32m0.63909[0m[0m | time: 79.025s
[2K| Adam | epoch: 013 | loss: 0.63909 - acc: 0.7794 -- iter: 05504/10000
[A[ATraining Step: 1971  | total loss: [1m[32m0.63572[0m[0m | time: 79.930s
[2K| Adam | epoch: 013 | loss: 0.63572 - acc: 0.7795 -- iter: 05568/10000
[A[ATraining Step: 1972  | total loss: [1m[32m0.63971[0m[0m | time: 80.857s
[2K| Adam | epoch: 013 | loss: 0.63971 - acc: 0.7797 -- iter: 05632/10000
[A[ATraining Step: 1973  | total loss: [1m[32m0.64054[0m[0m | time: 81.803s
[2K| Adam | epoch: 013 | loss: 0.64054 - acc: 0.7799 -- iter: 05696/10000
[A[ATraining Step: 1974  | total loss: [1m[32m0.63433[0m[0m | time: 82.776s
[2K| Adam | epoch: 013 | loss: 0.63433 - acc: 0.7769 -- iter: 05760/10000
[A[ATraining Step: 1975  | total loss: [1m[32m0.61737[0m[0m | time: 83.712s
[2K| Adam | epoch: 013 | loss: 0.61737 - acc: 0.7820 -- iter: 05824/10000
[A[ATraining Step: 1976  | total loss: [1m[32m0.61095[0m[0m | time: 84.632s
[2K| Adam | epoch: 013 | loss: 0.61095 - acc: 0.7835 -- iter: 05888/10000
[A[ATraining Step: 1977  | total loss: [1m[32m0.60801[0m[0m | time: 85.571s
[2K| Adam | epoch: 013 | loss: 0.60801 - acc: 0.7848 -- iter: 05952/10000
[A[ATraining Step: 1978  | total loss: [1m[32m0.62389[0m[0m | time: 86.509s
[2K| Adam | epoch: 013 | loss: 0.62389 - acc: 0.7751 -- iter: 06016/10000
[A[ATraining Step: 1979  | total loss: [1m[32m0.61549[0m[0m | time: 87.457s
[2K| Adam | epoch: 013 | loss: 0.61549 - acc: 0.7757 -- iter: 06080/10000
[A[ATraining Step: 1980  | total loss: [1m[32m0.62641[0m[0m | time: 88.402s
[2K| Adam | epoch: 013 | loss: 0.62641 - acc: 0.7747 -- iter: 06144/10000
[A[ATraining Step: 1981  | total loss: [1m[32m0.63631[0m[0m | time: 89.357s
[2K| Adam | epoch: 013 | loss: 0.63631 - acc: 0.7691 -- iter: 06208/10000
[A[ATraining Step: 1982  | total loss: [1m[32m0.63772[0m[0m | time: 90.314s
[2K| Adam | epoch: 013 | loss: 0.63772 - acc: 0.7703 -- iter: 06272/10000
[A[ATraining Step: 1983  | total loss: [1m[32m0.64233[0m[0m | time: 91.267s
[2K| Adam | epoch: 013 | loss: 0.64233 - acc: 0.7699 -- iter: 06336/10000
[A[ATraining Step: 1984  | total loss: [1m[32m0.62777[0m[0m | time: 92.246s
[2K| Adam | epoch: 013 | loss: 0.62777 - acc: 0.7741 -- iter: 06400/10000
[A[ATraining Step: 1985  | total loss: [1m[32m0.62384[0m[0m | time: 93.304s
[2K| Adam | epoch: 013 | loss: 0.62384 - acc: 0.7780 -- iter: 06464/10000
[A[ATraining Step: 1986  | total loss: [1m[32m0.60327[0m[0m | time: 94.296s
[2K| Adam | epoch: 013 | loss: 0.60327 - acc: 0.7877 -- iter: 06528/10000
[A[ATraining Step: 1987  | total loss: [1m[32m0.61257[0m[0m | time: 95.282s
[2K| Adam | epoch: 013 | loss: 0.61257 - acc: 0.7761 -- iter: 06592/10000
[A[ATraining Step: 1988  | total loss: [1m[32m0.59091[0m[0m | time: 96.267s
[2K| Adam | epoch: 013 | loss: 0.59091 - acc: 0.7782 -- iter: 06656/10000
[A[ATraining Step: 1989  | total loss: [1m[32m0.59570[0m[0m | time: 97.264s
[2K| Adam | epoch: 013 | loss: 0.59570 - acc: 0.7769 -- iter: 06720/10000
[A[ATraining Step: 1990  | total loss: [1m[32m0.60306[0m[0m | time: 98.240s
[2K| Adam | epoch: 013 | loss: 0.60306 - acc: 0.7680 -- iter: 06784/10000
[A[ATraining Step: 1991  | total loss: [1m[32m0.59524[0m[0m | time: 99.231s
[2K| Adam | epoch: 013 | loss: 0.59524 - acc: 0.7740 -- iter: 06848/10000
[A[ATraining Step: 1992  | total loss: [1m[32m0.59041[0m[0m | time: 100.207s
[2K| Adam | epoch: 013 | loss: 0.59041 - acc: 0.7731 -- iter: 06912/10000
[A[ATraining Step: 1993  | total loss: [1m[32m0.60648[0m[0m | time: 101.206s
[2K| Adam | epoch: 013 | loss: 0.60648 - acc: 0.7693 -- iter: 06976/10000
[A[ATraining Step: 1994  | total loss: [1m[32m0.60686[0m[0m | time: 102.179s
[2K| Adam | epoch: 013 | loss: 0.60686 - acc: 0.7767 -- iter: 07040/10000
[A[ATraining Step: 1995  | total loss: [1m[32m0.60375[0m[0m | time: 103.214s
[2K| Adam | epoch: 013 | loss: 0.60375 - acc: 0.7803 -- iter: 07104/10000
[A[ATraining Step: 1996  | total loss: [1m[32m0.60270[0m[0m | time: 104.190s
[2K| Adam | epoch: 013 | loss: 0.60270 - acc: 0.7820 -- iter: 07168/10000
[A[ATraining Step: 1997  | total loss: [1m[32m0.61059[0m[0m | time: 105.159s
[2K| Adam | epoch: 013 | loss: 0.61059 - acc: 0.7772 -- iter: 07232/10000
[A[ATraining Step: 1998  | total loss: [1m[32m0.63448[0m[0m | time: 106.128s
[2K| Adam | epoch: 013 | loss: 0.63448 - acc: 0.7729 -- iter: 07296/10000
[A[ATraining Step: 1999  | total loss: [1m[32m0.63173[0m[0m | time: 107.105s
[2K| Adam | epoch: 013 | loss: 0.63173 - acc: 0.7769 -- iter: 07360/10000
[A[ATraining Step: 2000  | total loss: [1m[32m0.64286[0m[0m | time: 110.522s
[2K| Adam | epoch: 013 | loss: 0.64286 - acc: 0.7726 | val_loss: 2.13939 - val_acc: 0.4129 -- iter: 07424/10000
--
Training Step: 2001  | total loss: [1m[32m0.63187[0m[0m | time: 111.462s
[2K| Adam | epoch: 013 | loss: 0.63187 - acc: 0.7719 -- iter: 07488/10000
[A[ATraining Step: 2002  | total loss: [1m[32m0.61024[0m[0m | time: 112.469s
[2K| Adam | epoch: 013 | loss: 0.61024 - acc: 0.7760 -- iter: 07552/10000
[A[ATraining Step: 2003  | total loss: [1m[32m0.63255[0m[0m | time: 113.574s
[2K| Adam | epoch: 013 | loss: 0.63255 - acc: 0.7749 -- iter: 07616/10000
[A[ATraining Step: 2004  | total loss: [1m[32m0.63043[0m[0m | time: 114.602s
[2K| Adam | epoch: 013 | loss: 0.63043 - acc: 0.7771 -- iter: 07680/10000
[A[ATraining Step: 2005  | total loss: [1m[32m0.64924[0m[0m | time: 115.626s
[2K| Adam | epoch: 013 | loss: 0.64924 - acc: 0.7666 -- iter: 07744/10000
[A[ATraining Step: 2006  | total loss: [1m[32m0.64172[0m[0m | time: 116.656s
[2K| Adam | epoch: 013 | loss: 0.64172 - acc: 0.7775 -- iter: 07808/10000
[A[ATraining Step: 2007  | total loss: [1m[32m0.62867[0m[0m | time: 117.695s
[2K| Adam | epoch: 013 | loss: 0.62867 - acc: 0.7841 -- iter: 07872/10000
[A[ATraining Step: 2008  | total loss: [1m[32m0.63400[0m[0m | time: 118.803s
[2K| Adam | epoch: 013 | loss: 0.63400 - acc: 0.7885 -- iter: 07936/10000
[A[ATraining Step: 2009  | total loss: [1m[32m0.61790[0m[0m | time: 119.917s
[2K| Adam | epoch: 013 | loss: 0.61790 - acc: 0.7878 -- iter: 08000/10000
[A[ATraining Step: 2010  | total loss: [1m[32m0.63556[0m[0m | time: 120.883s
[2K| Adam | epoch: 013 | loss: 0.63556 - acc: 0.7824 -- iter: 08064/10000
[A[ATraining Step: 2011  | total loss: [1m[32m0.62136[0m[0m | time: 121.878s
[2K| Adam | epoch: 013 | loss: 0.62136 - acc: 0.7854 -- iter: 08128/10000
[A[ATraining Step: 2012  | total loss: [1m[32m0.60879[0m[0m | time: 122.887s
[2K| Adam | epoch: 013 | loss: 0.60879 - acc: 0.7881 -- iter: 08192/10000
[A[ATraining Step: 2013  | total loss: [1m[32m0.62506[0m[0m | time: 123.873s
[2K| Adam | epoch: 013 | loss: 0.62506 - acc: 0.7781 -- iter: 08256/10000
[A[ATraining Step: 2014  | total loss: [1m[32m0.61457[0m[0m | time: 124.861s
[2K| Adam | epoch: 013 | loss: 0.61457 - acc: 0.7784 -- iter: 08320/10000
[A[ATraining Step: 2015  | total loss: [1m[32m0.62518[0m[0m | time: 125.847s
[2K| Adam | epoch: 013 | loss: 0.62518 - acc: 0.7724 -- iter: 08384/10000
[A[ATraining Step: 2016  | total loss: [1m[32m0.60723[0m[0m | time: 126.835s
[2K| Adam | epoch: 013 | loss: 0.60723 - acc: 0.7811 -- iter: 08448/10000
[A[ATraining Step: 2017  | total loss: [1m[32m0.60858[0m[0m | time: 127.827s
[2K| Adam | epoch: 013 | loss: 0.60858 - acc: 0.7905 -- iter: 08512/10000
[A[ATraining Step: 2018  | total loss: [1m[32m0.60173[0m[0m | time: 128.820s
[2K| Adam | epoch: 013 | loss: 0.60173 - acc: 0.7896 -- iter: 08576/10000
[A[ATraining Step: 2019  | total loss: [1m[32m0.58979[0m[0m | time: 129.876s
[2K| Adam | epoch: 013 | loss: 0.58979 - acc: 0.7966 -- iter: 08640/10000
[A[ATraining Step: 2020  | total loss: [1m[32m0.58897[0m[0m | time: 130.961s
[2K| Adam | epoch: 013 | loss: 0.58897 - acc: 0.7982 -- iter: 08704/10000
[A[ATraining Step: 2021  | total loss: [1m[32m0.58175[0m[0m | time: 132.008s
[2K| Adam | epoch: 013 | loss: 0.58175 - acc: 0.8027 -- iter: 08768/10000
[A[ATraining Step: 2022  | total loss: [1m[32m1.34316[0m[0m | time: 133.116s
[2K| Adam | epoch: 013 | loss: 1.34316 - acc: 0.7349 -- iter: 08832/10000
[A[ATraining Step: 2023  | total loss: [1m[32m1.26523[0m[0m | time: 134.150s
[2K| Adam | epoch: 013 | loss: 1.26523 - acc: 0.7443 -- iter: 08896/10000
[A[ATraining Step: 2024  | total loss: [1m[32m1.19114[0m[0m | time: 135.161s
[2K| Adam | epoch: 013 | loss: 1.19114 - acc: 0.7433 -- iter: 08960/10000
[A[ATraining Step: 2025  | total loss: [1m[32m1.11652[0m[0m | time: 136.200s
[2K| Adam | epoch: 013 | loss: 1.11652 - acc: 0.7549 -- iter: 09024/10000
[A[ATraining Step: 2026  | total loss: [1m[32m1.04820[0m[0m | time: 137.223s
[2K| Adam | epoch: 013 | loss: 1.04820 - acc: 0.7638 -- iter: 09088/10000
[A[ATraining Step: 2027  | total loss: [1m[32m0.99692[0m[0m | time: 138.263s
[2K| Adam | epoch: 013 | loss: 0.99692 - acc: 0.7718 -- iter: 09152/10000
[A[ATraining Step: 2028  | total loss: [1m[32m0.96008[0m[0m | time: 139.311s
[2K| Adam | epoch: 013 | loss: 0.96008 - acc: 0.7712 -- iter: 09216/10000
[A[ATraining Step: 2029  | total loss: [1m[32m0.93266[0m[0m | time: 140.319s
[2K| Adam | epoch: 013 | loss: 0.93266 - acc: 0.7690 -- iter: 09280/10000
[A[ATraining Step: 2030  | total loss: [1m[32m0.88402[0m[0m | time: 141.344s
[2K| Adam | epoch: 013 | loss: 0.88402 - acc: 0.7765 -- iter: 09344/10000
[A[ATraining Step: 2031  | total loss: [1m[32m0.86990[0m[0m | time: 142.402s
[2K| Adam | epoch: 013 | loss: 0.86990 - acc: 0.7723 -- iter: 09408/10000
[A[ATraining Step: 2032  | total loss: [1m[32m0.85199[0m[0m | time: 143.476s
[2K| Adam | epoch: 013 | loss: 0.85199 - acc: 0.7701 -- iter: 09472/10000
[A[ATraining Step: 2033  | total loss: [1m[32m0.81908[0m[0m | time: 144.518s
[2K| Adam | epoch: 013 | loss: 0.81908 - acc: 0.7727 -- iter: 09536/10000
[A[ATraining Step: 2034  | total loss: [1m[32m0.79073[0m[0m | time: 145.546s
[2K| Adam | epoch: 013 | loss: 0.79073 - acc: 0.7736 -- iter: 09600/10000
[A[ATraining Step: 2035  | total loss: [1m[32m0.76875[0m[0m | time: 146.563s
[2K| Adam | epoch: 013 | loss: 0.76875 - acc: 0.7775 -- iter: 09664/10000
[A[ATraining Step: 2036  | total loss: [1m[32m0.74068[0m[0m | time: 147.604s
[2K| Adam | epoch: 013 | loss: 0.74068 - acc: 0.7810 -- iter: 09728/10000
[A[ATraining Step: 2037  | total loss: [1m[32m0.71873[0m[0m | time: 148.647s
[2K| Adam | epoch: 013 | loss: 0.71873 - acc: 0.7841 -- iter: 09792/10000
[A[ATraining Step: 2038  | total loss: [1m[32m0.71639[0m[0m | time: 149.690s
[2K| Adam | epoch: 013 | loss: 0.71639 - acc: 0.7839 -- iter: 09856/10000
[A[ATraining Step: 2039  | total loss: [1m[32m0.71210[0m[0m | time: 150.716s
[2K| Adam | epoch: 013 | loss: 0.71210 - acc: 0.7805 -- iter: 09920/10000
[A[ATraining Step: 2040  | total loss: [1m[32m0.68783[0m[0m | time: 151.744s
[2K| Adam | epoch: 013 | loss: 0.68783 - acc: 0.7915 -- iter: 09984/10000
[A[ATraining Step: 2041  | total loss: [1m[32m0.68341[0m[0m | time: 155.638s
[2K| Adam | epoch: 013 | loss: 0.68341 - acc: 0.7905 | val_loss: 2.18650 - val_acc: 0.3929 -- iter: 10000/10000
--
Training Step: 2042  | total loss: [1m[32m0.67372[0m[0m | time: 0.978s
[2K| Adam | epoch: 014 | loss: 0.67372 - acc: 0.7974 -- iter: 00064/10000
[A[ATraining Step: 2043  | total loss: [1m[32m0.67098[0m[0m | time: 2.038s
[2K| Adam | epoch: 014 | loss: 0.67098 - acc: 0.8004 -- iter: 00128/10000
[A[ATraining Step: 2044  | total loss: [1m[32m0.66464[0m[0m | time: 3.161s
[2K| Adam | epoch: 014 | loss: 0.66464 - acc: 0.7985 -- iter: 00192/10000
[A[ATraining Step: 2045  | total loss: [1m[32m0.65952[0m[0m | time: 4.288s
[2K| Adam | epoch: 014 | loss: 0.65952 - acc: 0.7937 -- iter: 00256/10000
[A[ATraining Step: 2046  | total loss: [1m[32m0.64628[0m[0m | time: 5.398s
[2K| Adam | epoch: 014 | loss: 0.64628 - acc: 0.7940 -- iter: 00320/10000
[A[ATraining Step: 2047  | total loss: [1m[32m0.67123[0m[0m | time: 6.428s
[2K| Adam | epoch: 014 | loss: 0.67123 - acc: 0.7833 -- iter: 00384/10000
[A[ATraining Step: 2048  | total loss: [1m[32m0.66529[0m[0m | time: 7.431s
[2K| Adam | epoch: 014 | loss: 0.66529 - acc: 0.7831 -- iter: 00448/10000
[A[ATraining Step: 2049  | total loss: [1m[32m0.65846[0m[0m | time: 8.436s
[2K| Adam | epoch: 014 | loss: 0.65846 - acc: 0.7751 -- iter: 00512/10000
[A[ATraining Step: 2050  | total loss: [1m[32m0.64043[0m[0m | time: 9.411s
[2K| Adam | epoch: 014 | loss: 0.64043 - acc: 0.7726 -- iter: 00576/10000
[A[ATraining Step: 2051  | total loss: [1m[32m0.62287[0m[0m | time: 10.391s
[2K| Adam | epoch: 014 | loss: 0.62287 - acc: 0.7719 -- iter: 00640/10000
[A[ATraining Step: 2052  | total loss: [1m[32m0.62662[0m[0m | time: 11.370s
[2K| Adam | epoch: 014 | loss: 0.62662 - acc: 0.7760 -- iter: 00704/10000
[A[ATraining Step: 2053  | total loss: [1m[32m0.61458[0m[0m | time: 11.820s
[2K| Adam | epoch: 014 | loss: 0.61458 - acc: 0.7827 -- iter: 00768/10000
[A[ATraining Step: 2054  | total loss: [1m[32m0.62243[0m[0m | time: 12.294s
[2K| Adam | epoch: 014 | loss: 0.62243 - acc: 0.7732 -- iter: 00832/10000
[A[ATraining Step: 2055  | total loss: [1m[32m0.61122[0m[0m | time: 13.264s
[2K| Adam | epoch: 014 | loss: 0.61122 - acc: 0.7834 -- iter: 00896/10000
[A[ATraining Step: 2056  | total loss: [1m[32m0.61837[0m[0m | time: 14.302s
[2K| Adam | epoch: 014 | loss: 0.61837 - acc: 0.7926 -- iter: 00960/10000
[A[ATraining Step: 2057  | total loss: [1m[32m0.61497[0m[0m | time: 15.341s
[2K| Adam | epoch: 014 | loss: 0.61497 - acc: 0.7946 -- iter: 01024/10000
[A[ATraining Step: 2058  | total loss: [1m[32m0.60158[0m[0m | time: 16.454s
[2K| Adam | epoch: 014 | loss: 0.60158 - acc: 0.8026 -- iter: 01088/10000
[A[ATraining Step: 2059  | total loss: [1m[32m0.58982[0m[0m | time: 17.619s
[2K| Adam | epoch: 014 | loss: 0.58982 - acc: 0.8036 -- iter: 01152/10000
[A[ATraining Step: 2060  | total loss: [1m[32m0.56458[0m[0m | time: 18.732s
[2K| Adam | epoch: 014 | loss: 0.56458 - acc: 0.8170 -- iter: 01216/10000
[A[ATraining Step: 2061  | total loss: [1m[32m0.55980[0m[0m | time: 19.703s
[2K| Adam | epoch: 014 | loss: 0.55980 - acc: 0.8181 -- iter: 01280/10000
[A[ATraining Step: 2062  | total loss: [1m[32m0.56105[0m[0m | time: 20.694s
[2K| Adam | epoch: 014 | loss: 0.56105 - acc: 0.8144 -- iter: 01344/10000
[A[ATraining Step: 2063  | total loss: [1m[32m0.57865[0m[0m | time: 21.685s
[2K| Adam | epoch: 014 | loss: 0.57865 - acc: 0.8048 -- iter: 01408/10000
[A[ATraining Step: 2064  | total loss: [1m[32m0.56886[0m[0m | time: 22.673s
[2K| Adam | epoch: 014 | loss: 0.56886 - acc: 0.8056 -- iter: 01472/10000
[A[ATraining Step: 2065  | total loss: [1m[32m0.57238[0m[0m | time: 23.667s
[2K| Adam | epoch: 014 | loss: 0.57238 - acc: 0.8016 -- iter: 01536/10000
[A[ATraining Step: 2066  | total loss: [1m[32m0.58945[0m[0m | time: 24.638s
[2K| Adam | epoch: 014 | loss: 0.58945 - acc: 0.7949 -- iter: 01600/10000
[A[ATraining Step: 2067  | total loss: [1m[32m0.57744[0m[0m | time: 25.624s
[2K| Adam | epoch: 014 | loss: 0.57744 - acc: 0.7951 -- iter: 01664/10000
[A[ATraining Step: 2068  | total loss: [1m[32m0.57654[0m[0m | time: 26.601s
[2K| Adam | epoch: 014 | loss: 0.57654 - acc: 0.7968 -- iter: 01728/10000
[A[ATraining Step: 2069  | total loss: [1m[32m0.56961[0m[0m | time: 27.625s
[2K| Adam | epoch: 014 | loss: 0.56961 - acc: 0.7984 -- iter: 01792/10000
[A[ATraining Step: 2070  | total loss: [1m[32m0.56213[0m[0m | time: 28.664s
[2K| Adam | epoch: 014 | loss: 0.56213 - acc: 0.7967 -- iter: 01856/10000
[A[ATraining Step: 2071  | total loss: [1m[32m0.57115[0m[0m | time: 29.706s
[2K| Adam | epoch: 014 | loss: 0.57115 - acc: 0.7920 -- iter: 01920/10000
[A[ATraining Step: 2072  | total loss: [1m[32m0.58297[0m[0m | time: 30.751s
[2K| Adam | epoch: 014 | loss: 0.58297 - acc: 0.7878 -- iter: 01984/10000
[A[ATraining Step: 2073  | total loss: [1m[32m0.59449[0m[0m | time: 31.796s
[2K| Adam | epoch: 014 | loss: 0.59449 - acc: 0.7840 -- iter: 02048/10000
[A[ATraining Step: 2074  | total loss: [1m[32m0.59684[0m[0m | time: 32.874s
[2K| Adam | epoch: 014 | loss: 0.59684 - acc: 0.7900 -- iter: 02112/10000
[A[ATraining Step: 2075  | total loss: [1m[32m0.58859[0m[0m | time: 33.979s
[2K| Adam | epoch: 014 | loss: 0.58859 - acc: 0.7891 -- iter: 02176/10000
[A[ATraining Step: 2076  | total loss: [1m[32m0.59011[0m[0m | time: 35.211s
[2K| Adam | epoch: 014 | loss: 0.59011 - acc: 0.7915 -- iter: 02240/10000
[A[ATraining Step: 2077  | total loss: [1m[32m0.59179[0m[0m | time: 36.355s
[2K| Adam | epoch: 014 | loss: 0.59179 - acc: 0.7936 -- iter: 02304/10000
[A[ATraining Step: 2078  | total loss: [1m[32m0.57601[0m[0m | time: 37.553s
[2K| Adam | epoch: 014 | loss: 0.57601 - acc: 0.7955 -- iter: 02368/10000
[A[ATraining Step: 2079  | total loss: [1m[32m0.59789[0m[0m | time: 38.714s
[2K| Adam | epoch: 014 | loss: 0.59789 - acc: 0.7878 -- iter: 02432/10000
[A[ATraining Step: 2080  | total loss: [1m[32m0.60740[0m[0m | time: 39.801s
[2K| Adam | epoch: 014 | loss: 0.60740 - acc: 0.7746 -- iter: 02496/10000
[A[ATraining Step: 2081  | total loss: [1m[32m0.60474[0m[0m | time: 40.891s
[2K| Adam | epoch: 014 | loss: 0.60474 - acc: 0.7722 -- iter: 02560/10000
[A[ATraining Step: 2082  | total loss: [1m[32m0.62358[0m[0m | time: 42.024s
[2K| Adam | epoch: 014 | loss: 0.62358 - acc: 0.7668 -- iter: 02624/10000
[A[ATraining Step: 2083  | total loss: [1m[32m0.62076[0m[0m | time: 43.127s
[2K| Adam | epoch: 014 | loss: 0.62076 - acc: 0.7683 -- iter: 02688/10000
[A[ATraining Step: 2084  | total loss: [1m[32m0.63848[0m[0m | time: 44.236s
[2K| Adam | epoch: 014 | loss: 0.63848 - acc: 0.7664 -- iter: 02752/10000
[A[ATraining Step: 2085  | total loss: [1m[32m0.62681[0m[0m | time: 45.418s
[2K| Adam | epoch: 014 | loss: 0.62681 - acc: 0.7664 -- iter: 02816/10000
[A[ATraining Step: 2086  | total loss: [1m[32m0.63361[0m[0m | time: 46.903s
[2K| Adam | epoch: 014 | loss: 0.63361 - acc: 0.7616 -- iter: 02880/10000
[A[ATraining Step: 2087  | total loss: [1m[32m0.61984[0m[0m | time: 48.440s
[2K| Adam | epoch: 014 | loss: 0.61984 - acc: 0.7651 -- iter: 02944/10000
[A[ATraining Step: 2088  | total loss: [1m[32m0.62122[0m[0m | time: 49.617s
[2K| Adam | epoch: 014 | loss: 0.62122 - acc: 0.7714 -- iter: 03008/10000
[A[ATraining Step: 2089  | total loss: [1m[32m0.62597[0m[0m | time: 50.710s
[2K| Adam | epoch: 014 | loss: 0.62597 - acc: 0.7662 -- iter: 03072/10000
[A[ATraining Step: 2090  | total loss: [1m[32m0.63112[0m[0m | time: 51.797s
[2K| Adam | epoch: 014 | loss: 0.63112 - acc: 0.7645 -- iter: 03136/10000
[A[ATraining Step: 2091  | total loss: [1m[32m0.61529[0m[0m | time: 53.036s
[2K| Adam | epoch: 014 | loss: 0.61529 - acc: 0.7693 -- iter: 03200/10000
[A[ATraining Step: 2092  | total loss: [1m[32m0.60147[0m[0m | time: 54.179s
[2K| Adam | epoch: 014 | loss: 0.60147 - acc: 0.7752 -- iter: 03264/10000
[A[ATraining Step: 2093  | total loss: [1m[32m0.59930[0m[0m | time: 55.270s
[2K| Adam | epoch: 014 | loss: 0.59930 - acc: 0.7743 -- iter: 03328/10000
[A[ATraining Step: 2094  | total loss: [1m[32m0.58228[0m[0m | time: 56.372s
[2K| Adam | epoch: 014 | loss: 0.58228 - acc: 0.7828 -- iter: 03392/10000
[A[ATraining Step: 2095  | total loss: [1m[32m0.58469[0m[0m | time: 57.515s
[2K| Adam | epoch: 014 | loss: 0.58469 - acc: 0.7826 -- iter: 03456/10000
[A[ATraining Step: 2096  | total loss: [1m[32m0.57557[0m[0m | time: 58.582s
[2K| Adam | epoch: 014 | loss: 0.57557 - acc: 0.7840 -- iter: 03520/10000
[A[ATraining Step: 2097  | total loss: [1m[32m0.57337[0m[0m | time: 59.646s
[2K| Adam | epoch: 014 | loss: 0.57337 - acc: 0.7853 -- iter: 03584/10000
[A[ATraining Step: 2098  | total loss: [1m[32m0.57745[0m[0m | time: 60.678s
[2K| Adam | epoch: 014 | loss: 0.57745 - acc: 0.7849 -- iter: 03648/10000
[A[ATraining Step: 2099  | total loss: [1m[32m0.58237[0m[0m | time: 61.711s
[2K| Adam | epoch: 014 | loss: 0.58237 - acc: 0.7830 -- iter: 03712/10000
[A[ATraining Step: 2100  | total loss: [1m[32m0.56730[0m[0m | time: 65.737s
[2K| Adam | epoch: 014 | loss: 0.56730 - acc: 0.7828 | val_loss: 1.99158 - val_acc: 0.4629 -- iter: 03776/10000
--
Training Step: 2101  | total loss: [1m[32m0.57365[0m[0m | time: 66.707s
[2K| Adam | epoch: 014 | loss: 0.57365 - acc: 0.7842 -- iter: 03840/10000
[A[ATraining Step: 2102  | total loss: [1m[32m0.58393[0m[0m | time: 67.773s
[2K| Adam | epoch: 014 | loss: 0.58393 - acc: 0.7870 -- iter: 03904/10000
[A[ATraining Step: 2103  | total loss: [1m[32m0.58333[0m[0m | time: 68.820s
[2K| Adam | epoch: 014 | loss: 0.58333 - acc: 0.7849 -- iter: 03968/10000
[A[ATraining Step: 2104  | total loss: [1m[32m0.57099[0m[0m | time: 69.844s
[2K| Adam | epoch: 014 | loss: 0.57099 - acc: 0.7861 -- iter: 04032/10000
[A[ATraining Step: 2105  | total loss: [1m[32m0.57903[0m[0m | time: 70.857s
[2K| Adam | epoch: 014 | loss: 0.57903 - acc: 0.7856 -- iter: 04096/10000
[A[ATraining Step: 2106  | total loss: [1m[32m0.59327[0m[0m | time: 71.860s
[2K| Adam | epoch: 014 | loss: 0.59327 - acc: 0.7867 -- iter: 04160/10000
[A[ATraining Step: 2107  | total loss: [1m[32m0.57320[0m[0m | time: 72.870s
[2K| Adam | epoch: 014 | loss: 0.57320 - acc: 0.7971 -- iter: 04224/10000
[A[ATraining Step: 2108  | total loss: [1m[32m0.56926[0m[0m | time: 73.887s
[2K| Adam | epoch: 014 | loss: 0.56926 - acc: 0.7955 -- iter: 04288/10000
[A[ATraining Step: 2109  | total loss: [1m[32m0.57511[0m[0m | time: 74.905s
[2K| Adam | epoch: 014 | loss: 0.57511 - acc: 0.8004 -- iter: 04352/10000
[A[ATraining Step: 2110  | total loss: [1m[32m0.59223[0m[0m | time: 75.886s
[2K| Adam | epoch: 014 | loss: 0.59223 - acc: 0.8047 -- iter: 04416/10000
[A[ATraining Step: 2111  | total loss: [1m[32m0.60851[0m[0m | time: 76.902s
[2K| Adam | epoch: 014 | loss: 0.60851 - acc: 0.7992 -- iter: 04480/10000
[A[ATraining Step: 2112  | total loss: [1m[32m0.58504[0m[0m | time: 77.905s
[2K| Adam | epoch: 014 | loss: 0.58504 - acc: 0.8084 -- iter: 04544/10000
[A[ATraining Step: 2113  | total loss: [1m[32m0.59630[0m[0m | time: 78.858s
[2K| Adam | epoch: 014 | loss: 0.59630 - acc: 0.8041 -- iter: 04608/10000
[A[ATraining Step: 2114  | total loss: [1m[32m0.59691[0m[0m | time: 79.843s
[2K| Adam | epoch: 014 | loss: 0.59691 - acc: 0.7987 -- iter: 04672/10000
[A[ATraining Step: 2115  | total loss: [1m[32m0.59073[0m[0m | time: 80.969s
[2K| Adam | epoch: 014 | loss: 0.59073 - acc: 0.8032 -- iter: 04736/10000
[A[ATraining Step: 2116  | total loss: [1m[32m0.57380[0m[0m | time: 81.986s
[2K| Adam | epoch: 014 | loss: 0.57380 - acc: 0.8057 -- iter: 04800/10000
[A[ATraining Step: 2117  | total loss: [1m[32m0.57859[0m[0m | time: 83.159s
[2K| Adam | epoch: 014 | loss: 0.57859 - acc: 0.8017 -- iter: 04864/10000
[A[ATraining Step: 2118  | total loss: [1m[32m0.58759[0m[0m | time: 84.410s
[2K| Adam | epoch: 014 | loss: 0.58759 - acc: 0.7950 -- iter: 04928/10000
[A[ATraining Step: 2119  | total loss: [1m[32m0.58670[0m[0m | time: 85.715s
[2K| Adam | epoch: 014 | loss: 0.58670 - acc: 0.7983 -- iter: 04992/10000
[A[ATraining Step: 2120  | total loss: [1m[32m0.61135[0m[0m | time: 87.045s
[2K| Adam | epoch: 014 | loss: 0.61135 - acc: 0.7934 -- iter: 05056/10000
[A[ATraining Step: 2121  | total loss: [1m[32m0.61930[0m[0m | time: 88.222s
[2K| Adam | epoch: 014 | loss: 0.61930 - acc: 0.7891 -- iter: 05120/10000
[A[ATraining Step: 2122  | total loss: [1m[32m0.62121[0m[0m | time: 89.257s
[2K| Adam | epoch: 014 | loss: 0.62121 - acc: 0.7946 -- iter: 05184/10000
[A[ATraining Step: 2123  | total loss: [1m[32m0.63282[0m[0m | time: 90.378s
[2K| Adam | epoch: 014 | loss: 0.63282 - acc: 0.7885 -- iter: 05248/10000
[A[ATraining Step: 2124  | total loss: [1m[32m0.62245[0m[0m | time: 91.544s
[2K| Adam | epoch: 014 | loss: 0.62245 - acc: 0.7894 -- iter: 05312/10000
[A[ATraining Step: 2125  | total loss: [1m[32m0.62627[0m[0m | time: 92.738s
[2K| Adam | epoch: 014 | loss: 0.62627 - acc: 0.7901 -- iter: 05376/10000
[A[ATraining Step: 2126  | total loss: [1m[32m0.63926[0m[0m | time: 93.846s
[2K| Adam | epoch: 014 | loss: 0.63926 - acc: 0.7814 -- iter: 05440/10000
[A[ATraining Step: 2127  | total loss: [1m[32m0.62978[0m[0m | time: 94.838s
[2K| Adam | epoch: 014 | loss: 0.62978 - acc: 0.7845 -- iter: 05504/10000
[A[ATraining Step: 2128  | total loss: [1m[32m0.61989[0m[0m | time: 95.812s
[2K| Adam | epoch: 014 | loss: 0.61989 - acc: 0.7905 -- iter: 05568/10000
[A[ATraining Step: 2129  | total loss: [1m[32m0.59695[0m[0m | time: 96.785s
[2K| Adam | epoch: 014 | loss: 0.59695 - acc: 0.7958 -- iter: 05632/10000
[A[ATraining Step: 2130  | total loss: [1m[32m0.59734[0m[0m | time: 97.785s
[2K| Adam | epoch: 014 | loss: 0.59734 - acc: 0.7912 -- iter: 05696/10000
[A[ATraining Step: 2131  | total loss: [1m[32m0.57752[0m[0m | time: 98.761s
[2K| Adam | epoch: 014 | loss: 0.57752 - acc: 0.7965 -- iter: 05760/10000
[A[ATraining Step: 2132  | total loss: [1m[32m0.56281[0m[0m | time: 99.709s
[2K| Adam | epoch: 014 | loss: 0.56281 - acc: 0.7981 -- iter: 05824/10000
[A[ATraining Step: 2133  | total loss: [1m[32m0.57902[0m[0m | time: 100.662s
[2K| Adam | epoch: 014 | loss: 0.57902 - acc: 0.7933 -- iter: 05888/10000
[A[ATraining Step: 2134  | total loss: [1m[32m0.57746[0m[0m | time: 101.599s
[2K| Adam | epoch: 014 | loss: 0.57746 - acc: 0.7967 -- iter: 05952/10000
[A[ATraining Step: 2135  | total loss: [1m[32m0.58245[0m[0m | time: 102.561s
[2K| Adam | epoch: 014 | loss: 0.58245 - acc: 0.7952 -- iter: 06016/10000
[A[ATraining Step: 2136  | total loss: [1m[32m0.59031[0m[0m | time: 103.532s
[2K| Adam | epoch: 014 | loss: 0.59031 - acc: 0.7891 -- iter: 06080/10000
[A[ATraining Step: 2137  | total loss: [1m[32m0.58616[0m[0m | time: 104.506s
[2K| Adam | epoch: 014 | loss: 0.58616 - acc: 0.7899 -- iter: 06144/10000
[A[ATraining Step: 2138  | total loss: [1m[32m0.61392[0m[0m | time: 105.473s
[2K| Adam | epoch: 014 | loss: 0.61392 - acc: 0.7828 -- iter: 06208/10000
[A[ATraining Step: 2139  | total loss: [1m[32m0.62547[0m[0m | time: 106.441s
[2K| Adam | epoch: 014 | loss: 0.62547 - acc: 0.7779 -- iter: 06272/10000
[A[ATraining Step: 2140  | total loss: [1m[32m0.62942[0m[0m | time: 107.427s
[2K| Adam | epoch: 014 | loss: 0.62942 - acc: 0.7736 -- iter: 06336/10000
[A[ATraining Step: 2141  | total loss: [1m[32m0.63619[0m[0m | time: 108.386s
[2K| Adam | epoch: 014 | loss: 0.63619 - acc: 0.7665 -- iter: 06400/10000
[A[ATraining Step: 2142  | total loss: [1m[32m0.65181[0m[0m | time: 109.361s
[2K| Adam | epoch: 014 | loss: 0.65181 - acc: 0.7555 -- iter: 06464/10000
[A[ATraining Step: 2143  | total loss: [1m[32m0.65630[0m[0m | time: 110.335s
[2K| Adam | epoch: 014 | loss: 0.65630 - acc: 0.7534 -- iter: 06528/10000
[A[ATraining Step: 2144  | total loss: [1m[32m0.64642[0m[0m | time: 111.277s
[2K| Adam | epoch: 014 | loss: 0.64642 - acc: 0.7609 -- iter: 06592/10000
[A[ATraining Step: 2145  | total loss: [1m[32m0.64817[0m[0m | time: 112.212s
[2K| Adam | epoch: 014 | loss: 0.64817 - acc: 0.7645 -- iter: 06656/10000
[A[ATraining Step: 2146  | total loss: [1m[32m0.63165[0m[0m | time: 113.178s
[2K| Adam | epoch: 014 | loss: 0.63165 - acc: 0.7740 -- iter: 06720/10000
[A[ATraining Step: 2147  | total loss: [1m[32m0.61545[0m[0m | time: 114.143s
[2K| Adam | epoch: 014 | loss: 0.61545 - acc: 0.7887 -- iter: 06784/10000
[A[ATraining Step: 2148  | total loss: [1m[32m0.60698[0m[0m | time: 115.105s
[2K| Adam | epoch: 014 | loss: 0.60698 - acc: 0.7927 -- iter: 06848/10000
[A[ATraining Step: 2149  | total loss: [1m[32m0.58139[0m[0m | time: 116.053s
[2K| Adam | epoch: 014 | loss: 0.58139 - acc: 0.8025 -- iter: 06912/10000
[A[ATraining Step: 2150  | total loss: [1m[32m0.58471[0m[0m | time: 117.050s
[2K| Adam | epoch: 014 | loss: 0.58471 - acc: 0.8004 -- iter: 06976/10000
[A[ATraining Step: 2151  | total loss: [1m[32m0.56918[0m[0m | time: 118.022s
[2K| Adam | epoch: 014 | loss: 0.56918 - acc: 0.8078 -- iter: 07040/10000
[A[ATraining Step: 2152  | total loss: [1m[32m0.57723[0m[0m | time: 118.991s
[2K| Adam | epoch: 014 | loss: 0.57723 - acc: 0.8083 -- iter: 07104/10000
[A[ATraining Step: 2153  | total loss: [1m[32m0.56806[0m[0m | time: 119.985s
[2K| Adam | epoch: 014 | loss: 0.56806 - acc: 0.8118 -- iter: 07168/10000
[A[ATraining Step: 2154  | total loss: [1m[32m0.55564[0m[0m | time: 121.018s
[2K| Adam | epoch: 014 | loss: 0.55564 - acc: 0.8213 -- iter: 07232/10000
[A[ATraining Step: 2155  | total loss: [1m[32m0.55393[0m[0m | time: 122.035s
[2K| Adam | epoch: 014 | loss: 0.55393 - acc: 0.8235 -- iter: 07296/10000
[A[ATraining Step: 2156  | total loss: [1m[32m0.55300[0m[0m | time: 123.060s
[2K| Adam | epoch: 014 | loss: 0.55300 - acc: 0.8193 -- iter: 07360/10000
[A[ATraining Step: 2157  | total loss: [1m[32m0.55762[0m[0m | time: 124.223s
[2K| Adam | epoch: 014 | loss: 0.55762 - acc: 0.8139 -- iter: 07424/10000
[A[ATraining Step: 2158  | total loss: [1m[32m0.58872[0m[0m | time: 125.247s
[2K| Adam | epoch: 014 | loss: 0.58872 - acc: 0.7982 -- iter: 07488/10000
[A[ATraining Step: 2159  | total loss: [1m[32m0.59576[0m[0m | time: 126.256s
[2K| Adam | epoch: 014 | loss: 0.59576 - acc: 0.7902 -- iter: 07552/10000
[A[ATraining Step: 2160  | total loss: [1m[32m0.60628[0m[0m | time: 127.333s
[2K| Adam | epoch: 014 | loss: 0.60628 - acc: 0.7878 -- iter: 07616/10000
[A[ATraining Step: 2161  | total loss: [1m[32m0.62909[0m[0m | time: 128.354s
[2K| Adam | epoch: 014 | loss: 0.62909 - acc: 0.7793 -- iter: 07680/10000
[A[ATraining Step: 2162  | total loss: [1m[32m0.62924[0m[0m | time: 129.394s
[2K| Adam | epoch: 014 | loss: 0.62924 - acc: 0.7826 -- iter: 07744/10000
[A[ATraining Step: 2163  | total loss: [1m[32m0.64089[0m[0m | time: 130.439s
[2K| Adam | epoch: 014 | loss: 0.64089 - acc: 0.7762 -- iter: 07808/10000
[A[ATraining Step: 2164  | total loss: [1m[32m0.63289[0m[0m | time: 131.479s
[2K| Adam | epoch: 014 | loss: 0.63289 - acc: 0.7752 -- iter: 07872/10000
[A[ATraining Step: 2165  | total loss: [1m[32m0.62021[0m[0m | time: 132.486s
[2K| Adam | epoch: 014 | loss: 0.62021 - acc: 0.7789 -- iter: 07936/10000
[A[ATraining Step: 2166  | total loss: [1m[32m0.60340[0m[0m | time: 133.544s
[2K| Adam | epoch: 014 | loss: 0.60340 - acc: 0.7885 -- iter: 08000/10000
[A[ATraining Step: 2167  | total loss: [1m[32m0.61609[0m[0m | time: 134.573s
[2K| Adam | epoch: 014 | loss: 0.61609 - acc: 0.7831 -- iter: 08064/10000
[A[ATraining Step: 2168  | total loss: [1m[32m0.60011[0m[0m | time: 135.539s
[2K| Adam | epoch: 014 | loss: 0.60011 - acc: 0.7939 -- iter: 08128/10000
[A[ATraining Step: 2169  | total loss: [1m[32m0.60624[0m[0m | time: 136.515s
[2K| Adam | epoch: 014 | loss: 0.60624 - acc: 0.7988 -- iter: 08192/10000
[A[ATraining Step: 2170  | total loss: [1m[32m0.60910[0m[0m | time: 137.542s
[2K| Adam | epoch: 014 | loss: 0.60910 - acc: 0.7924 -- iter: 08256/10000
[A[ATraining Step: 2171  | total loss: [1m[32m0.61405[0m[0m | time: 138.527s
[2K| Adam | epoch: 014 | loss: 0.61405 - acc: 0.7882 -- iter: 08320/10000
[A[ATraining Step: 2172  | total loss: [1m[32m0.59676[0m[0m | time: 139.501s
[2K| Adam | epoch: 014 | loss: 0.59676 - acc: 0.7906 -- iter: 08384/10000
[A[ATraining Step: 2173  | total loss: [1m[32m0.59175[0m[0m | time: 140.516s
[2K| Adam | epoch: 014 | loss: 0.59175 - acc: 0.7881 -- iter: 08448/10000
[A[ATraining Step: 2174  | total loss: [1m[32m0.61498[0m[0m | time: 141.516s
[2K| Adam | epoch: 014 | loss: 0.61498 - acc: 0.7827 -- iter: 08512/10000
[A[ATraining Step: 2175  | total loss: [1m[32m0.63411[0m[0m | time: 142.468s
[2K| Adam | epoch: 014 | loss: 0.63411 - acc: 0.7779 -- iter: 08576/10000
[A[ATraining Step: 2176  | total loss: [1m[32m0.65342[0m[0m | time: 143.448s
[2K| Adam | epoch: 014 | loss: 0.65342 - acc: 0.7829 -- iter: 08640/10000
[A[ATraining Step: 2177  | total loss: [1m[32m0.64967[0m[0m | time: 144.426s
[2K| Adam | epoch: 014 | loss: 0.64967 - acc: 0.7890 -- iter: 08704/10000
[A[ATraining Step: 2178  | total loss: [1m[32m0.66189[0m[0m | time: 145.397s
[2K| Adam | epoch: 014 | loss: 0.66189 - acc: 0.7835 -- iter: 08768/10000
[A[ATraining Step: 2179  | total loss: [1m[32m0.65956[0m[0m | time: 146.382s
[2K| Adam | epoch: 014 | loss: 0.65956 - acc: 0.7771 -- iter: 08832/10000
[A[ATraining Step: 2180  | total loss: [1m[32m1.60177[0m[0m | time: 147.378s
[2K| Adam | epoch: 014 | loss: 1.60177 - acc: 0.7118 -- iter: 08896/10000
[A[ATraining Step: 2181  | total loss: [1m[32m1.50136[0m[0m | time: 148.331s
[2K| Adam | epoch: 014 | loss: 1.50136 - acc: 0.7188 -- iter: 08960/10000
[A[ATraining Step: 2182  | total loss: [1m[32m1.39897[0m[0m | time: 149.286s
[2K| Adam | epoch: 014 | loss: 1.39897 - acc: 0.7328 -- iter: 09024/10000
[A[ATraining Step: 2183  | total loss: [1m[32m1.32715[0m[0m | time: 150.267s
[2K| Adam | epoch: 014 | loss: 1.32715 - acc: 0.7283 -- iter: 09088/10000
[A[ATraining Step: 2184  | total loss: [1m[32m1.22665[0m[0m | time: 151.221s
[2K| Adam | epoch: 014 | loss: 1.22665 - acc: 0.7430 -- iter: 09152/10000
[A[ATraining Step: 2185  | total loss: [1m[32m1.14852[0m[0m | time: 152.188s
[2K| Adam | epoch: 014 | loss: 1.14852 - acc: 0.7515 -- iter: 09216/10000
[A[ATraining Step: 2186  | total loss: [1m[32m1.07946[0m[0m | time: 153.181s
[2K| Adam | epoch: 014 | loss: 1.07946 - acc: 0.7576 -- iter: 09280/10000
[A[ATraining Step: 2187  | total loss: [1m[32m1.02132[0m[0m | time: 154.184s
[2K| Adam | epoch: 014 | loss: 1.02132 - acc: 0.7615 -- iter: 09344/10000
[A[ATraining Step: 2188  | total loss: [1m[32m0.98210[0m[0m | time: 155.126s
[2K| Adam | epoch: 014 | loss: 0.98210 - acc: 0.7651 -- iter: 09408/10000
[A[ATraining Step: 2189  | total loss: [1m[32m0.93441[0m[0m | time: 156.083s
[2K| Adam | epoch: 014 | loss: 0.93441 - acc: 0.7698 -- iter: 09472/10000
[A[ATraining Step: 2190  | total loss: [1m[32m0.89196[0m[0m | time: 157.088s
[2K| Adam | epoch: 014 | loss: 0.89196 - acc: 0.7772 -- iter: 09536/10000
[A[ATraining Step: 2191  | total loss: [1m[32m0.86743[0m[0m | time: 158.071s
[2K| Adam | epoch: 014 | loss: 0.86743 - acc: 0.7729 -- iter: 09600/10000
[A[ATraining Step: 2192  | total loss: [1m[32m0.83408[0m[0m | time: 159.038s
[2K| Adam | epoch: 014 | loss: 0.83408 - acc: 0.7737 -- iter: 09664/10000
[A[ATraining Step: 2193  | total loss: [1m[32m0.80735[0m[0m | time: 159.992s
[2K| Adam | epoch: 014 | loss: 0.80735 - acc: 0.7776 -- iter: 09728/10000
[A[ATraining Step: 2194  | total loss: [1m[32m0.77824[0m[0m | time: 160.937s
[2K| Adam | epoch: 014 | loss: 0.77824 - acc: 0.7842 -- iter: 09792/10000
[A[ATraining Step: 2195  | total loss: [1m[32m0.74826[0m[0m | time: 161.883s
[2K| Adam | epoch: 014 | loss: 0.74826 - acc: 0.7980 -- iter: 09856/10000
[A[ATraining Step: 2196  | total loss: [1m[32m0.74146[0m[0m | time: 162.845s
[2K| Adam | epoch: 014 | loss: 0.74146 - acc: 0.7948 -- iter: 09920/10000
[A[ATraining Step: 2197  | total loss: [1m[32m0.73235[0m[0m | time: 163.807s
[2K| Adam | epoch: 014 | loss: 0.73235 - acc: 0.7981 -- iter: 09984/10000
[A[ATraining Step: 2198  | total loss: [1m[32m0.70468[0m[0m | time: 167.817s
[2K| Adam | epoch: 014 | loss: 0.70468 - acc: 0.8011 | val_loss: 2.08717 - val_acc: 0.3871 -- iter: 10000/10000
--
Training Step: 2199  | total loss: [1m[32m0.67833[0m[0m | time: 1.123s
[2K| Adam | epoch: 015 | loss: 0.67833 - acc: 0.8022 -- iter: 00064/10000
[A[ATraining Step: 2200  | total loss: [1m[32m0.66169[0m[0m | time: 5.337s
[2K| Adam | epoch: 015 | loss: 0.66169 - acc: 0.8001 | val_loss: 2.06285 - val_acc: 0.3743 -- iter: 00128/10000
--
Training Step: 2201  | total loss: [1m[32m0.66039[0m[0m | time: 6.295s
[2K| Adam | epoch: 015 | loss: 0.66039 - acc: 0.7920 -- iter: 00192/10000
[A[ATraining Step: 2202  | total loss: [1m[32m0.64987[0m[0m | time: 7.254s
[2K| Adam | epoch: 015 | loss: 0.64987 - acc: 0.7894 -- iter: 00256/10000
[A[ATraining Step: 2203  | total loss: [1m[32m0.64183[0m[0m | time: 8.250s
[2K| Adam | epoch: 015 | loss: 0.64183 - acc: 0.7839 -- iter: 00320/10000
[A[ATraining Step: 2204  | total loss: [1m[32m0.64642[0m[0m | time: 9.258s
[2K| Adam | epoch: 015 | loss: 0.64642 - acc: 0.7742 -- iter: 00384/10000
[A[ATraining Step: 2205  | total loss: [1m[32m0.65138[0m[0m | time: 10.245s
[2K| Adam | epoch: 015 | loss: 0.65138 - acc: 0.7687 -- iter: 00448/10000
[A[ATraining Step: 2206  | total loss: [1m[32m0.64532[0m[0m | time: 11.225s
[2K| Adam | epoch: 015 | loss: 0.64532 - acc: 0.7668 -- iter: 00512/10000
[A[ATraining Step: 2207  | total loss: [1m[32m0.65654[0m[0m | time: 12.228s
[2K| Adam | epoch: 015 | loss: 0.65654 - acc: 0.7636 -- iter: 00576/10000
[A[ATraining Step: 2208  | total loss: [1m[32m0.63736[0m[0m | time: 13.403s
[2K| Adam | epoch: 015 | loss: 0.63736 - acc: 0.7669 -- iter: 00640/10000
[A[ATraining Step: 2209  | total loss: [1m[32m0.63096[0m[0m | time: 14.515s
[2K| Adam | epoch: 015 | loss: 0.63096 - acc: 0.7715 -- iter: 00704/10000
[A[ATraining Step: 2210  | total loss: [1m[32m0.60907[0m[0m | time: 15.620s
[2K| Adam | epoch: 015 | loss: 0.60907 - acc: 0.7818 -- iter: 00768/10000
[A[ATraining Step: 2211  | total loss: [1m[32m0.63354[0m[0m | time: 16.160s
[2K| Adam | epoch: 015 | loss: 0.63354 - acc: 0.7755 -- iter: 00832/10000
[A[ATraining Step: 2212  | total loss: [1m[32m0.60666[0m[0m | time: 16.783s
[2K| Adam | epoch: 015 | loss: 0.60666 - acc: 0.7917 -- iter: 00896/10000
[A[ATraining Step: 2213  | total loss: [1m[32m0.58422[0m[0m | time: 17.979s
[2K| Adam | epoch: 015 | loss: 0.58422 - acc: 0.7938 -- iter: 00960/10000
[A[ATraining Step: 2214  | total loss: [1m[32m0.58376[0m[0m | time: 19.343s
[2K| Adam | epoch: 015 | loss: 0.58376 - acc: 0.7988 -- iter: 01024/10000
[A[ATraining Step: 2215  | total loss: [1m[32m0.57908[0m[0m | time: 20.546s
[2K| Adam | epoch: 015 | loss: 0.57908 - acc: 0.7986 -- iter: 01088/10000
[A[ATraining Step: 2216  | total loss: [1m[32m0.59026[0m[0m | time: 22.050s
[2K| Adam | epoch: 015 | loss: 0.59026 - acc: 0.7859 -- iter: 01152/10000
[A[ATraining Step: 2217  | total loss: [1m[32m0.59666[0m[0m | time: 23.653s
[2K| Adam | epoch: 015 | loss: 0.59666 - acc: 0.7776 -- iter: 01216/10000
[A[ATraining Step: 2218  | total loss: [1m[32m0.59629[0m[0m | time: 25.192s
[2K| Adam | epoch: 015 | loss: 0.59629 - acc: 0.7733 -- iter: 01280/10000
[A[ATraining Step: 2219  | total loss: [1m[32m0.60035[0m[0m | time: 26.597s
[2K| Adam | epoch: 015 | loss: 0.60035 - acc: 0.7663 -- iter: 01344/10000
[A[ATraining Step: 2220  | total loss: [1m[32m0.58535[0m[0m | time: 27.877s
[2K| Adam | epoch: 015 | loss: 0.58535 - acc: 0.7709 -- iter: 01408/10000
[A[ATraining Step: 2221  | total loss: [1m[32m0.60188[0m[0m | time: 29.182s
[2K| Adam | epoch: 015 | loss: 0.60188 - acc: 0.7688 -- iter: 01472/10000
[A[ATraining Step: 2222  | total loss: [1m[32m0.61463[0m[0m | time: 30.604s
[2K| Adam | epoch: 015 | loss: 0.61463 - acc: 0.7716 -- iter: 01536/10000
[A[ATraining Step: 2223  | total loss: [1m[32m0.63231[0m[0m | time: 31.913s
[2K| Adam | epoch: 015 | loss: 0.63231 - acc: 0.7710 -- iter: 01600/10000
[A[ATraining Step: 2224  | total loss: [1m[32m0.62223[0m[0m | time: 33.207s
[2K| Adam | epoch: 015 | loss: 0.62223 - acc: 0.7783 -- iter: 01664/10000
[A[ATraining Step: 2225  | total loss: [1m[32m0.62457[0m[0m | time: 34.851s
[2K| Adam | epoch: 015 | loss: 0.62457 - acc: 0.7786 -- iter: 01728/10000
[A[ATraining Step: 2226  | total loss: [1m[32m0.60937[0m[0m | time: 36.194s
[2K| Adam | epoch: 015 | loss: 0.60937 - acc: 0.7773 -- iter: 01792/10000
[A[ATraining Step: 2227  | total loss: [1m[32m0.61065[0m[0m | time: 37.521s
[2K| Adam | epoch: 015 | loss: 0.61065 - acc: 0.7793 -- iter: 01856/10000
[A[ATraining Step: 2228  | total loss: [1m[32m0.59987[0m[0m | time: 38.860s
[2K| Adam | epoch: 015 | loss: 0.59987 - acc: 0.7857 -- iter: 01920/10000
[A[ATraining Step: 2229  | total loss: [1m[32m0.59486[0m[0m | time: 40.185s
[2K| Adam | epoch: 015 | loss: 0.59486 - acc: 0.7853 -- iter: 01984/10000
[A[ATraining Step: 2230  | total loss: [1m[32m0.61191[0m[0m | time: 41.560s
[2K| Adam | epoch: 015 | loss: 0.61191 - acc: 0.7849 -- iter: 02048/10000
[A[ATraining Step: 2231  | total loss: [1m[32m0.62279[0m[0m | time: 42.905s
[2K| Adam | epoch: 015 | loss: 0.62279 - acc: 0.7798 -- iter: 02112/10000
[A[ATraining Step: 2232  | total loss: [1m[32m0.62338[0m[0m | time: 44.109s
[2K| Adam | epoch: 015 | loss: 0.62338 - acc: 0.7846 -- iter: 02176/10000
[A[ATraining Step: 2233  | total loss: [1m[32m0.62166[0m[0m | time: 45.344s
[2K| Adam | epoch: 015 | loss: 0.62166 - acc: 0.7827 -- iter: 02240/10000
[A[ATraining Step: 2234  | total loss: [1m[32m0.63831[0m[0m | time: 46.502s
[2K| Adam | epoch: 015 | loss: 0.63831 - acc: 0.7748 -- iter: 02304/10000
[A[ATraining Step: 2235  | total loss: [1m[32m0.63844[0m[0m | time: 47.784s
[2K| Adam | epoch: 015 | loss: 0.63844 - acc: 0.7707 -- iter: 02368/10000
[A[ATraining Step: 2236  | total loss: [1m[32m0.62469[0m[0m | time: 48.997s
[2K| Adam | epoch: 015 | loss: 0.62469 - acc: 0.7687 -- iter: 02432/10000
[A[ATraining Step: 2237  | total loss: [1m[32m0.63996[0m[0m | time: 50.230s
[2K| Adam | epoch: 015 | loss: 0.63996 - acc: 0.7543 -- iter: 02496/10000
[A[ATraining Step: 2238  | total loss: [1m[32m0.64081[0m[0m | time: 51.425s
[2K| Adam | epoch: 015 | loss: 0.64081 - acc: 0.7570 -- iter: 02560/10000
[A[ATraining Step: 2239  | total loss: [1m[32m0.61761[0m[0m | time: 52.601s
[2K| Adam | epoch: 015 | loss: 0.61761 - acc: 0.7672 -- iter: 02624/10000
[A[ATraining Step: 2240  | total loss: [1m[32m0.60257[0m[0m | time: 53.787s
[2K| Adam | epoch: 015 | loss: 0.60257 - acc: 0.7764 -- iter: 02688/10000
[A[ATraining Step: 2241  | total loss: [1m[32m0.59353[0m[0m | time: 54.949s
[2K| Adam | epoch: 015 | loss: 0.59353 - acc: 0.7801 -- iter: 02752/10000
[A[ATraining Step: 2242  | total loss: [1m[32m0.60886[0m[0m | time: 56.240s
[2K| Adam | epoch: 015 | loss: 0.60886 - acc: 0.7802 -- iter: 02816/10000
[A[ATraining Step: 2243  | total loss: [1m[32m0.60742[0m[0m | time: 57.639s
[2K| Adam | epoch: 015 | loss: 0.60742 - acc: 0.7803 -- iter: 02880/10000
[A[ATraining Step: 2244  | total loss: [1m[32m0.60890[0m[0m | time: 59.044s
[2K| Adam | epoch: 015 | loss: 0.60890 - acc: 0.7726 -- iter: 02944/10000
[A[ATraining Step: 2245  | total loss: [1m[32m0.60115[0m[0m | time: 60.643s
[2K| Adam | epoch: 015 | loss: 0.60115 - acc: 0.7734 -- iter: 03008/10000
[A[ATraining Step: 2246  | total loss: [1m[32m0.62011[0m[0m | time: 62.086s
[2K| Adam | epoch: 015 | loss: 0.62011 - acc: 0.7727 -- iter: 03072/10000
[A[ATraining Step: 2247  | total loss: [1m[32m0.62760[0m[0m | time: 63.445s
[2K| Adam | epoch: 015 | loss: 0.62760 - acc: 0.7735 -- iter: 03136/10000
[A[ATraining Step: 2248  | total loss: [1m[32m0.62141[0m[0m | time: 64.739s
[2K| Adam | epoch: 015 | loss: 0.62141 - acc: 0.7790 -- iter: 03200/10000
[A[ATraining Step: 2249  | total loss: [1m[32m0.61625[0m[0m | time: 66.057s
[2K| Adam | epoch: 015 | loss: 0.61625 - acc: 0.7808 -- iter: 03264/10000
[A[ATraining Step: 2250  | total loss: [1m[32m0.62557[0m[0m | time: 67.350s
[2K| Adam | epoch: 015 | loss: 0.62557 - acc: 0.7839 -- iter: 03328/10000
[A[ATraining Step: 2251  | total loss: [1m[32m0.62337[0m[0m | time: 68.659s
[2K| Adam | epoch: 015 | loss: 0.62337 - acc: 0.7899 -- iter: 03392/10000
[A[ATraining Step: 2252  | total loss: [1m[32m0.60541[0m[0m | time: 70.012s
[2K| Adam | epoch: 015 | loss: 0.60541 - acc: 0.7937 -- iter: 03456/10000
[A[ATraining Step: 2253  | total loss: [1m[32m0.61256[0m[0m | time: 71.254s
[2K| Adam | epoch: 015 | loss: 0.61256 - acc: 0.7909 -- iter: 03520/10000
[A[ATraining Step: 2254  | total loss: [1m[32m0.60005[0m[0m | time: 72.449s
[2K| Adam | epoch: 015 | loss: 0.60005 - acc: 0.7853 -- iter: 03584/10000
[A[ATraining Step: 2255  | total loss: [1m[32m0.61293[0m[0m | time: 73.647s
[2K| Adam | epoch: 015 | loss: 0.61293 - acc: 0.7802 -- iter: 03648/10000
[A[ATraining Step: 2256  | total loss: [1m[32m0.60715[0m[0m | time: 74.956s
[2K| Adam | epoch: 015 | loss: 0.60715 - acc: 0.7803 -- iter: 03712/10000
[A[ATraining Step: 2257  | total loss: [1m[32m0.61039[0m[0m | time: 76.206s
[2K| Adam | epoch: 015 | loss: 0.61039 - acc: 0.7804 -- iter: 03776/10000
[A[ATraining Step: 2258  | total loss: [1m[32m0.60778[0m[0m | time: 77.467s
[2K| Adam | epoch: 015 | loss: 0.60778 - acc: 0.7758 -- iter: 03840/10000
[A[ATraining Step: 2259  | total loss: [1m[32m0.62527[0m[0m | time: 78.768s
[2K| Adam | epoch: 015 | loss: 0.62527 - acc: 0.7685 -- iter: 03904/10000
[A[ATraining Step: 2260  | total loss: [1m[32m0.63779[0m[0m | time: 79.942s
[2K| Adam | epoch: 015 | loss: 0.63779 - acc: 0.7604 -- iter: 03968/10000
[A[ATraining Step: 2261  | total loss: [1m[32m0.65416[0m[0m | time: 80.990s
[2K| Adam | epoch: 015 | loss: 0.65416 - acc: 0.7500 -- iter: 04032/10000
[A[ATraining Step: 2262  | total loss: [1m[32m0.66169[0m[0m | time: 82.006s
[2K| Adam | epoch: 015 | loss: 0.66169 - acc: 0.7500 -- iter: 04096/10000
[A[ATraining Step: 2263  | total loss: [1m[32m0.65406[0m[0m | time: 83.029s
[2K| Adam | epoch: 015 | loss: 0.65406 - acc: 0.7547 -- iter: 04160/10000
[A[ATraining Step: 2264  | total loss: [1m[32m0.65992[0m[0m | time: 84.089s
[2K| Adam | epoch: 015 | loss: 0.65992 - acc: 0.7620 -- iter: 04224/10000
[A[ATraining Step: 2265  | total loss: [1m[32m0.65451[0m[0m | time: 85.290s
[2K| Adam | epoch: 015 | loss: 0.65451 - acc: 0.7655 -- iter: 04288/10000
[A[ATraining Step: 2266  | total loss: [1m[32m0.65737[0m[0m | time: 86.410s
[2K| Adam | epoch: 015 | loss: 0.65737 - acc: 0.7733 -- iter: 04352/10000
[A[ATraining Step: 2267  | total loss: [1m[32m0.65941[0m[0m | time: 87.644s
[2K| Adam | epoch: 015 | loss: 0.65941 - acc: 0.7726 -- iter: 04416/10000
[A[ATraining Step: 2268  | total loss: [1m[32m0.63970[0m[0m | time: 88.747s
[2K| Adam | epoch: 015 | loss: 0.63970 - acc: 0.7750 -- iter: 04480/10000
[A[ATraining Step: 2269  | total loss: [1m[32m0.63032[0m[0m | time: 90.013s
[2K| Adam | epoch: 015 | loss: 0.63032 - acc: 0.7787 -- iter: 04544/10000
[A[ATraining Step: 2270  | total loss: [1m[32m0.63259[0m[0m | time: 91.148s
[2K| Adam | epoch: 015 | loss: 0.63259 - acc: 0.7696 -- iter: 04608/10000
[A[ATraining Step: 2271  | total loss: [1m[32m0.62231[0m[0m | time: 92.275s
[2K| Adam | epoch: 015 | loss: 0.62231 - acc: 0.7739 -- iter: 04672/10000
[A[ATraining Step: 2272  | total loss: [1m[32m0.61572[0m[0m | time: 93.385s
[2K| Adam | epoch: 015 | loss: 0.61572 - acc: 0.7746 -- iter: 04736/10000
[A[ATraining Step: 2273  | total loss: [1m[32m0.61013[0m[0m | time: 94.487s
[2K| Adam | epoch: 015 | loss: 0.61013 - acc: 0.7816 -- iter: 04800/10000
[A[ATraining Step: 2274  | total loss: [1m[32m0.60363[0m[0m | time: 95.589s
[2K| Adam | epoch: 015 | loss: 0.60363 - acc: 0.7893 -- iter: 04864/10000
[A[ATraining Step: 2275  | total loss: [1m[32m0.61621[0m[0m | time: 96.732s
[2K| Adam | epoch: 015 | loss: 0.61621 - acc: 0.7854 -- iter: 04928/10000
[A[ATraining Step: 2276  | total loss: [1m[32m0.62943[0m[0m | time: 97.837s
[2K| Adam | epoch: 015 | loss: 0.62943 - acc: 0.7725 -- iter: 04992/10000
[A[ATraining Step: 2277  | total loss: [1m[32m0.61767[0m[0m | time: 98.945s
[2K| Adam | epoch: 015 | loss: 0.61767 - acc: 0.7781 -- iter: 05056/10000
[A[ATraining Step: 2278  | total loss: [1m[32m0.61120[0m[0m | time: 100.141s
[2K| Adam | epoch: 015 | loss: 0.61120 - acc: 0.7784 -- iter: 05120/10000
[A[ATraining Step: 2279  | total loss: [1m[32m0.60051[0m[0m | time: 101.294s
[2K| Adam | epoch: 015 | loss: 0.60051 - acc: 0.7865 -- iter: 05184/10000
[A[ATraining Step: 2280  | total loss: [1m[32m0.59013[0m[0m | time: 102.449s
[2K| Adam | epoch: 015 | loss: 0.59013 - acc: 0.7844 -- iter: 05248/10000
[A[ATraining Step: 2281  | total loss: [1m[32m0.60377[0m[0m | time: 103.682s
[2K| Adam | epoch: 015 | loss: 0.60377 - acc: 0.7809 -- iter: 05312/10000
[A[ATraining Step: 2282  | total loss: [1m[32m0.58413[0m[0m | time: 104.884s
[2K| Adam | epoch: 015 | loss: 0.58413 - acc: 0.7841 -- iter: 05376/10000
[A[ATraining Step: 2283  | total loss: [1m[32m0.57967[0m[0m | time: 106.083s
[2K| Adam | epoch: 015 | loss: 0.57967 - acc: 0.7838 -- iter: 05440/10000
[A[ATraining Step: 2284  | total loss: [1m[32m0.56621[0m[0m | time: 107.207s
[2K| Adam | epoch: 015 | loss: 0.56621 - acc: 0.7976 -- iter: 05504/10000
[A[ATraining Step: 2285  | total loss: [1m[32m0.56477[0m[0m | time: 108.338s
[2K| Adam | epoch: 015 | loss: 0.56477 - acc: 0.7991 -- iter: 05568/10000
[A[ATraining Step: 2286  | total loss: [1m[32m0.54808[0m[0m | time: 109.554s
[2K| Adam | epoch: 015 | loss: 0.54808 - acc: 0.8020 -- iter: 05632/10000
[A[ATraining Step: 2287  | total loss: [1m[32m0.57303[0m[0m | time: 110.659s
[2K| Adam | epoch: 015 | loss: 0.57303 - acc: 0.8046 -- iter: 05696/10000
[A[ATraining Step: 2288  | total loss: [1m[32m0.56582[0m[0m | time: 111.831s
[2K| Adam | epoch: 015 | loss: 0.56582 - acc: 0.8023 -- iter: 05760/10000
[A[ATraining Step: 2289  | total loss: [1m[32m0.56845[0m[0m | time: 112.935s
[2K| Adam | epoch: 015 | loss: 0.56845 - acc: 0.8017 -- iter: 05824/10000
[A[ATraining Step: 2290  | total loss: [1m[32m0.58101[0m[0m | time: 114.053s
[2K| Adam | epoch: 015 | loss: 0.58101 - acc: 0.8044 -- iter: 05888/10000
[A[ATraining Step: 2291  | total loss: [1m[32m0.59609[0m[0m | time: 115.187s
[2K| Adam | epoch: 015 | loss: 0.59609 - acc: 0.7989 -- iter: 05952/10000
[A[ATraining Step: 2292  | total loss: [1m[32m0.60487[0m[0m | time: 116.320s
[2K| Adam | epoch: 015 | loss: 0.60487 - acc: 0.7925 -- iter: 06016/10000
[A[ATraining Step: 2293  | total loss: [1m[32m0.60549[0m[0m | time: 117.441s
[2K| Adam | epoch: 015 | loss: 0.60549 - acc: 0.7914 -- iter: 06080/10000
[A[ATraining Step: 2294  | total loss: [1m[32m0.64042[0m[0m | time: 118.695s
[2K| Adam | epoch: 015 | loss: 0.64042 - acc: 0.7779 -- iter: 06144/10000
[A[ATraining Step: 2295  | total loss: [1m[32m0.63341[0m[0m | time: 119.992s
[2K| Adam | epoch: 015 | loss: 0.63341 - acc: 0.7813 -- iter: 06208/10000
[A[ATraining Step: 2296  | total loss: [1m[32m0.62023[0m[0m | time: 121.122s
[2K| Adam | epoch: 015 | loss: 0.62023 - acc: 0.7829 -- iter: 06272/10000
[A[ATraining Step: 2297  | total loss: [1m[32m0.62030[0m[0m | time: 122.303s
[2K| Adam | epoch: 015 | loss: 0.62030 - acc: 0.7796 -- iter: 06336/10000
[A[ATraining Step: 2298  | total loss: [1m[32m0.59778[0m[0m | time: 123.392s
[2K| Adam | epoch: 015 | loss: 0.59778 - acc: 0.7876 -- iter: 06400/10000
[A[ATraining Step: 2299  | total loss: [1m[32m0.59085[0m[0m | time: 124.392s
[2K| Adam | epoch: 015 | loss: 0.59085 - acc: 0.7854 -- iter: 06464/10000
[A[ATraining Step: 2300  | total loss: [1m[32m0.60993[0m[0m | time: 128.028s
[2K| Adam | epoch: 015 | loss: 0.60993 - acc: 0.7740 | val_loss: 1.99850 - val_acc: 0.3971 -- iter: 06528/10000
--
Training Step: 2301  | total loss: [1m[32m0.63824[0m[0m | time: 129.098s
[2K| Adam | epoch: 015 | loss: 0.63824 - acc: 0.7654 -- iter: 06592/10000
[A[ATraining Step: 2302  | total loss: [1m[32m0.64043[0m[0m | time: 130.211s
[2K| Adam | epoch: 015 | loss: 0.64043 - acc: 0.7670 -- iter: 06656/10000
[A[ATraining Step: 2303  | total loss: [1m[32m0.63621[0m[0m | time: 131.304s
[2K| Adam | epoch: 015 | loss: 0.63621 - acc: 0.7699 -- iter: 06720/10000
[A[ATraining Step: 2304  | total loss: [1m[32m0.61589[0m[0m | time: 132.448s
[2K| Adam | epoch: 015 | loss: 0.61589 - acc: 0.7805 -- iter: 06784/10000
[A[ATraining Step: 2305  | total loss: [1m[32m0.60899[0m[0m | time: 133.635s
[2K| Adam | epoch: 015 | loss: 0.60899 - acc: 0.7899 -- iter: 06848/10000
[A[ATraining Step: 2306  | total loss: [1m[32m0.60495[0m[0m | time: 134.730s
[2K| Adam | epoch: 015 | loss: 0.60495 - acc: 0.7844 -- iter: 06912/10000
[A[ATraining Step: 2307  | total loss: [1m[32m0.58877[0m[0m | time: 135.880s
[2K| Adam | epoch: 015 | loss: 0.58877 - acc: 0.7919 -- iter: 06976/10000
[A[ATraining Step: 2308  | total loss: [1m[32m0.56510[0m[0m | time: 136.990s
[2K| Adam | epoch: 015 | loss: 0.56510 - acc: 0.7986 -- iter: 07040/10000
[A[ATraining Step: 2309  | total loss: [1m[32m0.56337[0m[0m | time: 138.109s
[2K| Adam | epoch: 015 | loss: 0.56337 - acc: 0.8016 -- iter: 07104/10000
[A[ATraining Step: 2310  | total loss: [1m[32m0.56906[0m[0m | time: 139.314s
[2K| Adam | epoch: 015 | loss: 0.56906 - acc: 0.8058 -- iter: 07168/10000
[A[ATraining Step: 2311  | total loss: [1m[32m0.56663[0m[0m | time: 140.418s
[2K| Adam | epoch: 015 | loss: 0.56663 - acc: 0.8111 -- iter: 07232/10000
[A[ATraining Step: 2312  | total loss: [1m[32m0.54894[0m[0m | time: 141.545s
[2K| Adam | epoch: 015 | loss: 0.54894 - acc: 0.8175 -- iter: 07296/10000
[A[ATraining Step: 2313  | total loss: [1m[32m0.56860[0m[0m | time: 142.684s
[2K| Adam | epoch: 015 | loss: 0.56860 - acc: 0.8123 -- iter: 07360/10000
[A[ATraining Step: 2314  | total loss: [1m[32m0.57337[0m[0m | time: 143.835s
[2K| Adam | epoch: 015 | loss: 0.57337 - acc: 0.8108 -- iter: 07424/10000
[A[ATraining Step: 2315  | total loss: [1m[32m0.58835[0m[0m | time: 144.952s
[2K| Adam | epoch: 015 | loss: 0.58835 - acc: 0.8047 -- iter: 07488/10000
[A[ATraining Step: 2316  | total loss: [1m[32m0.59978[0m[0m | time: 146.112s
[2K| Adam | epoch: 015 | loss: 0.59978 - acc: 0.7961 -- iter: 07552/10000
[A[ATraining Step: 2317  | total loss: [1m[32m0.59769[0m[0m | time: 147.340s
[2K| Adam | epoch: 015 | loss: 0.59769 - acc: 0.7993 -- iter: 07616/10000
[A[ATraining Step: 2318  | total loss: [1m[32m0.60157[0m[0m | time: 148.501s
[2K| Adam | epoch: 015 | loss: 0.60157 - acc: 0.8022 -- iter: 07680/10000
[A[ATraining Step: 2319  | total loss: [1m[32m0.60057[0m[0m | time: 149.701s
[2K| Adam | epoch: 015 | loss: 0.60057 - acc: 0.8032 -- iter: 07744/10000
[A[ATraining Step: 2320  | total loss: [1m[32m0.60348[0m[0m | time: 150.845s
[2K| Adam | epoch: 015 | loss: 0.60348 - acc: 0.8026 -- iter: 07808/10000
[A[ATraining Step: 2321  | total loss: [1m[32m0.59964[0m[0m | time: 151.982s
[2K| Adam | epoch: 015 | loss: 0.59964 - acc: 0.8083 -- iter: 07872/10000
[A[ATraining Step: 2322  | total loss: [1m[32m0.57446[0m[0m | time: 153.131s
[2K| Adam | epoch: 015 | loss: 0.57446 - acc: 0.8196 -- iter: 07936/10000
[A[ATraining Step: 2323  | total loss: [1m[32m0.57324[0m[0m | time: 154.288s
[2K| Adam | epoch: 015 | loss: 0.57324 - acc: 0.8095 -- iter: 08000/10000
[A[ATraining Step: 2324  | total loss: [1m[32m0.56966[0m[0m | time: 155.424s
[2K| Adam | epoch: 015 | loss: 0.56966 - acc: 0.8005 -- iter: 08064/10000
[A[ATraining Step: 2325  | total loss: [1m[32m0.57210[0m[0m | time: 156.559s
[2K| Adam | epoch: 015 | loss: 0.57210 - acc: 0.7954 -- iter: 08128/10000
[A[ATraining Step: 2326  | total loss: [1m[32m0.54563[0m[0m | time: 157.805s
[2K| Adam | epoch: 015 | loss: 0.54563 - acc: 0.8049 -- iter: 08192/10000
[A[ATraining Step: 2327  | total loss: [1m[32m0.54885[0m[0m | time: 158.951s
[2K| Adam | epoch: 015 | loss: 0.54885 - acc: 0.7963 -- iter: 08256/10000
[A[ATraining Step: 2328  | total loss: [1m[32m0.56379[0m[0m | time: 160.141s
[2K| Adam | epoch: 015 | loss: 0.56379 - acc: 0.7979 -- iter: 08320/10000
[A[ATraining Step: 2329  | total loss: [1m[32m0.56505[0m[0m | time: 161.163s
[2K| Adam | epoch: 015 | loss: 0.56505 - acc: 0.7963 -- iter: 08384/10000
[A[ATraining Step: 2330  | total loss: [1m[32m0.56766[0m[0m | time: 162.180s
[2K| Adam | epoch: 015 | loss: 0.56766 - acc: 0.7963 -- iter: 08448/10000
[A[ATraining Step: 2331  | total loss: [1m[32m0.56302[0m[0m | time: 163.174s
[2K| Adam | epoch: 015 | loss: 0.56302 - acc: 0.8026 -- iter: 08512/10000
[A[ATraining Step: 2332  | total loss: [1m[32m0.56695[0m[0m | time: 164.190s
[2K| Adam | epoch: 015 | loss: 0.56695 - acc: 0.8036 -- iter: 08576/10000
[A[ATraining Step: 2333  | total loss: [1m[32m0.56399[0m[0m | time: 165.240s
[2K| Adam | epoch: 015 | loss: 0.56399 - acc: 0.8045 -- iter: 08640/10000
[A[ATraining Step: 2334  | total loss: [1m[32m0.56726[0m[0m | time: 166.307s
[2K| Adam | epoch: 015 | loss: 0.56726 - acc: 0.8053 -- iter: 08704/10000
[A[ATraining Step: 2335  | total loss: [1m[32m0.56198[0m[0m | time: 167.391s
[2K| Adam | epoch: 015 | loss: 0.56198 - acc: 0.8060 -- iter: 08768/10000
[A[ATraining Step: 2336  | total loss: [1m[32m0.55435[0m[0m | time: 168.473s
[2K| Adam | epoch: 015 | loss: 0.55435 - acc: 0.8114 -- iter: 08832/10000
[A[ATraining Step: 2337  | total loss: [1m[32m0.55148[0m[0m | time: 169.607s
[2K| Adam | epoch: 015 | loss: 0.55148 - acc: 0.8099 -- iter: 08896/10000
[A[ATraining Step: 2338  | total loss: [1m[32m1.42042[0m[0m | time: 170.741s
[2K| Adam | epoch: 015 | loss: 1.42042 - acc: 0.7430 -- iter: 08960/10000
[A[ATraining Step: 2339  | total loss: [1m[32m1.33188[0m[0m | time: 171.888s
[2K| Adam | epoch: 015 | loss: 1.33188 - acc: 0.7515 -- iter: 09024/10000
[A[ATraining Step: 2340  | total loss: [1m[32m1.24110[0m[0m | time: 173.024s
[2K| Adam | epoch: 015 | loss: 1.24110 - acc: 0.7576 -- iter: 09088/10000
[A[ATraining Step: 2341  | total loss: [1m[32m1.16675[0m[0m | time: 174.170s
[2K| Adam | epoch: 015 | loss: 1.16675 - acc: 0.7615 -- iter: 09152/10000
[A[ATraining Step: 2342  | total loss: [1m[32m1.10681[0m[0m | time: 175.309s
[2K| Adam | epoch: 015 | loss: 1.10681 - acc: 0.7666 -- iter: 09216/10000
[A[ATraining Step: 2343  | total loss: [1m[32m1.06925[0m[0m | time: 176.409s
[2K| Adam | epoch: 015 | loss: 1.06925 - acc: 0.7618 -- iter: 09280/10000
[A[ATraining Step: 2344  | total loss: [1m[32m1.05634[0m[0m | time: 177.520s
[2K| Adam | epoch: 015 | loss: 1.05634 - acc: 0.7497 -- iter: 09344/10000
[A[ATraining Step: 2345  | total loss: [1m[32m0.99908[0m[0m | time: 178.654s
[2K| Adam | epoch: 015 | loss: 0.99908 - acc: 0.7544 -- iter: 09408/10000
[A[ATraining Step: 2346  | total loss: [1m[32m0.96237[0m[0m | time: 179.846s
[2K| Adam | epoch: 015 | loss: 0.96237 - acc: 0.7571 -- iter: 09472/10000
[A[ATraining Step: 2347  | total loss: [1m[32m0.92416[0m[0m | time: 180.977s
[2K| Adam | epoch: 015 | loss: 0.92416 - acc: 0.7580 -- iter: 09536/10000
[A[ATraining Step: 2348  | total loss: [1m[32m0.87275[0m[0m | time: 182.094s
[2K| Adam | epoch: 015 | loss: 0.87275 - acc: 0.7665 -- iter: 09600/10000
[A[ATraining Step: 2349  | total loss: [1m[32m0.83982[0m[0m | time: 183.272s
[2K| Adam | epoch: 015 | loss: 0.83982 - acc: 0.7743 -- iter: 09664/10000
[A[ATraining Step: 2350  | total loss: [1m[32m0.81182[0m[0m | time: 184.409s
[2K| Adam | epoch: 015 | loss: 0.81182 - acc: 0.7765 -- iter: 09728/10000
[A[ATraining Step: 2351  | total loss: [1m[32m0.80050[0m[0m | time: 185.579s
[2K| Adam | epoch: 015 | loss: 0.80050 - acc: 0.7786 -- iter: 09792/10000
[A[ATraining Step: 2352  | total loss: [1m[32m0.77765[0m[0m | time: 186.780s
[2K| Adam | epoch: 015 | loss: 0.77765 - acc: 0.7913 -- iter: 09856/10000
[A[ATraining Step: 2353  | total loss: [1m[32m0.76468[0m[0m | time: 187.986s
[2K| Adam | epoch: 015 | loss: 0.76468 - acc: 0.7903 -- iter: 09920/10000
[A[ATraining Step: 2354  | total loss: [1m[32m0.72987[0m[0m | time: 189.246s
[2K| Adam | epoch: 015 | loss: 0.72987 - acc: 0.8035 -- iter: 09984/10000
[A[ATraining Step: 2355  | total loss: [1m[32m0.72044[0m[0m | time: 192.998s
[2K| Adam | epoch: 015 | loss: 0.72044 - acc: 0.8075 | val_loss: 2.21598 - val_acc: 0.3471 -- iter: 10000/10000
--
Training Step: 2356  | total loss: [1m[32m0.69892[0m[0m | time: 1.035s
[2K| Adam | epoch: 016 | loss: 0.69892 - acc: 0.8064 -- iter: 00064/10000
[A[ATraining Step: 2357  | total loss: [1m[32m0.67027[0m[0m | time: 2.128s
[2K| Adam | epoch: 016 | loss: 0.67027 - acc: 0.8117 -- iter: 00128/10000
[A[ATraining Step: 2358  | total loss: [1m[32m0.67938[0m[0m | time: 3.319s
[2K| Adam | epoch: 016 | loss: 0.67938 - acc: 0.8102 -- iter: 00192/10000
[A[ATraining Step: 2359  | total loss: [1m[32m0.65979[0m[0m | time: 4.766s
[2K| Adam | epoch: 016 | loss: 0.65979 - acc: 0.8136 -- iter: 00256/10000
[A[ATraining Step: 2360  | total loss: [1m[32m0.65386[0m[0m | time: 6.211s
[2K| Adam | epoch: 016 | loss: 0.65386 - acc: 0.8072 -- iter: 00320/10000
[A[ATraining Step: 2361  | total loss: [1m[32m0.64547[0m[0m | time: 7.547s
[2K| Adam | epoch: 016 | loss: 0.64547 - acc: 0.8046 -- iter: 00384/10000
[A[ATraining Step: 2362  | total loss: [1m[32m0.63442[0m[0m | time: 8.953s
[2K| Adam | epoch: 016 | loss: 0.63442 - acc: 0.8054 -- iter: 00448/10000
[A[ATraining Step: 2363  | total loss: [1m[32m0.62430[0m[0m | time: 10.240s
[2K| Adam | epoch: 016 | loss: 0.62430 - acc: 0.7999 -- iter: 00512/10000
[A[ATraining Step: 2364  | total loss: [1m[32m0.63872[0m[0m | time: 11.484s
[2K| Adam | epoch: 016 | loss: 0.63872 - acc: 0.7886 -- iter: 00576/10000
[A[ATraining Step: 2365  | total loss: [1m[32m0.63097[0m[0m | time: 12.711s
[2K| Adam | epoch: 016 | loss: 0.63097 - acc: 0.7879 -- iter: 00640/10000
[A[ATraining Step: 2366  | total loss: [1m[32m0.62494[0m[0m | time: 13.902s
[2K| Adam | epoch: 016 | loss: 0.62494 - acc: 0.7935 -- iter: 00704/10000
[A[ATraining Step: 2367  | total loss: [1m[32m0.64286[0m[0m | time: 14.961s
[2K| Adam | epoch: 016 | loss: 0.64286 - acc: 0.7829 -- iter: 00768/10000
[A[ATraining Step: 2368  | total loss: [1m[32m0.62725[0m[0m | time: 15.967s
[2K| Adam | epoch: 016 | loss: 0.62725 - acc: 0.7843 -- iter: 00832/10000
[A[ATraining Step: 2369  | total loss: [1m[32m0.61385[0m[0m | time: 16.525s
[2K| Adam | epoch: 016 | loss: 0.61385 - acc: 0.7902 -- iter: 00896/10000
[A[ATraining Step: 2370  | total loss: [1m[32m0.61517[0m[0m | time: 16.973s
[2K| Adam | epoch: 016 | loss: 0.61517 - acc: 0.7925 -- iter: 00960/10000
[A[ATraining Step: 2371  | total loss: [1m[32m0.62287[0m[0m | time: 17.995s
[2K| Adam | epoch: 016 | loss: 0.62287 - acc: 0.7945 -- iter: 01024/10000
[A[ATraining Step: 2372  | total loss: [1m[32m0.61992[0m[0m | time: 19.033s
[2K| Adam | epoch: 016 | loss: 0.61992 - acc: 0.7947 -- iter: 01088/10000
[A[ATraining Step: 2373  | total loss: [1m[32m0.61971[0m[0m | time: 20.090s
[2K| Adam | epoch: 016 | loss: 0.61971 - acc: 0.7902 -- iter: 01152/10000
[A[ATraining Step: 2374  | total loss: [1m[32m0.61582[0m[0m | time: 21.193s
[2K| Adam | epoch: 016 | loss: 0.61582 - acc: 0.7831 -- iter: 01216/10000
[A[ATraining Step: 2375  | total loss: [1m[32m0.62624[0m[0m | time: 22.357s
[2K| Adam | epoch: 016 | loss: 0.62624 - acc: 0.7735 -- iter: 01280/10000
[A[ATraining Step: 2376  | total loss: [1m[32m0.62180[0m[0m | time: 23.519s
[2K| Adam | epoch: 016 | loss: 0.62180 - acc: 0.7743 -- iter: 01344/10000
[A[ATraining Step: 2377  | total loss: [1m[32m0.61308[0m[0m | time: 24.752s
[2K| Adam | epoch: 016 | loss: 0.61308 - acc: 0.7750 -- iter: 01408/10000
[A[ATraining Step: 2378  | total loss: [1m[32m0.60652[0m[0m | time: 25.933s
[2K| Adam | epoch: 016 | loss: 0.60652 - acc: 0.7741 -- iter: 01472/10000
[A[ATraining Step: 2379  | total loss: [1m[32m0.62078[0m[0m | time: 27.299s
[2K| Adam | epoch: 016 | loss: 0.62078 - acc: 0.7717 -- iter: 01536/10000
[A[ATraining Step: 2380  | total loss: [1m[32m0.61186[0m[0m | time: 28.687s
[2K| Adam | epoch: 016 | loss: 0.61186 - acc: 0.7679 -- iter: 01600/10000
[A[ATraining Step: 2381  | total loss: [1m[32m0.60198[0m[0m | time: 30.221s
[2K| Adam | epoch: 016 | loss: 0.60198 - acc: 0.7661 -- iter: 01664/10000
[A[ATraining Step: 2382  | total loss: [1m[32m0.61657[0m[0m | time: 31.566s
[2K| Adam | epoch: 016 | loss: 0.61657 - acc: 0.7583 -- iter: 01728/10000
[A[ATraining Step: 2383  | total loss: [1m[32m0.61294[0m[0m | time: 33.004s
[2K| Adam | epoch: 016 | loss: 0.61294 - acc: 0.7590 -- iter: 01792/10000
[A[ATraining Step: 2384  | total loss: [1m[32m0.60650[0m[0m | time: 34.798s
[2K| Adam | epoch: 016 | loss: 0.60650 - acc: 0.7581 -- iter: 01856/10000
[A[ATraining Step: 2385  | total loss: [1m[32m0.59680[0m[0m | time: 36.578s
[2K| Adam | epoch: 016 | loss: 0.59680 - acc: 0.7620 -- iter: 01920/10000
[A[ATraining Step: 2386  | total loss: [1m[32m0.61175[0m[0m | time: 38.254s
[2K| Adam | epoch: 016 | loss: 0.61175 - acc: 0.7608 -- iter: 01984/10000
[A[ATraining Step: 2387  | total loss: [1m[32m0.61504[0m[0m | time: 39.771s
[2K| Adam | epoch: 016 | loss: 0.61504 - acc: 0.7597 -- iter: 02048/10000
[A[ATraining Step: 2388  | total loss: [1m[32m0.60840[0m[0m | time: 41.065s
[2K| Adam | epoch: 016 | loss: 0.60840 - acc: 0.7650 -- iter: 02112/10000
[A[ATraining Step: 2389  | total loss: [1m[32m0.60511[0m[0m | time: 42.262s
[2K| Adam | epoch: 016 | loss: 0.60511 - acc: 0.7729 -- iter: 02176/10000
[A[ATraining Step: 2390  | total loss: [1m[32m0.58332[0m[0m | time: 43.567s
[2K| Adam | epoch: 016 | loss: 0.58332 - acc: 0.7784 -- iter: 02240/10000
[A[ATraining Step: 2391  | total loss: [1m[32m0.56937[0m[0m | time: 44.734s
[2K| Adam | epoch: 016 | loss: 0.56937 - acc: 0.7865 -- iter: 02304/10000
[A[ATraining Step: 2392  | total loss: [1m[32m0.56996[0m[0m | time: 45.943s
[2K| Adam | epoch: 016 | loss: 0.56996 - acc: 0.7922 -- iter: 02368/10000
[A[ATraining Step: 2393  | total loss: [1m[32m0.55222[0m[0m | time: 47.122s
[2K| Adam | epoch: 016 | loss: 0.55222 - acc: 0.7989 -- iter: 02432/10000
[A[ATraining Step: 2394  | total loss: [1m[32m0.54514[0m[0m | time: 48.234s
[2K| Adam | epoch: 016 | loss: 0.54514 - acc: 0.8034 -- iter: 02496/10000
[A[ATraining Step: 2395  | total loss: [1m[32m0.55430[0m[0m | time: 49.328s
[2K| Adam | epoch: 016 | loss: 0.55430 - acc: 0.8012 -- iter: 02560/10000
[A[ATraining Step: 2396  | total loss: [1m[32m0.57627[0m[0m | time: 50.515s
[2K| Adam | epoch: 016 | loss: 0.57627 - acc: 0.7992 -- iter: 02624/10000
[A[ATraining Step: 2397  | total loss: [1m[32m0.56933[0m[0m | time: 51.681s
[2K| Adam | epoch: 016 | loss: 0.56933 - acc: 0.8052 -- iter: 02688/10000
[A[ATraining Step: 2398  | total loss: [1m[32m0.56320[0m[0m | time: 52.859s
[2K| Adam | epoch: 016 | loss: 0.56320 - acc: 0.8106 -- iter: 02752/10000
[A[ATraining Step: 2399  | total loss: [1m[32m0.56110[0m[0m | time: 53.995s
[2K| Adam | epoch: 016 | loss: 0.56110 - acc: 0.8077 -- iter: 02816/10000
[A[ATraining Step: 2400  | total loss: [1m[32m0.56336[0m[0m | time: 58.682s
[2K| Adam | epoch: 016 | loss: 0.56336 - acc: 0.8051 | val_loss: 2.51060 - val_acc: 0.3557 -- iter: 02880/10000
--
Training Step: 2401  | total loss: [1m[32m0.58544[0m[0m | time: 59.833s
[2K| Adam | epoch: 016 | loss: 0.58544 - acc: 0.8027 -- iter: 02944/10000
[A[ATraining Step: 2402  | total loss: [1m[32m0.58061[0m[0m | time: 61.036s
[2K| Adam | epoch: 016 | loss: 0.58061 - acc: 0.8005 -- iter: 03008/10000
[A[ATraining Step: 2403  | total loss: [1m[32m0.57545[0m[0m | time: 62.312s
[2K| Adam | epoch: 016 | loss: 0.57545 - acc: 0.8049 -- iter: 03072/10000
[A[ATraining Step: 2404  | total loss: [1m[32m0.56832[0m[0m | time: 63.491s
[2K| Adam | epoch: 016 | loss: 0.56832 - acc: 0.8087 -- iter: 03136/10000
[A[ATraining Step: 2405  | total loss: [1m[32m0.57260[0m[0m | time: 64.569s
[2K| Adam | epoch: 016 | loss: 0.57260 - acc: 0.8060 -- iter: 03200/10000
[A[ATraining Step: 2406  | total loss: [1m[32m0.57555[0m[0m | time: 65.562s
[2K| Adam | epoch: 016 | loss: 0.57555 - acc: 0.8082 -- iter: 03264/10000
[A[ATraining Step: 2407  | total loss: [1m[32m0.55815[0m[0m | time: 66.564s
[2K| Adam | epoch: 016 | loss: 0.55815 - acc: 0.8149 -- iter: 03328/10000
[A[ATraining Step: 2408  | total loss: [1m[32m0.56278[0m[0m | time: 67.543s
[2K| Adam | epoch: 016 | loss: 0.56278 - acc: 0.8131 -- iter: 03392/10000
[A[ATraining Step: 2409  | total loss: [1m[32m0.55289[0m[0m | time: 68.544s
[2K| Adam | epoch: 016 | loss: 0.55289 - acc: 0.8130 -- iter: 03456/10000
[A[ATraining Step: 2410  | total loss: [1m[32m0.54396[0m[0m | time: 69.544s
[2K| Adam | epoch: 016 | loss: 0.54396 - acc: 0.8114 -- iter: 03520/10000
[A[ATraining Step: 2411  | total loss: [1m[32m0.52689[0m[0m | time: 70.565s
[2K| Adam | epoch: 016 | loss: 0.52689 - acc: 0.8162 -- iter: 03584/10000
[A[ATraining Step: 2412  | total loss: [1m[32m0.54806[0m[0m | time: 71.599s
[2K| Adam | epoch: 016 | loss: 0.54806 - acc: 0.8049 -- iter: 03648/10000
[A[ATraining Step: 2413  | total loss: [1m[32m0.55121[0m[0m | time: 72.740s
[2K| Adam | epoch: 016 | loss: 0.55121 - acc: 0.8025 -- iter: 03712/10000
[A[ATraining Step: 2414  | total loss: [1m[32m0.55241[0m[0m | time: 73.868s
[2K| Adam | epoch: 016 | loss: 0.55241 - acc: 0.7942 -- iter: 03776/10000
[A[ATraining Step: 2415  | total loss: [1m[32m0.54246[0m[0m | time: 75.017s
[2K| Adam | epoch: 016 | loss: 0.54246 - acc: 0.8022 -- iter: 03840/10000
[A[ATraining Step: 2416  | total loss: [1m[32m0.53717[0m[0m | time: 76.086s
[2K| Adam | epoch: 016 | loss: 0.53717 - acc: 0.8048 -- iter: 03904/10000
[A[ATraining Step: 2417  | total loss: [1m[32m0.53430[0m[0m | time: 77.110s
[2K| Adam | epoch: 016 | loss: 0.53430 - acc: 0.8056 -- iter: 03968/10000
[A[ATraining Step: 2418  | total loss: [1m[32m0.57510[0m[0m | time: 78.113s
[2K| Adam | epoch: 016 | loss: 0.57510 - acc: 0.7969 -- iter: 04032/10000
[A[ATraining Step: 2419  | total loss: [1m[32m0.56549[0m[0m | time: 79.120s
[2K| Adam | epoch: 016 | loss: 0.56549 - acc: 0.8000 -- iter: 04096/10000
[A[ATraining Step: 2420  | total loss: [1m[32m0.55245[0m[0m | time: 80.131s
[2K| Adam | epoch: 016 | loss: 0.55245 - acc: 0.8013 -- iter: 04160/10000
[A[ATraining Step: 2421  | total loss: [1m[32m0.57394[0m[0m | time: 81.190s
[2K| Adam | epoch: 016 | loss: 0.57394 - acc: 0.7962 -- iter: 04224/10000
[A[ATraining Step: 2422  | total loss: [1m[32m0.57355[0m[0m | time: 82.251s
[2K| Adam | epoch: 016 | loss: 0.57355 - acc: 0.7978 -- iter: 04288/10000
[A[ATraining Step: 2423  | total loss: [1m[32m0.57497[0m[0m | time: 83.349s
[2K| Adam | epoch: 016 | loss: 0.57497 - acc: 0.7946 -- iter: 04352/10000
[A[ATraining Step: 2424  | total loss: [1m[32m0.55844[0m[0m | time: 84.420s
[2K| Adam | epoch: 016 | loss: 0.55844 - acc: 0.7979 -- iter: 04416/10000
[A[ATraining Step: 2425  | total loss: [1m[32m0.54490[0m[0m | time: 85.509s
[2K| Adam | epoch: 016 | loss: 0.54490 - acc: 0.8056 -- iter: 04480/10000
[A[ATraining Step: 2426  | total loss: [1m[32m0.54151[0m[0m | time: 86.762s
[2K| Adam | epoch: 016 | loss: 0.54151 - acc: 0.8001 -- iter: 04544/10000
[A[ATraining Step: 2427  | total loss: [1m[32m0.53071[0m[0m | time: 87.901s
[2K| Adam | epoch: 016 | loss: 0.53071 - acc: 0.8013 -- iter: 04608/10000
[A[ATraining Step: 2428  | total loss: [1m[32m0.53665[0m[0m | time: 89.159s
[2K| Adam | epoch: 016 | loss: 0.53665 - acc: 0.8024 -- iter: 04672/10000
[A[ATraining Step: 2429  | total loss: [1m[32m0.55096[0m[0m | time: 90.398s
[2K| Adam | epoch: 016 | loss: 0.55096 - acc: 0.8019 -- iter: 04736/10000
[A[ATraining Step: 2430  | total loss: [1m[32m0.56276[0m[0m | time: 91.615s
[2K| Adam | epoch: 016 | loss: 0.56276 - acc: 0.7936 -- iter: 04800/10000
[A[ATraining Step: 2431  | total loss: [1m[32m0.56791[0m[0m | time: 92.801s
[2K| Adam | epoch: 016 | loss: 0.56791 - acc: 0.7892 -- iter: 04864/10000
[A[ATraining Step: 2432  | total loss: [1m[32m0.57103[0m[0m | time: 93.878s
[2K| Adam | epoch: 016 | loss: 0.57103 - acc: 0.7822 -- iter: 04928/10000
[A[ATraining Step: 2433  | total loss: [1m[32m0.59895[0m[0m | time: 94.895s
[2K| Adam | epoch: 016 | loss: 0.59895 - acc: 0.7805 -- iter: 04992/10000
[A[ATraining Step: 2434  | total loss: [1m[32m0.59337[0m[0m | time: 95.928s
[2K| Adam | epoch: 016 | loss: 0.59337 - acc: 0.7837 -- iter: 05056/10000
[A[ATraining Step: 2435  | total loss: [1m[32m0.61213[0m[0m | time: 97.003s
[2K| Adam | epoch: 016 | loss: 0.61213 - acc: 0.7788 -- iter: 05120/10000
[A[ATraining Step: 2436  | total loss: [1m[32m0.61801[0m[0m | time: 98.057s
[2K| Adam | epoch: 016 | loss: 0.61801 - acc: 0.7806 -- iter: 05184/10000
[A[ATraining Step: 2437  | total loss: [1m[32m0.61363[0m[0m | time: 99.104s
[2K| Adam | epoch: 016 | loss: 0.61363 - acc: 0.7869 -- iter: 05248/10000
[A[ATraining Step: 2438  | total loss: [1m[32m0.60661[0m[0m | time: 100.209s
[2K| Adam | epoch: 016 | loss: 0.60661 - acc: 0.7895 -- iter: 05312/10000
[A[ATraining Step: 2439  | total loss: [1m[32m0.57767[0m[0m | time: 101.296s
[2K| Adam | epoch: 016 | loss: 0.57767 - acc: 0.7996 -- iter: 05376/10000
[A[ATraining Step: 2440  | total loss: [1m[32m0.57709[0m[0m | time: 102.399s
[2K| Adam | epoch: 016 | loss: 0.57709 - acc: 0.7993 -- iter: 05440/10000
[A[ATraining Step: 2441  | total loss: [1m[32m0.60906[0m[0m | time: 103.550s
[2K| Adam | epoch: 016 | loss: 0.60906 - acc: 0.7881 -- iter: 05504/10000
[A[ATraining Step: 2442  | total loss: [1m[32m0.61319[0m[0m | time: 104.768s
[2K| Adam | epoch: 016 | loss: 0.61319 - acc: 0.7843 -- iter: 05568/10000
[A[ATraining Step: 2443  | total loss: [1m[32m0.61674[0m[0m | time: 105.987s
[2K| Adam | epoch: 016 | loss: 0.61674 - acc: 0.7824 -- iter: 05632/10000
[A[ATraining Step: 2444  | total loss: [1m[32m0.60373[0m[0m | time: 107.260s
[2K| Adam | epoch: 016 | loss: 0.60373 - acc: 0.7855 -- iter: 05696/10000
[A[ATraining Step: 2445  | total loss: [1m[32m0.60351[0m[0m | time: 108.466s
[2K| Adam | epoch: 016 | loss: 0.60351 - acc: 0.7928 -- iter: 05760/10000
[A[ATraining Step: 2446  | total loss: [1m[32m0.59491[0m[0m | time: 109.680s
[2K| Adam | epoch: 016 | loss: 0.59491 - acc: 0.7932 -- iter: 05824/10000
[A[ATraining Step: 2447  | total loss: [1m[32m0.58190[0m[0m | time: 110.714s
[2K| Adam | epoch: 016 | loss: 0.58190 - acc: 0.7967 -- iter: 05888/10000
[A[ATraining Step: 2448  | total loss: [1m[32m0.58402[0m[0m | time: 111.732s
[2K| Adam | epoch: 016 | loss: 0.58402 - acc: 0.7874 -- iter: 05952/10000
[A[ATraining Step: 2449  | total loss: [1m[32m0.58319[0m[0m | time: 112.747s
[2K| Adam | epoch: 016 | loss: 0.58319 - acc: 0.7852 -- iter: 06016/10000
[A[ATraining Step: 2450  | total loss: [1m[32m0.57866[0m[0m | time: 113.757s
[2K| Adam | epoch: 016 | loss: 0.57866 - acc: 0.7911 -- iter: 06080/10000
[A[ATraining Step: 2451  | total loss: [1m[32m0.57808[0m[0m | time: 114.766s
[2K| Adam | epoch: 016 | loss: 0.57808 - acc: 0.7948 -- iter: 06144/10000
[A[ATraining Step: 2452  | total loss: [1m[32m0.56651[0m[0m | time: 115.805s
[2K| Adam | epoch: 016 | loss: 0.56651 - acc: 0.7981 -- iter: 06208/10000
[A[ATraining Step: 2453  | total loss: [1m[32m0.57030[0m[0m | time: 116.852s
[2K| Adam | epoch: 016 | loss: 0.57030 - acc: 0.7933 -- iter: 06272/10000
[A[ATraining Step: 2454  | total loss: [1m[32m0.58028[0m[0m | time: 117.874s
[2K| Adam | epoch: 016 | loss: 0.58028 - acc: 0.7874 -- iter: 06336/10000
[A[ATraining Step: 2455  | total loss: [1m[32m0.58964[0m[0m | time: 118.963s
[2K| Adam | epoch: 016 | loss: 0.58964 - acc: 0.7821 -- iter: 06400/10000
[A[ATraining Step: 2456  | total loss: [1m[32m0.57980[0m[0m | time: 120.051s
[2K| Adam | epoch: 016 | loss: 0.57980 - acc: 0.7898 -- iter: 06464/10000
[A[ATraining Step: 2457  | total loss: [1m[32m0.58456[0m[0m | time: 121.129s
[2K| Adam | epoch: 016 | loss: 0.58456 - acc: 0.7812 -- iter: 06528/10000
[A[ATraining Step: 2458  | total loss: [1m[32m0.56809[0m[0m | time: 122.218s
[2K| Adam | epoch: 016 | loss: 0.56809 - acc: 0.7858 -- iter: 06592/10000
[A[ATraining Step: 2459  | total loss: [1m[32m0.57076[0m[0m | time: 123.364s
[2K| Adam | epoch: 016 | loss: 0.57076 - acc: 0.7885 -- iter: 06656/10000
[A[ATraining Step: 2460  | total loss: [1m[32m0.55579[0m[0m | time: 124.458s
[2K| Adam | epoch: 016 | loss: 0.55579 - acc: 0.8003 -- iter: 06720/10000
[A[ATraining Step: 2461  | total loss: [1m[32m0.55271[0m[0m | time: 125.544s
[2K| Adam | epoch: 016 | loss: 0.55271 - acc: 0.7968 -- iter: 06784/10000
[A[ATraining Step: 2462  | total loss: [1m[32m0.54202[0m[0m | time: 126.673s
[2K| Adam | epoch: 016 | loss: 0.54202 - acc: 0.7968 -- iter: 06848/10000
[A[ATraining Step: 2463  | total loss: [1m[32m0.55572[0m[0m | time: 127.768s
[2K| Adam | epoch: 016 | loss: 0.55572 - acc: 0.7968 -- iter: 06912/10000
[A[ATraining Step: 2464  | total loss: [1m[32m0.55561[0m[0m | time: 128.846s
[2K| Adam | epoch: 016 | loss: 0.55561 - acc: 0.7937 -- iter: 06976/10000
[A[ATraining Step: 2465  | total loss: [1m[32m0.56429[0m[0m | time: 129.949s
[2K| Adam | epoch: 016 | loss: 0.56429 - acc: 0.7893 -- iter: 07040/10000
[A[ATraining Step: 2466  | total loss: [1m[32m0.57143[0m[0m | time: 131.042s
[2K| Adam | epoch: 016 | loss: 0.57143 - acc: 0.7776 -- iter: 07104/10000
[A[ATraining Step: 2467  | total loss: [1m[32m0.56681[0m[0m | time: 132.100s
[2K| Adam | epoch: 016 | loss: 0.56681 - acc: 0.7795 -- iter: 07168/10000
[A[ATraining Step: 2468  | total loss: [1m[32m0.55967[0m[0m | time: 133.193s
[2K| Adam | epoch: 016 | loss: 0.55967 - acc: 0.7859 -- iter: 07232/10000
[A[ATraining Step: 2469  | total loss: [1m[32m0.56528[0m[0m | time: 134.276s
[2K| Adam | epoch: 016 | loss: 0.56528 - acc: 0.7839 -- iter: 07296/10000
[A[ATraining Step: 2470  | total loss: [1m[32m0.55857[0m[0m | time: 135.365s
[2K| Adam | epoch: 016 | loss: 0.55857 - acc: 0.7821 -- iter: 07360/10000
[A[ATraining Step: 2471  | total loss: [1m[32m0.55502[0m[0m | time: 136.456s
[2K| Adam | epoch: 016 | loss: 0.55502 - acc: 0.7929 -- iter: 07424/10000
[A[ATraining Step: 2472  | total loss: [1m[32m0.55510[0m[0m | time: 137.536s
[2K| Adam | epoch: 016 | loss: 0.55510 - acc: 0.7996 -- iter: 07488/10000
[A[ATraining Step: 2473  | total loss: [1m[32m0.53579[0m[0m | time: 138.612s
[2K| Adam | epoch: 016 | loss: 0.53579 - acc: 0.8087 -- iter: 07552/10000
[A[ATraining Step: 2474  | total loss: [1m[32m0.53258[0m[0m | time: 139.682s
[2K| Adam | epoch: 016 | loss: 0.53258 - acc: 0.8075 -- iter: 07616/10000
[A[ATraining Step: 2475  | total loss: [1m[32m0.53572[0m[0m | time: 140.781s
[2K| Adam | epoch: 016 | loss: 0.53572 - acc: 0.8049 -- iter: 07680/10000
[A[ATraining Step: 2476  | total loss: [1m[32m0.54042[0m[0m | time: 141.858s
[2K| Adam | epoch: 016 | loss: 0.54042 - acc: 0.7978 -- iter: 07744/10000
[A[ATraining Step: 2477  | total loss: [1m[32m0.54548[0m[0m | time: 142.877s
[2K| Adam | epoch: 016 | loss: 0.54548 - acc: 0.7962 -- iter: 07808/10000
[A[ATraining Step: 2478  | total loss: [1m[32m0.56312[0m[0m | time: 143.984s
[2K| Adam | epoch: 016 | loss: 0.56312 - acc: 0.7931 -- iter: 07872/10000
[A[ATraining Step: 2479  | total loss: [1m[32m0.57188[0m[0m | time: 145.059s
[2K| Adam | epoch: 016 | loss: 0.57188 - acc: 0.7857 -- iter: 07936/10000
[A[ATraining Step: 2480  | total loss: [1m[32m0.57899[0m[0m | time: 146.169s
[2K| Adam | epoch: 016 | loss: 0.57899 - acc: 0.7805 -- iter: 08000/10000
[A[ATraining Step: 2481  | total loss: [1m[32m0.57978[0m[0m | time: 147.308s
[2K| Adam | epoch: 016 | loss: 0.57978 - acc: 0.7791 -- iter: 08064/10000
[A[ATraining Step: 2482  | total loss: [1m[32m0.56262[0m[0m | time: 148.391s
[2K| Adam | epoch: 016 | loss: 0.56262 - acc: 0.7855 -- iter: 08128/10000
[A[ATraining Step: 2483  | total loss: [1m[32m0.55227[0m[0m | time: 149.489s
[2K| Adam | epoch: 016 | loss: 0.55227 - acc: 0.7898 -- iter: 08192/10000
[A[ATraining Step: 2484  | total loss: [1m[32m0.54610[0m[0m | time: 150.590s
[2K| Adam | epoch: 016 | loss: 0.54610 - acc: 0.7999 -- iter: 08256/10000
[A[ATraining Step: 2485  | total loss: [1m[32m0.55544[0m[0m | time: 151.668s
[2K| Adam | epoch: 016 | loss: 0.55544 - acc: 0.7949 -- iter: 08320/10000
[A[ATraining Step: 2486  | total loss: [1m[32m0.55116[0m[0m | time: 152.779s
[2K| Adam | epoch: 016 | loss: 0.55116 - acc: 0.7920 -- iter: 08384/10000
[A[ATraining Step: 2487  | total loss: [1m[32m0.54674[0m[0m | time: 153.868s
[2K| Adam | epoch: 016 | loss: 0.54674 - acc: 0.7893 -- iter: 08448/10000
[A[ATraining Step: 2488  | total loss: [1m[32m0.57619[0m[0m | time: 154.970s
[2K| Adam | epoch: 016 | loss: 0.57619 - acc: 0.7776 -- iter: 08512/10000
[A[ATraining Step: 2489  | total loss: [1m[32m0.56612[0m[0m | time: 156.102s
[2K| Adam | epoch: 016 | loss: 0.56612 - acc: 0.7826 -- iter: 08576/10000
[A[ATraining Step: 2490  | total loss: [1m[32m0.58297[0m[0m | time: 157.206s
[2K| Adam | epoch: 016 | loss: 0.58297 - acc: 0.7794 -- iter: 08640/10000
[A[ATraining Step: 2491  | total loss: [1m[32m0.58018[0m[0m | time: 158.391s
[2K| Adam | epoch: 016 | loss: 0.58018 - acc: 0.7717 -- iter: 08704/10000
[A[ATraining Step: 2492  | total loss: [1m[32m0.58462[0m[0m | time: 159.586s
[2K| Adam | epoch: 016 | loss: 0.58462 - acc: 0.7680 -- iter: 08768/10000
[A[ATraining Step: 2493  | total loss: [1m[32m0.60348[0m[0m | time: 160.775s
[2K| Adam | epoch: 016 | loss: 0.60348 - acc: 0.7662 -- iter: 08832/10000
[A[ATraining Step: 2494  | total loss: [1m[32m0.58147[0m[0m | time: 161.978s
[2K| Adam | epoch: 016 | loss: 0.58147 - acc: 0.7693 -- iter: 08896/10000
[A[ATraining Step: 2495  | total loss: [1m[32m0.57041[0m[0m | time: 163.091s
[2K| Adam | epoch: 016 | loss: 0.57041 - acc: 0.7736 -- iter: 08960/10000
[A[ATraining Step: 2496  | total loss: [1m[32m1.54535[0m[0m | time: 164.127s
[2K| Adam | epoch: 016 | loss: 1.54535 - acc: 0.7072 -- iter: 09024/10000
[A[ATraining Step: 2497  | total loss: [1m[32m1.44674[0m[0m | time: 165.160s
[2K| Adam | epoch: 016 | loss: 1.44674 - acc: 0.7146 -- iter: 09088/10000
[A[ATraining Step: 2498  | total loss: [1m[32m1.37010[0m[0m | time: 166.259s
[2K| Adam | epoch: 016 | loss: 1.37010 - acc: 0.7197 -- iter: 09152/10000
[A[ATraining Step: 2499  | total loss: [1m[32m1.30744[0m[0m | time: 167.288s
[2K| Adam | epoch: 016 | loss: 1.30744 - acc: 0.7258 -- iter: 09216/10000
[A[ATraining Step: 2500  | total loss: [1m[32m1.24368[0m[0m | time: 171.165s
[2K| Adam | epoch: 016 | loss: 1.24368 - acc: 0.7329 | val_loss: 2.34489 - val_acc: 0.3857 -- iter: 09280/10000
--
Training Step: 2501  | total loss: [1m[32m1.18133[0m[0m | time: 172.210s
[2K| Adam | epoch: 016 | loss: 1.18133 - acc: 0.7440 -- iter: 09344/10000
[A[ATraining Step: 2502  | total loss: [1m[32m1.12049[0m[0m | time: 173.393s
[2K| Adam | epoch: 016 | loss: 1.12049 - acc: 0.7509 -- iter: 09408/10000
[A[ATraining Step: 2503  | total loss: [1m[32m1.05744[0m[0m | time: 174.552s
[2K| Adam | epoch: 016 | loss: 1.05744 - acc: 0.7633 -- iter: 09472/10000
[A[ATraining Step: 2504  | total loss: [1m[32m1.01986[0m[0m | time: 175.796s
[2K| Adam | epoch: 016 | loss: 1.01986 - acc: 0.7620 -- iter: 09536/10000
[A[ATraining Step: 2505  | total loss: [1m[32m0.96631[0m[0m | time: 177.004s
[2K| Adam | epoch: 016 | loss: 0.96631 - acc: 0.7733 -- iter: 09600/10000
[A[ATraining Step: 2506  | total loss: [1m[32m0.92449[0m[0m | time: 178.189s
[2K| Adam | epoch: 016 | loss: 0.92449 - acc: 0.7741 -- iter: 09664/10000
[A[ATraining Step: 2507  | total loss: [1m[32m0.89083[0m[0m | time: 179.332s
[2K| Adam | epoch: 016 | loss: 0.89083 - acc: 0.7654 -- iter: 09728/10000
[A[ATraining Step: 2508  | total loss: [1m[32m0.84624[0m[0m | time: 180.501s
[2K| Adam | epoch: 016 | loss: 0.84624 - acc: 0.7717 -- iter: 09792/10000
[A[ATraining Step: 2509  | total loss: [1m[32m0.83660[0m[0m | time: 181.675s
[2K| Adam | epoch: 016 | loss: 0.83660 - acc: 0.7648 -- iter: 09856/10000
[A[ATraining Step: 2510  | total loss: [1m[32m0.83985[0m[0m | time: 182.881s
[2K| Adam | epoch: 016 | loss: 0.83985 - acc: 0.7618 -- iter: 09920/10000
[A[ATraining Step: 2511  | total loss: [1m[32m0.82061[0m[0m | time: 183.954s
[2K| Adam | epoch: 016 | loss: 0.82061 - acc: 0.7606 -- iter: 09984/10000
[A[ATraining Step: 2512  | total loss: [1m[32m0.81985[0m[0m | time: 187.800s
[2K| Adam | epoch: 016 | loss: 0.81985 - acc: 0.7611 | val_loss: 2.78310 - val_acc: 0.3300 -- iter: 10000/10000
--
Training Step: 2513  | total loss: [1m[32m0.78310[0m[0m | time: 1.027s
[2K| Adam | epoch: 017 | loss: 0.78310 - acc: 0.7616 -- iter: 00064/10000
[A[ATraining Step: 2514  | total loss: [1m[32m0.74444[0m[0m | time: 2.104s
[2K| Adam | epoch: 017 | loss: 0.74444 - acc: 0.7682 -- iter: 00128/10000
[A[ATraining Step: 2515  | total loss: [1m[32m0.73725[0m[0m | time: 3.211s
[2K| Adam | epoch: 017 | loss: 0.73725 - acc: 0.7711 -- iter: 00192/10000
[A[ATraining Step: 2516  | total loss: [1m[32m0.72274[0m[0m | time: 4.302s
[2K| Adam | epoch: 017 | loss: 0.72274 - acc: 0.7768 -- iter: 00256/10000
[A[ATraining Step: 2517  | total loss: [1m[32m0.68454[0m[0m | time: 5.387s
[2K| Adam | epoch: 017 | loss: 0.68454 - acc: 0.7882 -- iter: 00320/10000
[A[ATraining Step: 2518  | total loss: [1m[32m0.67927[0m[0m | time: 6.464s
[2K| Adam | epoch: 017 | loss: 0.67927 - acc: 0.7890 -- iter: 00384/10000
[A[ATraining Step: 2519  | total loss: [1m[32m0.67145[0m[0m | time: 7.575s
[2K| Adam | epoch: 017 | loss: 0.67145 - acc: 0.7883 -- iter: 00448/10000
[A[ATraining Step: 2520  | total loss: [1m[32m0.63979[0m[0m | time: 8.679s
[2K| Adam | epoch: 017 | loss: 0.63979 - acc: 0.8001 -- iter: 00512/10000
[A[ATraining Step: 2521  | total loss: [1m[32m0.62584[0m[0m | time: 9.795s
[2K| Adam | epoch: 017 | loss: 0.62584 - acc: 0.8029 -- iter: 00576/10000
[A[ATraining Step: 2522  | total loss: [1m[32m0.62589[0m[0m | time: 10.855s
[2K| Adam | epoch: 017 | loss: 0.62589 - acc: 0.7960 -- iter: 00640/10000
[A[ATraining Step: 2523  | total loss: [1m[32m0.62272[0m[0m | time: 11.934s
[2K| Adam | epoch: 017 | loss: 0.62272 - acc: 0.7977 -- iter: 00704/10000
[A[ATraining Step: 2524  | total loss: [1m[32m0.62712[0m[0m | time: 13.019s
[2K| Adam | epoch: 017 | loss: 0.62712 - acc: 0.7945 -- iter: 00768/10000
[A[ATraining Step: 2525  | total loss: [1m[32m0.63232[0m[0m | time: 14.083s
[2K| Adam | epoch: 017 | loss: 0.63232 - acc: 0.7838 -- iter: 00832/10000
[A[ATraining Step: 2526  | total loss: [1m[32m0.61290[0m[0m | time: 15.170s
[2K| Adam | epoch: 017 | loss: 0.61290 - acc: 0.7820 -- iter: 00896/10000
[A[ATraining Step: 2527  | total loss: [1m[32m0.61256[0m[0m | time: 15.694s
[2K| Adam | epoch: 017 | loss: 0.61256 - acc: 0.7772 -- iter: 00960/10000
[A[ATraining Step: 2528  | total loss: [1m[32m0.59564[0m[0m | time: 16.209s
[2K| Adam | epoch: 017 | loss: 0.59564 - acc: 0.7932 -- iter: 01024/10000
[A[ATraining Step: 2529  | total loss: [1m[32m0.56807[0m[0m | time: 17.284s
[2K| Adam | epoch: 017 | loss: 0.56807 - acc: 0.8014 -- iter: 01088/10000
[A[ATraining Step: 2530  | total loss: [1m[32m0.55530[0m[0m | time: 18.407s
[2K| Adam | epoch: 017 | loss: 0.55530 - acc: 0.8041 -- iter: 01152/10000
[A[ATraining Step: 2531  | total loss: [1m[32m0.54685[0m[0m | time: 19.550s
[2K| Adam | epoch: 017 | loss: 0.54685 - acc: 0.8018 -- iter: 01216/10000
[A[ATraining Step: 2532  | total loss: [1m[32m0.53225[0m[0m | time: 20.825s
[2K| Adam | epoch: 017 | loss: 0.53225 - acc: 0.8044 -- iter: 01280/10000
[A[ATraining Step: 2533  | total loss: [1m[32m0.54772[0m[0m | time: 22.051s
[2K| Adam | epoch: 017 | loss: 0.54772 - acc: 0.7974 -- iter: 01344/10000
[A[ATraining Step: 2534  | total loss: [1m[32m0.53285[0m[0m | time: 23.282s
[2K| Adam | epoch: 017 | loss: 0.53285 - acc: 0.8021 -- iter: 01408/10000
[A[ATraining Step: 2535  | total loss: [1m[32m0.54172[0m[0m | time: 24.336s
[2K| Adam | epoch: 017 | loss: 0.54172 - acc: 0.7984 -- iter: 01472/10000
[A[ATraining Step: 2536  | total loss: [1m[32m0.54805[0m[0m | time: 25.337s
[2K| Adam | epoch: 017 | loss: 0.54805 - acc: 0.7998 -- iter: 01536/10000
[A[ATraining Step: 2537  | total loss: [1m[32m0.54937[0m[0m | time: 26.355s
[2K| Adam | epoch: 017 | loss: 0.54937 - acc: 0.7980 -- iter: 01600/10000
[A[ATraining Step: 2538  | total loss: [1m[32m0.55245[0m[0m | time: 27.355s
[2K| Adam | epoch: 017 | loss: 0.55245 - acc: 0.8010 -- iter: 01664/10000
[A[ATraining Step: 2539  | total loss: [1m[32m0.55514[0m[0m | time: 28.505s
[2K| Adam | epoch: 017 | loss: 0.55514 - acc: 0.8037 -- iter: 01728/10000
[A[ATraining Step: 2540  | total loss: [1m[32m0.54446[0m[0m | time: 29.529s
[2K| Adam | epoch: 017 | loss: 0.54446 - acc: 0.8061 -- iter: 01792/10000
[A[ATraining Step: 2541  | total loss: [1m[32m0.52755[0m[0m | time: 30.543s
[2K| Adam | epoch: 017 | loss: 0.52755 - acc: 0.8146 -- iter: 01856/10000
[A[ATraining Step: 2542  | total loss: [1m[32m0.52018[0m[0m | time: 31.640s
[2K| Adam | epoch: 017 | loss: 0.52018 - acc: 0.8128 -- iter: 01920/10000
[A[ATraining Step: 2543  | total loss: [1m[32m0.51627[0m[0m | time: 32.716s
[2K| Adam | epoch: 017 | loss: 0.51627 - acc: 0.8143 -- iter: 01984/10000
[A[ATraining Step: 2544  | total loss: [1m[32m0.53583[0m[0m | time: 33.788s
[2K| Adam | epoch: 017 | loss: 0.53583 - acc: 0.8157 -- iter: 02048/10000
[A[ATraining Step: 2545  | total loss: [1m[32m0.54426[0m[0m | time: 34.873s
[2K| Adam | epoch: 017 | loss: 0.54426 - acc: 0.8138 -- iter: 02112/10000
[A[ATraining Step: 2546  | total loss: [1m[32m0.53359[0m[0m | time: 36.055s
[2K| Adam | epoch: 017 | loss: 0.53359 - acc: 0.8121 -- iter: 02176/10000
[A[ATraining Step: 2547  | total loss: [1m[32m0.53202[0m[0m | time: 37.083s
[2K| Adam | epoch: 017 | loss: 0.53202 - acc: 0.8106 -- iter: 02240/10000
[A[ATraining Step: 2548  | total loss: [1m[32m0.52294[0m[0m | time: 38.165s
[2K| Adam | epoch: 017 | loss: 0.52294 - acc: 0.8171 -- iter: 02304/10000
[A[ATraining Step: 2549  | total loss: [1m[32m0.53275[0m[0m | time: 39.263s
[2K| Adam | epoch: 017 | loss: 0.53275 - acc: 0.8088 -- iter: 02368/10000
[A[ATraining Step: 2550  | total loss: [1m[32m0.52933[0m[0m | time: 40.349s
[2K| Adam | epoch: 017 | loss: 0.52933 - acc: 0.8154 -- iter: 02432/10000
[A[ATraining Step: 2551  | total loss: [1m[32m0.52502[0m[0m | time: 41.437s
[2K| Adam | epoch: 017 | loss: 0.52502 - acc: 0.8120 -- iter: 02496/10000
[A[ATraining Step: 2552  | total loss: [1m[32m0.52238[0m[0m | time: 42.572s
[2K| Adam | epoch: 017 | loss: 0.52238 - acc: 0.8152 -- iter: 02560/10000
[A[ATraining Step: 2553  | total loss: [1m[32m0.51880[0m[0m | time: 43.719s
[2K| Adam | epoch: 017 | loss: 0.51880 - acc: 0.8149 -- iter: 02624/10000
[A[ATraining Step: 2554  | total loss: [1m[32m0.53237[0m[0m | time: 44.860s
[2K| Adam | epoch: 017 | loss: 0.53237 - acc: 0.8162 -- iter: 02688/10000
[A[ATraining Step: 2555  | total loss: [1m[32m0.51141[0m[0m | time: 46.010s
[2K| Adam | epoch: 017 | loss: 0.51141 - acc: 0.8284 -- iter: 02752/10000
[A[ATraining Step: 2556  | total loss: [1m[32m0.53755[0m[0m | time: 47.159s
[2K| Adam | epoch: 017 | loss: 0.53755 - acc: 0.8299 -- iter: 02816/10000
[A[ATraining Step: 2557  | total loss: [1m[32m0.53924[0m[0m | time: 48.315s
[2K| Adam | epoch: 017 | loss: 0.53924 - acc: 0.8282 -- iter: 02880/10000
[A[ATraining Step: 2558  | total loss: [1m[32m0.55189[0m[0m | time: 49.457s
[2K| Adam | epoch: 017 | loss: 0.55189 - acc: 0.8250 -- iter: 02944/10000
[A[ATraining Step: 2559  | total loss: [1m[32m0.55892[0m[0m | time: 50.561s
[2K| Adam | epoch: 017 | loss: 0.55892 - acc: 0.8222 -- iter: 03008/10000
[A[ATraining Step: 2560  | total loss: [1m[32m0.58232[0m[0m | time: 51.662s
[2K| Adam | epoch: 017 | loss: 0.58232 - acc: 0.8119 -- iter: 03072/10000
[A[ATraining Step: 2561  | total loss: [1m[32m0.57637[0m[0m | time: 52.719s
[2K| Adam | epoch: 017 | loss: 0.57637 - acc: 0.8072 -- iter: 03136/10000
[A[ATraining Step: 2562  | total loss: [1m[32m0.57527[0m[0m | time: 53.791s
[2K| Adam | epoch: 017 | loss: 0.57527 - acc: 0.7984 -- iter: 03200/10000
[A[ATraining Step: 2563  | total loss: [1m[32m0.57548[0m[0m | time: 54.832s
[2K| Adam | epoch: 017 | loss: 0.57548 - acc: 0.7904 -- iter: 03264/10000
[A[ATraining Step: 2564  | total loss: [1m[32m0.60098[0m[0m | time: 55.938s
[2K| Adam | epoch: 017 | loss: 0.60098 - acc: 0.7770 -- iter: 03328/10000
[A[ATraining Step: 2565  | total loss: [1m[32m0.59241[0m[0m | time: 57.017s
[2K| Adam | epoch: 017 | loss: 0.59241 - acc: 0.7852 -- iter: 03392/10000
[A[ATraining Step: 2566  | total loss: [1m[32m0.58759[0m[0m | time: 58.092s
[2K| Adam | epoch: 017 | loss: 0.58759 - acc: 0.7848 -- iter: 03456/10000
[A[ATraining Step: 2567  | total loss: [1m[32m0.57300[0m[0m | time: 59.224s
[2K| Adam | epoch: 017 | loss: 0.57300 - acc: 0.7923 -- iter: 03520/10000
[A[ATraining Step: 2568  | total loss: [1m[32m0.59415[0m[0m | time: 60.355s
[2K| Adam | epoch: 017 | loss: 0.59415 - acc: 0.7818 -- iter: 03584/10000
[A[ATraining Step: 2569  | total loss: [1m[32m0.57840[0m[0m | time: 61.481s
[2K| Adam | epoch: 017 | loss: 0.57840 - acc: 0.7880 -- iter: 03648/10000
[A[ATraining Step: 2570  | total loss: [1m[32m0.57839[0m[0m | time: 62.583s
[2K| Adam | epoch: 017 | loss: 0.57839 - acc: 0.7889 -- iter: 03712/10000
[A[ATraining Step: 2571  | total loss: [1m[32m0.56606[0m[0m | time: 63.719s
[2K| Adam | epoch: 017 | loss: 0.56606 - acc: 0.7959 -- iter: 03776/10000
[A[ATraining Step: 2572  | total loss: [1m[32m0.54483[0m[0m | time: 64.939s
[2K| Adam | epoch: 017 | loss: 0.54483 - acc: 0.8039 -- iter: 03840/10000
[A[ATraining Step: 2573  | total loss: [1m[32m0.55847[0m[0m | time: 66.109s
[2K| Adam | epoch: 017 | loss: 0.55847 - acc: 0.8032 -- iter: 03904/10000
[A[ATraining Step: 2574  | total loss: [1m[32m0.55437[0m[0m | time: 67.283s
[2K| Adam | epoch: 017 | loss: 0.55437 - acc: 0.8025 -- iter: 03968/10000
[A[ATraining Step: 2575  | total loss: [1m[32m0.55637[0m[0m | time: 68.408s
[2K| Adam | epoch: 017 | loss: 0.55637 - acc: 0.8035 -- iter: 04032/10000
[A[ATraining Step: 2576  | total loss: [1m[32m0.56755[0m[0m | time: 69.500s
[2K| Adam | epoch: 017 | loss: 0.56755 - acc: 0.7997 -- iter: 04096/10000
[A[ATraining Step: 2577  | total loss: [1m[32m0.56675[0m[0m | time: 70.575s
[2K| Adam | epoch: 017 | loss: 0.56675 - acc: 0.7948 -- iter: 04160/10000
[A[ATraining Step: 2578  | total loss: [1m[32m0.57730[0m[0m | time: 71.633s
[2K| Adam | epoch: 017 | loss: 0.57730 - acc: 0.7856 -- iter: 04224/10000
[A[ATraining Step: 2579  | total loss: [1m[32m0.60016[0m[0m | time: 72.782s
[2K| Adam | epoch: 017 | loss: 0.60016 - acc: 0.7789 -- iter: 04288/10000
[A[ATraining Step: 2580  | total loss: [1m[32m0.58942[0m[0m | time: 74.062s
[2K| Adam | epoch: 017 | loss: 0.58942 - acc: 0.7807 -- iter: 04352/10000
[A[ATraining Step: 2581  | total loss: [1m[32m0.61418[0m[0m | time: 75.325s
[2K| Adam | epoch: 017 | loss: 0.61418 - acc: 0.7714 -- iter: 04416/10000
[A[ATraining Step: 2582  | total loss: [1m[32m0.62207[0m[0m | time: 76.491s
[2K| Adam | epoch: 017 | loss: 0.62207 - acc: 0.7614 -- iter: 04480/10000
[A[ATraining Step: 2583  | total loss: [1m[32m0.63004[0m[0m | time: 77.669s
[2K| Adam | epoch: 017 | loss: 0.63004 - acc: 0.7619 -- iter: 04544/10000
[A[ATraining Step: 2584  | total loss: [1m[32m0.61176[0m[0m | time: 78.888s
[2K| Adam | epoch: 017 | loss: 0.61176 - acc: 0.7716 -- iter: 04608/10000
[A[ATraining Step: 2585  | total loss: [1m[32m0.62055[0m[0m | time: 80.274s
[2K| Adam | epoch: 017 | loss: 0.62055 - acc: 0.7726 -- iter: 04672/10000
[A[ATraining Step: 2586  | total loss: [1m[32m0.61400[0m[0m | time: 81.347s
[2K| Adam | epoch: 017 | loss: 0.61400 - acc: 0.7734 -- iter: 04736/10000
[A[ATraining Step: 2587  | total loss: [1m[32m0.59998[0m[0m | time: 82.411s
[2K| Adam | epoch: 017 | loss: 0.59998 - acc: 0.7773 -- iter: 04800/10000
[A[ATraining Step: 2588  | total loss: [1m[32m0.59831[0m[0m | time: 83.446s
[2K| Adam | epoch: 017 | loss: 0.59831 - acc: 0.7746 -- iter: 04864/10000
[A[ATraining Step: 2589  | total loss: [1m[32m0.59322[0m[0m | time: 84.470s
[2K| Adam | epoch: 017 | loss: 0.59322 - acc: 0.7737 -- iter: 04928/10000
[A[ATraining Step: 2590  | total loss: [1m[32m0.60304[0m[0m | time: 85.496s
[2K| Adam | epoch: 017 | loss: 0.60304 - acc: 0.7729 -- iter: 04992/10000
[A[ATraining Step: 2591  | total loss: [1m[32m0.59289[0m[0m | time: 86.584s
[2K| Adam | epoch: 017 | loss: 0.59289 - acc: 0.7722 -- iter: 05056/10000
[A[ATraining Step: 2592  | total loss: [1m[32m0.57583[0m[0m | time: 87.663s
[2K| Adam | epoch: 017 | loss: 0.57583 - acc: 0.7825 -- iter: 05120/10000
[A[ATraining Step: 2593  | total loss: [1m[32m0.57688[0m[0m | time: 88.801s
[2K| Adam | epoch: 017 | loss: 0.57688 - acc: 0.7792 -- iter: 05184/10000
[A[ATraining Step: 2594  | total loss: [1m[32m0.59049[0m[0m | time: 89.867s
[2K| Adam | epoch: 017 | loss: 0.59049 - acc: 0.7794 -- iter: 05248/10000
[A[ATraining Step: 2595  | total loss: [1m[32m0.57891[0m[0m | time: 90.933s
[2K| Adam | epoch: 017 | loss: 0.57891 - acc: 0.7812 -- iter: 05312/10000
[A[ATraining Step: 2596  | total loss: [1m[32m0.56515[0m[0m | time: 92.148s
[2K| Adam | epoch: 017 | loss: 0.56515 - acc: 0.7827 -- iter: 05376/10000
[A[ATraining Step: 2597  | total loss: [1m[32m0.56174[0m[0m | time: 93.370s
[2K| Adam | epoch: 017 | loss: 0.56174 - acc: 0.7873 -- iter: 05440/10000
[A[ATraining Step: 2598  | total loss: [1m[32m0.56030[0m[0m | time: 94.598s
[2K| Adam | epoch: 017 | loss: 0.56030 - acc: 0.7867 -- iter: 05504/10000
[A[ATraining Step: 2599  | total loss: [1m[32m0.55621[0m[0m | time: 95.725s
[2K| Adam | epoch: 017 | loss: 0.55621 - acc: 0.7908 -- iter: 05568/10000
[A[ATraining Step: 2600  | total loss: [1m[32m0.55266[0m[0m | time: 99.584s
[2K| Adam | epoch: 017 | loss: 0.55266 - acc: 0.7992 | val_loss: 2.47529 - val_acc: 0.4129 -- iter: 05632/10000
--
Training Step: 2601  | total loss: [1m[32m0.56609[0m[0m | time: 100.631s
[2K| Adam | epoch: 017 | loss: 0.56609 - acc: 0.7990 -- iter: 05696/10000
[A[ATraining Step: 2602  | total loss: [1m[32m0.57563[0m[0m | time: 101.717s
[2K| Adam | epoch: 017 | loss: 0.57563 - acc: 0.7957 -- iter: 05760/10000
[A[ATraining Step: 2603  | total loss: [1m[32m0.57480[0m[0m | time: 102.786s
[2K| Adam | epoch: 017 | loss: 0.57480 - acc: 0.7973 -- iter: 05824/10000
[A[ATraining Step: 2604  | total loss: [1m[32m0.59455[0m[0m | time: 103.880s
[2K| Adam | epoch: 017 | loss: 0.59455 - acc: 0.7864 -- iter: 05888/10000
[A[ATraining Step: 2605  | total loss: [1m[32m0.58289[0m[0m | time: 104.946s
[2K| Adam | epoch: 017 | loss: 0.58289 - acc: 0.7858 -- iter: 05952/10000
[A[ATraining Step: 2606  | total loss: [1m[32m0.56690[0m[0m | time: 106.040s
[2K| Adam | epoch: 017 | loss: 0.56690 - acc: 0.7901 -- iter: 06016/10000
[A[ATraining Step: 2607  | total loss: [1m[32m0.56792[0m[0m | time: 107.142s
[2K| Adam | epoch: 017 | loss: 0.56792 - acc: 0.7876 -- iter: 06080/10000
[A[ATraining Step: 2608  | total loss: [1m[32m0.57325[0m[0m | time: 108.333s
[2K| Adam | epoch: 017 | loss: 0.57325 - acc: 0.7823 -- iter: 06144/10000
[A[ATraining Step: 2609  | total loss: [1m[32m0.58452[0m[0m | time: 109.551s
[2K| Adam | epoch: 017 | loss: 0.58452 - acc: 0.7806 -- iter: 06208/10000
[A[ATraining Step: 2610  | total loss: [1m[32m0.59305[0m[0m | time: 110.728s
[2K| Adam | epoch: 017 | loss: 0.59305 - acc: 0.7791 -- iter: 06272/10000
[A[ATraining Step: 2611  | total loss: [1m[32m0.60791[0m[0m | time: 111.847s
[2K| Adam | epoch: 017 | loss: 0.60791 - acc: 0.7778 -- iter: 06336/10000
[A[ATraining Step: 2612  | total loss: [1m[32m0.60321[0m[0m | time: 112.872s
[2K| Adam | epoch: 017 | loss: 0.60321 - acc: 0.7813 -- iter: 06400/10000
[A[ATraining Step: 2613  | total loss: [1m[32m0.59569[0m[0m | time: 113.834s
[2K| Adam | epoch: 017 | loss: 0.59569 - acc: 0.7828 -- iter: 06464/10000
[A[ATraining Step: 2614  | total loss: [1m[32m0.57458[0m[0m | time: 114.830s
[2K| Adam | epoch: 017 | loss: 0.57458 - acc: 0.7905 -- iter: 06528/10000
[A[ATraining Step: 2615  | total loss: [1m[32m0.56359[0m[0m | time: 115.805s
[2K| Adam | epoch: 017 | loss: 0.56359 - acc: 0.7974 -- iter: 06592/10000
[A[ATraining Step: 2616  | total loss: [1m[32m0.56328[0m[0m | time: 116.799s
[2K| Adam | epoch: 017 | loss: 0.56328 - acc: 0.7926 -- iter: 06656/10000
[A[ATraining Step: 2617  | total loss: [1m[32m0.57702[0m[0m | time: 117.781s
[2K| Adam | epoch: 017 | loss: 0.57702 - acc: 0.7946 -- iter: 06720/10000
[A[ATraining Step: 2618  | total loss: [1m[32m0.57015[0m[0m | time: 118.782s
[2K| Adam | epoch: 017 | loss: 0.57015 - acc: 0.7980 -- iter: 06784/10000
[A[ATraining Step: 2619  | total loss: [1m[32m0.55895[0m[0m | time: 119.749s
[2K| Adam | epoch: 017 | loss: 0.55895 - acc: 0.8025 -- iter: 06848/10000
[A[ATraining Step: 2620  | total loss: [1m[32m0.56206[0m[0m | time: 120.736s
[2K| Adam | epoch: 017 | loss: 0.56206 - acc: 0.8004 -- iter: 06912/10000
[A[ATraining Step: 2621  | total loss: [1m[32m0.55087[0m[0m | time: 121.764s
[2K| Adam | epoch: 017 | loss: 0.55087 - acc: 0.8016 -- iter: 06976/10000
[A[ATraining Step: 2622  | total loss: [1m[32m0.55863[0m[0m | time: 122.897s
[2K| Adam | epoch: 017 | loss: 0.55863 - acc: 0.7996 -- iter: 07040/10000
[A[ATraining Step: 2623  | total loss: [1m[32m0.55236[0m[0m | time: 123.978s
[2K| Adam | epoch: 017 | loss: 0.55236 - acc: 0.8009 -- iter: 07104/10000
[A[ATraining Step: 2624  | total loss: [1m[32m0.55762[0m[0m | time: 125.164s
[2K| Adam | epoch: 017 | loss: 0.55762 - acc: 0.7942 -- iter: 07168/10000
[A[ATraining Step: 2625  | total loss: [1m[32m0.56486[0m[0m | time: 126.337s
[2K| Adam | epoch: 017 | loss: 0.56486 - acc: 0.7898 -- iter: 07232/10000
[A[ATraining Step: 2626  | total loss: [1m[32m0.55757[0m[0m | time: 127.525s
[2K| Adam | epoch: 017 | loss: 0.55757 - acc: 0.7889 -- iter: 07296/10000
[A[ATraining Step: 2627  | total loss: [1m[32m0.58223[0m[0m | time: 128.654s
[2K| Adam | epoch: 017 | loss: 0.58223 - acc: 0.7866 -- iter: 07360/10000
[A[ATraining Step: 2628  | total loss: [1m[32m0.57579[0m[0m | time: 129.688s
[2K| Adam | epoch: 017 | loss: 0.57579 - acc: 0.7939 -- iter: 07424/10000
[A[ATraining Step: 2629  | total loss: [1m[32m0.58836[0m[0m | time: 130.721s
[2K| Adam | epoch: 017 | loss: 0.58836 - acc: 0.7926 -- iter: 07488/10000
[A[ATraining Step: 2630  | total loss: [1m[32m0.58709[0m[0m | time: 131.739s
[2K| Adam | epoch: 017 | loss: 0.58709 - acc: 0.7915 -- iter: 07552/10000
[A[ATraining Step: 2631  | total loss: [1m[32m0.58186[0m[0m | time: 132.751s
[2K| Adam | epoch: 017 | loss: 0.58186 - acc: 0.7920 -- iter: 07616/10000
[A[ATraining Step: 2632  | total loss: [1m[32m0.55781[0m[0m | time: 133.778s
[2K| Adam | epoch: 017 | loss: 0.55781 - acc: 0.7988 -- iter: 07680/10000
[A[ATraining Step: 2633  | total loss: [1m[32m0.54363[0m[0m | time: 134.840s
[2K| Adam | epoch: 017 | loss: 0.54363 - acc: 0.8001 -- iter: 07744/10000
[A[ATraining Step: 2634  | total loss: [1m[32m0.54311[0m[0m | time: 135.985s
[2K| Adam | epoch: 017 | loss: 0.54311 - acc: 0.7982 -- iter: 07808/10000
[A[ATraining Step: 2635  | total loss: [1m[32m0.55133[0m[0m | time: 137.131s
[2K| Adam | epoch: 017 | loss: 0.55133 - acc: 0.7950 -- iter: 07872/10000
[A[ATraining Step: 2636  | total loss: [1m[32m0.56354[0m[0m | time: 138.344s
[2K| Adam | epoch: 017 | loss: 0.56354 - acc: 0.7983 -- iter: 07936/10000
[A[ATraining Step: 2637  | total loss: [1m[32m0.58792[0m[0m | time: 139.496s
[2K| Adam | epoch: 017 | loss: 0.58792 - acc: 0.7888 -- iter: 08000/10000
[A[ATraining Step: 2638  | total loss: [1m[32m0.57965[0m[0m | time: 140.689s
[2K| Adam | epoch: 017 | loss: 0.57965 - acc: 0.7833 -- iter: 08064/10000
[A[ATraining Step: 2639  | total loss: [1m[32m0.57320[0m[0m | time: 141.935s
[2K| Adam | epoch: 017 | loss: 0.57320 - acc: 0.7878 -- iter: 08128/10000
[A[ATraining Step: 2640  | total loss: [1m[32m0.57144[0m[0m | time: 143.024s
[2K| Adam | epoch: 017 | loss: 0.57144 - acc: 0.7840 -- iter: 08192/10000
[A[ATraining Step: 2641  | total loss: [1m[32m0.57565[0m[0m | time: 144.030s
[2K| Adam | epoch: 017 | loss: 0.57565 - acc: 0.7853 -- iter: 08256/10000
[A[ATraining Step: 2642  | total loss: [1m[32m0.57988[0m[0m | time: 145.059s
[2K| Adam | epoch: 017 | loss: 0.57988 - acc: 0.7865 -- iter: 08320/10000
[A[ATraining Step: 2643  | total loss: [1m[32m0.55992[0m[0m | time: 146.081s
[2K| Adam | epoch: 017 | loss: 0.55992 - acc: 0.7953 -- iter: 08384/10000
[A[ATraining Step: 2644  | total loss: [1m[32m0.56522[0m[0m | time: 147.100s
[2K| Adam | epoch: 017 | loss: 0.56522 - acc: 0.7955 -- iter: 08448/10000
[A[ATraining Step: 2645  | total loss: [1m[32m0.56596[0m[0m | time: 148.130s
[2K| Adam | epoch: 017 | loss: 0.56596 - acc: 0.7987 -- iter: 08512/10000
[A[ATraining Step: 2646  | total loss: [1m[32m0.57078[0m[0m | time: 149.212s
[2K| Adam | epoch: 017 | loss: 0.57078 - acc: 0.7986 -- iter: 08576/10000
[A[ATraining Step: 2647  | total loss: [1m[32m0.59029[0m[0m | time: 150.285s
[2K| Adam | epoch: 017 | loss: 0.59029 - acc: 0.7953 -- iter: 08640/10000
[A[ATraining Step: 2648  | total loss: [1m[32m0.57376[0m[0m | time: 151.355s
[2K| Adam | epoch: 017 | loss: 0.57376 - acc: 0.8001 -- iter: 08704/10000
[A[ATraining Step: 2649  | total loss: [1m[32m0.60638[0m[0m | time: 152.402s
[2K| Adam | epoch: 017 | loss: 0.60638 - acc: 0.7873 -- iter: 08768/10000
[A[ATraining Step: 2650  | total loss: [1m[32m0.61267[0m[0m | time: 153.460s
[2K| Adam | epoch: 017 | loss: 0.61267 - acc: 0.7867 -- iter: 08832/10000
[A[ATraining Step: 2651  | total loss: [1m[32m0.61068[0m[0m | time: 154.597s
[2K| Adam | epoch: 017 | loss: 0.61068 - acc: 0.7861 -- iter: 08896/10000
[A[ATraining Step: 2652  | total loss: [1m[32m0.61074[0m[0m | time: 155.684s
[2K| Adam | epoch: 017 | loss: 0.61074 - acc: 0.7888 -- iter: 08960/10000
[A[ATraining Step: 2653  | total loss: [1m[32m0.61034[0m[0m | time: 156.748s
[2K| Adam | epoch: 017 | loss: 0.61034 - acc: 0.7818 -- iter: 09024/10000
[A[ATraining Step: 2654  | total loss: [1m[32m1.46182[0m[0m | time: 157.880s
[2K| Adam | epoch: 017 | loss: 1.46182 - acc: 0.7130 -- iter: 09088/10000
[A[ATraining Step: 2655  | total loss: [1m[32m1.37830[0m[0m | time: 159.111s
[2K| Adam | epoch: 017 | loss: 1.37830 - acc: 0.7229 -- iter: 09152/10000
[A[ATraining Step: 2656  | total loss: [1m[32m1.29006[0m[0m | time: 160.220s
[2K| Adam | epoch: 017 | loss: 1.29006 - acc: 0.7319 -- iter: 09216/10000
[A[ATraining Step: 2657  | total loss: [1m[32m1.21555[0m[0m | time: 161.442s
[2K| Adam | epoch: 017 | loss: 1.21555 - acc: 0.7353 -- iter: 09280/10000
[A[ATraining Step: 2658  | total loss: [1m[32m1.12523[0m[0m | time: 162.670s
[2K| Adam | epoch: 017 | loss: 1.12523 - acc: 0.7461 -- iter: 09344/10000
[A[ATraining Step: 2659  | total loss: [1m[32m1.05985[0m[0m | time: 163.796s
[2K| Adam | epoch: 017 | loss: 1.05985 - acc: 0.7496 -- iter: 09408/10000
[A[ATraining Step: 2660  | total loss: [1m[32m1.01569[0m[0m | time: 164.848s
[2K| Adam | epoch: 017 | loss: 1.01569 - acc: 0.7512 -- iter: 09472/10000
[A[ATraining Step: 2661  | total loss: [1m[32m0.96936[0m[0m | time: 165.877s
[2K| Adam | epoch: 017 | loss: 0.96936 - acc: 0.7558 -- iter: 09536/10000
[A[ATraining Step: 2662  | total loss: [1m[32m0.92182[0m[0m | time: 166.881s
[2K| Adam | epoch: 017 | loss: 0.92182 - acc: 0.7536 -- iter: 09600/10000
[A[ATraining Step: 2663  | total loss: [1m[32m0.87675[0m[0m | time: 167.901s
[2K| Adam | epoch: 017 | loss: 0.87675 - acc: 0.7564 -- iter: 09664/10000
[A[ATraining Step: 2664  | total loss: [1m[32m0.83670[0m[0m | time: 168.993s
[2K| Adam | epoch: 017 | loss: 0.83670 - acc: 0.7698 -- iter: 09728/10000
[A[ATraining Step: 2665  | total loss: [1m[32m0.81085[0m[0m | time: 169.976s
[2K| Adam | epoch: 017 | loss: 0.81085 - acc: 0.7725 -- iter: 09792/10000
[A[ATraining Step: 2666  | total loss: [1m[32m0.79669[0m[0m | time: 170.991s
[2K| Adam | epoch: 017 | loss: 0.79669 - acc: 0.7718 -- iter: 09856/10000
[A[ATraining Step: 2667  | total loss: [1m[32m0.77712[0m[0m | time: 172.015s
[2K| Adam | epoch: 017 | loss: 0.77712 - acc: 0.7759 -- iter: 09920/10000
[A[ATraining Step: 2668  | total loss: [1m[32m0.73910[0m[0m | time: 173.066s
[2K| Adam | epoch: 017 | loss: 0.73910 - acc: 0.7889 -- iter: 09984/10000
[A[ATraining Step: 2669  | total loss: [1m[32m0.73663[0m[0m | time: 177.077s
[2K| Adam | epoch: 017 | loss: 0.73663 - acc: 0.7850 | val_loss: 2.41306 - val_acc: 0.3686 -- iter: 10000/10000
--
Training Step: 2670  | total loss: [1m[32m0.71238[0m[0m | time: 1.103s
[2K| Adam | epoch: 018 | loss: 0.71238 - acc: 0.7925 -- iter: 00064/10000
[A[ATraining Step: 2671  | total loss: [1m[32m0.69597[0m[0m | time: 2.303s
[2K| Adam | epoch: 018 | loss: 0.69597 - acc: 0.7945 -- iter: 00128/10000
[A[ATraining Step: 2672  | total loss: [1m[32m0.68176[0m[0m | time: 3.539s
[2K| Adam | epoch: 018 | loss: 0.68176 - acc: 0.7916 -- iter: 00192/10000
[A[ATraining Step: 2673  | total loss: [1m[32m0.67856[0m[0m | time: 4.722s
[2K| Adam | epoch: 018 | loss: 0.67856 - acc: 0.7859 -- iter: 00256/10000
[A[ATraining Step: 2674  | total loss: [1m[32m0.66215[0m[0m | time: 5.821s
[2K| Adam | epoch: 018 | loss: 0.66215 - acc: 0.7854 -- iter: 00320/10000
[A[ATraining Step: 2675  | total loss: [1m[32m0.67341[0m[0m | time: 6.958s
[2K| Adam | epoch: 018 | loss: 0.67341 - acc: 0.7725 -- iter: 00384/10000
[A[ATraining Step: 2676  | total loss: [1m[32m0.66307[0m[0m | time: 8.074s
[2K| Adam | epoch: 018 | loss: 0.66307 - acc: 0.7687 -- iter: 00448/10000
[A[ATraining Step: 2677  | total loss: [1m[32m0.63645[0m[0m | time: 9.249s
[2K| Adam | epoch: 018 | loss: 0.63645 - acc: 0.7731 -- iter: 00512/10000
[A[ATraining Step: 2678  | total loss: [1m[32m0.61252[0m[0m | time: 10.327s
[2K| Adam | epoch: 018 | loss: 0.61252 - acc: 0.7770 -- iter: 00576/10000
[A[ATraining Step: 2679  | total loss: [1m[32m0.59514[0m[0m | time: 11.407s
[2K| Adam | epoch: 018 | loss: 0.59514 - acc: 0.7837 -- iter: 00640/10000
[A[ATraining Step: 2680  | total loss: [1m[32m0.59810[0m[0m | time: 12.482s
[2K| Adam | epoch: 018 | loss: 0.59810 - acc: 0.7866 -- iter: 00704/10000
[A[ATraining Step: 2681  | total loss: [1m[32m0.60513[0m[0m | time: 13.580s
[2K| Adam | epoch: 018 | loss: 0.60513 - acc: 0.7907 -- iter: 00768/10000
[A[ATraining Step: 2682  | total loss: [1m[32m0.59173[0m[0m | time: 14.740s
[2K| Adam | epoch: 018 | loss: 0.59173 - acc: 0.7913 -- iter: 00832/10000
[A[ATraining Step: 2683  | total loss: [1m[32m0.59647[0m[0m | time: 15.813s
[2K| Adam | epoch: 018 | loss: 0.59647 - acc: 0.7997 -- iter: 00896/10000
[A[ATraining Step: 2684  | total loss: [1m[32m0.58739[0m[0m | time: 16.966s
[2K| Adam | epoch: 018 | loss: 0.58739 - acc: 0.8057 -- iter: 00960/10000
[A[ATraining Step: 2685  | total loss: [1m[32m0.57398[0m[0m | time: 17.475s
[2K| Adam | epoch: 018 | loss: 0.57398 - acc: 0.8126 -- iter: 01024/10000
[A[ATraining Step: 2686  | total loss: [1m[32m0.56273[0m[0m | time: 17.987s
[2K| Adam | epoch: 018 | loss: 0.56273 - acc: 0.8063 -- iter: 01088/10000
[A[ATraining Step: 2687  | total loss: [1m[32m0.54153[0m[0m | time: 19.054s
[2K| Adam | epoch: 018 | loss: 0.54153 - acc: 0.8070 -- iter: 01152/10000
[A[ATraining Step: 2688  | total loss: [1m[32m0.53698[0m[0m | time: 20.117s
[2K| Adam | epoch: 018 | loss: 0.53698 - acc: 0.8013 -- iter: 01216/10000
[A[ATraining Step: 2689  | total loss: [1m[32m0.53546[0m[0m | time: 21.207s
[2K| Adam | epoch: 018 | loss: 0.53546 - acc: 0.8024 -- iter: 01280/10000
[A[ATraining Step: 2690  | total loss: [1m[32m0.53026[0m[0m | time: 22.307s
[2K| Adam | epoch: 018 | loss: 0.53026 - acc: 0.8034 -- iter: 01344/10000
[A[ATraining Step: 2691  | total loss: [1m[32m0.51238[0m[0m | time: 23.374s
[2K| Adam | epoch: 018 | loss: 0.51238 - acc: 0.8106 -- iter: 01408/10000
[A[ATraining Step: 2692  | total loss: [1m[32m0.50061[0m[0m | time: 24.417s
[2K| Adam | epoch: 018 | loss: 0.50061 - acc: 0.8139 -- iter: 01472/10000
[A[ATraining Step: 2693  | total loss: [1m[32m0.49718[0m[0m | time: 25.499s
[2K| Adam | epoch: 018 | loss: 0.49718 - acc: 0.8137 -- iter: 01536/10000
[A[ATraining Step: 2694  | total loss: [1m[32m0.53387[0m[0m | time: 26.570s
[2K| Adam | epoch: 018 | loss: 0.53387 - acc: 0.8074 -- iter: 01600/10000
[A[ATraining Step: 2695  | total loss: [1m[32m0.54478[0m[0m | time: 27.663s
[2K| Adam | epoch: 018 | loss: 0.54478 - acc: 0.8001 -- iter: 01664/10000
[A[ATraining Step: 2696  | total loss: [1m[32m0.53962[0m[0m | time: 28.735s
[2K| Adam | epoch: 018 | loss: 0.53962 - acc: 0.8029 -- iter: 01728/10000
[A[ATraining Step: 2697  | total loss: [1m[32m0.54618[0m[0m | time: 29.807s
[2K| Adam | epoch: 018 | loss: 0.54618 - acc: 0.8054 -- iter: 01792/10000
[A[ATraining Step: 2698  | total loss: [1m[32m0.55522[0m[0m | time: 30.896s
[2K| Adam | epoch: 018 | loss: 0.55522 - acc: 0.8061 -- iter: 01856/10000
[A[ATraining Step: 2699  | total loss: [1m[32m0.54217[0m[0m | time: 32.003s
[2K| Adam | epoch: 018 | loss: 0.54217 - acc: 0.8099 -- iter: 01920/10000
[A[ATraining Step: 2700  | total loss: [1m[32m0.53344[0m[0m | time: 36.007s
[2K| Adam | epoch: 018 | loss: 0.53344 - acc: 0.8117 | val_loss: 2.30027 - val_acc: 0.3829 -- iter: 01984/10000
--
Training Step: 2701  | total loss: [1m[32m0.53285[0m[0m | time: 37.159s
[2K| Adam | epoch: 018 | loss: 0.53285 - acc: 0.8118 -- iter: 02048/10000
[A[ATraining Step: 2702  | total loss: [1m[32m0.52633[0m[0m | time: 38.332s
[2K| Adam | epoch: 018 | loss: 0.52633 - acc: 0.8165 -- iter: 02112/10000
[A[ATraining Step: 2703  | total loss: [1m[32m0.52633[0m[0m | time: 39.523s
[2K| Adam | epoch: 018 | loss: 0.52633 - acc: 0.8161 -- iter: 02176/10000
[A[ATraining Step: 2704  | total loss: [1m[32m0.54028[0m[0m | time: 40.597s
[2K| Adam | epoch: 018 | loss: 0.54028 - acc: 0.8001 -- iter: 02240/10000
[A[ATraining Step: 2705  | total loss: [1m[32m0.53011[0m[0m | time: 41.622s
[2K| Adam | epoch: 018 | loss: 0.53011 - acc: 0.8014 -- iter: 02304/10000
[A[ATraining Step: 2706  | total loss: [1m[32m0.52891[0m[0m | time: 42.641s
[2K| Adam | epoch: 018 | loss: 0.52891 - acc: 0.8041 -- iter: 02368/10000
[A[ATraining Step: 2707  | total loss: [1m[32m0.53677[0m[0m | time: 43.653s
[2K| Adam | epoch: 018 | loss: 0.53677 - acc: 0.7940 -- iter: 02432/10000
[A[ATraining Step: 2708  | total loss: [1m[32m0.53463[0m[0m | time: 44.649s
[2K| Adam | epoch: 018 | loss: 0.53463 - acc: 0.7943 -- iter: 02496/10000
[A[ATraining Step: 2709  | total loss: [1m[32m0.53703[0m[0m | time: 45.714s
[2K| Adam | epoch: 018 | loss: 0.53703 - acc: 0.7976 -- iter: 02560/10000
[A[ATraining Step: 2710  | total loss: [1m[32m0.54412[0m[0m | time: 46.739s
[2K| Adam | epoch: 018 | loss: 0.54412 - acc: 0.7913 -- iter: 02624/10000
[A[ATraining Step: 2711  | total loss: [1m[32m0.54990[0m[0m | time: 47.900s
[2K| Adam | epoch: 018 | loss: 0.54990 - acc: 0.7887 -- iter: 02688/10000
[A[ATraining Step: 2712  | total loss: [1m[32m0.53051[0m[0m | time: 49.021s
[2K| Adam | epoch: 018 | loss: 0.53051 - acc: 0.7942 -- iter: 02752/10000
[A[ATraining Step: 2713  | total loss: [1m[32m0.53560[0m[0m | time: 50.197s
[2K| Adam | epoch: 018 | loss: 0.53560 - acc: 0.7976 -- iter: 02816/10000
[A[ATraining Step: 2714  | total loss: [1m[32m0.52956[0m[0m | time: 51.524s
[2K| Adam | epoch: 018 | loss: 0.52956 - acc: 0.8007 -- iter: 02880/10000
[A[ATraining Step: 2715  | total loss: [1m[32m0.52662[0m[0m | time: 52.823s
[2K| Adam | epoch: 018 | loss: 0.52662 - acc: 0.7941 -- iter: 02944/10000
[A[ATraining Step: 2716  | total loss: [1m[32m0.53628[0m[0m | time: 54.184s
[2K| Adam | epoch: 018 | loss: 0.53628 - acc: 0.7912 -- iter: 03008/10000
[A[ATraining Step: 2717  | total loss: [1m[32m0.55638[0m[0m | time: 55.482s
[2K| Adam | epoch: 018 | loss: 0.55638 - acc: 0.7808 -- iter: 03072/10000
[A[ATraining Step: 2718  | total loss: [1m[32m0.57020[0m[0m | time: 56.754s
[2K| Adam | epoch: 018 | loss: 0.57020 - acc: 0.7778 -- iter: 03136/10000
[A[ATraining Step: 2719  | total loss: [1m[32m0.55710[0m[0m | time: 57.964s
[2K| Adam | epoch: 018 | loss: 0.55710 - acc: 0.7781 -- iter: 03200/10000
[A[ATraining Step: 2720  | total loss: [1m[32m0.55845[0m[0m | time: 59.132s
[2K| Adam | epoch: 018 | loss: 0.55845 - acc: 0.7769 -- iter: 03264/10000
[A[ATraining Step: 2721  | total loss: [1m[32m0.56560[0m[0m | time: 60.375s
[2K| Adam | epoch: 018 | loss: 0.56560 - acc: 0.7695 -- iter: 03328/10000
[A[ATraining Step: 2722  | total loss: [1m[32m0.60083[0m[0m | time: 61.555s
[2K| Adam | epoch: 018 | loss: 0.60083 - acc: 0.7707 -- iter: 03392/10000
[A[ATraining Step: 2723  | total loss: [1m[32m0.59250[0m[0m | time: 62.718s
[2K| Adam | epoch: 018 | loss: 0.59250 - acc: 0.7780 -- iter: 03456/10000
[A[ATraining Step: 2724  | total loss: [1m[32m0.56892[0m[0m | time: 63.825s
[2K| Adam | epoch: 018 | loss: 0.56892 - acc: 0.7939 -- iter: 03520/10000
[A[ATraining Step: 2725  | total loss: [1m[32m0.57266[0m[0m | time: 64.966s
[2K| Adam | epoch: 018 | loss: 0.57266 - acc: 0.7973 -- iter: 03584/10000
[A[ATraining Step: 2726  | total loss: [1m[32m0.57017[0m[0m | time: 66.134s
[2K| Adam | epoch: 018 | loss: 0.57017 - acc: 0.7989 -- iter: 03648/10000
[A[ATraining Step: 2727  | total loss: [1m[32m0.56563[0m[0m | time: 67.315s
[2K| Adam | epoch: 018 | loss: 0.56563 - acc: 0.8049 -- iter: 03712/10000
[A[ATraining Step: 2728  | total loss: [1m[32m0.55192[0m[0m | time: 68.504s
[2K| Adam | epoch: 018 | loss: 0.55192 - acc: 0.8135 -- iter: 03776/10000
[A[ATraining Step: 2729  | total loss: [1m[32m0.53992[0m[0m | time: 69.694s
[2K| Adam | epoch: 018 | loss: 0.53992 - acc: 0.8149 -- iter: 03840/10000
[A[ATraining Step: 2730  | total loss: [1m[32m0.54392[0m[0m | time: 70.839s
[2K| Adam | epoch: 018 | loss: 0.54392 - acc: 0.8194 -- iter: 03904/10000
[A[ATraining Step: 2731  | total loss: [1m[32m0.55316[0m[0m | time: 72.075s
[2K| Adam | epoch: 018 | loss: 0.55316 - acc: 0.8171 -- iter: 03968/10000
[A[ATraining Step: 2732  | total loss: [1m[32m0.55476[0m[0m | time: 73.257s
[2K| Adam | epoch: 018 | loss: 0.55476 - acc: 0.8167 -- iter: 04032/10000
[A[ATraining Step: 2733  | total loss: [1m[32m0.55932[0m[0m | time: 74.415s
[2K| Adam | epoch: 018 | loss: 0.55932 - acc: 0.8131 -- iter: 04096/10000
[A[ATraining Step: 2734  | total loss: [1m[32m0.57168[0m[0m | time: 75.661s
[2K| Adam | epoch: 018 | loss: 0.57168 - acc: 0.8006 -- iter: 04160/10000
[A[ATraining Step: 2735  | total loss: [1m[32m0.57278[0m[0m | time: 76.928s
[2K| Adam | epoch: 018 | loss: 0.57278 - acc: 0.7939 -- iter: 04224/10000
[A[ATraining Step: 2736  | total loss: [1m[32m0.58650[0m[0m | time: 78.170s
[2K| Adam | epoch: 018 | loss: 0.58650 - acc: 0.7896 -- iter: 04288/10000
[A[ATraining Step: 2737  | total loss: [1m[32m0.57323[0m[0m | time: 79.252s
[2K| Adam | epoch: 018 | loss: 0.57323 - acc: 0.7965 -- iter: 04352/10000
[A[ATraining Step: 2738  | total loss: [1m[32m0.57218[0m[0m | time: 80.303s
[2K| Adam | epoch: 018 | loss: 0.57218 - acc: 0.7966 -- iter: 04416/10000
[A[ATraining Step: 2739  | total loss: [1m[32m0.57129[0m[0m | time: 81.366s
[2K| Adam | epoch: 018 | loss: 0.57129 - acc: 0.7935 -- iter: 04480/10000
[A[ATraining Step: 2740  | total loss: [1m[32m0.57302[0m[0m | time: 82.410s
[2K| Adam | epoch: 018 | loss: 0.57302 - acc: 0.7985 -- iter: 04544/10000
[A[ATraining Step: 2741  | total loss: [1m[32m0.61626[0m[0m | time: 83.432s
[2K| Adam | epoch: 018 | loss: 0.61626 - acc: 0.7827 -- iter: 04608/10000
[A[ATraining Step: 2742  | total loss: [1m[32m0.60666[0m[0m | time: 84.465s
[2K| Adam | epoch: 018 | loss: 0.60666 - acc: 0.7873 -- iter: 04672/10000
[A[ATraining Step: 2743  | total loss: [1m[32m0.59937[0m[0m | time: 85.577s
[2K| Adam | epoch: 018 | loss: 0.59937 - acc: 0.7851 -- iter: 04736/10000
[A[ATraining Step: 2744  | total loss: [1m[32m0.61142[0m[0m | time: 86.785s
[2K| Adam | epoch: 018 | loss: 0.61142 - acc: 0.7831 -- iter: 04800/10000
[A[ATraining Step: 2745  | total loss: [1m[32m0.61216[0m[0m | time: 87.979s
[2K| Adam | epoch: 018 | loss: 0.61216 - acc: 0.7845 -- iter: 04864/10000
[A[ATraining Step: 2746  | total loss: [1m[32m0.60447[0m[0m | time: 89.184s
[2K| Adam | epoch: 018 | loss: 0.60447 - acc: 0.7842 -- iter: 04928/10000
[A[ATraining Step: 2747  | total loss: [1m[32m0.59851[0m[0m | time: 90.311s
[2K| Adam | epoch: 018 | loss: 0.59851 - acc: 0.7855 -- iter: 04992/10000
[A[ATraining Step: 2748  | total loss: [1m[32m0.61870[0m[0m | time: 91.427s
[2K| Adam | epoch: 018 | loss: 0.61870 - acc: 0.7725 -- iter: 05056/10000
[A[ATraining Step: 2749  | total loss: [1m[32m0.61654[0m[0m | time: 92.564s
[2K| Adam | epoch: 018 | loss: 0.61654 - acc: 0.7781 -- iter: 05120/10000
[A[ATraining Step: 2750  | total loss: [1m[32m0.62725[0m[0m | time: 93.590s
[2K| Adam | epoch: 018 | loss: 0.62725 - acc: 0.7737 -- iter: 05184/10000
[A[ATraining Step: 2751  | total loss: [1m[32m0.61337[0m[0m | time: 94.683s
[2K| Adam | epoch: 018 | loss: 0.61337 - acc: 0.7792 -- iter: 05248/10000
[A[ATraining Step: 2752  | total loss: [1m[32m0.58755[0m[0m | time: 95.785s
[2K| Adam | epoch: 018 | loss: 0.58755 - acc: 0.7809 -- iter: 05312/10000
[A[ATraining Step: 2753  | total loss: [1m[32m0.57804[0m[0m | time: 96.800s
[2K| Adam | epoch: 018 | loss: 0.57804 - acc: 0.7841 -- iter: 05376/10000
[A[ATraining Step: 2754  | total loss: [1m[32m0.55686[0m[0m | time: 97.915s
[2K| Adam | epoch: 018 | loss: 0.55686 - acc: 0.7901 -- iter: 05440/10000
[A[ATraining Step: 2755  | total loss: [1m[32m0.54642[0m[0m | time: 99.091s
[2K| Adam | epoch: 018 | loss: 0.54642 - acc: 0.7986 -- iter: 05504/10000
[A[ATraining Step: 2756  | total loss: [1m[32m0.53872[0m[0m | time: 100.324s
[2K| Adam | epoch: 018 | loss: 0.53872 - acc: 0.8015 -- iter: 05568/10000
[A[ATraining Step: 2757  | total loss: [1m[32m0.55238[0m[0m | time: 101.571s
[2K| Adam | epoch: 018 | loss: 0.55238 - acc: 0.7995 -- iter: 05632/10000
[A[ATraining Step: 2758  | total loss: [1m[32m0.54513[0m[0m | time: 102.795s
[2K| Adam | epoch: 018 | loss: 0.54513 - acc: 0.8008 -- iter: 05696/10000
[A[ATraining Step: 2759  | total loss: [1m[32m0.56570[0m[0m | time: 104.058s
[2K| Adam | epoch: 018 | loss: 0.56570 - acc: 0.7895 -- iter: 05760/10000
[A[ATraining Step: 2760  | total loss: [1m[32m0.55371[0m[0m | time: 105.299s
[2K| Adam | epoch: 018 | loss: 0.55371 - acc: 0.7949 -- iter: 05824/10000
[A[ATraining Step: 2761  | total loss: [1m[32m0.55433[0m[0m | time: 106.508s
[2K| Adam | epoch: 018 | loss: 0.55433 - acc: 0.7982 -- iter: 05888/10000
[A[ATraining Step: 2762  | total loss: [1m[32m0.53874[0m[0m | time: 107.707s
[2K| Adam | epoch: 018 | loss: 0.53874 - acc: 0.8012 -- iter: 05952/10000
[A[ATraining Step: 2763  | total loss: [1m[32m0.52461[0m[0m | time: 108.902s
[2K| Adam | epoch: 018 | loss: 0.52461 - acc: 0.8101 -- iter: 06016/10000
[A[ATraining Step: 2764  | total loss: [1m[32m0.51844[0m[0m | time: 110.059s
[2K| Adam | epoch: 018 | loss: 0.51844 - acc: 0.8088 -- iter: 06080/10000
[A[ATraining Step: 2765  | total loss: [1m[32m0.53153[0m[0m | time: 111.238s
[2K| Adam | epoch: 018 | loss: 0.53153 - acc: 0.8045 -- iter: 06144/10000
[A[ATraining Step: 2766  | total loss: [1m[32m0.54963[0m[0m | time: 112.401s
[2K| Adam | epoch: 018 | loss: 0.54963 - acc: 0.7990 -- iter: 06208/10000
[A[ATraining Step: 2767  | total loss: [1m[32m0.56261[0m[0m | time: 113.615s
[2K| Adam | epoch: 018 | loss: 0.56261 - acc: 0.7988 -- iter: 06272/10000
[A[ATraining Step: 2768  | total loss: [1m[32m0.56285[0m[0m | time: 115.192s
[2K| Adam | epoch: 018 | loss: 0.56285 - acc: 0.8033 -- iter: 06336/10000
[A[ATraining Step: 2769  | total loss: [1m[32m0.56197[0m[0m | time: 116.741s
[2K| Adam | epoch: 018 | loss: 0.56197 - acc: 0.8027 -- iter: 06400/10000
[A[ATraining Step: 2770  | total loss: [1m[32m0.56441[0m[0m | time: 118.312s
[2K| Adam | epoch: 018 | loss: 0.56441 - acc: 0.7990 -- iter: 06464/10000
[A[ATraining Step: 2771  | total loss: [1m[32m0.56168[0m[0m | time: 119.725s
[2K| Adam | epoch: 018 | loss: 0.56168 - acc: 0.8050 -- iter: 06528/10000
[A[ATraining Step: 2772  | total loss: [1m[32m0.55683[0m[0m | time: 121.016s
[2K| Adam | epoch: 018 | loss: 0.55683 - acc: 0.8042 -- iter: 06592/10000
[A[ATraining Step: 2773  | total loss: [1m[32m0.54587[0m[0m | time: 122.442s
[2K| Adam | epoch: 018 | loss: 0.54587 - acc: 0.8113 -- iter: 06656/10000
[A[ATraining Step: 2774  | total loss: [1m[32m0.53124[0m[0m | time: 123.845s
[2K| Adam | epoch: 018 | loss: 0.53124 - acc: 0.8161 -- iter: 06720/10000
[A[ATraining Step: 2775  | total loss: [1m[32m0.53452[0m[0m | time: 125.131s
[2K| Adam | epoch: 018 | loss: 0.53452 - acc: 0.8189 -- iter: 06784/10000
[A[ATraining Step: 2776  | total loss: [1m[32m0.55542[0m[0m | time: 126.394s
[2K| Adam | epoch: 018 | loss: 0.55542 - acc: 0.8167 -- iter: 06848/10000
[A[ATraining Step: 2777  | total loss: [1m[32m0.54451[0m[0m | time: 127.678s
[2K| Adam | epoch: 018 | loss: 0.54451 - acc: 0.8147 -- iter: 06912/10000
[A[ATraining Step: 2778  | total loss: [1m[32m0.53400[0m[0m | time: 128.819s
[2K| Adam | epoch: 018 | loss: 0.53400 - acc: 0.8176 -- iter: 06976/10000
[A[ATraining Step: 2779  | total loss: [1m[32m0.53059[0m[0m | time: 129.819s
[2K| Adam | epoch: 018 | loss: 0.53059 - acc: 0.8171 -- iter: 07040/10000
[A[ATraining Step: 2780  | total loss: [1m[32m0.54244[0m[0m | time: 130.808s
[2K| Adam | epoch: 018 | loss: 0.54244 - acc: 0.8166 -- iter: 07104/10000
[A[ATraining Step: 2781  | total loss: [1m[32m0.53049[0m[0m | time: 131.842s
[2K| Adam | epoch: 018 | loss: 0.53049 - acc: 0.8193 -- iter: 07168/10000
[A[ATraining Step: 2782  | total loss: [1m[32m0.52317[0m[0m | time: 132.817s
[2K| Adam | epoch: 018 | loss: 0.52317 - acc: 0.8171 -- iter: 07232/10000
[A[ATraining Step: 2783  | total loss: [1m[32m0.53683[0m[0m | time: 133.863s
[2K| Adam | epoch: 018 | loss: 0.53683 - acc: 0.8119 -- iter: 07296/10000
[A[ATraining Step: 2784  | total loss: [1m[32m0.54698[0m[0m | time: 134.926s
[2K| Adam | epoch: 018 | loss: 0.54698 - acc: 0.8042 -- iter: 07360/10000
[A[ATraining Step: 2785  | total loss: [1m[32m0.53351[0m[0m | time: 135.954s
[2K| Adam | epoch: 018 | loss: 0.53351 - acc: 0.8050 -- iter: 07424/10000
[A[ATraining Step: 2786  | total loss: [1m[32m0.53071[0m[0m | time: 137.000s
[2K| Adam | epoch: 018 | loss: 0.53071 - acc: 0.8026 -- iter: 07488/10000
[A[ATraining Step: 2787  | total loss: [1m[32m0.55002[0m[0m | time: 138.135s
[2K| Adam | epoch: 018 | loss: 0.55002 - acc: 0.7864 -- iter: 07552/10000
[A[ATraining Step: 2788  | total loss: [1m[32m0.54312[0m[0m | time: 139.380s
[2K| Adam | epoch: 018 | loss: 0.54312 - acc: 0.7859 -- iter: 07616/10000
[A[ATraining Step: 2789  | total loss: [1m[32m0.52653[0m[0m | time: 140.553s
[2K| Adam | epoch: 018 | loss: 0.52653 - acc: 0.7964 -- iter: 07680/10000
[A[ATraining Step: 2790  | total loss: [1m[32m0.52598[0m[0m | time: 141.924s
[2K| Adam | epoch: 018 | loss: 0.52598 - acc: 0.7964 -- iter: 07744/10000
[A[ATraining Step: 2791  | total loss: [1m[32m0.52340[0m[0m | time: 143.307s
[2K| Adam | epoch: 018 | loss: 0.52340 - acc: 0.8027 -- iter: 07808/10000
[A[ATraining Step: 2792  | total loss: [1m[32m0.54462[0m[0m | time: 144.660s
[2K| Adam | epoch: 018 | loss: 0.54462 - acc: 0.8084 -- iter: 07872/10000
[A[ATraining Step: 2793  | total loss: [1m[32m0.54814[0m[0m | time: 145.947s
[2K| Adam | epoch: 018 | loss: 0.54814 - acc: 0.8010 -- iter: 07936/10000
[A[ATraining Step: 2794  | total loss: [1m[32m0.54809[0m[0m | time: 147.327s
[2K| Adam | epoch: 018 | loss: 0.54809 - acc: 0.7943 -- iter: 08000/10000
[A[ATraining Step: 2795  | total loss: [1m[32m0.53400[0m[0m | time: 148.596s
[2K| Adam | epoch: 018 | loss: 0.53400 - acc: 0.7961 -- iter: 08064/10000
[A[ATraining Step: 2796  | total loss: [1m[32m0.54587[0m[0m | time: 149.780s
[2K| Adam | epoch: 018 | loss: 0.54587 - acc: 0.7837 -- iter: 08128/10000
[A[ATraining Step: 2797  | total loss: [1m[32m0.54420[0m[0m | time: 150.977s
[2K| Adam | epoch: 018 | loss: 0.54420 - acc: 0.7850 -- iter: 08192/10000
[A[ATraining Step: 2798  | total loss: [1m[32m0.55391[0m[0m | time: 152.061s
[2K| Adam | epoch: 018 | loss: 0.55391 - acc: 0.7847 -- iter: 08256/10000
[A[ATraining Step: 2799  | total loss: [1m[32m0.57743[0m[0m | time: 153.050s
[2K| Adam | epoch: 018 | loss: 0.57743 - acc: 0.7781 -- iter: 08320/10000
[A[ATraining Step: 2800  | total loss: [1m[32m0.56314[0m[0m | time: 156.928s
[2K| Adam | epoch: 018 | loss: 0.56314 - acc: 0.7831 | val_loss: 2.36269 - val_acc: 0.3900 -- iter: 08384/10000
--
Training Step: 2801  | total loss: [1m[32m0.55983[0m[0m | time: 158.019s
[2K| Adam | epoch: 018 | loss: 0.55983 - acc: 0.7845 -- iter: 08448/10000
[A[ATraining Step: 2802  | total loss: [1m[32m0.55752[0m[0m | time: 159.199s
[2K| Adam | epoch: 018 | loss: 0.55752 - acc: 0.7873 -- iter: 08512/10000
[A[ATraining Step: 2803  | total loss: [1m[32m0.55227[0m[0m | time: 160.448s
[2K| Adam | epoch: 018 | loss: 0.55227 - acc: 0.7929 -- iter: 08576/10000
[A[ATraining Step: 2804  | total loss: [1m[32m0.53436[0m[0m | time: 161.670s
[2K| Adam | epoch: 018 | loss: 0.53436 - acc: 0.7996 -- iter: 08640/10000
[A[ATraining Step: 2805  | total loss: [1m[32m0.54550[0m[0m | time: 162.903s
[2K| Adam | epoch: 018 | loss: 0.54550 - acc: 0.7946 -- iter: 08704/10000
[A[ATraining Step: 2806  | total loss: [1m[32m0.54742[0m[0m | time: 164.158s
[2K| Adam | epoch: 018 | loss: 0.54742 - acc: 0.7917 -- iter: 08768/10000
[A[ATraining Step: 2807  | total loss: [1m[32m0.52047[0m[0m | time: 165.346s
[2K| Adam | epoch: 018 | loss: 0.52047 - acc: 0.8032 -- iter: 08832/10000
[A[ATraining Step: 2808  | total loss: [1m[32m0.51648[0m[0m | time: 166.530s
[2K| Adam | epoch: 018 | loss: 0.51648 - acc: 0.8025 -- iter: 08896/10000
[A[ATraining Step: 2809  | total loss: [1m[32m0.50855[0m[0m | time: 167.697s
[2K| Adam | epoch: 018 | loss: 0.50855 - acc: 0.8020 -- iter: 08960/10000
[A[ATraining Step: 2810  | total loss: [1m[32m0.50583[0m[0m | time: 168.799s
[2K| Adam | epoch: 018 | loss: 0.50583 - acc: 0.8030 -- iter: 09024/10000
[A[ATraining Step: 2811  | total loss: [1m[32m0.50474[0m[0m | time: 169.805s
[2K| Adam | epoch: 018 | loss: 0.50474 - acc: 0.8008 -- iter: 09088/10000
[A[ATraining Step: 2812  | total loss: [1m[32m1.31361[0m[0m | time: 170.826s
[2K| Adam | epoch: 018 | loss: 1.31361 - acc: 0.7301 -- iter: 09152/10000
[A[ATraining Step: 2813  | total loss: [1m[32m1.23858[0m[0m | time: 172.038s
[2K| Adam | epoch: 018 | loss: 1.23858 - acc: 0.7352 -- iter: 09216/10000
[A[ATraining Step: 2814  | total loss: [1m[32m1.16403[0m[0m | time: 173.130s
[2K| Adam | epoch: 018 | loss: 1.16403 - acc: 0.7430 -- iter: 09280/10000
[A[ATraining Step: 2815  | total loss: [1m[32m1.09436[0m[0m | time: 174.208s
[2K| Adam | epoch: 018 | loss: 1.09436 - acc: 0.7530 -- iter: 09344/10000
[A[ATraining Step: 2816  | total loss: [1m[32m1.03655[0m[0m | time: 175.273s
[2K| Adam | epoch: 018 | loss: 1.03655 - acc: 0.7559 -- iter: 09408/10000
[A[ATraining Step: 2817  | total loss: [1m[32m1.00156[0m[0m | time: 176.345s
[2K| Adam | epoch: 018 | loss: 1.00156 - acc: 0.7522 -- iter: 09472/10000
[A[ATraining Step: 2818  | total loss: [1m[32m0.95138[0m[0m | time: 177.421s
[2K| Adam | epoch: 018 | loss: 0.95138 - acc: 0.7551 -- iter: 09536/10000
[A[ATraining Step: 2819  | total loss: [1m[32m0.90108[0m[0m | time: 178.499s
[2K| Adam | epoch: 018 | loss: 0.90108 - acc: 0.7671 -- iter: 09600/10000
[A[ATraining Step: 2820  | total loss: [1m[32m0.87851[0m[0m | time: 179.596s
[2K| Adam | epoch: 018 | loss: 0.87851 - acc: 0.7716 -- iter: 09664/10000
[A[ATraining Step: 2821  | total loss: [1m[32m0.82776[0m[0m | time: 180.676s
[2K| Adam | epoch: 018 | loss: 0.82776 - acc: 0.7866 -- iter: 09728/10000
[A[ATraining Step: 2822  | total loss: [1m[32m0.79485[0m[0m | time: 181.827s
[2K| Adam | epoch: 018 | loss: 0.79485 - acc: 0.7939 -- iter: 09792/10000
[A[ATraining Step: 2823  | total loss: [1m[32m0.75178[0m[0m | time: 182.878s
[2K| Adam | epoch: 018 | loss: 0.75178 - acc: 0.8051 -- iter: 09856/10000
[A[ATraining Step: 2824  | total loss: [1m[32m0.73001[0m[0m | time: 183.936s
[2K| Adam | epoch: 018 | loss: 0.73001 - acc: 0.8137 -- iter: 09920/10000
[A[ATraining Step: 2825  | total loss: [1m[32m0.72192[0m[0m | time: 185.011s
[2K| Adam | epoch: 018 | loss: 0.72192 - acc: 0.8042 -- iter: 09984/10000
[A[ATraining Step: 2826  | total loss: [1m[32m0.71426[0m[0m | time: 190.034s
[2K| Adam | epoch: 018 | loss: 0.71426 - acc: 0.8019 | val_loss: 2.47987 - val_acc: 0.3929 -- iter: 10000/10000
--
Training Step: 2827  | total loss: [1m[32m0.71121[0m[0m | time: 1.348s
[2K| Adam | epoch: 019 | loss: 0.71121 - acc: 0.7936 -- iter: 00064/10000
[A[ATraining Step: 2828  | total loss: [1m[32m0.68946[0m[0m | time: 2.628s
[2K| Adam | epoch: 019 | loss: 0.68946 - acc: 0.7908 -- iter: 00128/10000
[A[ATraining Step: 2829  | total loss: [1m[32m0.68144[0m[0m | time: 3.875s
[2K| Adam | epoch: 019 | loss: 0.68144 - acc: 0.7867 -- iter: 00192/10000
[A[ATraining Step: 2830  | total loss: [1m[32m0.68144[0m[0m | time: 5.057s
[2K| Adam | epoch: 019 | loss: 0.68144 - acc: 0.7830 -- iter: 00256/10000
[A[ATraining Step: 2831  | total loss: [1m[32m0.67713[0m[0m | time: 6.188s
[2K| Adam | epoch: 019 | loss: 0.67713 - acc: 0.7844 -- iter: 00320/10000
[A[ATraining Step: 2832  | total loss: [1m[32m0.68178[0m[0m | time: 7.361s
[2K| Adam | epoch: 019 | loss: 0.68178 - acc: 0.7919 -- iter: 00384/10000
[A[ATraining Step: 2833  | total loss: [1m[32m0.66655[0m[0m | time: 8.386s
[2K| Adam | epoch: 019 | loss: 0.66655 - acc: 0.7940 -- iter: 00448/10000
[A[ATraining Step: 2834  | total loss: [1m[32m0.63808[0m[0m | time: 9.339s
[2K| Adam | epoch: 019 | loss: 0.63808 - acc: 0.8036 -- iter: 00512/10000
[A[ATraining Step: 2835  | total loss: [1m[32m0.61161[0m[0m | time: 10.303s
[2K| Adam | epoch: 019 | loss: 0.61161 - acc: 0.8170 -- iter: 00576/10000
[A[ATraining Step: 2836  | total loss: [1m[32m0.61013[0m[0m | time: 11.286s
[2K| Adam | epoch: 019 | loss: 0.61013 - acc: 0.8150 -- iter: 00640/10000
[A[ATraining Step: 2837  | total loss: [1m[32m0.59691[0m[0m | time: 12.246s
[2K| Adam | epoch: 019 | loss: 0.59691 - acc: 0.8194 -- iter: 00704/10000
[A[ATraining Step: 2838  | total loss: [1m[32m0.58555[0m[0m | time: 13.208s
[2K| Adam | epoch: 019 | loss: 0.58555 - acc: 0.8234 -- iter: 00768/10000
[A[ATraining Step: 2839  | total loss: [1m[32m0.58665[0m[0m | time: 14.210s
[2K| Adam | epoch: 019 | loss: 0.58665 - acc: 0.8161 -- iter: 00832/10000
[A[ATraining Step: 2840  | total loss: [1m[32m0.58653[0m[0m | time: 15.204s
[2K| Adam | epoch: 019 | loss: 0.58653 - acc: 0.8126 -- iter: 00896/10000
[A[ATraining Step: 2841  | total loss: [1m[32m0.58016[0m[0m | time: 16.231s
[2K| Adam | epoch: 019 | loss: 0.58016 - acc: 0.8126 -- iter: 00960/10000
[A[ATraining Step: 2842  | total loss: [1m[32m0.59525[0m[0m | time: 17.235s
[2K| Adam | epoch: 019 | loss: 0.59525 - acc: 0.8095 -- iter: 01024/10000
[A[ATraining Step: 2843  | total loss: [1m[32m0.58095[0m[0m | time: 17.713s
[2K| Adam | epoch: 019 | loss: 0.58095 - acc: 0.8129 -- iter: 01088/10000
[A[ATraining Step: 2844  | total loss: [1m[32m0.57109[0m[0m | time: 18.180s
[2K| Adam | epoch: 019 | loss: 0.57109 - acc: 0.8066 -- iter: 01152/10000
[A[ATraining Step: 2845  | total loss: [1m[32m0.58777[0m[0m | time: 19.266s
[2K| Adam | epoch: 019 | loss: 0.58777 - acc: 0.8009 -- iter: 01216/10000
[A[ATraining Step: 2846  | total loss: [1m[32m0.56994[0m[0m | time: 20.328s
[2K| Adam | epoch: 019 | loss: 0.56994 - acc: 0.8005 -- iter: 01280/10000
[A[ATraining Step: 2847  | total loss: [1m[32m0.58156[0m[0m | time: 21.442s
[2K| Adam | epoch: 019 | loss: 0.58156 - acc: 0.7924 -- iter: 01344/10000
[A[ATraining Step: 2848  | total loss: [1m[32m0.56265[0m[0m | time: 22.506s
[2K| Adam | epoch: 019 | loss: 0.56265 - acc: 0.7975 -- iter: 01408/10000
[A[ATraining Step: 2849  | total loss: [1m[32m0.56602[0m[0m | time: 23.569s
[2K| Adam | epoch: 019 | loss: 0.56602 - acc: 0.7990 -- iter: 01472/10000
[A[ATraining Step: 2850  | total loss: [1m[32m0.56980[0m[0m | time: 24.626s
[2K| Adam | epoch: 019 | loss: 0.56980 - acc: 0.8003 -- iter: 01536/10000
[A[ATraining Step: 2851  | total loss: [1m[32m0.57181[0m[0m | time: 25.703s
[2K| Adam | epoch: 019 | loss: 0.57181 - acc: 0.7969 -- iter: 01600/10000
[A[ATraining Step: 2852  | total loss: [1m[32m0.56519[0m[0m | time: 26.759s
[2K| Adam | epoch: 019 | loss: 0.56519 - acc: 0.7938 -- iter: 01664/10000
[A[ATraining Step: 2853  | total loss: [1m[32m0.55582[0m[0m | time: 27.819s
[2K| Adam | epoch: 019 | loss: 0.55582 - acc: 0.7941 -- iter: 01728/10000
[A[ATraining Step: 2854  | total loss: [1m[32m0.54847[0m[0m | time: 28.883s
[2K| Adam | epoch: 019 | loss: 0.54847 - acc: 0.7943 -- iter: 01792/10000
[A[ATraining Step: 2855  | total loss: [1m[32m0.54315[0m[0m | time: 30.029s
[2K| Adam | epoch: 019 | loss: 0.54315 - acc: 0.7977 -- iter: 01856/10000
[A[ATraining Step: 2856  | total loss: [1m[32m0.53744[0m[0m | time: 31.224s
[2K| Adam | epoch: 019 | loss: 0.53744 - acc: 0.8008 -- iter: 01920/10000
[A[ATraining Step: 2857  | total loss: [1m[32m0.53820[0m[0m | time: 32.384s
[2K| Adam | epoch: 019 | loss: 0.53820 - acc: 0.8066 -- iter: 01984/10000
[A[ATraining Step: 2858  | total loss: [1m[32m0.56809[0m[0m | time: 33.534s
[2K| Adam | epoch: 019 | loss: 0.56809 - acc: 0.8041 -- iter: 02048/10000
[A[ATraining Step: 2859  | total loss: [1m[32m0.56952[0m[0m | time: 34.663s
[2K| Adam | epoch: 019 | loss: 0.56952 - acc: 0.8049 -- iter: 02112/10000
[A[ATraining Step: 2860  | total loss: [1m[32m0.56107[0m[0m | time: 35.711s
[2K| Adam | epoch: 019 | loss: 0.56107 - acc: 0.8104 -- iter: 02176/10000
[A[ATraining Step: 2861  | total loss: [1m[32m0.56201[0m[0m | time: 36.674s
[2K| Adam | epoch: 019 | loss: 0.56201 - acc: 0.8059 -- iter: 02240/10000
[A[ATraining Step: 2862  | total loss: [1m[32m0.55444[0m[0m | time: 37.620s
[2K| Adam | epoch: 019 | loss: 0.55444 - acc: 0.8034 -- iter: 02304/10000
[A[ATraining Step: 2863  | total loss: [1m[32m0.55375[0m[0m | time: 38.578s
[2K| Adam | epoch: 019 | loss: 0.55375 - acc: 0.8075 -- iter: 02368/10000
[A[ATraining Step: 2864  | total loss: [1m[32m0.54426[0m[0m | time: 39.542s
[2K| Adam | epoch: 019 | loss: 0.54426 - acc: 0.8095 -- iter: 02432/10000
[A[ATraining Step: 2865  | total loss: [1m[32m0.54953[0m[0m | time: 40.501s
[2K| Adam | epoch: 019 | loss: 0.54953 - acc: 0.7989 -- iter: 02496/10000
[A[ATraining Step: 2866  | total loss: [1m[32m0.53323[0m[0m | time: 41.486s
[2K| Adam | epoch: 019 | loss: 0.53323 - acc: 0.8003 -- iter: 02560/10000
[A[ATraining Step: 2867  | total loss: [1m[32m0.53330[0m[0m | time: 42.442s
[2K| Adam | epoch: 019 | loss: 0.53330 - acc: 0.7952 -- iter: 02624/10000
[A[ATraining Step: 2868  | total loss: [1m[32m0.52895[0m[0m | time: 43.448s
[2K| Adam | epoch: 019 | loss: 0.52895 - acc: 0.7985 -- iter: 02688/10000
[A[ATraining Step: 2869  | total loss: [1m[32m0.53341[0m[0m | time: 44.447s
[2K| Adam | epoch: 019 | loss: 0.53341 - acc: 0.7921 -- iter: 02752/10000
[A[ATraining Step: 2870  | total loss: [1m[32m0.54823[0m[0m | time: 45.463s
[2K| Adam | epoch: 019 | loss: 0.54823 - acc: 0.7879 -- iter: 02816/10000
[A[ATraining Step: 2871  | total loss: [1m[32m0.56884[0m[0m | time: 46.490s
[2K| Adam | epoch: 019 | loss: 0.56884 - acc: 0.7779 -- iter: 02880/10000
[A[ATraining Step: 2872  | total loss: [1m[32m0.59342[0m[0m | time: 47.505s
[2K| Adam | epoch: 019 | loss: 0.59342 - acc: 0.7751 -- iter: 02944/10000
[A[ATraining Step: 2873  | total loss: [1m[32m0.59636[0m[0m | time: 48.523s
[2K| Adam | epoch: 019 | loss: 0.59636 - acc: 0.7772 -- iter: 03008/10000
[A[ATraining Step: 2874  | total loss: [1m[32m0.57841[0m[0m | time: 49.569s
[2K| Adam | epoch: 019 | loss: 0.57841 - acc: 0.7823 -- iter: 03072/10000
[A[ATraining Step: 2875  | total loss: [1m[32m0.56033[0m[0m | time: 50.567s
[2K| Adam | epoch: 019 | loss: 0.56033 - acc: 0.7916 -- iter: 03136/10000
[A[ATraining Step: 2876  | total loss: [1m[32m0.54436[0m[0m | time: 51.634s
[2K| Adam | epoch: 019 | loss: 0.54436 - acc: 0.7984 -- iter: 03200/10000
[A[ATraining Step: 2877  | total loss: [1m[32m0.54902[0m[0m | time: 52.657s
[2K| Adam | epoch: 019 | loss: 0.54902 - acc: 0.8029 -- iter: 03264/10000
[A[ATraining Step: 2878  | total loss: [1m[32m0.56421[0m[0m | time: 53.734s
[2K| Adam | epoch: 019 | loss: 0.56421 - acc: 0.7961 -- iter: 03328/10000
[A[ATraining Step: 2879  | total loss: [1m[32m0.54882[0m[0m | time: 54.808s
[2K| Adam | epoch: 019 | loss: 0.54882 - acc: 0.8040 -- iter: 03392/10000
[A[ATraining Step: 2880  | total loss: [1m[32m0.55037[0m[0m | time: 55.882s
[2K| Adam | epoch: 019 | loss: 0.55037 - acc: 0.8032 -- iter: 03456/10000
[A[ATraining Step: 2881  | total loss: [1m[32m0.54945[0m[0m | time: 56.967s
[2K| Adam | epoch: 019 | loss: 0.54945 - acc: 0.8026 -- iter: 03520/10000
[A[ATraining Step: 2882  | total loss: [1m[32m0.55048[0m[0m | time: 58.055s
[2K| Adam | epoch: 019 | loss: 0.55048 - acc: 0.8036 -- iter: 03584/10000
[A[ATraining Step: 2883  | total loss: [1m[32m0.54476[0m[0m | time: 59.300s
[2K| Adam | epoch: 019 | loss: 0.54476 - acc: 0.8076 -- iter: 03648/10000
[A[ATraining Step: 2884  | total loss: [1m[32m0.54699[0m[0m | time: 60.594s
[2K| Adam | epoch: 019 | loss: 0.54699 - acc: 0.8019 -- iter: 03712/10000
[A[ATraining Step: 2885  | total loss: [1m[32m0.53570[0m[0m | time: 61.918s
[2K| Adam | epoch: 019 | loss: 0.53570 - acc: 0.8076 -- iter: 03776/10000
[A[ATraining Step: 2886  | total loss: [1m[32m0.55087[0m[0m | time: 63.139s
[2K| Adam | epoch: 019 | loss: 0.55087 - acc: 0.8018 -- iter: 03840/10000
[A[ATraining Step: 2887  | total loss: [1m[32m0.55695[0m[0m | time: 64.332s
[2K| Adam | epoch: 019 | loss: 0.55695 - acc: 0.8029 -- iter: 03904/10000
[A[ATraining Step: 2888  | total loss: [1m[32m0.55341[0m[0m | time: 65.459s
[2K| Adam | epoch: 019 | loss: 0.55341 - acc: 0.7976 -- iter: 03968/10000
[A[ATraining Step: 2889  | total loss: [1m[32m0.54050[0m[0m | time: 66.624s
[2K| Adam | epoch: 019 | loss: 0.54050 - acc: 0.8022 -- iter: 04032/10000
[A[ATraining Step: 2890  | total loss: [1m[32m0.54071[0m[0m | time: 67.780s
[2K| Adam | epoch: 019 | loss: 0.54071 - acc: 0.7986 -- iter: 04096/10000
[A[ATraining Step: 2891  | total loss: [1m[32m0.56901[0m[0m | time: 68.869s
[2K| Adam | epoch: 019 | loss: 0.56901 - acc: 0.7906 -- iter: 04160/10000
[A[ATraining Step: 2892  | total loss: [1m[32m0.55951[0m[0m | time: 69.966s
[2K| Adam | epoch: 019 | loss: 0.55951 - acc: 0.7959 -- iter: 04224/10000
[A[ATraining Step: 2893  | total loss: [1m[32m0.56874[0m[0m | time: 71.072s
[2K| Adam | epoch: 019 | loss: 0.56874 - acc: 0.7913 -- iter: 04288/10000
[A[ATraining Step: 2894  | total loss: [1m[32m0.56738[0m[0m | time: 72.217s
[2K| Adam | epoch: 019 | loss: 0.56738 - acc: 0.7919 -- iter: 04352/10000
[A[ATraining Step: 2895  | total loss: [1m[32m0.56334[0m[0m | time: 73.332s
[2K| Adam | epoch: 019 | loss: 0.56334 - acc: 0.7971 -- iter: 04416/10000
[A[ATraining Step: 2896  | total loss: [1m[32m0.56273[0m[0m | time: 74.456s
[2K| Adam | epoch: 019 | loss: 0.56273 - acc: 0.7986 -- iter: 04480/10000
[A[ATraining Step: 2897  | total loss: [1m[32m0.56022[0m[0m | time: 75.635s
[2K| Adam | epoch: 019 | loss: 0.56022 - acc: 0.7969 -- iter: 04544/10000
[A[ATraining Step: 2898  | total loss: [1m[32m0.55221[0m[0m | time: 76.845s
[2K| Adam | epoch: 019 | loss: 0.55221 - acc: 0.7937 -- iter: 04608/10000
[A[ATraining Step: 2899  | total loss: [1m[32m0.56516[0m[0m | time: 78.085s
[2K| Adam | epoch: 019 | loss: 0.56516 - acc: 0.7909 -- iter: 04672/10000
[A[ATraining Step: 2900  | total loss: [1m[32m0.58235[0m[0m | time: 82.766s
[2K| Adam | epoch: 019 | loss: 0.58235 - acc: 0.7915 | val_loss: 2.68603 - val_acc: 0.3500 -- iter: 04736/10000
--
Training Step: 2901  | total loss: [1m[32m0.57563[0m[0m | time: 84.056s
[2K| Adam | epoch: 019 | loss: 0.57563 - acc: 0.7936 -- iter: 04800/10000
[A[ATraining Step: 2902  | total loss: [1m[32m0.57392[0m[0m | time: 85.313s
[2K| Adam | epoch: 019 | loss: 0.57392 - acc: 0.7939 -- iter: 04864/10000
[A[ATraining Step: 2903  | total loss: [1m[32m0.56189[0m[0m | time: 86.619s
[2K| Adam | epoch: 019 | loss: 0.56189 - acc: 0.7911 -- iter: 04928/10000
[A[ATraining Step: 2904  | total loss: [1m[32m0.58030[0m[0m | time: 87.927s
[2K| Adam | epoch: 019 | loss: 0.58030 - acc: 0.7776 -- iter: 04992/10000
[A[ATraining Step: 2905  | total loss: [1m[32m0.58139[0m[0m | time: 89.108s
[2K| Adam | epoch: 019 | loss: 0.58139 - acc: 0.7796 -- iter: 05056/10000
[A[ATraining Step: 2906  | total loss: [1m[32m0.57320[0m[0m | time: 90.276s
[2K| Adam | epoch: 019 | loss: 0.57320 - acc: 0.7750 -- iter: 05120/10000
[A[ATraining Step: 2907  | total loss: [1m[32m0.58105[0m[0m | time: 91.466s
[2K| Adam | epoch: 019 | loss: 0.58105 - acc: 0.7772 -- iter: 05184/10000
[A[ATraining Step: 2908  | total loss: [1m[32m0.57261[0m[0m | time: 92.570s
[2K| Adam | epoch: 019 | loss: 0.57261 - acc: 0.7823 -- iter: 05248/10000
[A[ATraining Step: 2909  | total loss: [1m[32m0.55902[0m[0m | time: 93.698s
[2K| Adam | epoch: 019 | loss: 0.55902 - acc: 0.7931 -- iter: 05312/10000
[A[ATraining Step: 2910  | total loss: [1m[32m0.55536[0m[0m | time: 94.660s
[2K| Adam | epoch: 019 | loss: 0.55536 - acc: 0.7888 -- iter: 05376/10000
[A[ATraining Step: 2911  | total loss: [1m[32m0.55989[0m[0m | time: 95.612s
[2K| Adam | epoch: 019 | loss: 0.55989 - acc: 0.7912 -- iter: 05440/10000
[A[ATraining Step: 2912  | total loss: [1m[32m0.55366[0m[0m | time: 96.563s
[2K| Adam | epoch: 019 | loss: 0.55366 - acc: 0.7902 -- iter: 05504/10000
[A[ATraining Step: 2913  | total loss: [1m[32m0.55523[0m[0m | time: 97.534s
[2K| Adam | epoch: 019 | loss: 0.55523 - acc: 0.7846 -- iter: 05568/10000
[A[ATraining Step: 2914  | total loss: [1m[32m0.57028[0m[0m | time: 98.494s
[2K| Adam | epoch: 019 | loss: 0.57028 - acc: 0.7812 -- iter: 05632/10000
[A[ATraining Step: 2915  | total loss: [1m[32m0.57888[0m[0m | time: 99.458s
[2K| Adam | epoch: 019 | loss: 0.57888 - acc: 0.7812 -- iter: 05696/10000
[A[ATraining Step: 2916  | total loss: [1m[32m0.58315[0m[0m | time: 100.457s
[2K| Adam | epoch: 019 | loss: 0.58315 - acc: 0.7827 -- iter: 05760/10000
[A[ATraining Step: 2917  | total loss: [1m[32m0.60398[0m[0m | time: 101.484s
[2K| Adam | epoch: 019 | loss: 0.60398 - acc: 0.7763 -- iter: 05824/10000
[A[ATraining Step: 2918  | total loss: [1m[32m0.58321[0m[0m | time: 102.483s
[2K| Adam | epoch: 019 | loss: 0.58321 - acc: 0.7815 -- iter: 05888/10000
[A[ATraining Step: 2919  | total loss: [1m[32m0.60006[0m[0m | time: 103.500s
[2K| Adam | epoch: 019 | loss: 0.60006 - acc: 0.7768 -- iter: 05952/10000
[A[ATraining Step: 2920  | total loss: [1m[32m0.59345[0m[0m | time: 104.522s
[2K| Adam | epoch: 019 | loss: 0.59345 - acc: 0.7866 -- iter: 06016/10000
[A[ATraining Step: 2921  | total loss: [1m[32m0.58242[0m[0m | time: 105.578s
[2K| Adam | epoch: 019 | loss: 0.58242 - acc: 0.7892 -- iter: 06080/10000
[A[ATraining Step: 2922  | total loss: [1m[32m0.58857[0m[0m | time: 106.639s
[2K| Adam | epoch: 019 | loss: 0.58857 - acc: 0.7978 -- iter: 06144/10000
[A[ATraining Step: 2923  | total loss: [1m[32m0.58667[0m[0m | time: 107.722s
[2K| Adam | epoch: 019 | loss: 0.58667 - acc: 0.7946 -- iter: 06208/10000
[A[ATraining Step: 2924  | total loss: [1m[32m0.56851[0m[0m | time: 108.793s
[2K| Adam | epoch: 019 | loss: 0.56851 - acc: 0.8026 -- iter: 06272/10000
[A[ATraining Step: 2925  | total loss: [1m[32m0.56742[0m[0m | time: 109.853s
[2K| Adam | epoch: 019 | loss: 0.56742 - acc: 0.8005 -- iter: 06336/10000
[A[ATraining Step: 2926  | total loss: [1m[32m0.56181[0m[0m | time: 110.914s
[2K| Adam | epoch: 019 | loss: 0.56181 - acc: 0.8032 -- iter: 06400/10000
[A[ATraining Step: 2927  | total loss: [1m[32m0.57139[0m[0m | time: 112.025s
[2K| Adam | epoch: 019 | loss: 0.57139 - acc: 0.7932 -- iter: 06464/10000
[A[ATraining Step: 2928  | total loss: [1m[32m0.58238[0m[0m | time: 113.088s
[2K| Adam | epoch: 019 | loss: 0.58238 - acc: 0.7920 -- iter: 06528/10000
[A[ATraining Step: 2929  | total loss: [1m[32m0.59068[0m[0m | time: 114.168s
[2K| Adam | epoch: 019 | loss: 0.59068 - acc: 0.7878 -- iter: 06592/10000
[A[ATraining Step: 2930  | total loss: [1m[32m0.59476[0m[0m | time: 115.234s
[2K| Adam | epoch: 019 | loss: 0.59476 - acc: 0.7856 -- iter: 06656/10000
[A[ATraining Step: 2931  | total loss: [1m[32m0.60219[0m[0m | time: 116.304s
[2K| Adam | epoch: 019 | loss: 0.60219 - acc: 0.7820 -- iter: 06720/10000
[A[ATraining Step: 2932  | total loss: [1m[32m0.59158[0m[0m | time: 117.368s
[2K| Adam | epoch: 019 | loss: 0.59158 - acc: 0.7867 -- iter: 06784/10000
[A[ATraining Step: 2933  | total loss: [1m[32m0.60610[0m[0m | time: 118.438s
[2K| Adam | epoch: 019 | loss: 0.60610 - acc: 0.7830 -- iter: 06848/10000
[A[ATraining Step: 2934  | total loss: [1m[32m0.59880[0m[0m | time: 119.435s
[2K| Adam | epoch: 019 | loss: 0.59880 - acc: 0.7859 -- iter: 06912/10000
[A[ATraining Step: 2935  | total loss: [1m[32m0.57484[0m[0m | time: 120.446s
[2K| Adam | epoch: 019 | loss: 0.57484 - acc: 0.7933 -- iter: 06976/10000
[A[ATraining Step: 2936  | total loss: [1m[32m0.58132[0m[0m | time: 121.488s
[2K| Adam | epoch: 019 | loss: 0.58132 - acc: 0.7905 -- iter: 07040/10000
[A[ATraining Step: 2937  | total loss: [1m[32m0.57336[0m[0m | time: 122.490s
[2K| Adam | epoch: 019 | loss: 0.57336 - acc: 0.7943 -- iter: 07104/10000
[A[ATraining Step: 2938  | total loss: [1m[32m0.58729[0m[0m | time: 123.505s
[2K| Adam | epoch: 019 | loss: 0.58729 - acc: 0.7914 -- iter: 07168/10000
[A[ATraining Step: 2939  | total loss: [1m[32m0.58950[0m[0m | time: 124.505s
[2K| Adam | epoch: 019 | loss: 0.58950 - acc: 0.7904 -- iter: 07232/10000
[A[ATraining Step: 2940  | total loss: [1m[32m0.57938[0m[0m | time: 125.513s
[2K| Adam | epoch: 019 | loss: 0.57938 - acc: 0.7879 -- iter: 07296/10000
[A[ATraining Step: 2941  | total loss: [1m[32m0.57308[0m[0m | time: 126.512s
[2K| Adam | epoch: 019 | loss: 0.57308 - acc: 0.7919 -- iter: 07360/10000
[A[ATraining Step: 2942  | total loss: [1m[32m0.56939[0m[0m | time: 127.520s
[2K| Adam | epoch: 019 | loss: 0.56939 - acc: 0.7924 -- iter: 07424/10000
[A[ATraining Step: 2943  | total loss: [1m[32m0.56764[0m[0m | time: 128.575s
[2K| Adam | epoch: 019 | loss: 0.56764 - acc: 0.7913 -- iter: 07488/10000
[A[ATraining Step: 2944  | total loss: [1m[32m0.56871[0m[0m | time: 129.651s
[2K| Adam | epoch: 019 | loss: 0.56871 - acc: 0.7919 -- iter: 07552/10000
[A[ATraining Step: 2945  | total loss: [1m[32m0.57187[0m[0m | time: 130.617s
[2K| Adam | epoch: 019 | loss: 0.57187 - acc: 0.7861 -- iter: 07616/10000
[A[ATraining Step: 2946  | total loss: [1m[32m0.57041[0m[0m | time: 131.611s
[2K| Adam | epoch: 019 | loss: 0.57041 - acc: 0.7841 -- iter: 07680/10000
[A[ATraining Step: 2947  | total loss: [1m[32m0.56416[0m[0m | time: 132.565s
[2K| Adam | epoch: 019 | loss: 0.56416 - acc: 0.7854 -- iter: 07744/10000
[A[ATraining Step: 2948  | total loss: [1m[32m0.56928[0m[0m | time: 133.522s
[2K| Adam | epoch: 019 | loss: 0.56928 - acc: 0.7818 -- iter: 07808/10000
[A[ATraining Step: 2949  | total loss: [1m[32m0.57672[0m[0m | time: 134.500s
[2K| Adam | epoch: 019 | loss: 0.57672 - acc: 0.7739 -- iter: 07872/10000
[A[ATraining Step: 2950  | total loss: [1m[32m0.57547[0m[0m | time: 135.473s
[2K| Adam | epoch: 019 | loss: 0.57547 - acc: 0.7825 -- iter: 07936/10000
[A[ATraining Step: 2951  | total loss: [1m[32m0.56288[0m[0m | time: 136.418s
[2K| Adam | epoch: 019 | loss: 0.56288 - acc: 0.7855 -- iter: 08000/10000
[A[ATraining Step: 2952  | total loss: [1m[32m0.56303[0m[0m | time: 137.374s
[2K| Adam | epoch: 019 | loss: 0.56303 - acc: 0.7898 -- iter: 08064/10000
[A[ATraining Step: 2953  | total loss: [1m[32m0.55505[0m[0m | time: 138.284s
[2K| Adam | epoch: 019 | loss: 0.55505 - acc: 0.7967 -- iter: 08128/10000
[A[ATraining Step: 2954  | total loss: [1m[32m0.53727[0m[0m | time: 139.256s
[2K| Adam | epoch: 019 | loss: 0.53727 - acc: 0.8030 -- iter: 08192/10000
[A[ATraining Step: 2955  | total loss: [1m[32m0.55789[0m[0m | time: 140.300s
[2K| Adam | epoch: 019 | loss: 0.55789 - acc: 0.8008 -- iter: 08256/10000
[A[ATraining Step: 2956  | total loss: [1m[32m0.56474[0m[0m | time: 141.441s
[2K| Adam | epoch: 019 | loss: 0.56474 - acc: 0.8020 -- iter: 08320/10000
[A[ATraining Step: 2957  | total loss: [1m[32m0.57820[0m[0m | time: 142.545s
[2K| Adam | epoch: 019 | loss: 0.57820 - acc: 0.8015 -- iter: 08384/10000
[A[ATraining Step: 2958  | total loss: [1m[32m0.55650[0m[0m | time: 143.571s
[2K| Adam | epoch: 019 | loss: 0.55650 - acc: 0.8119 -- iter: 08448/10000
[A[ATraining Step: 2959  | total loss: [1m[32m0.55653[0m[0m | time: 144.598s
[2K| Adam | epoch: 019 | loss: 0.55653 - acc: 0.8120 -- iter: 08512/10000
[A[ATraining Step: 2960  | total loss: [1m[32m0.54294[0m[0m | time: 145.555s
[2K| Adam | epoch: 019 | loss: 0.54294 - acc: 0.8136 -- iter: 08576/10000
[A[ATraining Step: 2961  | total loss: [1m[32m0.53660[0m[0m | time: 146.503s
[2K| Adam | epoch: 019 | loss: 0.53660 - acc: 0.8135 -- iter: 08640/10000
[A[ATraining Step: 2962  | total loss: [1m[32m0.52463[0m[0m | time: 147.458s
[2K| Adam | epoch: 019 | loss: 0.52463 - acc: 0.8134 -- iter: 08704/10000
[A[ATraining Step: 2963  | total loss: [1m[32m0.53414[0m[0m | time: 148.414s
[2K| Adam | epoch: 019 | loss: 0.53414 - acc: 0.8117 -- iter: 08768/10000
[A[ATraining Step: 2964  | total loss: [1m[32m0.55185[0m[0m | time: 149.372s
[2K| Adam | epoch: 019 | loss: 0.55185 - acc: 0.8040 -- iter: 08832/10000
[A[ATraining Step: 2965  | total loss: [1m[32m0.55552[0m[0m | time: 150.323s
[2K| Adam | epoch: 019 | loss: 0.55552 - acc: 0.8017 -- iter: 08896/10000
[A[ATraining Step: 2966  | total loss: [1m[32m0.55011[0m[0m | time: 151.307s
[2K| Adam | epoch: 019 | loss: 0.55011 - acc: 0.7997 -- iter: 08960/10000
[A[ATraining Step: 2967  | total loss: [1m[32m0.54433[0m[0m | time: 152.266s
[2K| Adam | epoch: 019 | loss: 0.54433 - acc: 0.7963 -- iter: 09024/10000
[A[ATraining Step: 2968  | total loss: [1m[32m0.53540[0m[0m | time: 153.223s
[2K| Adam | epoch: 019 | loss: 0.53540 - acc: 0.7948 -- iter: 09088/10000
[A[ATraining Step: 2969  | total loss: [1m[32m0.55835[0m[0m | time: 154.239s
[2K| Adam | epoch: 019 | loss: 0.55835 - acc: 0.7934 -- iter: 09152/10000
[A[ATraining Step: 2970  | total loss: [1m[32m1.57589[0m[0m | time: 155.246s
[2K| Adam | epoch: 019 | loss: 1.57589 - acc: 0.7250 -- iter: 09216/10000
[A[ATraining Step: 2971  | total loss: [1m[32m1.46899[0m[0m | time: 156.271s
[2K| Adam | epoch: 019 | loss: 1.46899 - acc: 0.7353 -- iter: 09280/10000
[A[ATraining Step: 2972  | total loss: [1m[32m1.38891[0m[0m | time: 157.371s
[2K| Adam | epoch: 019 | loss: 1.38891 - acc: 0.7415 -- iter: 09344/10000
[A[ATraining Step: 2973  | total loss: [1m[32m1.31837[0m[0m | time: 158.475s
[2K| Adam | epoch: 019 | loss: 1.31837 - acc: 0.7408 -- iter: 09408/10000
[A[ATraining Step: 2974  | total loss: [1m[32m1.24125[0m[0m | time: 159.488s
[2K| Adam | epoch: 019 | loss: 1.24125 - acc: 0.7448 -- iter: 09472/10000
[A[ATraining Step: 2975  | total loss: [1m[32m1.17082[0m[0m | time: 160.441s
[2K| Adam | epoch: 019 | loss: 1.17082 - acc: 0.7485 -- iter: 09536/10000
[A[ATraining Step: 2976  | total loss: [1m[32m1.08436[0m[0m | time: 161.424s
[2K| Adam | epoch: 019 | loss: 1.08436 - acc: 0.7642 -- iter: 09600/10000
[A[ATraining Step: 2977  | total loss: [1m[32m1.00699[0m[0m | time: 162.398s
[2K| Adam | epoch: 019 | loss: 1.00699 - acc: 0.7722 -- iter: 09664/10000
[A[ATraining Step: 2978  | total loss: [1m[32m0.96120[0m[0m | time: 163.365s
[2K| Adam | epoch: 019 | loss: 0.96120 - acc: 0.7700 -- iter: 09728/10000
[A[ATraining Step: 2979  | total loss: [1m[32m0.91868[0m[0m | time: 164.317s
[2K| Adam | epoch: 019 | loss: 0.91868 - acc: 0.7711 -- iter: 09792/10000
[A[ATraining Step: 2980  | total loss: [1m[32m0.88729[0m[0m | time: 165.271s
[2K| Adam | epoch: 019 | loss: 0.88729 - acc: 0.7752 -- iter: 09856/10000
[A[ATraining Step: 2981  | total loss: [1m[32m0.86364[0m[0m | time: 166.226s
[2K| Adam | epoch: 019 | loss: 0.86364 - acc: 0.7774 -- iter: 09920/10000
[A[ATraining Step: 2982  | total loss: [1m[32m0.82928[0m[0m | time: 167.169s
[2K| Adam | epoch: 019 | loss: 0.82928 - acc: 0.7825 -- iter: 09984/10000
[A[ATraining Step: 2983  | total loss: [1m[32m0.78876[0m[0m | time: 170.678s
[2K| Adam | epoch: 019 | loss: 0.78876 - acc: 0.7933 | val_loss: 2.45835 - val_acc: 0.4029 -- iter: 10000/10000
--
Training Step: 2984  | total loss: [1m[32m0.76808[0m[0m | time: 1.005s
[2K| Adam | epoch: 020 | loss: 0.76808 - acc: 0.7890 -- iter: 00064/10000
[A[ATraining Step: 2985  | total loss: [1m[32m0.74914[0m[0m | time: 2.008s
[2K| Adam | epoch: 020 | loss: 0.74914 - acc: 0.7913 -- iter: 00128/10000
[A[ATraining Step: 2986  | total loss: [1m[32m0.71844[0m[0m | time: 3.021s
[2K| Adam | epoch: 020 | loss: 0.71844 - acc: 0.7997 -- iter: 00192/10000
[A[ATraining Step: 2987  | total loss: [1m[32m0.70741[0m[0m | time: 4.024s
[2K| Adam | epoch: 020 | loss: 0.70741 - acc: 0.7978 -- iter: 00256/10000
[A[ATraining Step: 2988  | total loss: [1m[32m0.67703[0m[0m | time: 5.035s
[2K| Adam | epoch: 020 | loss: 0.67703 - acc: 0.8024 -- iter: 00320/10000
[A[ATraining Step: 2989  | total loss: [1m[32m0.65222[0m[0m | time: 6.037s
[2K| Adam | epoch: 020 | loss: 0.65222 - acc: 0.8066 -- iter: 00384/10000
[A[ATraining Step: 2990  | total loss: [1m[32m0.64481[0m[0m | time: 7.042s
[2K| Adam | epoch: 020 | loss: 0.64481 - acc: 0.8056 -- iter: 00448/10000
[A[ATraining Step: 2991  | total loss: [1m[32m0.61548[0m[0m | time: 8.112s
[2K| Adam | epoch: 020 | loss: 0.61548 - acc: 0.8078 -- iter: 00512/10000
[A[ATraining Step: 2992  | total loss: [1m[32m0.61133[0m[0m | time: 9.202s
[2K| Adam | epoch: 020 | loss: 0.61133 - acc: 0.8021 -- iter: 00576/10000
[A[ATraining Step: 2993  | total loss: [1m[32m0.61334[0m[0m | time: 10.302s
[2K| Adam | epoch: 020 | loss: 0.61334 - acc: 0.7937 -- iter: 00640/10000
[A[ATraining Step: 2994  | total loss: [1m[32m0.60521[0m[0m | time: 11.324s
[2K| Adam | epoch: 020 | loss: 0.60521 - acc: 0.7940 -- iter: 00704/10000
[A[ATraining Step: 2995  | total loss: [1m[32m0.59894[0m[0m | time: 12.276s
[2K| Adam | epoch: 020 | loss: 0.59894 - acc: 0.7975 -- iter: 00768/10000
[A[ATraining Step: 2996  | total loss: [1m[32m0.58979[0m[0m | time: 13.233s
[2K| Adam | epoch: 020 | loss: 0.58979 - acc: 0.7943 -- iter: 00832/10000
[A[ATraining Step: 2997  | total loss: [1m[32m0.59473[0m[0m | time: 14.193s
[2K| Adam | epoch: 020 | loss: 0.59473 - acc: 0.7992 -- iter: 00896/10000
[A[ATraining Step: 2998  | total loss: [1m[32m0.56627[0m[0m | time: 15.141s
[2K| Adam | epoch: 020 | loss: 0.56627 - acc: 0.8084 -- iter: 00960/10000
[A[ATraining Step: 2999  | total loss: [1m[32m0.56199[0m[0m | time: 16.089s
[2K| Adam | epoch: 020 | loss: 0.56199 - acc: 0.8135 -- iter: 01024/10000
[A[ATraining Step: 3000  | total loss: [1m[32m0.56303[0m[0m | time: 19.536s
[2K| Adam | epoch: 020 | loss: 0.56303 - acc: 0.8071 | val_loss: 2.53844 - val_acc: 0.3957 -- iter: 01088/10000
--
Training Step: 3001  | total loss: [1m[32m0.56100[0m[0m | time: 19.976s
[2K| Adam | epoch: 020 | loss: 0.56100 - acc: 0.8061 -- iter: 01152/10000
[A[ATraining Step: 3002  | total loss: [1m[32m0.53783[0m[0m | time: 20.404s
[2K| Adam | epoch: 020 | loss: 0.53783 - acc: 0.8130 -- iter: 01216/10000
[A[ATraining Step: 3003  | total loss: [1m[32m0.51121[0m[0m | time: 21.437s
[2K| Adam | epoch: 020 | loss: 0.51121 - acc: 0.8317 -- iter: 01280/10000
[A[ATraining Step: 3004  | total loss: [1m[32m0.50890[0m[0m | time: 22.468s
[2K| Adam | epoch: 020 | loss: 0.50890 - acc: 0.8298 -- iter: 01344/10000
[A[ATraining Step: 3005  | total loss: [1m[32m0.53259[0m[0m | time: 23.468s
[2K| Adam | epoch: 020 | loss: 0.53259 - acc: 0.8202 -- iter: 01408/10000
[A[ATraining Step: 3006  | total loss: [1m[32m0.53956[0m[0m | time: 24.476s
[2K| Adam | epoch: 020 | loss: 0.53956 - acc: 0.8179 -- iter: 01472/10000
[A[ATraining Step: 3007  | total loss: [1m[32m0.52688[0m[0m | time: 25.474s
[2K| Adam | epoch: 020 | loss: 0.52688 - acc: 0.8189 -- iter: 01536/10000
[A[ATraining Step: 3008  | total loss: [1m[32m0.53027[0m[0m | time: 26.475s
[2K| Adam | epoch: 020 | loss: 0.53027 - acc: 0.8151 -- iter: 01600/10000
[A[ATraining Step: 3009  | total loss: [1m[32m0.54052[0m[0m | time: 27.529s
[2K| Adam | epoch: 020 | loss: 0.54052 - acc: 0.8149 -- iter: 01664/10000
[A[ATraining Step: 3010  | total loss: [1m[32m0.53403[0m[0m | time: 28.535s
[2K| Adam | epoch: 020 | loss: 0.53403 - acc: 0.8131 -- iter: 01728/10000
[A[ATraining Step: 3011  | total loss: [1m[32m0.53664[0m[0m | time: 29.546s
[2K| Adam | epoch: 020 | loss: 0.53664 - acc: 0.8099 -- iter: 01792/10000
[A[ATraining Step: 3012  | total loss: [1m[32m0.52423[0m[0m | time: 30.574s
[2K| Adam | epoch: 020 | loss: 0.52423 - acc: 0.8133 -- iter: 01856/10000
[A[ATraining Step: 3013  | total loss: [1m[32m0.51537[0m[0m | time: 31.579s
[2K| Adam | epoch: 020 | loss: 0.51537 - acc: 0.8179 -- iter: 01920/10000
[A[ATraining Step: 3014  | total loss: [1m[32m0.52090[0m[0m | time: 32.584s
[2K| Adam | epoch: 020 | loss: 0.52090 - acc: 0.8205 -- iter: 01984/10000
[A[ATraining Step: 3015  | total loss: [1m[32m0.51504[0m[0m | time: 33.600s
[2K| Adam | epoch: 020 | loss: 0.51504 - acc: 0.8212 -- iter: 02048/10000
[A[ATraining Step: 3016  | total loss: [1m[32m0.50915[0m[0m | time: 34.679s
[2K| Adam | epoch: 020 | loss: 0.50915 - acc: 0.8188 -- iter: 02112/10000
[A[ATraining Step: 3017  | total loss: [1m[32m0.50735[0m[0m | time: 35.780s
[2K| Adam | epoch: 020 | loss: 0.50735 - acc: 0.8197 -- iter: 02176/10000
[A[ATraining Step: 3018  | total loss: [1m[32m0.50903[0m[0m | time: 36.844s
[2K| Adam | epoch: 020 | loss: 0.50903 - acc: 0.8175 -- iter: 02240/10000
[A[ATraining Step: 3019  | total loss: [1m[32m0.49941[0m[0m | time: 37.792s
[2K| Adam | epoch: 020 | loss: 0.49941 - acc: 0.8170 -- iter: 02304/10000
[A[ATraining Step: 3020  | total loss: [1m[32m0.50919[0m[0m | time: 38.713s
[2K| Adam | epoch: 020 | loss: 0.50919 - acc: 0.8071 -- iter: 02368/10000
[A[ATraining Step: 3021  | total loss: [1m[32m0.50508[0m[0m | time: 39.666s
[2K| Adam | epoch: 020 | loss: 0.50508 - acc: 0.8092 -- iter: 02432/10000
[A[ATraining Step: 3022  | total loss: [1m[32m0.51180[0m[0m | time: 40.653s
[2K| Adam | epoch: 020 | loss: 0.51180 - acc: 0.8096 -- iter: 02496/10000
[A[ATraining Step: 3023  | total loss: [1m[32m0.51776[0m[0m | time: 41.628s
[2K| Adam | epoch: 020 | loss: 0.51776 - acc: 0.8099 -- iter: 02560/10000
[A[ATraining Step: 3024  | total loss: [1m[32m0.51382[0m[0m | time: 42.576s
[2K| Adam | epoch: 020 | loss: 0.51382 - acc: 0.8039 -- iter: 02624/10000
[A[ATraining Step: 3025  | total loss: [1m[32m0.52168[0m[0m | time: 43.539s
[2K| Adam | epoch: 020 | loss: 0.52168 - acc: 0.8000 -- iter: 02688/10000
[A[ATraining Step: 3026  | total loss: [1m[32m0.53250[0m[0m | time: 44.493s
[2K| Adam | epoch: 020 | loss: 0.53250 - acc: 0.8013 -- iter: 02752/10000
[A[ATraining Step: 3027  | total loss: [1m[32m0.52572[0m[0m | time: 45.445s
[2K| Adam | epoch: 020 | loss: 0.52572 - acc: 0.8071 -- iter: 02816/10000
[A[ATraining Step: 3028  | total loss: [1m[32m0.52690[0m[0m | time: 46.415s
[2K| Adam | epoch: 020 | loss: 0.52690 - acc: 0.8092 -- iter: 02880/10000
[A[ATraining Step: 3029  | total loss: [1m[32m0.52945[0m[0m | time: 47.419s
[2K| Adam | epoch: 020 | loss: 0.52945 - acc: 0.8127 -- iter: 02944/10000
[A[ATraining Step: 3030  | total loss: [1m[32m0.53389[0m[0m | time: 48.514s
[2K| Adam | epoch: 020 | loss: 0.53389 - acc: 0.8158 -- iter: 03008/10000
[A[ATraining Step: 3031  | total loss: [1m[32m0.53070[0m[0m | time: 49.621s
[2K| Adam | epoch: 020 | loss: 0.53070 - acc: 0.8186 -- iter: 03072/10000
[A[ATraining Step: 3032  | total loss: [1m[32m0.53760[0m[0m | time: 50.785s
[2K| Adam | epoch: 020 | loss: 0.53760 - acc: 0.8180 -- iter: 03136/10000
[A[ATraining Step: 3033  | total loss: [1m[32m0.53406[0m[0m | time: 51.779s
[2K| Adam | epoch: 020 | loss: 0.53406 - acc: 0.8190 -- iter: 03200/10000
[A[ATraining Step: 3034  | total loss: [1m[32m0.54182[0m[0m | time: 52.729s
[2K| Adam | epoch: 020 | loss: 0.54182 - acc: 0.8136 -- iter: 03264/10000
[A[ATraining Step: 3035  | total loss: [1m[32m0.51617[0m[0m | time: 53.680s
[2K| Adam | epoch: 020 | loss: 0.51617 - acc: 0.8151 -- iter: 03328/10000
[A[ATraining Step: 3036  | total loss: [1m[32m0.50820[0m[0m | time: 54.632s
[2K| Adam | epoch: 020 | loss: 0.50820 - acc: 0.8195 -- iter: 03392/10000
[A[ATraining Step: 3037  | total loss: [1m[32m0.51429[0m[0m | time: 55.582s
[2K| Adam | epoch: 020 | loss: 0.51429 - acc: 0.8094 -- iter: 03456/10000
[A[ATraining Step: 3038  | total loss: [1m[32m0.51040[0m[0m | time: 56.536s
[2K| Adam | epoch: 020 | loss: 0.51040 - acc: 0.8113 -- iter: 03520/10000
[A[ATraining Step: 3039  | total loss: [1m[32m0.50679[0m[0m | time: 57.499s
[2K| Adam | epoch: 020 | loss: 0.50679 - acc: 0.8083 -- iter: 03584/10000
[A[ATraining Step: 3040  | total loss: [1m[32m0.51327[0m[0m | time: 58.451s
[2K| Adam | epoch: 020 | loss: 0.51327 - acc: 0.8025 -- iter: 03648/10000
[A[ATraining Step: 3041  | total loss: [1m[32m0.50245[0m[0m | time: 59.404s
[2K| Adam | epoch: 020 | loss: 0.50245 - acc: 0.8097 -- iter: 03712/10000
[A[ATraining Step: 3042  | total loss: [1m[32m0.51267[0m[0m | time: 60.355s
[2K| Adam | epoch: 020 | loss: 0.51267 - acc: 0.8100 -- iter: 03776/10000
[A[ATraining Step: 3043  | total loss: [1m[32m0.55707[0m[0m | time: 61.399s
[2K| Adam | epoch: 020 | loss: 0.55707 - acc: 0.8009 -- iter: 03840/10000
[A[ATraining Step: 3044  | total loss: [1m[32m0.54617[0m[0m | time: 62.409s
[2K| Adam | epoch: 020 | loss: 0.54617 - acc: 0.8083 -- iter: 03904/10000
[A[ATraining Step: 3045  | total loss: [1m[32m0.55906[0m[0m | time: 63.410s
[2K| Adam | epoch: 020 | loss: 0.55906 - acc: 0.8056 -- iter: 03968/10000
[A[ATraining Step: 3046  | total loss: [1m[32m0.57688[0m[0m | time: 64.366s
[2K| Adam | epoch: 020 | loss: 0.57688 - acc: 0.8000 -- iter: 04032/10000
[A[ATraining Step: 3047  | total loss: [1m[32m0.56086[0m[0m | time: 65.376s
[2K| Adam | epoch: 020 | loss: 0.56086 - acc: 0.8091 -- iter: 04096/10000
[A[ATraining Step: 3048  | total loss: [1m[32m0.56109[0m[0m | time: 66.372s
[2K| Adam | epoch: 020 | loss: 0.56109 - acc: 0.8157 -- iter: 04160/10000
[A[ATraining Step: 3049  | total loss: [1m[32m0.56746[0m[0m | time: 67.381s
[2K| Adam | epoch: 020 | loss: 0.56746 - acc: 0.8107 -- iter: 04224/10000
[A[ATraining Step: 3050  | total loss: [1m[32m0.55151[0m[0m | time: 68.388s
[2K| Adam | epoch: 020 | loss: 0.55151 - acc: 0.8140 -- iter: 04288/10000
[A[ATraining Step: 3051  | total loss: [1m[32m0.56094[0m[0m | time: 69.395s
[2K| Adam | epoch: 020 | loss: 0.56094 - acc: 0.8123 -- iter: 04352/10000
[A[ATraining Step: 3052  | total loss: [1m[32m0.55519[0m[0m | time: 70.394s
[2K| Adam | epoch: 020 | loss: 0.55519 - acc: 0.8123 -- iter: 04416/10000
[A[ATraining Step: 3053  | total loss: [1m[32m0.53223[0m[0m | time: 71.474s
[2K| Adam | epoch: 020 | loss: 0.53223 - acc: 0.8201 -- iter: 04480/10000
[A[ATraining Step: 3054  | total loss: [1m[32m0.52952[0m[0m | time: 72.683s
[2K| Adam | epoch: 020 | loss: 0.52952 - acc: 0.8131 -- iter: 04544/10000
[A[ATraining Step: 3055  | total loss: [1m[32m0.52752[0m[0m | time: 73.791s
[2K| Adam | epoch: 020 | loss: 0.52752 - acc: 0.8115 -- iter: 04608/10000
[A[ATraining Step: 3056  | total loss: [1m[32m0.51321[0m[0m | time: 74.893s
[2K| Adam | epoch: 020 | loss: 0.51321 - acc: 0.8132 -- iter: 04672/10000
[A[ATraining Step: 3057  | total loss: [1m[32m0.50718[0m[0m | time: 75.861s
[2K| Adam | epoch: 020 | loss: 0.50718 - acc: 0.8131 -- iter: 04736/10000
[A[ATraining Step: 3058  | total loss: [1m[32m0.51958[0m[0m | time: 76.807s
[2K| Adam | epoch: 020 | loss: 0.51958 - acc: 0.8099 -- iter: 04800/10000
[A[ATraining Step: 3059  | total loss: [1m[32m0.51670[0m[0m | time: 77.753s
[2K| Adam | epoch: 020 | loss: 0.51670 - acc: 0.8086 -- iter: 04864/10000
[A[ATraining Step: 3060  | total loss: [1m[32m0.50980[0m[0m | time: 78.712s
[2K| Adam | epoch: 020 | loss: 0.50980 - acc: 0.8137 -- iter: 04928/10000
[A[ATraining Step: 3061  | total loss: [1m[32m0.53026[0m[0m | time: 79.661s
[2K| Adam | epoch: 020 | loss: 0.53026 - acc: 0.8089 -- iter: 04992/10000
[A[ATraining Step: 3062  | total loss: [1m[32m0.51771[0m[0m | time: 80.636s
[2K| Adam | epoch: 020 | loss: 0.51771 - acc: 0.8170 -- iter: 05056/10000
[A[ATraining Step: 3063  | total loss: [1m[32m0.53366[0m[0m | time: 81.624s
[2K| Adam | epoch: 020 | loss: 0.53366 - acc: 0.8150 -- iter: 05120/10000
[A[ATraining Step: 3064  | total loss: [1m[32m0.54356[0m[0m | time: 82.575s
[2K| Adam | epoch: 020 | loss: 0.54356 - acc: 0.8117 -- iter: 05184/10000
[A[ATraining Step: 3065  | total loss: [1m[32m0.52556[0m[0m | time: 83.551s
[2K| Adam | epoch: 020 | loss: 0.52556 - acc: 0.8211 -- iter: 05248/10000
[A[ATraining Step: 3066  | total loss: [1m[32m0.51740[0m[0m | time: 84.553s
[2K| Adam | epoch: 020 | loss: 0.51740 - acc: 0.8249 -- iter: 05312/10000
[A[ATraining Step: 3067  | total loss: [1m[32m0.51395[0m[0m | time: 85.560s
[2K| Adam | epoch: 020 | loss: 0.51395 - acc: 0.8253 -- iter: 05376/10000
[A[ATraining Step: 3068  | total loss: [1m[32m0.53073[0m[0m | time: 86.578s
[2K| Adam | epoch: 020 | loss: 0.53073 - acc: 0.8115 -- iter: 05440/10000
[A[ATraining Step: 3069  | total loss: [1m[32m0.52585[0m[0m | time: 87.581s
[2K| Adam | epoch: 020 | loss: 0.52585 - acc: 0.8085 -- iter: 05504/10000
[A[ATraining Step: 3070  | total loss: [1m[32m0.51533[0m[0m | time: 88.592s
[2K| Adam | epoch: 020 | loss: 0.51533 - acc: 0.8120 -- iter: 05568/10000
[A[ATraining Step: 3071  | total loss: [1m[32m0.52500[0m[0m | time: 89.593s
[2K| Adam | epoch: 020 | loss: 0.52500 - acc: 0.8074 -- iter: 05632/10000
[A[ATraining Step: 3072  | total loss: [1m[32m0.52264[0m[0m | time: 90.635s
[2K| Adam | epoch: 020 | loss: 0.52264 - acc: 0.8032 -- iter: 05696/10000
[A[ATraining Step: 3073  | total loss: [1m[32m0.52470[0m[0m | time: 91.666s
[2K| Adam | epoch: 020 | loss: 0.52470 - acc: 0.8072 -- iter: 05760/10000
[A[ATraining Step: 3074  | total loss: [1m[32m0.51962[0m[0m | time: 92.670s
[2K| Adam | epoch: 020 | loss: 0.51962 - acc: 0.8140 -- iter: 05824/10000
[A[ATraining Step: 3075  | total loss: [1m[32m0.53464[0m[0m | time: 93.680s
[2K| Adam | epoch: 020 | loss: 0.53464 - acc: 0.8201 -- iter: 05888/10000
[A[ATraining Step: 3076  | total loss: [1m[32m0.53179[0m[0m | time: 94.690s
[2K| Adam | epoch: 020 | loss: 0.53179 - acc: 0.8209 -- iter: 05952/10000
[A[ATraining Step: 3077  | total loss: [1m[32m0.52110[0m[0m | time: 95.698s
[2K| Adam | epoch: 020 | loss: 0.52110 - acc: 0.8279 -- iter: 06016/10000
[A[ATraining Step: 3078  | total loss: [1m[32m0.53819[0m[0m | time: 96.697s
[2K| Adam | epoch: 020 | loss: 0.53819 - acc: 0.8232 -- iter: 06080/10000
[A[ATraining Step: 3079  | total loss: [1m[32m0.53837[0m[0m | time: 97.701s
[2K| Adam | epoch: 020 | loss: 0.53837 - acc: 0.8190 -- iter: 06144/10000
[A[ATraining Step: 3080  | total loss: [1m[32m0.52571[0m[0m | time: 98.773s
[2K| Adam | epoch: 020 | loss: 0.52571 - acc: 0.8262 -- iter: 06208/10000
[A[ATraining Step: 3081  | total loss: [1m[32m0.52767[0m[0m | time: 99.843s
[2K| Adam | epoch: 020 | loss: 0.52767 - acc: 0.8248 -- iter: 06272/10000
[A[ATraining Step: 3082  | total loss: [1m[32m0.53173[0m[0m | time: 100.954s
[2K| Adam | epoch: 020 | loss: 0.53173 - acc: 0.8142 -- iter: 06336/10000
[A[ATraining Step: 3083  | total loss: [1m[32m0.55994[0m[0m | time: 102.021s
[2K| Adam | epoch: 020 | loss: 0.55994 - acc: 0.8109 -- iter: 06400/10000
[A[ATraining Step: 3084  | total loss: [1m[32m0.57120[0m[0m | time: 103.083s
[2K| Adam | epoch: 020 | loss: 0.57120 - acc: 0.8064 -- iter: 06464/10000
[A[ATraining Step: 3085  | total loss: [1m[32m0.56216[0m[0m | time: 104.143s
[2K| Adam | epoch: 020 | loss: 0.56216 - acc: 0.8007 -- iter: 06528/10000
[A[ATraining Step: 3086  | total loss: [1m[32m0.56747[0m[0m | time: 105.197s
[2K| Adam | epoch: 020 | loss: 0.56747 - acc: 0.7957 -- iter: 06592/10000
[A[ATraining Step: 3087  | total loss: [1m[32m0.56122[0m[0m | time: 106.213s
[2K| Adam | epoch: 020 | loss: 0.56122 - acc: 0.7958 -- iter: 06656/10000
[A[ATraining Step: 3088  | total loss: [1m[32m0.55438[0m[0m | time: 107.214s
[2K| Adam | epoch: 020 | loss: 0.55438 - acc: 0.8006 -- iter: 06720/10000
[A[ATraining Step: 3089  | total loss: [1m[32m0.53999[0m[0m | time: 108.221s
[2K| Adam | epoch: 020 | loss: 0.53999 - acc: 0.8018 -- iter: 06784/10000
[A[ATraining Step: 3090  | total loss: [1m[32m0.53329[0m[0m | time: 109.223s
[2K| Adam | epoch: 020 | loss: 0.53329 - acc: 0.8029 -- iter: 06848/10000
[A[ATraining Step: 3091  | total loss: [1m[32m0.52590[0m[0m | time: 110.233s
[2K| Adam | epoch: 020 | loss: 0.52590 - acc: 0.8069 -- iter: 06912/10000
[A[ATraining Step: 3092  | total loss: [1m[32m0.51414[0m[0m | time: 111.292s
[2K| Adam | epoch: 020 | loss: 0.51414 - acc: 0.8153 -- iter: 06976/10000
[A[ATraining Step: 3093  | total loss: [1m[32m0.51587[0m[0m | time: 112.300s
[2K| Adam | epoch: 020 | loss: 0.51587 - acc: 0.8166 -- iter: 07040/10000
[A[ATraining Step: 3094  | total loss: [1m[32m0.50384[0m[0m | time: 113.302s
[2K| Adam | epoch: 020 | loss: 0.50384 - acc: 0.8209 -- iter: 07104/10000
[A[ATraining Step: 3095  | total loss: [1m[32m0.50845[0m[0m | time: 114.307s
[2K| Adam | epoch: 020 | loss: 0.50845 - acc: 0.8232 -- iter: 07168/10000
[A[ATraining Step: 3096  | total loss: [1m[32m0.51989[0m[0m | time: 115.318s
[2K| Adam | epoch: 020 | loss: 0.51989 - acc: 0.8221 -- iter: 07232/10000
[A[ATraining Step: 3097  | total loss: [1m[32m0.51936[0m[0m | time: 116.322s
[2K| Adam | epoch: 020 | loss: 0.51936 - acc: 0.8164 -- iter: 07296/10000
[A[ATraining Step: 3098  | total loss: [1m[32m0.51997[0m[0m | time: 117.328s
[2K| Adam | epoch: 020 | loss: 0.51997 - acc: 0.8161 -- iter: 07360/10000
[A[ATraining Step: 3099  | total loss: [1m[32m0.52854[0m[0m | time: 118.335s
[2K| Adam | epoch: 020 | loss: 0.52854 - acc: 0.8126 -- iter: 07424/10000
[A[ATraining Step: 3100  | total loss: [1m[32m0.52057[0m[0m | time: 122.039s
[2K| Adam | epoch: 020 | loss: 0.52057 - acc: 0.8094 | val_loss: 2.64743 - val_acc: 0.3629 -- iter: 07488/10000
--
Training Step: 3101  | total loss: [1m[32m0.53000[0m[0m | time: 123.005s
[2K| Adam | epoch: 020 | loss: 0.53000 - acc: 0.8097 -- iter: 07552/10000
[A[ATraining Step: 3102  | total loss: [1m[32m0.54451[0m[0m | time: 124.015s
[2K| Adam | epoch: 020 | loss: 0.54451 - acc: 0.8116 -- iter: 07616/10000
[A[ATraining Step: 3103  | total loss: [1m[32m0.55543[0m[0m | time: 125.064s
[2K| Adam | epoch: 020 | loss: 0.55543 - acc: 0.8085 -- iter: 07680/10000
[A[ATraining Step: 3104  | total loss: [1m[32m0.55239[0m[0m | time: 126.167s
[2K| Adam | epoch: 020 | loss: 0.55239 - acc: 0.8074 -- iter: 07744/10000
[A[ATraining Step: 3105  | total loss: [1m[32m0.55065[0m[0m | time: 127.263s
[2K| Adam | epoch: 020 | loss: 0.55065 - acc: 0.8063 -- iter: 07808/10000
[A[ATraining Step: 3106  | total loss: [1m[32m0.53434[0m[0m | time: 128.355s
[2K| Adam | epoch: 020 | loss: 0.53434 - acc: 0.8038 -- iter: 07872/10000
[A[ATraining Step: 3107  | total loss: [1m[32m0.56034[0m[0m | time: 129.384s
[2K| Adam | epoch: 020 | loss: 0.56034 - acc: 0.7953 -- iter: 07936/10000
[A[ATraining Step: 3108  | total loss: [1m[32m0.55865[0m[0m | time: 130.329s
[2K| Adam | epoch: 020 | loss: 0.55865 - acc: 0.7939 -- iter: 08000/10000
[A[ATraining Step: 3109  | total loss: [1m[32m0.55018[0m[0m | time: 131.343s
[2K| Adam | epoch: 020 | loss: 0.55018 - acc: 0.7958 -- iter: 08064/10000
[A[ATraining Step: 3110  | total loss: [1m[32m0.54335[0m[0m | time: 132.294s
[2K| Adam | epoch: 020 | loss: 0.54335 - acc: 0.8068 -- iter: 08128/10000
[A[ATraining Step: 3111  | total loss: [1m[32m0.55104[0m[0m | time: 133.253s
[2K| Adam | epoch: 020 | loss: 0.55104 - acc: 0.8043 -- iter: 08192/10000
[A[ATraining Step: 3112  | total loss: [1m[32m0.53487[0m[0m | time: 134.205s
[2K| Adam | epoch: 020 | loss: 0.53487 - acc: 0.8129 -- iter: 08256/10000
[A[ATraining Step: 3113  | total loss: [1m[32m0.53160[0m[0m | time: 135.156s
[2K| Adam | epoch: 020 | loss: 0.53160 - acc: 0.8191 -- iter: 08320/10000
[A[ATraining Step: 3114  | total loss: [1m[32m0.53079[0m[0m | time: 136.125s
[2K| Adam | epoch: 020 | loss: 0.53079 - acc: 0.8184 -- iter: 08384/10000
[A[ATraining Step: 3115  | total loss: [1m[32m0.52454[0m[0m | time: 137.120s
[2K| Adam | epoch: 020 | loss: 0.52454 - acc: 0.8179 -- iter: 08448/10000
[A[ATraining Step: 3116  | total loss: [1m[32m0.53234[0m[0m | time: 138.121s
[2K| Adam | epoch: 020 | loss: 0.53234 - acc: 0.8142 -- iter: 08512/10000
[A[ATraining Step: 3117  | total loss: [1m[32m0.54754[0m[0m | time: 139.125s
[2K| Adam | epoch: 020 | loss: 0.54754 - acc: 0.8062 -- iter: 08576/10000
[A[ATraining Step: 3118  | total loss: [1m[32m0.54351[0m[0m | time: 140.126s
[2K| Adam | epoch: 020 | loss: 0.54351 - acc: 0.8037 -- iter: 08640/10000
[A[ATraining Step: 3119  | total loss: [1m[32m0.52936[0m[0m | time: 141.221s
[2K| Adam | epoch: 020 | loss: 0.52936 - acc: 0.8077 -- iter: 08704/10000
[A[ATraining Step: 3120  | total loss: [1m[32m0.54394[0m[0m | time: 142.245s
[2K| Adam | epoch: 020 | loss: 0.54394 - acc: 0.8019 -- iter: 08768/10000
[A[ATraining Step: 3121  | total loss: [1m[32m0.53829[0m[0m | time: 143.252s
[2K| Adam | epoch: 020 | loss: 0.53829 - acc: 0.8014 -- iter: 08832/10000
[A[ATraining Step: 3122  | total loss: [1m[32m0.55618[0m[0m | time: 144.259s
[2K| Adam | epoch: 020 | loss: 0.55618 - acc: 0.8010 -- iter: 08896/10000
[A[ATraining Step: 3123  | total loss: [1m[32m0.55257[0m[0m | time: 145.252s
[2K| Adam | epoch: 020 | loss: 0.55257 - acc: 0.7990 -- iter: 08960/10000
[A[ATraining Step: 3124  | total loss: [1m[32m0.57900[0m[0m | time: 146.248s
[2K| Adam | epoch: 020 | loss: 0.57900 - acc: 0.7941 -- iter: 09024/10000
[A[ATraining Step: 3125  | total loss: [1m[32m0.57709[0m[0m | time: 147.250s
[2K| Adam | epoch: 020 | loss: 0.57709 - acc: 0.7944 -- iter: 09088/10000
[A[ATraining Step: 3126  | total loss: [1m[32m0.55894[0m[0m | time: 148.259s
[2K| Adam | epoch: 020 | loss: 0.55894 - acc: 0.7931 -- iter: 09152/10000
[A[ATraining Step: 3127  | total loss: [1m[32m0.57267[0m[0m | time: 149.298s
[2K| Adam | epoch: 020 | loss: 0.57267 - acc: 0.7872 -- iter: 09216/10000
[A[ATraining Step: 3128  | total loss: [1m[32m1.50894[0m[0m | time: 150.400s
[2K| Adam | epoch: 020 | loss: 1.50894 - acc: 0.7225 -- iter: 09280/10000
[A[ATraining Step: 3129  | total loss: [1m[32m1.43494[0m[0m | time: 151.481s
[2K| Adam | epoch: 020 | loss: 1.43494 - acc: 0.7269 -- iter: 09344/10000
[A[ATraining Step: 3130  | total loss: [1m[32m1.33624[0m[0m | time: 152.485s
[2K| Adam | epoch: 020 | loss: 1.33624 - acc: 0.7370 -- iter: 09408/10000
[A[ATraining Step: 3131  | total loss: [1m[32m1.24678[0m[0m | time: 153.494s
[2K| Adam | epoch: 020 | loss: 1.24678 - acc: 0.7445 -- iter: 09472/10000
[A[ATraining Step: 3132  | total loss: [1m[32m1.18519[0m[0m | time: 154.494s
[2K| Adam | epoch: 020 | loss: 1.18519 - acc: 0.7498 -- iter: 09536/10000
[A[ATraining Step: 3133  | total loss: [1m[32m1.12158[0m[0m | time: 155.500s
[2K| Adam | epoch: 020 | loss: 1.12158 - acc: 0.7514 -- iter: 09600/10000
[A[ATraining Step: 3134  | total loss: [1m[32m1.06012[0m[0m | time: 156.499s
[2K| Adam | epoch: 020 | loss: 1.06012 - acc: 0.7528 -- iter: 09664/10000
[A[ATraining Step: 3135  | total loss: [1m[32m0.99214[0m[0m | time: 157.503s
[2K| Adam | epoch: 020 | loss: 0.99214 - acc: 0.7650 -- iter: 09728/10000
[A[ATraining Step: 3136  | total loss: [1m[32m0.95199[0m[0m | time: 158.511s
[2K| Adam | epoch: 020 | loss: 0.95199 - acc: 0.7619 -- iter: 09792/10000
[A[ATraining Step: 3137  | total loss: [1m[32m0.91636[0m[0m | time: 159.523s
[2K| Adam | epoch: 020 | loss: 0.91636 - acc: 0.7592 -- iter: 09856/10000
[A[ATraining Step: 3138  | total loss: [1m[32m0.86888[0m[0m | time: 160.547s
[2K| Adam | epoch: 020 | loss: 0.86888 - acc: 0.7708 -- iter: 09920/10000
[A[ATraining Step: 3139  | total loss: [1m[32m0.83124[0m[0m | time: 161.637s
[2K| Adam | epoch: 020 | loss: 0.83124 - acc: 0.7718 -- iter: 09984/10000
[A[ATraining Step: 3140  | total loss: [1m[32m0.80042[0m[0m | time: 165.809s
[2K| Adam | epoch: 020 | loss: 0.80042 - acc: 0.7774 | val_loss: 2.25594 - val_acc: 0.4129 -- iter: 10000/10000
--
Training Step: 3141  | total loss: [1m[32m0.76286[0m[0m | time: 1.038s
[2K| Adam | epoch: 021 | loss: 0.76286 - acc: 0.7841 -- iter: 00064/10000
[A[ATraining Step: 3142  | total loss: [1m[32m0.72811[0m[0m | time: 1.986s
[2K| Adam | epoch: 021 | loss: 0.72811 - acc: 0.7947 -- iter: 00128/10000
[A[ATraining Step: 3143  | total loss: [1m[32m0.71253[0m[0m | time: 2.959s
[2K| Adam | epoch: 021 | loss: 0.71253 - acc: 0.7949 -- iter: 00192/10000
[A[ATraining Step: 3144  | total loss: [1m[32m0.68477[0m[0m | time: 3.993s
[2K| Adam | epoch: 021 | loss: 0.68477 - acc: 0.8014 -- iter: 00256/10000
[A[ATraining Step: 3145  | total loss: [1m[32m0.68186[0m[0m | time: 4.977s
[2K| Adam | epoch: 021 | loss: 0.68186 - acc: 0.7978 -- iter: 00320/10000
[A[ATraining Step: 3146  | total loss: [1m[32m0.69000[0m[0m | time: 5.936s
[2K| Adam | epoch: 021 | loss: 0.69000 - acc: 0.7962 -- iter: 00384/10000
[A[ATraining Step: 3147  | total loss: [1m[32m0.66583[0m[0m | time: 6.896s
[2K| Adam | epoch: 021 | loss: 0.66583 - acc: 0.8009 -- iter: 00448/10000
[A[ATraining Step: 3148  | total loss: [1m[32m0.65409[0m[0m | time: 7.852s
[2K| Adam | epoch: 021 | loss: 0.65409 - acc: 0.7958 -- iter: 00512/10000
[A[ATraining Step: 3149  | total loss: [1m[32m0.63496[0m[0m | time: 8.808s
[2K| Adam | epoch: 021 | loss: 0.63496 - acc: 0.7991 -- iter: 00576/10000
[A[ATraining Step: 3150  | total loss: [1m[32m0.62087[0m[0m | time: 9.770s
[2K| Adam | epoch: 021 | loss: 0.62087 - acc: 0.7988 -- iter: 00640/10000
[A[ATraining Step: 3151  | total loss: [1m[32m0.60955[0m[0m | time: 10.785s
[2K| Adam | epoch: 021 | loss: 0.60955 - acc: 0.7971 -- iter: 00704/10000
[A[ATraining Step: 3152  | total loss: [1m[32m0.59806[0m[0m | time: 11.787s
[2K| Adam | epoch: 021 | loss: 0.59806 - acc: 0.7955 -- iter: 00768/10000
[A[ATraining Step: 3153  | total loss: [1m[32m0.59794[0m[0m | time: 12.794s
[2K| Adam | epoch: 021 | loss: 0.59794 - acc: 0.7956 -- iter: 00832/10000
[A[ATraining Step: 3154  | total loss: [1m[32m0.61411[0m[0m | time: 13.821s
[2K| Adam | epoch: 021 | loss: 0.61411 - acc: 0.7864 -- iter: 00896/10000
[A[ATraining Step: 3155  | total loss: [1m[32m0.60906[0m[0m | time: 14.939s
[2K| Adam | epoch: 021 | loss: 0.60906 - acc: 0.7874 -- iter: 00960/10000
[A[ATraining Step: 3156  | total loss: [1m[32m0.60695[0m[0m | time: 16.039s
[2K| Adam | epoch: 021 | loss: 0.60695 - acc: 0.7899 -- iter: 01024/10000
[A[ATraining Step: 3157  | total loss: [1m[32m0.61130[0m[0m | time: 17.146s
[2K| Adam | epoch: 021 | loss: 0.61130 - acc: 0.7797 -- iter: 01088/10000
[A[ATraining Step: 3158  | total loss: [1m[32m0.59395[0m[0m | time: 18.152s
[2K| Adam | epoch: 021 | loss: 0.59395 - acc: 0.7877 -- iter: 01152/10000
[A[ATraining Step: 3159  | total loss: [1m[32m0.56915[0m[0m | time: 18.602s
[2K| Adam | epoch: 021 | loss: 0.56915 - acc: 0.7980 -- iter: 01216/10000
[A[ATraining Step: 3160  | total loss: [1m[32m0.58250[0m[0m | time: 19.061s
[2K| Adam | epoch: 021 | loss: 0.58250 - acc: 0.7807 -- iter: 01280/10000
[A[ATraining Step: 3161  | total loss: [1m[32m0.58318[0m[0m | time: 20.015s
[2K| Adam | epoch: 021 | loss: 0.58318 - acc: 0.7776 -- iter: 01344/10000
[A[ATraining Step: 3162  | total loss: [1m[32m0.57619[0m[0m | time: 20.974s
[2K| Adam | epoch: 021 | loss: 0.57619 - acc: 0.7811 -- iter: 01408/10000
[A[ATraining Step: 3163  | total loss: [1m[32m0.55850[0m[0m | time: 21.928s
[2K| Adam | epoch: 021 | loss: 0.55850 - acc: 0.7827 -- iter: 01472/10000
[A[ATraining Step: 3164  | total loss: [1m[32m0.54449[0m[0m | time: 22.887s
[2K| Adam | epoch: 021 | loss: 0.54449 - acc: 0.7872 -- iter: 01536/10000
[A[ATraining Step: 3165  | total loss: [1m[32m0.55209[0m[0m | time: 23.873s
[2K| Adam | epoch: 021 | loss: 0.55209 - acc: 0.7772 -- iter: 01600/10000
[A[ATraining Step: 3166  | total loss: [1m[32m0.54120[0m[0m | time: 24.865s
[2K| Adam | epoch: 021 | loss: 0.54120 - acc: 0.7776 -- iter: 01664/10000
[A[ATraining Step: 3167  | total loss: [1m[32m0.55726[0m[0m | time: 25.823s
[2K| Adam | epoch: 021 | loss: 0.55726 - acc: 0.7827 -- iter: 01728/10000
[A[ATraining Step: 3168  | total loss: [1m[32m0.55752[0m[0m | time: 26.787s
[2K| Adam | epoch: 021 | loss: 0.55752 - acc: 0.7857 -- iter: 01792/10000
[A[ATraining Step: 3169  | total loss: [1m[32m0.55150[0m[0m | time: 27.787s
[2K| Adam | epoch: 021 | loss: 0.55150 - acc: 0.7899 -- iter: 01856/10000
[A[ATraining Step: 3170  | total loss: [1m[32m0.53994[0m[0m | time: 28.795s
[2K| Adam | epoch: 021 | loss: 0.53994 - acc: 0.7953 -- iter: 01920/10000
[A[ATraining Step: 3171  | total loss: [1m[32m0.53621[0m[0m | time: 29.848s
[2K| Adam | epoch: 021 | loss: 0.53621 - acc: 0.7939 -- iter: 01984/10000
[A[ATraining Step: 3172  | total loss: [1m[32m0.54052[0m[0m | time: 30.946s
[2K| Adam | epoch: 021 | loss: 0.54052 - acc: 0.7895 -- iter: 02048/10000
[A[ATraining Step: 3173  | total loss: [1m[32m0.55589[0m[0m | time: 32.049s
[2K| Adam | epoch: 021 | loss: 0.55589 - acc: 0.7840 -- iter: 02112/10000
[A[ATraining Step: 3174  | total loss: [1m[32m0.54986[0m[0m | time: 33.045s
[2K| Adam | epoch: 021 | loss: 0.54986 - acc: 0.7884 -- iter: 02176/10000
[A[ATraining Step: 3175  | total loss: [1m[32m0.53608[0m[0m | time: 34.019s
[2K| Adam | epoch: 021 | loss: 0.53608 - acc: 0.7908 -- iter: 02240/10000
[A[ATraining Step: 3176  | total loss: [1m[32m0.52740[0m[0m | time: 35.009s
[2K| Adam | epoch: 021 | loss: 0.52740 - acc: 0.7945 -- iter: 02304/10000
[A[ATraining Step: 3177  | total loss: [1m[32m0.51019[0m[0m | time: 35.966s
[2K| Adam | epoch: 021 | loss: 0.51019 - acc: 0.8057 -- iter: 02368/10000
[A[ATraining Step: 3178  | total loss: [1m[32m0.51752[0m[0m | time: 36.930s
[2K| Adam | epoch: 021 | loss: 0.51752 - acc: 0.8064 -- iter: 02432/10000
[A[ATraining Step: 3179  | total loss: [1m[32m0.50977[0m[0m | time: 37.882s
[2K| Adam | epoch: 021 | loss: 0.50977 - acc: 0.8148 -- iter: 02496/10000
[A[ATraining Step: 3180  | total loss: [1m[32m0.50333[0m[0m | time: 38.795s
[2K| Adam | epoch: 021 | loss: 0.50333 - acc: 0.8177 -- iter: 02560/10000
[A[ATraining Step: 3181  | total loss: [1m[32m0.52283[0m[0m | time: 39.751s
[2K| Adam | epoch: 021 | loss: 0.52283 - acc: 0.8109 -- iter: 02624/10000
[A[ATraining Step: 3182  | total loss: [1m[32m0.52627[0m[0m | time: 40.706s
[2K| Adam | epoch: 021 | loss: 0.52627 - acc: 0.8095 -- iter: 02688/10000
[A[ATraining Step: 3183  | total loss: [1m[32m0.51291[0m[0m | time: 41.666s
[2K| Adam | epoch: 021 | loss: 0.51291 - acc: 0.8161 -- iter: 02752/10000
[A[ATraining Step: 3184  | total loss: [1m[32m0.50873[0m[0m | time: 42.660s
[2K| Adam | epoch: 021 | loss: 0.50873 - acc: 0.8173 -- iter: 02816/10000
[A[ATraining Step: 3185  | total loss: [1m[32m0.51447[0m[0m | time: 43.740s
[2K| Adam | epoch: 021 | loss: 0.51447 - acc: 0.8137 -- iter: 02880/10000
[A[ATraining Step: 3186  | total loss: [1m[32m0.52779[0m[0m | time: 44.840s
[2K| Adam | epoch: 021 | loss: 0.52779 - acc: 0.8073 -- iter: 02944/10000
[A[ATraining Step: 3187  | total loss: [1m[32m0.53557[0m[0m | time: 45.962s
[2K| Adam | epoch: 021 | loss: 0.53557 - acc: 0.8000 -- iter: 03008/10000
[A[ATraining Step: 3188  | total loss: [1m[32m0.52250[0m[0m | time: 47.061s
[2K| Adam | epoch: 021 | loss: 0.52250 - acc: 0.8060 -- iter: 03072/10000
[A[ATraining Step: 3189  | total loss: [1m[32m0.51447[0m[0m | time: 48.086s
[2K| Adam | epoch: 021 | loss: 0.51447 - acc: 0.8097 -- iter: 03136/10000
[A[ATraining Step: 3190  | total loss: [1m[32m0.49228[0m[0m | time: 49.027s
[2K| Adam | epoch: 021 | loss: 0.49228 - acc: 0.8147 -- iter: 03200/10000
[A[ATraining Step: 3191  | total loss: [1m[32m0.49079[0m[0m | time: 49.971s
[2K| Adam | epoch: 021 | loss: 0.49079 - acc: 0.8192 -- iter: 03264/10000
[A[ATraining Step: 3192  | total loss: [1m[32m0.50266[0m[0m | time: 50.922s
[2K| Adam | epoch: 021 | loss: 0.50266 - acc: 0.8185 -- iter: 03328/10000
[A[ATraining Step: 3193  | total loss: [1m[32m0.50565[0m[0m | time: 51.869s
[2K| Adam | epoch: 021 | loss: 0.50565 - acc: 0.8210 -- iter: 03392/10000
[A[ATraining Step: 3194  | total loss: [1m[32m0.50712[0m[0m | time: 52.838s
[2K| Adam | epoch: 021 | loss: 0.50712 - acc: 0.8170 -- iter: 03456/10000
[A[ATraining Step: 3195  | total loss: [1m[32m0.53057[0m[0m | time: 53.795s
[2K| Adam | epoch: 021 | loss: 0.53057 - acc: 0.8057 -- iter: 03520/10000
[A[ATraining Step: 3196  | total loss: [1m[32m0.52373[0m[0m | time: 54.777s
[2K| Adam | epoch: 021 | loss: 0.52373 - acc: 0.8063 -- iter: 03584/10000
[A[ATraining Step: 3197  | total loss: [1m[32m0.53374[0m[0m | time: 55.745s
[2K| Adam | epoch: 021 | loss: 0.53374 - acc: 0.7945 -- iter: 03648/10000
[A[ATraining Step: 3198  | total loss: [1m[32m0.52757[0m[0m | time: 56.709s
[2K| Adam | epoch: 021 | loss: 0.52757 - acc: 0.7931 -- iter: 03712/10000
[A[ATraining Step: 3199  | total loss: [1m[32m0.52734[0m[0m | time: 57.682s
[2K| Adam | epoch: 021 | loss: 0.52734 - acc: 0.7904 -- iter: 03776/10000
[A[ATraining Step: 3200  | total loss: [1m[32m0.54060[0m[0m | time: 61.735s
[2K| Adam | epoch: 021 | loss: 0.54060 - acc: 0.7863 | val_loss: 2.94790 - val_acc: 0.3771 -- iter: 03840/10000
--
Training Step: 3201  | total loss: [1m[32m0.53680[0m[0m | time: 62.792s
[2K| Adam | epoch: 021 | loss: 0.53680 - acc: 0.7874 -- iter: 03904/10000
[A[ATraining Step: 3202  | total loss: [1m[32m0.54543[0m[0m | time: 63.838s
[2K| Adam | epoch: 021 | loss: 0.54543 - acc: 0.7852 -- iter: 03968/10000
[A[ATraining Step: 3203  | total loss: [1m[32m0.55296[0m[0m | time: 64.822s
[2K| Adam | epoch: 021 | loss: 0.55296 - acc: 0.7848 -- iter: 04032/10000
[A[ATraining Step: 3204  | total loss: [1m[32m0.55903[0m[0m | time: 65.784s
[2K| Adam | epoch: 021 | loss: 0.55903 - acc: 0.7845 -- iter: 04096/10000
[A[ATraining Step: 3205  | total loss: [1m[32m0.55139[0m[0m | time: 66.745s
[2K| Adam | epoch: 021 | loss: 0.55139 - acc: 0.7873 -- iter: 04160/10000
[A[ATraining Step: 3206  | total loss: [1m[32m0.55604[0m[0m | time: 67.697s
[2K| Adam | epoch: 021 | loss: 0.55604 - acc: 0.7914 -- iter: 04224/10000
[A[ATraining Step: 3207  | total loss: [1m[32m0.54338[0m[0m | time: 68.647s
[2K| Adam | epoch: 021 | loss: 0.54338 - acc: 0.7997 -- iter: 04288/10000
[A[ATraining Step: 3208  | total loss: [1m[32m0.54072[0m[0m | time: 69.597s
[2K| Adam | epoch: 021 | loss: 0.54072 - acc: 0.8072 -- iter: 04352/10000
[A[ATraining Step: 3209  | total loss: [1m[32m0.55155[0m[0m | time: 70.557s
[2K| Adam | epoch: 021 | loss: 0.55155 - acc: 0.8031 -- iter: 04416/10000
[A[ATraining Step: 3210  | total loss: [1m[32m0.54000[0m[0m | time: 71.521s
[2K| Adam | epoch: 021 | loss: 0.54000 - acc: 0.8118 -- iter: 04480/10000
[A[ATraining Step: 3211  | total loss: [1m[32m0.54329[0m[0m | time: 72.491s
[2K| Adam | epoch: 021 | loss: 0.54329 - acc: 0.8119 -- iter: 04544/10000
[A[ATraining Step: 3212  | total loss: [1m[32m0.53804[0m[0m | time: 73.506s
[2K| Adam | epoch: 021 | loss: 0.53804 - acc: 0.8167 -- iter: 04608/10000
[A[ATraining Step: 3213  | total loss: [1m[32m0.55447[0m[0m | time: 74.520s
[2K| Adam | epoch: 021 | loss: 0.55447 - acc: 0.8037 -- iter: 04672/10000
[A[ATraining Step: 3214  | total loss: [1m[32m0.57490[0m[0m | time: 75.583s
[2K| Adam | epoch: 021 | loss: 0.57490 - acc: 0.7937 -- iter: 04736/10000
[A[ATraining Step: 3215  | total loss: [1m[32m0.55450[0m[0m | time: 76.582s
[2K| Adam | epoch: 021 | loss: 0.55450 - acc: 0.7987 -- iter: 04800/10000
[A[ATraining Step: 3216  | total loss: [1m[32m0.55381[0m[0m | time: 77.586s
[2K| Adam | epoch: 021 | loss: 0.55381 - acc: 0.7923 -- iter: 04864/10000
[A[ATraining Step: 3217  | total loss: [1m[32m0.57183[0m[0m | time: 78.581s
[2K| Adam | epoch: 021 | loss: 0.57183 - acc: 0.7771 -- iter: 04928/10000
[A[ATraining Step: 3218  | total loss: [1m[32m0.56800[0m[0m | time: 79.588s
[2K| Adam | epoch: 021 | loss: 0.56800 - acc: 0.7806 -- iter: 04992/10000
[A[ATraining Step: 3219  | total loss: [1m[32m0.56202[0m[0m | time: 80.599s
[2K| Adam | epoch: 021 | loss: 0.56202 - acc: 0.7823 -- iter: 05056/10000
[A[ATraining Step: 3220  | total loss: [1m[32m0.56450[0m[0m | time: 81.596s
[2K| Adam | epoch: 021 | loss: 0.56450 - acc: 0.7806 -- iter: 05120/10000
[A[ATraining Step: 3221  | total loss: [1m[32m0.57977[0m[0m | time: 82.608s
[2K| Adam | epoch: 021 | loss: 0.57977 - acc: 0.7760 -- iter: 05184/10000
[A[ATraining Step: 3222  | total loss: [1m[32m0.58620[0m[0m | time: 83.622s
[2K| Adam | epoch: 021 | loss: 0.58620 - acc: 0.7749 -- iter: 05248/10000
[A[ATraining Step: 3223  | total loss: [1m[32m0.56903[0m[0m | time: 84.671s
[2K| Adam | epoch: 021 | loss: 0.56903 - acc: 0.7834 -- iter: 05312/10000
[A[ATraining Step: 3224  | total loss: [1m[32m0.55336[0m[0m | time: 85.806s
[2K| Adam | epoch: 021 | loss: 0.55336 - acc: 0.7879 -- iter: 05376/10000
[A[ATraining Step: 3225  | total loss: [1m[32m0.58201[0m[0m | time: 86.907s
[2K| Adam | epoch: 021 | loss: 0.58201 - acc: 0.7856 -- iter: 05440/10000
[A[ATraining Step: 3226  | total loss: [1m[32m0.57274[0m[0m | time: 87.961s
[2K| Adam | epoch: 021 | loss: 0.57274 - acc: 0.7914 -- iter: 05504/10000
[A[ATraining Step: 3227  | total loss: [1m[32m0.57014[0m[0m | time: 88.915s
[2K| Adam | epoch: 021 | loss: 0.57014 - acc: 0.7935 -- iter: 05568/10000
[A[ATraining Step: 3228  | total loss: [1m[32m0.56027[0m[0m | time: 89.873s
[2K| Adam | epoch: 021 | loss: 0.56027 - acc: 0.7986 -- iter: 05632/10000
[A[ATraining Step: 3229  | total loss: [1m[32m0.56135[0m[0m | time: 90.831s
[2K| Adam | epoch: 021 | loss: 0.56135 - acc: 0.8046 -- iter: 05696/10000
[A[ATraining Step: 3230  | total loss: [1m[32m0.57404[0m[0m | time: 91.789s
[2K| Adam | epoch: 021 | loss: 0.57404 - acc: 0.8023 -- iter: 05760/10000
[A[ATraining Step: 3231  | total loss: [1m[32m0.57174[0m[0m | time: 92.741s
[2K| Adam | epoch: 021 | loss: 0.57174 - acc: 0.8033 -- iter: 05824/10000
[A[ATraining Step: 3232  | total loss: [1m[32m0.55836[0m[0m | time: 93.714s
[2K| Adam | epoch: 021 | loss: 0.55836 - acc: 0.8011 -- iter: 05888/10000
[A[ATraining Step: 3233  | total loss: [1m[32m0.57689[0m[0m | time: 94.663s
[2K| Adam | epoch: 021 | loss: 0.57689 - acc: 0.7944 -- iter: 05952/10000
[A[ATraining Step: 3234  | total loss: [1m[32m0.55316[0m[0m | time: 95.668s
[2K| Adam | epoch: 021 | loss: 0.55316 - acc: 0.8025 -- iter: 06016/10000
[A[ATraining Step: 3235  | total loss: [1m[32m0.52633[0m[0m | time: 96.671s
[2K| Adam | epoch: 021 | loss: 0.52633 - acc: 0.8082 -- iter: 06080/10000
[A[ATraining Step: 3236  | total loss: [1m[32m0.53470[0m[0m | time: 97.679s
[2K| Adam | epoch: 021 | loss: 0.53470 - acc: 0.8008 -- iter: 06144/10000
[A[ATraining Step: 3237  | total loss: [1m[32m0.53116[0m[0m | time: 98.689s
[2K| Adam | epoch: 021 | loss: 0.53116 - acc: 0.7989 -- iter: 06208/10000
[A[ATraining Step: 3238  | total loss: [1m[32m0.52723[0m[0m | time: 99.698s
[2K| Adam | epoch: 021 | loss: 0.52723 - acc: 0.7987 -- iter: 06272/10000
[A[ATraining Step: 3239  | total loss: [1m[32m0.52081[0m[0m | time: 100.701s
[2K| Adam | epoch: 021 | loss: 0.52081 - acc: 0.8000 -- iter: 06336/10000
[A[ATraining Step: 3240  | total loss: [1m[32m0.50303[0m[0m | time: 101.702s
[2K| Adam | epoch: 021 | loss: 0.50303 - acc: 0.8075 -- iter: 06400/10000
[A[ATraining Step: 3241  | total loss: [1m[32m0.49721[0m[0m | time: 102.707s
[2K| Adam | epoch: 021 | loss: 0.49721 - acc: 0.8158 -- iter: 06464/10000
[A[ATraining Step: 3242  | total loss: [1m[32m0.50351[0m[0m | time: 103.721s
[2K| Adam | epoch: 021 | loss: 0.50351 - acc: 0.8108 -- iter: 06528/10000
[A[ATraining Step: 3243  | total loss: [1m[32m0.51415[0m[0m | time: 104.756s
[2K| Adam | epoch: 021 | loss: 0.51415 - acc: 0.8016 -- iter: 06592/10000
[A[ATraining Step: 3244  | total loss: [1m[32m0.52207[0m[0m | time: 105.787s
[2K| Adam | epoch: 021 | loss: 0.52207 - acc: 0.7949 -- iter: 06656/10000
[A[ATraining Step: 3245  | total loss: [1m[32m0.53192[0m[0m | time: 106.796s
[2K| Adam | epoch: 021 | loss: 0.53192 - acc: 0.7888 -- iter: 06720/10000
[A[ATraining Step: 3246  | total loss: [1m[32m0.55623[0m[0m | time: 107.811s
[2K| Adam | epoch: 021 | loss: 0.55623 - acc: 0.7865 -- iter: 06784/10000
[A[ATraining Step: 3247  | total loss: [1m[32m0.56358[0m[0m | time: 108.820s
[2K| Adam | epoch: 021 | loss: 0.56358 - acc: 0.7797 -- iter: 06848/10000
[A[ATraining Step: 3248  | total loss: [1m[32m0.54977[0m[0m | time: 109.826s
[2K| Adam | epoch: 021 | loss: 0.54977 - acc: 0.7861 -- iter: 06912/10000
[A[ATraining Step: 3249  | total loss: [1m[32m0.53221[0m[0m | time: 110.828s
[2K| Adam | epoch: 021 | loss: 0.53221 - acc: 0.7919 -- iter: 06976/10000
[A[ATraining Step: 3250  | total loss: [1m[32m0.55360[0m[0m | time: 111.827s
[2K| Adam | epoch: 021 | loss: 0.55360 - acc: 0.7830 -- iter: 07040/10000
[A[ATraining Step: 3251  | total loss: [1m[32m0.55601[0m[0m | time: 112.847s
[2K| Adam | epoch: 021 | loss: 0.55601 - acc: 0.7860 -- iter: 07104/10000
[A[ATraining Step: 3252  | total loss: [1m[32m0.55947[0m[0m | time: 113.917s
[2K| Adam | epoch: 021 | loss: 0.55947 - acc: 0.7949 -- iter: 07168/10000
[A[ATraining Step: 3253  | total loss: [1m[32m0.54745[0m[0m | time: 114.952s
[2K| Adam | epoch: 021 | loss: 0.54745 - acc: 0.7951 -- iter: 07232/10000
[A[ATraining Step: 3254  | total loss: [1m[32m0.55467[0m[0m | time: 115.964s
[2K| Adam | epoch: 021 | loss: 0.55467 - acc: 0.7968 -- iter: 07296/10000
[A[ATraining Step: 3255  | total loss: [1m[32m0.55174[0m[0m | time: 116.974s
[2K| Adam | epoch: 021 | loss: 0.55174 - acc: 0.8031 -- iter: 07360/10000
[A[ATraining Step: 3256  | total loss: [1m[32m0.53747[0m[0m | time: 117.983s
[2K| Adam | epoch: 021 | loss: 0.53747 - acc: 0.8071 -- iter: 07424/10000
[A[ATraining Step: 3257  | total loss: [1m[32m0.52556[0m[0m | time: 118.988s
[2K| Adam | epoch: 021 | loss: 0.52556 - acc: 0.8077 -- iter: 07488/10000
[A[ATraining Step: 3258  | total loss: [1m[32m0.56093[0m[0m | time: 119.979s
[2K| Adam | epoch: 021 | loss: 0.56093 - acc: 0.8019 -- iter: 07552/10000
[A[ATraining Step: 3259  | total loss: [1m[32m0.56286[0m[0m | time: 121.053s
[2K| Adam | epoch: 021 | loss: 0.56286 - acc: 0.7998 -- iter: 07616/10000
[A[ATraining Step: 3260  | total loss: [1m[32m0.55848[0m[0m | time: 122.181s
[2K| Adam | epoch: 021 | loss: 0.55848 - acc: 0.7980 -- iter: 07680/10000
[A[ATraining Step: 3261  | total loss: [1m[32m0.55600[0m[0m | time: 123.346s
[2K| Adam | epoch: 021 | loss: 0.55600 - acc: 0.7932 -- iter: 07744/10000
[A[ATraining Step: 3262  | total loss: [1m[32m0.55418[0m[0m | time: 124.452s
[2K| Adam | epoch: 021 | loss: 0.55418 - acc: 0.7842 -- iter: 07808/10000
[A[ATraining Step: 3263  | total loss: [1m[32m0.55929[0m[0m | time: 125.542s
[2K| Adam | epoch: 021 | loss: 0.55929 - acc: 0.7761 -- iter: 07872/10000
[A[ATraining Step: 3264  | total loss: [1m[32m0.56181[0m[0m | time: 126.484s
[2K| Adam | epoch: 021 | loss: 0.56181 - acc: 0.7657 -- iter: 07936/10000
[A[ATraining Step: 3265  | total loss: [1m[32m0.53960[0m[0m | time: 127.436s
[2K| Adam | epoch: 021 | loss: 0.53960 - acc: 0.7766 -- iter: 08000/10000
[A[ATraining Step: 3266  | total loss: [1m[32m0.54280[0m[0m | time: 128.391s
[2K| Adam | epoch: 021 | loss: 0.54280 - acc: 0.7755 -- iter: 08064/10000
[A[ATraining Step: 3267  | total loss: [1m[32m0.54185[0m[0m | time: 129.339s
[2K| Adam | epoch: 021 | loss: 0.54185 - acc: 0.7808 -- iter: 08128/10000
[A[ATraining Step: 3268  | total loss: [1m[32m0.52580[0m[0m | time: 130.285s
[2K| Adam | epoch: 021 | loss: 0.52580 - acc: 0.7964 -- iter: 08192/10000
[A[ATraining Step: 3269  | total loss: [1m[32m0.52231[0m[0m | time: 131.248s
[2K| Adam | epoch: 021 | loss: 0.52231 - acc: 0.8027 -- iter: 08256/10000
[A[ATraining Step: 3270  | total loss: [1m[32m0.53859[0m[0m | time: 132.217s
[2K| Adam | epoch: 021 | loss: 0.53859 - acc: 0.8037 -- iter: 08320/10000
[A[ATraining Step: 3271  | total loss: [1m[32m0.55406[0m[0m | time: 133.224s
[2K| Adam | epoch: 021 | loss: 0.55406 - acc: 0.7936 -- iter: 08384/10000
[A[ATraining Step: 3272  | total loss: [1m[32m0.54387[0m[0m | time: 134.243s
[2K| Adam | epoch: 021 | loss: 0.54387 - acc: 0.7924 -- iter: 08448/10000
[A[ATraining Step: 3273  | total loss: [1m[32m0.54605[0m[0m | time: 135.279s
[2K| Adam | epoch: 021 | loss: 0.54605 - acc: 0.7991 -- iter: 08512/10000
[A[ATraining Step: 3274  | total loss: [1m[32m0.54105[0m[0m | time: 136.289s
[2K| Adam | epoch: 021 | loss: 0.54105 - acc: 0.7989 -- iter: 08576/10000
[A[ATraining Step: 3275  | total loss: [1m[32m0.53163[0m[0m | time: 137.292s
[2K| Adam | epoch: 021 | loss: 0.53163 - acc: 0.7987 -- iter: 08640/10000
[A[ATraining Step: 3276  | total loss: [1m[32m0.50509[0m[0m | time: 138.288s
[2K| Adam | epoch: 021 | loss: 0.50509 - acc: 0.8047 -- iter: 08704/10000
[A[ATraining Step: 3277  | total loss: [1m[32m0.50814[0m[0m | time: 139.293s
[2K| Adam | epoch: 021 | loss: 0.50814 - acc: 0.8055 -- iter: 08768/10000
[A[ATraining Step: 3278  | total loss: [1m[32m0.49950[0m[0m | time: 140.294s
[2K| Adam | epoch: 021 | loss: 0.49950 - acc: 0.8047 -- iter: 08832/10000
[A[ATraining Step: 3279  | total loss: [1m[32m0.50681[0m[0m | time: 141.297s
[2K| Adam | epoch: 021 | loss: 0.50681 - acc: 0.8008 -- iter: 08896/10000
[A[ATraining Step: 3280  | total loss: [1m[32m0.50414[0m[0m | time: 142.360s
[2K| Adam | epoch: 021 | loss: 0.50414 - acc: 0.7988 -- iter: 08960/10000
[A[ATraining Step: 3281  | total loss: [1m[32m0.51276[0m[0m | time: 143.421s
[2K| Adam | epoch: 021 | loss: 0.51276 - acc: 0.7892 -- iter: 09024/10000
[A[ATraining Step: 3282  | total loss: [1m[32m0.51944[0m[0m | time: 144.494s
[2K| Adam | epoch: 021 | loss: 0.51944 - acc: 0.7900 -- iter: 09088/10000
[A[ATraining Step: 3283  | total loss: [1m[32m0.51310[0m[0m | time: 145.606s
[2K| Adam | epoch: 021 | loss: 0.51310 - acc: 0.7907 -- iter: 09152/10000
[A[ATraining Step: 3284  | total loss: [1m[32m0.51753[0m[0m | time: 146.673s
[2K| Adam | epoch: 021 | loss: 0.51753 - acc: 0.7976 -- iter: 09216/10000
[A[ATraining Step: 3285  | total loss: [1m[32m0.52992[0m[0m | time: 147.726s
[2K| Adam | epoch: 021 | loss: 0.52992 - acc: 0.8006 -- iter: 09280/10000
[A[ATraining Step: 3286  | total loss: [1m[32m1.49137[0m[0m | time: 148.789s
[2K| Adam | epoch: 021 | loss: 1.49137 - acc: 0.7268 -- iter: 09344/10000
[A[ATraining Step: 3287  | total loss: [1m[32m1.39495[0m[0m | time: 149.848s
[2K| Adam | epoch: 021 | loss: 1.39495 - acc: 0.7322 -- iter: 09408/10000
[A[ATraining Step: 3288  | total loss: [1m[32m1.30129[0m[0m | time: 150.908s
[2K| Adam | epoch: 021 | loss: 1.30129 - acc: 0.7403 -- iter: 09472/10000
[A[ATraining Step: 3289  | total loss: [1m[32m1.21019[0m[0m | time: 151.969s
[2K| Adam | epoch: 021 | loss: 1.21019 - acc: 0.7553 -- iter: 09536/10000
[A[ATraining Step: 3290  | total loss: [1m[32m1.13690[0m[0m | time: 152.991s
[2K| Adam | epoch: 021 | loss: 1.13690 - acc: 0.7626 -- iter: 09600/10000
[A[ATraining Step: 3291  | total loss: [1m[32m1.06281[0m[0m | time: 154.005s
[2K| Adam | epoch: 021 | loss: 1.06281 - acc: 0.7676 -- iter: 09664/10000
[A[ATraining Step: 3292  | total loss: [1m[32m0.99683[0m[0m | time: 155.042s
[2K| Adam | epoch: 021 | loss: 0.99683 - acc: 0.7721 -- iter: 09728/10000
[A[ATraining Step: 3293  | total loss: [1m[32m0.93331[0m[0m | time: 156.059s
[2K| Adam | epoch: 021 | loss: 0.93331 - acc: 0.7808 -- iter: 09792/10000
[A[ATraining Step: 3294  | total loss: [1m[32m0.87468[0m[0m | time: 157.066s
[2K| Adam | epoch: 021 | loss: 0.87468 - acc: 0.7871 -- iter: 09856/10000
[A[ATraining Step: 3295  | total loss: [1m[32m0.85233[0m[0m | time: 158.065s
[2K| Adam | epoch: 021 | loss: 0.85233 - acc: 0.7803 -- iter: 09920/10000
[A[ATraining Step: 3296  | total loss: [1m[32m0.80122[0m[0m | time: 159.063s
[2K| Adam | epoch: 021 | loss: 0.80122 - acc: 0.7897 -- iter: 09984/10000
[A[ATraining Step: 3297  | total loss: [1m[32m0.77917[0m[0m | time: 162.662s
[2K| Adam | epoch: 021 | loss: 0.77917 - acc: 0.7842 | val_loss: 2.63101 - val_acc: 0.3886 -- iter: 10000/10000
--
Training Step: 3298  | total loss: [1m[32m0.74985[0m[0m | time: 0.971s
[2K| Adam | epoch: 022 | loss: 0.74985 - acc: 0.7870 -- iter: 00064/10000
[A[ATraining Step: 3299  | total loss: [1m[32m0.73250[0m[0m | time: 2.058s
[2K| Adam | epoch: 022 | loss: 0.73250 - acc: 0.7896 -- iter: 00128/10000
[A[ATraining Step: 3300  | total loss: [1m[32m0.70185[0m[0m | time: 6.241s
[2K| Adam | epoch: 022 | loss: 0.70185 - acc: 0.7966 | val_loss: 2.60533 - val_acc: 0.3914 -- iter: 00192/10000
--
Training Step: 3301  | total loss: [1m[32m0.67653[0m[0m | time: 7.304s
[2K| Adam | epoch: 022 | loss: 0.67653 - acc: 0.8028 -- iter: 00256/10000
[A[ATraining Step: 3302  | total loss: [1m[32m0.65818[0m[0m | time: 8.398s
[2K| Adam | epoch: 022 | loss: 0.65818 - acc: 0.8054 -- iter: 00320/10000
[A[ATraining Step: 3303  | total loss: [1m[32m0.65073[0m[0m | time: 9.373s
[2K| Adam | epoch: 022 | loss: 0.65073 - acc: 0.8014 -- iter: 00384/10000
[A[ATraining Step: 3304  | total loss: [1m[32m0.62955[0m[0m | time: 10.329s
[2K| Adam | epoch: 022 | loss: 0.62955 - acc: 0.8041 -- iter: 00448/10000
[A[ATraining Step: 3305  | total loss: [1m[32m0.61941[0m[0m | time: 11.289s
[2K| Adam | epoch: 022 | loss: 0.61941 - acc: 0.7971 -- iter: 00512/10000
[A[ATraining Step: 3306  | total loss: [1m[32m0.61077[0m[0m | time: 12.278s
[2K| Adam | epoch: 022 | loss: 0.61077 - acc: 0.8002 -- iter: 00576/10000
[A[ATraining Step: 3307  | total loss: [1m[32m0.59676[0m[0m | time: 13.236s
[2K| Adam | epoch: 022 | loss: 0.59676 - acc: 0.8030 -- iter: 00640/10000
[A[ATraining Step: 3308  | total loss: [1m[32m0.59418[0m[0m | time: 14.189s
[2K| Adam | epoch: 022 | loss: 0.59418 - acc: 0.7993 -- iter: 00704/10000
[A[ATraining Step: 3309  | total loss: [1m[32m0.56408[0m[0m | time: 15.163s
[2K| Adam | epoch: 022 | loss: 0.56408 - acc: 0.8068 -- iter: 00768/10000
[A[ATraining Step: 3310  | total loss: [1m[32m0.55667[0m[0m | time: 16.166s
[2K| Adam | epoch: 022 | loss: 0.55667 - acc: 0.8058 -- iter: 00832/10000
[A[ATraining Step: 3311  | total loss: [1m[32m0.55904[0m[0m | time: 17.174s
[2K| Adam | epoch: 022 | loss: 0.55904 - acc: 0.8081 -- iter: 00896/10000
[A[ATraining Step: 3312  | total loss: [1m[32m0.55047[0m[0m | time: 18.170s
[2K| Adam | epoch: 022 | loss: 0.55047 - acc: 0.8116 -- iter: 00960/10000
[A[ATraining Step: 3313  | total loss: [1m[32m0.54720[0m[0m | time: 19.205s
[2K| Adam | epoch: 022 | loss: 0.54720 - acc: 0.8102 -- iter: 01024/10000
[A[ATraining Step: 3314  | total loss: [1m[32m0.54136[0m[0m | time: 20.318s
[2K| Adam | epoch: 022 | loss: 0.54136 - acc: 0.8088 -- iter: 01088/10000
[A[ATraining Step: 3315  | total loss: [1m[32m0.53501[0m[0m | time: 21.436s
[2K| Adam | epoch: 022 | loss: 0.53501 - acc: 0.8123 -- iter: 01152/10000
[A[ATraining Step: 3316  | total loss: [1m[32m0.52711[0m[0m | time: 22.571s
[2K| Adam | epoch: 022 | loss: 0.52711 - acc: 0.8045 -- iter: 01216/10000
[A[ATraining Step: 3317  | total loss: [1m[32m0.52508[0m[0m | time: 23.112s
[2K| Adam | epoch: 022 | loss: 0.52508 - acc: 0.7991 -- iter: 01280/10000
[A[ATraining Step: 3318  | total loss: [1m[32m0.53310[0m[0m | time: 23.609s
[2K| Adam | epoch: 022 | loss: 0.53310 - acc: 0.7879 -- iter: 01344/10000
[A[ATraining Step: 3319  | total loss: [1m[32m0.53155[0m[0m | time: 24.674s
[2K| Adam | epoch: 022 | loss: 0.53155 - acc: 0.7841 -- iter: 01408/10000
[A[ATraining Step: 3320  | total loss: [1m[32m0.54283[0m[0m | time: 25.638s
[2K| Adam | epoch: 022 | loss: 0.54283 - acc: 0.7838 -- iter: 01472/10000
[A[ATraining Step: 3321  | total loss: [1m[32m0.55655[0m[0m | time: 26.587s
[2K| Adam | epoch: 022 | loss: 0.55655 - acc: 0.7851 -- iter: 01536/10000
[A[ATraining Step: 3322  | total loss: [1m[32m0.54592[0m[0m | time: 27.545s
[2K| Adam | epoch: 022 | loss: 0.54592 - acc: 0.7957 -- iter: 01600/10000
[A[ATraining Step: 3323  | total loss: [1m[32m0.54261[0m[0m | time: 28.496s
[2K| Adam | epoch: 022 | loss: 0.54261 - acc: 0.8005 -- iter: 01664/10000
[A[ATraining Step: 3324  | total loss: [1m[32m0.54571[0m[0m | time: 29.507s
[2K| Adam | epoch: 022 | loss: 0.54571 - acc: 0.8017 -- iter: 01728/10000
[A[ATraining Step: 3325  | total loss: [1m[32m0.53600[0m[0m | time: 30.457s
[2K| Adam | epoch: 022 | loss: 0.53600 - acc: 0.8043 -- iter: 01792/10000
[A[ATraining Step: 3326  | total loss: [1m[32m0.54412[0m[0m | time: 31.434s
[2K| Adam | epoch: 022 | loss: 0.54412 - acc: 0.7927 -- iter: 01856/10000
[A[ATraining Step: 3327  | total loss: [1m[32m0.54706[0m[0m | time: 32.465s
[2K| Adam | epoch: 022 | loss: 0.54706 - acc: 0.7946 -- iter: 01920/10000
[A[ATraining Step: 3328  | total loss: [1m[32m0.52448[0m[0m | time: 33.473s
[2K| Adam | epoch: 022 | loss: 0.52448 - acc: 0.8011 -- iter: 01984/10000
[A[ATraining Step: 3329  | total loss: [1m[32m0.52900[0m[0m | time: 34.471s
[2K| Adam | epoch: 022 | loss: 0.52900 - acc: 0.7976 -- iter: 02048/10000
[A[ATraining Step: 3330  | total loss: [1m[32m0.51262[0m[0m | time: 35.473s
[2K| Adam | epoch: 022 | loss: 0.51262 - acc: 0.8053 -- iter: 02112/10000
[A[ATraining Step: 3331  | total loss: [1m[32m0.52029[0m[0m | time: 36.485s
[2K| Adam | epoch: 022 | loss: 0.52029 - acc: 0.8060 -- iter: 02176/10000
[A[ATraining Step: 3332  | total loss: [1m[32m0.51021[0m[0m | time: 37.487s
[2K| Adam | epoch: 022 | loss: 0.51021 - acc: 0.8114 -- iter: 02240/10000
[A[ATraining Step: 3333  | total loss: [1m[32m0.51119[0m[0m | time: 38.508s
[2K| Adam | epoch: 022 | loss: 0.51119 - acc: 0.8162 -- iter: 02304/10000
[A[ATraining Step: 3334  | total loss: [1m[32m0.51920[0m[0m | time: 39.509s
[2K| Adam | epoch: 022 | loss: 0.51920 - acc: 0.8174 -- iter: 02368/10000
[A[ATraining Step: 3335  | total loss: [1m[32m0.50909[0m[0m | time: 40.602s
[2K| Adam | epoch: 022 | loss: 0.50909 - acc: 0.8216 -- iter: 02432/10000
[A[ATraining Step: 3336  | total loss: [1m[32m0.50246[0m[0m | time: 41.703s
[2K| Adam | epoch: 022 | loss: 0.50246 - acc: 0.8253 -- iter: 02496/10000
[A[ATraining Step: 3337  | total loss: [1m[32m0.50117[0m[0m | time: 42.807s
[2K| Adam | epoch: 022 | loss: 0.50117 - acc: 0.8194 -- iter: 02560/10000
[A[ATraining Step: 3338  | total loss: [1m[32m0.51361[0m[0m | time: 43.900s
[2K| Adam | epoch: 022 | loss: 0.51361 - acc: 0.8140 -- iter: 02624/10000
[A[ATraining Step: 3339  | total loss: [1m[32m0.51671[0m[0m | time: 44.904s
[2K| Adam | epoch: 022 | loss: 0.51671 - acc: 0.8123 -- iter: 02688/10000
[A[ATraining Step: 3340  | total loss: [1m[32m0.54651[0m[0m | time: 45.864s
[2K| Adam | epoch: 022 | loss: 0.54651 - acc: 0.8029 -- iter: 02752/10000
[A[ATraining Step: 3341  | total loss: [1m[32m0.52419[0m[0m | time: 46.816s
[2K| Adam | epoch: 022 | loss: 0.52419 - acc: 0.8070 -- iter: 02816/10000
[A[ATraining Step: 3342  | total loss: [1m[32m0.53161[0m[0m | time: 47.766s
[2K| Adam | epoch: 022 | loss: 0.53161 - acc: 0.8029 -- iter: 02880/10000
[A[ATraining Step: 3343  | total loss: [1m[32m0.51589[0m[0m | time: 48.737s
[2K| Adam | epoch: 022 | loss: 0.51589 - acc: 0.8085 -- iter: 02944/10000
[A[ATraining Step: 3344  | total loss: [1m[32m0.51069[0m[0m | time: 49.695s
[2K| Adam | epoch: 022 | loss: 0.51069 - acc: 0.8120 -- iter: 03008/10000
[A[ATraining Step: 3345  | total loss: [1m[32m0.51657[0m[0m | time: 50.646s
[2K| Adam | epoch: 022 | loss: 0.51657 - acc: 0.8058 -- iter: 03072/10000
[A[ATraining Step: 3346  | total loss: [1m[32m0.51052[0m[0m | time: 51.594s
[2K| Adam | epoch: 022 | loss: 0.51052 - acc: 0.8065 -- iter: 03136/10000
[A[ATraining Step: 3347  | total loss: [1m[32m0.50023[0m[0m | time: 52.587s
[2K| Adam | epoch: 022 | loss: 0.50023 - acc: 0.8102 -- iter: 03200/10000
[A[ATraining Step: 3348  | total loss: [1m[32m0.50124[0m[0m | time: 53.601s
[2K| Adam | epoch: 022 | loss: 0.50124 - acc: 0.8058 -- iter: 03264/10000
[A[ATraining Step: 3349  | total loss: [1m[32m0.50258[0m[0m | time: 54.676s
[2K| Adam | epoch: 022 | loss: 0.50258 - acc: 0.8127 -- iter: 03328/10000
[A[ATraining Step: 3350  | total loss: [1m[32m0.49534[0m[0m | time: 55.773s
[2K| Adam | epoch: 022 | loss: 0.49534 - acc: 0.8220 -- iter: 03392/10000
[A[ATraining Step: 3351  | total loss: [1m[32m0.50650[0m[0m | time: 56.870s
[2K| Adam | epoch: 022 | loss: 0.50650 - acc: 0.8133 -- iter: 03456/10000
[A[ATraining Step: 3352  | total loss: [1m[32m0.50831[0m[0m | time: 57.908s
[2K| Adam | epoch: 022 | loss: 0.50831 - acc: 0.8054 -- iter: 03520/10000
[A[ATraining Step: 3353  | total loss: [1m[32m0.50621[0m[0m | time: 58.876s
[2K| Adam | epoch: 022 | loss: 0.50621 - acc: 0.8108 -- iter: 03584/10000
[A[ATraining Step: 3354  | total loss: [1m[32m0.48816[0m[0m | time: 59.911s
[2K| Adam | epoch: 022 | loss: 0.48816 - acc: 0.8172 -- iter: 03648/10000
[A[ATraining Step: 3355  | total loss: [1m[32m0.51285[0m[0m | time: 60.867s
[2K| Adam | epoch: 022 | loss: 0.51285 - acc: 0.8074 -- iter: 03712/10000
[A[ATraining Step: 3356  | total loss: [1m[32m0.52609[0m[0m | time: 61.816s
[2K| Adam | epoch: 022 | loss: 0.52609 - acc: 0.7985 -- iter: 03776/10000
[A[ATraining Step: 3357  | total loss: [1m[32m0.53907[0m[0m | time: 62.808s
[2K| Adam | epoch: 022 | loss: 0.53907 - acc: 0.7874 -- iter: 03840/10000
[A[ATraining Step: 3358  | total loss: [1m[32m0.56610[0m[0m | time: 63.762s
[2K| Adam | epoch: 022 | loss: 0.56610 - acc: 0.7930 -- iter: 03904/10000
[A[ATraining Step: 3359  | total loss: [1m[32m0.56855[0m[0m | time: 64.734s
[2K| Adam | epoch: 022 | loss: 0.56855 - acc: 0.7919 -- iter: 03968/10000
[A[ATraining Step: 3360  | total loss: [1m[32m0.57345[0m[0m | time: 65.731s
[2K| Adam | epoch: 022 | loss: 0.57345 - acc: 0.7924 -- iter: 04032/10000
[A[ATraining Step: 3361  | total loss: [1m[32m0.57285[0m[0m | time: 66.760s
[2K| Adam | epoch: 022 | loss: 0.57285 - acc: 0.7959 -- iter: 04096/10000
[A[ATraining Step: 3362  | total loss: [1m[32m0.55884[0m[0m | time: 67.854s
[2K| Adam | epoch: 022 | loss: 0.55884 - acc: 0.8007 -- iter: 04160/10000
[A[ATraining Step: 3363  | total loss: [1m[32m0.54899[0m[0m | time: 68.967s
[2K| Adam | epoch: 022 | loss: 0.54899 - acc: 0.8081 -- iter: 04224/10000
[A[ATraining Step: 3364  | total loss: [1m[32m0.54935[0m[0m | time: 70.067s
[2K| Adam | epoch: 022 | loss: 0.54935 - acc: 0.8086 -- iter: 04288/10000
[A[ATraining Step: 3365  | total loss: [1m[32m0.54872[0m[0m | time: 71.053s
[2K| Adam | epoch: 022 | loss: 0.54872 - acc: 0.8121 -- iter: 04352/10000
[A[ATraining Step: 3366  | total loss: [1m[32m0.54819[0m[0m | time: 72.014s
[2K| Adam | epoch: 022 | loss: 0.54819 - acc: 0.8106 -- iter: 04416/10000
[A[ATraining Step: 3367  | total loss: [1m[32m0.53007[0m[0m | time: 73.013s
[2K| Adam | epoch: 022 | loss: 0.53007 - acc: 0.8139 -- iter: 04480/10000
[A[ATraining Step: 3368  | total loss: [1m[32m0.50796[0m[0m | time: 73.966s
[2K| Adam | epoch: 022 | loss: 0.50796 - acc: 0.8200 -- iter: 04544/10000
[A[ATraining Step: 3369  | total loss: [1m[32m0.50913[0m[0m | time: 74.928s
[2K| Adam | epoch: 022 | loss: 0.50913 - acc: 0.8114 -- iter: 04608/10000
[A[ATraining Step: 3370  | total loss: [1m[32m0.50510[0m[0m | time: 75.875s
[2K| Adam | epoch: 022 | loss: 0.50510 - acc: 0.8053 -- iter: 04672/10000
[A[ATraining Step: 3371  | total loss: [1m[32m0.50996[0m[0m | time: 76.818s
[2K| Adam | epoch: 022 | loss: 0.50996 - acc: 0.8076 -- iter: 04736/10000
[A[ATraining Step: 3372  | total loss: [1m[32m0.51800[0m[0m | time: 77.779s
[2K| Adam | epoch: 022 | loss: 0.51800 - acc: 0.7956 -- iter: 04800/10000
[A[ATraining Step: 3373  | total loss: [1m[32m0.51706[0m[0m | time: 78.786s
[2K| Adam | epoch: 022 | loss: 0.51706 - acc: 0.7988 -- iter: 04864/10000
[A[ATraining Step: 3374  | total loss: [1m[32m0.49753[0m[0m | time: 79.873s
[2K| Adam | epoch: 022 | loss: 0.49753 - acc: 0.8033 -- iter: 04928/10000
[A[ATraining Step: 3375  | total loss: [1m[32m0.51932[0m[0m | time: 80.969s
[2K| Adam | epoch: 022 | loss: 0.51932 - acc: 0.7886 -- iter: 04992/10000
[A[ATraining Step: 3376  | total loss: [1m[32m0.53045[0m[0m | time: 82.079s
[2K| Adam | epoch: 022 | loss: 0.53045 - acc: 0.7863 -- iter: 05056/10000
[A[ATraining Step: 3377  | total loss: [1m[32m0.53427[0m[0m | time: 83.164s
[2K| Adam | epoch: 022 | loss: 0.53427 - acc: 0.7905 -- iter: 05120/10000
[A[ATraining Step: 3378  | total loss: [1m[32m0.52900[0m[0m | time: 84.116s
[2K| Adam | epoch: 022 | loss: 0.52900 - acc: 0.7943 -- iter: 05184/10000
[A[ATraining Step: 3379  | total loss: [1m[32m0.53879[0m[0m | time: 85.066s
[2K| Adam | epoch: 022 | loss: 0.53879 - acc: 0.7914 -- iter: 05248/10000
[A[ATraining Step: 3380  | total loss: [1m[32m0.53531[0m[0m | time: 86.015s
[2K| Adam | epoch: 022 | loss: 0.53531 - acc: 0.7935 -- iter: 05312/10000
[A[ATraining Step: 3381  | total loss: [1m[32m0.54142[0m[0m | time: 86.976s
[2K| Adam | epoch: 022 | loss: 0.54142 - acc: 0.7954 -- iter: 05376/10000
[A[ATraining Step: 3382  | total loss: [1m[32m0.54999[0m[0m | time: 87.935s
[2K| Adam | epoch: 022 | loss: 0.54999 - acc: 0.7924 -- iter: 05440/10000
[A[ATraining Step: 3383  | total loss: [1m[32m0.56756[0m[0m | time: 88.902s
[2K| Adam | epoch: 022 | loss: 0.56756 - acc: 0.7976 -- iter: 05504/10000
[A[ATraining Step: 3384  | total loss: [1m[32m0.56436[0m[0m | time: 89.858s
[2K| Adam | epoch: 022 | loss: 0.56436 - acc: 0.7991 -- iter: 05568/10000
[A[ATraining Step: 3385  | total loss: [1m[32m0.54454[0m[0m | time: 90.801s
[2K| Adam | epoch: 022 | loss: 0.54454 - acc: 0.8020 -- iter: 05632/10000
[A[ATraining Step: 3386  | total loss: [1m[32m0.55262[0m[0m | time: 91.755s
[2K| Adam | epoch: 022 | loss: 0.55262 - acc: 0.7968 -- iter: 05696/10000
[A[ATraining Step: 3387  | total loss: [1m[32m0.55462[0m[0m | time: 92.775s
[2K| Adam | epoch: 022 | loss: 0.55462 - acc: 0.8030 -- iter: 05760/10000
[A[ATraining Step: 3388  | total loss: [1m[32m0.57909[0m[0m | time: 93.776s
[2K| Adam | epoch: 022 | loss: 0.57909 - acc: 0.7962 -- iter: 05824/10000
[A[ATraining Step: 3389  | total loss: [1m[32m0.57947[0m[0m | time: 94.795s
[2K| Adam | epoch: 022 | loss: 0.57947 - acc: 0.7978 -- iter: 05888/10000
[A[ATraining Step: 3390  | total loss: [1m[32m0.57629[0m[0m | time: 95.792s
[2K| Adam | epoch: 022 | loss: 0.57629 - acc: 0.7930 -- iter: 05952/10000
[A[ATraining Step: 3391  | total loss: [1m[32m0.58071[0m[0m | time: 96.792s
[2K| Adam | epoch: 022 | loss: 0.58071 - acc: 0.7903 -- iter: 06016/10000
[A[ATraining Step: 3392  | total loss: [1m[32m0.57265[0m[0m | time: 97.795s
[2K| Adam | epoch: 022 | loss: 0.57265 - acc: 0.7894 -- iter: 06080/10000
[A[ATraining Step: 3393  | total loss: [1m[32m0.58118[0m[0m | time: 98.814s
[2K| Adam | epoch: 022 | loss: 0.58118 - acc: 0.7948 -- iter: 06144/10000
[A[ATraining Step: 3394  | total loss: [1m[32m0.58435[0m[0m | time: 99.811s
[2K| Adam | epoch: 022 | loss: 0.58435 - acc: 0.7935 -- iter: 06208/10000
[A[ATraining Step: 3395  | total loss: [1m[32m0.59999[0m[0m | time: 100.814s
[2K| Adam | epoch: 022 | loss: 0.59999 - acc: 0.7891 -- iter: 06272/10000
[A[ATraining Step: 3396  | total loss: [1m[32m0.57626[0m[0m | time: 101.811s
[2K| Adam | epoch: 022 | loss: 0.57626 - acc: 0.7961 -- iter: 06336/10000
[A[ATraining Step: 3397  | total loss: [1m[32m0.58825[0m[0m | time: 102.869s
[2K| Adam | epoch: 022 | loss: 0.58825 - acc: 0.7978 -- iter: 06400/10000
[A[ATraining Step: 3398  | total loss: [1m[32m0.58649[0m[0m | time: 103.840s
[2K| Adam | epoch: 022 | loss: 0.58649 - acc: 0.7961 -- iter: 06464/10000
[A[ATraining Step: 3399  | total loss: [1m[32m0.58689[0m[0m | time: 104.841s
[2K| Adam | epoch: 022 | loss: 0.58689 - acc: 0.7962 -- iter: 06528/10000
[A[ATraining Step: 3400  | total loss: [1m[32m0.58423[0m[0m | time: 109.037s
[2K| Adam | epoch: 022 | loss: 0.58423 - acc: 0.7994 | val_loss: 2.98168 - val_acc: 0.3729 -- iter: 06592/10000
--
Training Step: 3401  | total loss: [1m[32m0.56616[0m[0m | time: 110.097s
[2K| Adam | epoch: 022 | loss: 0.56616 - acc: 0.8038 -- iter: 06656/10000
[A[ATraining Step: 3402  | total loss: [1m[32m0.56227[0m[0m | time: 111.149s
[2K| Adam | epoch: 022 | loss: 0.56227 - acc: 0.8063 -- iter: 06720/10000
[A[ATraining Step: 3403  | total loss: [1m[32m0.55572[0m[0m | time: 112.122s
[2K| Adam | epoch: 022 | loss: 0.55572 - acc: 0.8053 -- iter: 06784/10000
[A[ATraining Step: 3404  | total loss: [1m[32m0.54511[0m[0m | time: 113.113s
[2K| Adam | epoch: 022 | loss: 0.54511 - acc: 0.8060 -- iter: 06848/10000
[A[ATraining Step: 3405  | total loss: [1m[32m0.54195[0m[0m | time: 114.130s
[2K| Adam | epoch: 022 | loss: 0.54195 - acc: 0.8067 -- iter: 06912/10000
[A[ATraining Step: 3406  | total loss: [1m[32m0.55410[0m[0m | time: 115.306s
[2K| Adam | epoch: 022 | loss: 0.55410 - acc: 0.7932 -- iter: 06976/10000
[A[ATraining Step: 3407  | total loss: [1m[32m0.53631[0m[0m | time: 116.471s
[2K| Adam | epoch: 022 | loss: 0.53631 - acc: 0.7998 -- iter: 07040/10000
[A[ATraining Step: 3408  | total loss: [1m[32m0.53574[0m[0m | time: 117.696s
[2K| Adam | epoch: 022 | loss: 0.53574 - acc: 0.7948 -- iter: 07104/10000
[A[ATraining Step: 3409  | total loss: [1m[32m0.53600[0m[0m | time: 118.997s
[2K| Adam | epoch: 022 | loss: 0.53600 - acc: 0.7950 -- iter: 07168/10000
[A[ATraining Step: 3410  | total loss: [1m[32m0.52340[0m[0m | time: 120.533s
[2K| Adam | epoch: 022 | loss: 0.52340 - acc: 0.8062 -- iter: 07232/10000
[A[ATraining Step: 3411  | total loss: [1m[32m0.51512[0m[0m | time: 122.002s
[2K| Adam | epoch: 022 | loss: 0.51512 - acc: 0.8052 -- iter: 07296/10000
[A[ATraining Step: 3412  | total loss: [1m[32m0.51580[0m[0m | time: 124.151s
[2K| Adam | epoch: 022 | loss: 0.51580 - acc: 0.8013 -- iter: 07360/10000
[A[ATraining Step: 3413  | total loss: [1m[32m0.53209[0m[0m | time: 125.573s
[2K| Adam | epoch: 022 | loss: 0.53209 - acc: 0.7977 -- iter: 07424/10000
[A[ATraining Step: 3414  | total loss: [1m[32m0.52226[0m[0m | time: 126.848s
[2K| Adam | epoch: 022 | loss: 0.52226 - acc: 0.8039 -- iter: 07488/10000
[A[ATraining Step: 3415  | total loss: [1m[32m0.54344[0m[0m | time: 128.036s
[2K| Adam | epoch: 022 | loss: 0.54344 - acc: 0.7985 -- iter: 07552/10000
[A[ATraining Step: 3416  | total loss: [1m[32m0.53935[0m[0m | time: 129.216s
[2K| Adam | epoch: 022 | loss: 0.53935 - acc: 0.8015 -- iter: 07616/10000
[A[ATraining Step: 3417  | total loss: [1m[32m0.53563[0m[0m | time: 130.331s
[2K| Adam | epoch: 022 | loss: 0.53563 - acc: 0.8010 -- iter: 07680/10000
[A[ATraining Step: 3418  | total loss: [1m[32m0.52056[0m[0m | time: 131.368s
[2K| Adam | epoch: 022 | loss: 0.52056 - acc: 0.8162 -- iter: 07744/10000
[A[ATraining Step: 3419  | total loss: [1m[32m0.50038[0m[0m | time: 132.357s
[2K| Adam | epoch: 022 | loss: 0.50038 - acc: 0.8268 -- iter: 07808/10000
[A[ATraining Step: 3420  | total loss: [1m[32m0.49981[0m[0m | time: 133.310s
[2K| Adam | epoch: 022 | loss: 0.49981 - acc: 0.8238 -- iter: 07872/10000
[A[ATraining Step: 3421  | total loss: [1m[32m0.48654[0m[0m | time: 134.266s
[2K| Adam | epoch: 022 | loss: 0.48654 - acc: 0.8289 -- iter: 07936/10000
[A[ATraining Step: 3422  | total loss: [1m[32m0.49738[0m[0m | time: 135.228s
[2K| Adam | epoch: 022 | loss: 0.49738 - acc: 0.8304 -- iter: 08000/10000
[A[ATraining Step: 3423  | total loss: [1m[32m0.49763[0m[0m | time: 136.176s
[2K| Adam | epoch: 022 | loss: 0.49763 - acc: 0.8255 -- iter: 08064/10000
[A[ATraining Step: 3424  | total loss: [1m[32m0.49767[0m[0m | time: 137.212s
[2K| Adam | epoch: 022 | loss: 0.49767 - acc: 0.8226 -- iter: 08128/10000
[A[ATraining Step: 3425  | total loss: [1m[32m0.48376[0m[0m | time: 138.248s
[2K| Adam | epoch: 022 | loss: 0.48376 - acc: 0.8232 -- iter: 08192/10000
[A[ATraining Step: 3426  | total loss: [1m[32m0.49747[0m[0m | time: 139.338s
[2K| Adam | epoch: 022 | loss: 0.49747 - acc: 0.8112 -- iter: 08256/10000
[A[ATraining Step: 3427  | total loss: [1m[32m0.50070[0m[0m | time: 140.413s
[2K| Adam | epoch: 022 | loss: 0.50070 - acc: 0.8113 -- iter: 08320/10000
[A[ATraining Step: 3428  | total loss: [1m[32m0.50050[0m[0m | time: 141.551s
[2K| Adam | epoch: 022 | loss: 0.50050 - acc: 0.8099 -- iter: 08384/10000
[A[ATraining Step: 3429  | total loss: [1m[32m0.50693[0m[0m | time: 142.704s
[2K| Adam | epoch: 022 | loss: 0.50693 - acc: 0.8086 -- iter: 08448/10000
[A[ATraining Step: 3430  | total loss: [1m[32m0.51935[0m[0m | time: 143.854s
[2K| Adam | epoch: 022 | loss: 0.51935 - acc: 0.8074 -- iter: 08512/10000
[A[ATraining Step: 3431  | total loss: [1m[32m0.50443[0m[0m | time: 145.154s
[2K| Adam | epoch: 022 | loss: 0.50443 - acc: 0.8110 -- iter: 08576/10000
[A[ATraining Step: 3432  | total loss: [1m[32m0.49515[0m[0m | time: 146.463s
[2K| Adam | epoch: 022 | loss: 0.49515 - acc: 0.8143 -- iter: 08640/10000
[A[ATraining Step: 3433  | total loss: [1m[32m0.48176[0m[0m | time: 147.803s
[2K| Adam | epoch: 022 | loss: 0.48176 - acc: 0.8204 -- iter: 08704/10000
[A[ATraining Step: 3434  | total loss: [1m[32m0.49602[0m[0m | time: 149.098s
[2K| Adam | epoch: 022 | loss: 0.49602 - acc: 0.8165 -- iter: 08768/10000
[A[ATraining Step: 3435  | total loss: [1m[32m0.48651[0m[0m | time: 150.334s
[2K| Adam | epoch: 022 | loss: 0.48651 - acc: 0.8192 -- iter: 08832/10000
[A[ATraining Step: 3436  | total loss: [1m[32m0.47853[0m[0m | time: 151.513s
[2K| Adam | epoch: 022 | loss: 0.47853 - acc: 0.8170 -- iter: 08896/10000
[A[ATraining Step: 3437  | total loss: [1m[32m0.48630[0m[0m | time: 152.703s
[2K| Adam | epoch: 022 | loss: 0.48630 - acc: 0.8149 -- iter: 08960/10000
[A[ATraining Step: 3438  | total loss: [1m[32m0.48070[0m[0m | time: 153.866s
[2K| Adam | epoch: 022 | loss: 0.48070 - acc: 0.8163 -- iter: 09024/10000
[A[ATraining Step: 3439  | total loss: [1m[32m0.48376[0m[0m | time: 155.029s
[2K| Adam | epoch: 022 | loss: 0.48376 - acc: 0.8128 -- iter: 09088/10000
[A[ATraining Step: 3440  | total loss: [1m[32m0.50032[0m[0m | time: 156.146s
[2K| Adam | epoch: 022 | loss: 0.50032 - acc: 0.8065 -- iter: 09152/10000
[A[ATraining Step: 3441  | total loss: [1m[32m0.50017[0m[0m | time: 157.277s
[2K| Adam | epoch: 022 | loss: 0.50017 - acc: 0.8118 -- iter: 09216/10000
[A[ATraining Step: 3442  | total loss: [1m[32m0.49613[0m[0m | time: 158.376s
[2K| Adam | epoch: 022 | loss: 0.49613 - acc: 0.8134 -- iter: 09280/10000
[A[ATraining Step: 3443  | total loss: [1m[32m0.49393[0m[0m | time: 159.482s
[2K| Adam | epoch: 022 | loss: 0.49393 - acc: 0.8102 -- iter: 09344/10000
[A[ATraining Step: 3444  | total loss: [1m[32m1.39839[0m[0m | time: 160.589s
[2K| Adam | epoch: 022 | loss: 1.39839 - acc: 0.7464 -- iter: 09408/10000
[A[ATraining Step: 3445  | total loss: [1m[32m1.30766[0m[0m | time: 161.648s
[2K| Adam | epoch: 022 | loss: 1.30766 - acc: 0.7499 -- iter: 09472/10000
[A[ATraining Step: 3446  | total loss: [1m[32m1.24169[0m[0m | time: 162.817s
[2K| Adam | epoch: 022 | loss: 1.24169 - acc: 0.7514 -- iter: 09536/10000
[A[ATraining Step: 3447  | total loss: [1m[32m1.17120[0m[0m | time: 163.926s
[2K| Adam | epoch: 022 | loss: 1.17120 - acc: 0.7638 -- iter: 09600/10000
[A[ATraining Step: 3448  | total loss: [1m[32m1.08701[0m[0m | time: 165.036s
[2K| Adam | epoch: 022 | loss: 1.08701 - acc: 0.7733 -- iter: 09664/10000
[A[ATraining Step: 3449  | total loss: [1m[32m1.02769[0m[0m | time: 166.154s
[2K| Adam | epoch: 022 | loss: 1.02769 - acc: 0.7819 -- iter: 09728/10000
[A[ATraining Step: 3450  | total loss: [1m[32m0.96131[0m[0m | time: 167.364s
[2K| Adam | epoch: 022 | loss: 0.96131 - acc: 0.7913 -- iter: 09792/10000
[A[ATraining Step: 3451  | total loss: [1m[32m0.90395[0m[0m | time: 168.487s
[2K| Adam | epoch: 022 | loss: 0.90395 - acc: 0.8012 -- iter: 09856/10000
[A[ATraining Step: 3452  | total loss: [1m[32m0.85760[0m[0m | time: 169.688s
[2K| Adam | epoch: 022 | loss: 0.85760 - acc: 0.8023 -- iter: 09920/10000
[A[ATraining Step: 3453  | total loss: [1m[32m0.81723[0m[0m | time: 170.920s
[2K| Adam | epoch: 022 | loss: 0.81723 - acc: 0.8033 -- iter: 09984/10000
[A[ATraining Step: 3454  | total loss: [1m[32m0.78046[0m[0m | time: 175.362s
[2K| Adam | epoch: 022 | loss: 0.78046 - acc: 0.8105 | val_loss: 2.59110 - val_acc: 0.4171 -- iter: 10000/10000
--
Training Step: 3455  | total loss: [1m[32m0.74294[0m[0m | time: 1.109s
[2K| Adam | epoch: 023 | loss: 0.74294 - acc: 0.8185 -- iter: 00064/10000
[A[ATraining Step: 3456  | total loss: [1m[32m0.71673[0m[0m | time: 2.286s
[2K| Adam | epoch: 023 | loss: 0.71673 - acc: 0.8179 -- iter: 00128/10000
[A[ATraining Step: 3457  | total loss: [1m[32m0.67877[0m[0m | time: 3.445s
[2K| Adam | epoch: 023 | loss: 0.67877 - acc: 0.8205 -- iter: 00192/10000
[A[ATraining Step: 3458  | total loss: [1m[32m0.67730[0m[0m | time: 4.559s
[2K| Adam | epoch: 023 | loss: 0.67730 - acc: 0.8056 -- iter: 00256/10000
[A[ATraining Step: 3459  | total loss: [1m[32m0.64921[0m[0m | time: 5.657s
[2K| Adam | epoch: 023 | loss: 0.64921 - acc: 0.8094 -- iter: 00320/10000
[A[ATraining Step: 3460  | total loss: [1m[32m0.63455[0m[0m | time: 6.816s
[2K| Adam | epoch: 023 | loss: 0.63455 - acc: 0.8051 -- iter: 00384/10000
[A[ATraining Step: 3461  | total loss: [1m[32m0.61527[0m[0m | time: 7.807s
[2K| Adam | epoch: 023 | loss: 0.61527 - acc: 0.8121 -- iter: 00448/10000
[A[ATraining Step: 3462  | total loss: [1m[32m0.59477[0m[0m | time: 8.766s
[2K| Adam | epoch: 023 | loss: 0.59477 - acc: 0.8168 -- iter: 00512/10000
[A[ATraining Step: 3463  | total loss: [1m[32m0.59929[0m[0m | time: 9.721s
[2K| Adam | epoch: 023 | loss: 0.59929 - acc: 0.8148 -- iter: 00576/10000
[A[ATraining Step: 3464  | total loss: [1m[32m0.58465[0m[0m | time: 10.670s
[2K| Adam | epoch: 023 | loss: 0.58465 - acc: 0.8161 -- iter: 00640/10000
[A[ATraining Step: 3465  | total loss: [1m[32m0.57076[0m[0m | time: 11.650s
[2K| Adam | epoch: 023 | loss: 0.57076 - acc: 0.8158 -- iter: 00704/10000
[A[ATraining Step: 3466  | total loss: [1m[32m0.58682[0m[0m | time: 12.655s
[2K| Adam | epoch: 023 | loss: 0.58682 - acc: 0.8076 -- iter: 00768/10000
[A[ATraining Step: 3467  | total loss: [1m[32m0.59848[0m[0m | time: 13.663s
[2K| Adam | epoch: 023 | loss: 0.59848 - acc: 0.8034 -- iter: 00832/10000
[A[ATraining Step: 3468  | total loss: [1m[32m0.62679[0m[0m | time: 14.666s
[2K| Adam | epoch: 023 | loss: 0.62679 - acc: 0.7950 -- iter: 00896/10000
[A[ATraining Step: 3469  | total loss: [1m[32m0.60496[0m[0m | time: 15.668s
[2K| Adam | epoch: 023 | loss: 0.60496 - acc: 0.8014 -- iter: 00960/10000
[A[ATraining Step: 3470  | total loss: [1m[32m0.61143[0m[0m | time: 16.713s
[2K| Adam | epoch: 023 | loss: 0.61143 - acc: 0.8009 -- iter: 01024/10000
[A[ATraining Step: 3471  | total loss: [1m[32m0.60443[0m[0m | time: 17.799s
[2K| Adam | epoch: 023 | loss: 0.60443 - acc: 0.7990 -- iter: 01088/10000
[A[ATraining Step: 3472  | total loss: [1m[32m0.60311[0m[0m | time: 18.867s
[2K| Adam | epoch: 023 | loss: 0.60311 - acc: 0.8019 -- iter: 01152/10000
[A[ATraining Step: 3473  | total loss: [1m[32m0.59887[0m[0m | time: 19.927s
[2K| Adam | epoch: 023 | loss: 0.59887 - acc: 0.8076 -- iter: 01216/10000
[A[ATraining Step: 3474  | total loss: [1m[32m0.58893[0m[0m | time: 21.003s
[2K| Adam | epoch: 023 | loss: 0.58893 - acc: 0.8066 -- iter: 01280/10000
[A[ATraining Step: 3475  | total loss: [1m[32m0.58264[0m[0m | time: 21.525s
[2K| Adam | epoch: 023 | loss: 0.58264 - acc: 0.8087 -- iter: 01344/10000
[A[ATraining Step: 3476  | total loss: [1m[32m0.56993[0m[0m | time: 22.030s
[2K| Adam | epoch: 023 | loss: 0.56993 - acc: 0.8153 -- iter: 01408/10000
[A[ATraining Step: 3477  | total loss: [1m[32m0.53670[0m[0m | time: 23.203s
[2K| Adam | epoch: 023 | loss: 0.53670 - acc: 0.8213 -- iter: 01472/10000
[A[ATraining Step: 3478  | total loss: [1m[32m0.51017[0m[0m | time: 24.355s
[2K| Adam | epoch: 023 | loss: 0.51017 - acc: 0.8267 -- iter: 01536/10000
[A[ATraining Step: 3479  | total loss: [1m[32m0.50783[0m[0m | time: 25.470s
[2K| Adam | epoch: 023 | loss: 0.50783 - acc: 0.8268 -- iter: 01600/10000
[A[ATraining Step: 3480  | total loss: [1m[32m0.49403[0m[0m | time: 26.568s
[2K| Adam | epoch: 023 | loss: 0.49403 - acc: 0.8316 -- iter: 01664/10000
[A[ATraining Step: 3481  | total loss: [1m[32m0.48988[0m[0m | time: 27.600s
[2K| Adam | epoch: 023 | loss: 0.48988 - acc: 0.8344 -- iter: 01728/10000
[A[ATraining Step: 3482  | total loss: [1m[32m0.47306[0m[0m | time: 28.556s
[2K| Adam | epoch: 023 | loss: 0.47306 - acc: 0.8322 -- iter: 01792/10000
[A[ATraining Step: 3483  | total loss: [1m[32m0.47601[0m[0m | time: 29.505s
[2K| Adam | epoch: 023 | loss: 0.47601 - acc: 0.8303 -- iter: 01856/10000
[A[ATraining Step: 3484  | total loss: [1m[32m0.47684[0m[0m | time: 30.458s
[2K| Adam | epoch: 023 | loss: 0.47684 - acc: 0.8269 -- iter: 01920/10000
[A[ATraining Step: 3485  | total loss: [1m[32m0.50294[0m[0m | time: 31.443s
[2K| Adam | epoch: 023 | loss: 0.50294 - acc: 0.8177 -- iter: 01984/10000
[A[ATraining Step: 3486  | total loss: [1m[32m0.48964[0m[0m | time: 32.404s
[2K| Adam | epoch: 023 | loss: 0.48964 - acc: 0.8250 -- iter: 02048/10000
[A[ATraining Step: 3487  | total loss: [1m[32m0.47152[0m[0m | time: 33.409s
[2K| Adam | epoch: 023 | loss: 0.47152 - acc: 0.8300 -- iter: 02112/10000
[A[ATraining Step: 3488  | total loss: [1m[32m0.45682[0m[0m | time: 34.418s
[2K| Adam | epoch: 023 | loss: 0.45682 - acc: 0.8360 -- iter: 02176/10000
[A[ATraining Step: 3489  | total loss: [1m[32m0.45228[0m[0m | time: 35.416s
[2K| Adam | epoch: 023 | loss: 0.45228 - acc: 0.8399 -- iter: 02240/10000
[A[ATraining Step: 3490  | total loss: [1m[32m0.45532[0m[0m | time: 36.422s
[2K| Adam | epoch: 023 | loss: 0.45532 - acc: 0.8356 -- iter: 02304/10000
[A[ATraining Step: 3491  | total loss: [1m[32m0.46132[0m[0m | time: 37.547s
[2K| Adam | epoch: 023 | loss: 0.46132 - acc: 0.8317 -- iter: 02368/10000
[A[ATraining Step: 3492  | total loss: [1m[32m0.48769[0m[0m | time: 38.648s
[2K| Adam | epoch: 023 | loss: 0.48769 - acc: 0.8251 -- iter: 02432/10000
[A[ATraining Step: 3493  | total loss: [1m[32m0.50913[0m[0m | time: 39.759s
[2K| Adam | epoch: 023 | loss: 0.50913 - acc: 0.8192 -- iter: 02496/10000
[A[ATraining Step: 3494  | total loss: [1m[32m0.50449[0m[0m | time: 40.866s
[2K| Adam | epoch: 023 | loss: 0.50449 - acc: 0.8216 -- iter: 02560/10000
[A[ATraining Step: 3495  | total loss: [1m[32m0.51032[0m[0m | time: 42.076s
[2K| Adam | epoch: 023 | loss: 0.51032 - acc: 0.8207 -- iter: 02624/10000
[A[ATraining Step: 3496  | total loss: [1m[32m0.49909[0m[0m | time: 43.182s
[2K| Adam | epoch: 023 | loss: 0.49909 - acc: 0.8262 -- iter: 02688/10000
[A[ATraining Step: 3497  | total loss: [1m[32m0.49994[0m[0m | time: 44.279s
[2K| Adam | epoch: 023 | loss: 0.49994 - acc: 0.8217 -- iter: 02752/10000
[A[ATraining Step: 3498  | total loss: [1m[32m0.48846[0m[0m | time: 45.307s
[2K| Adam | epoch: 023 | loss: 0.48846 - acc: 0.8254 -- iter: 02816/10000
[A[ATraining Step: 3499  | total loss: [1m[32m0.48935[0m[0m | time: 46.249s
[2K| Adam | epoch: 023 | loss: 0.48935 - acc: 0.8273 -- iter: 02880/10000
[A[ATraining Step: 3500  | total loss: [1m[32m0.47804[0m[0m | time: 49.712s
[2K| Adam | epoch: 023 | loss: 0.47804 - acc: 0.8289 | val_loss: 2.89291 - val_acc: 0.3943 -- iter: 02944/10000
--
Training Step: 3501  | total loss: [1m[32m0.49186[0m[0m | time: 50.653s
[2K| Adam | epoch: 023 | loss: 0.49186 - acc: 0.8226 -- iter: 03008/10000
[A[ATraining Step: 3502  | total loss: [1m[32m0.48874[0m[0m | time: 51.662s
[2K| Adam | epoch: 023 | loss: 0.48874 - acc: 0.8185 -- iter: 03072/10000
[A[ATraining Step: 3503  | total loss: [1m[32m0.48131[0m[0m | time: 52.679s
[2K| Adam | epoch: 023 | loss: 0.48131 - acc: 0.8225 -- iter: 03136/10000
[A[ATraining Step: 3504  | total loss: [1m[32m0.47863[0m[0m | time: 53.684s
[2K| Adam | epoch: 023 | loss: 0.47863 - acc: 0.8262 -- iter: 03200/10000
[A[ATraining Step: 3505  | total loss: [1m[32m0.47193[0m[0m | time: 54.682s
[2K| Adam | epoch: 023 | loss: 0.47193 - acc: 0.8264 -- iter: 03264/10000
[A[ATraining Step: 3506  | total loss: [1m[32m0.47814[0m[0m | time: 55.683s
[2K| Adam | epoch: 023 | loss: 0.47814 - acc: 0.8157 -- iter: 03328/10000
[A[ATraining Step: 3507  | total loss: [1m[32m0.48714[0m[0m | time: 56.787s
[2K| Adam | epoch: 023 | loss: 0.48714 - acc: 0.8122 -- iter: 03392/10000
[A[ATraining Step: 3508  | total loss: [1m[32m0.47574[0m[0m | time: 57.852s
[2K| Adam | epoch: 023 | loss: 0.47574 - acc: 0.8154 -- iter: 03456/10000
[A[ATraining Step: 3509  | total loss: [1m[32m0.48843[0m[0m | time: 58.971s
[2K| Adam | epoch: 023 | loss: 0.48843 - acc: 0.8151 -- iter: 03520/10000
[A[ATraining Step: 3510  | total loss: [1m[32m0.48765[0m[0m | time: 60.094s
[2K| Adam | epoch: 023 | loss: 0.48765 - acc: 0.8195 -- iter: 03584/10000
[A[ATraining Step: 3511  | total loss: [1m[32m0.49065[0m[0m | time: 61.064s
[2K| Adam | epoch: 023 | loss: 0.49065 - acc: 0.8282 -- iter: 03648/10000
[A[ATraining Step: 3512  | total loss: [1m[32m0.49706[0m[0m | time: 62.016s
[2K| Adam | epoch: 023 | loss: 0.49706 - acc: 0.8266 -- iter: 03712/10000
[A[ATraining Step: 3513  | total loss: [1m[32m0.50618[0m[0m | time: 62.968s
[2K| Adam | epoch: 023 | loss: 0.50618 - acc: 0.8236 -- iter: 03776/10000
[A[ATraining Step: 3514  | total loss: [1m[32m0.51848[0m[0m | time: 63.909s
[2K| Adam | epoch: 023 | loss: 0.51848 - acc: 0.8194 -- iter: 03840/10000
[A[ATraining Step: 3515  | total loss: [1m[32m0.52509[0m[0m | time: 64.861s
[2K| Adam | epoch: 023 | loss: 0.52509 - acc: 0.8203 -- iter: 03904/10000
[A[ATraining Step: 3516  | total loss: [1m[32m0.52666[0m[0m | time: 65.821s
[2K| Adam | epoch: 023 | loss: 0.52666 - acc: 0.8148 -- iter: 03968/10000
[A[ATraining Step: 3517  | total loss: [1m[32m0.52440[0m[0m | time: 66.807s
[2K| Adam | epoch: 023 | loss: 0.52440 - acc: 0.8146 -- iter: 04032/10000
[A[ATraining Step: 3518  | total loss: [1m[32m0.52421[0m[0m | time: 67.770s
[2K| Adam | epoch: 023 | loss: 0.52421 - acc: 0.8034 -- iter: 04096/10000
[A[ATraining Step: 3519  | total loss: [1m[32m0.51342[0m[0m | time: 68.777s
[2K| Adam | epoch: 023 | loss: 0.51342 - acc: 0.8043 -- iter: 04160/10000
[A[ATraining Step: 3520  | total loss: [1m[32m0.53644[0m[0m | time: 69.802s
[2K| Adam | epoch: 023 | loss: 0.53644 - acc: 0.7833 -- iter: 04224/10000
[A[ATraining Step: 3521  | total loss: [1m[32m0.52828[0m[0m | time: 70.800s
[2K| Adam | epoch: 023 | loss: 0.52828 - acc: 0.7862 -- iter: 04288/10000
[A[ATraining Step: 3522  | total loss: [1m[32m0.54141[0m[0m | time: 71.802s
[2K| Adam | epoch: 023 | loss: 0.54141 - acc: 0.7841 -- iter: 04352/10000
[A[ATraining Step: 3523  | total loss: [1m[32m0.54725[0m[0m | time: 72.805s
[2K| Adam | epoch: 023 | loss: 0.54725 - acc: 0.7839 -- iter: 04416/10000
[A[ATraining Step: 3524  | total loss: [1m[32m0.55042[0m[0m | time: 73.811s
[2K| Adam | epoch: 023 | loss: 0.55042 - acc: 0.7914 -- iter: 04480/10000
[A[ATraining Step: 3525  | total loss: [1m[32m0.54728[0m[0m | time: 74.816s
[2K| Adam | epoch: 023 | loss: 0.54728 - acc: 0.7998 -- iter: 04544/10000
[A[ATraining Step: 3526  | total loss: [1m[32m0.55618[0m[0m | time: 75.824s
[2K| Adam | epoch: 023 | loss: 0.55618 - acc: 0.7995 -- iter: 04608/10000
[A[ATraining Step: 3527  | total loss: [1m[32m0.54348[0m[0m | time: 76.855s
[2K| Adam | epoch: 023 | loss: 0.54348 - acc: 0.8117 -- iter: 04672/10000
[A[ATraining Step: 3528  | total loss: [1m[32m0.53080[0m[0m | time: 77.864s
[2K| Adam | epoch: 023 | loss: 0.53080 - acc: 0.8165 -- iter: 04736/10000
[A[ATraining Step: 3529  | total loss: [1m[32m0.52618[0m[0m | time: 78.874s
[2K| Adam | epoch: 023 | loss: 0.52618 - acc: 0.8223 -- iter: 04800/10000
[A[ATraining Step: 3530  | total loss: [1m[32m0.52363[0m[0m | time: 79.874s
[2K| Adam | epoch: 023 | loss: 0.52363 - acc: 0.8229 -- iter: 04864/10000
[A[ATraining Step: 3531  | total loss: [1m[32m0.53010[0m[0m | time: 80.961s
[2K| Adam | epoch: 023 | loss: 0.53010 - acc: 0.8156 -- iter: 04928/10000
[A[ATraining Step: 3532  | total loss: [1m[32m0.53926[0m[0m | time: 82.053s
[2K| Adam | epoch: 023 | loss: 0.53926 - acc: 0.8059 -- iter: 04992/10000
[A[ATraining Step: 3533  | total loss: [1m[32m0.53907[0m[0m | time: 83.139s
[2K| Adam | epoch: 023 | loss: 0.53907 - acc: 0.8082 -- iter: 05056/10000
[A[ATraining Step: 3534  | total loss: [1m[32m0.52884[0m[0m | time: 84.226s
[2K| Adam | epoch: 023 | loss: 0.52884 - acc: 0.8117 -- iter: 05120/10000
[A[ATraining Step: 3535  | total loss: [1m[32m0.52896[0m[0m | time: 85.275s
[2K| Adam | epoch: 023 | loss: 0.52896 - acc: 0.8087 -- iter: 05184/10000
[A[ATraining Step: 3536  | total loss: [1m[32m0.51831[0m[0m | time: 86.237s
[2K| Adam | epoch: 023 | loss: 0.51831 - acc: 0.8122 -- iter: 05248/10000
[A[ATraining Step: 3537  | total loss: [1m[32m0.51091[0m[0m | time: 87.220s
[2K| Adam | epoch: 023 | loss: 0.51091 - acc: 0.8122 -- iter: 05312/10000
[A[ATraining Step: 3538  | total loss: [1m[32m0.51142[0m[0m | time: 88.169s
[2K| Adam | epoch: 023 | loss: 0.51142 - acc: 0.8060 -- iter: 05376/10000
[A[ATraining Step: 3539  | total loss: [1m[32m0.50789[0m[0m | time: 89.144s
[2K| Adam | epoch: 023 | loss: 0.50789 - acc: 0.8066 -- iter: 05440/10000
[A[ATraining Step: 3540  | total loss: [1m[32m0.52472[0m[0m | time: 90.088s
[2K| Adam | epoch: 023 | loss: 0.52472 - acc: 0.8057 -- iter: 05504/10000
[A[ATraining Step: 3541  | total loss: [1m[32m0.50937[0m[0m | time: 91.035s
[2K| Adam | epoch: 023 | loss: 0.50937 - acc: 0.8157 -- iter: 05568/10000
[A[ATraining Step: 3542  | total loss: [1m[32m0.50619[0m[0m | time: 92.013s
[2K| Adam | epoch: 023 | loss: 0.50619 - acc: 0.8216 -- iter: 05632/10000
[A[ATraining Step: 3543  | total loss: [1m[32m0.50953[0m[0m | time: 93.020s
[2K| Adam | epoch: 023 | loss: 0.50953 - acc: 0.8207 -- iter: 05696/10000
[A[ATraining Step: 3544  | total loss: [1m[32m0.51871[0m[0m | time: 94.028s
[2K| Adam | epoch: 023 | loss: 0.51871 - acc: 0.8215 -- iter: 05760/10000
[A[ATraining Step: 3545  | total loss: [1m[32m0.52570[0m[0m | time: 95.030s
[2K| Adam | epoch: 023 | loss: 0.52570 - acc: 0.8237 -- iter: 05824/10000
[A[ATraining Step: 3546  | total loss: [1m[32m0.51234[0m[0m | time: 96.042s
[2K| Adam | epoch: 023 | loss: 0.51234 - acc: 0.8241 -- iter: 05888/10000
[A[ATraining Step: 3547  | total loss: [1m[32m0.50664[0m[0m | time: 97.084s
[2K| Adam | epoch: 023 | loss: 0.50664 - acc: 0.8230 -- iter: 05952/10000
[A[ATraining Step: 3548  | total loss: [1m[32m0.51087[0m[0m | time: 98.089s
[2K| Adam | epoch: 023 | loss: 0.51087 - acc: 0.8235 -- iter: 06016/10000
[A[ATraining Step: 3549  | total loss: [1m[32m0.49040[0m[0m | time: 99.102s
[2K| Adam | epoch: 023 | loss: 0.49040 - acc: 0.8302 -- iter: 06080/10000
[A[ATraining Step: 3550  | total loss: [1m[32m0.49325[0m[0m | time: 100.136s
[2K| Adam | epoch: 023 | loss: 0.49325 - acc: 0.8284 -- iter: 06144/10000
[A[ATraining Step: 3551  | total loss: [1m[32m0.51898[0m[0m | time: 101.262s
[2K| Adam | epoch: 023 | loss: 0.51898 - acc: 0.8175 -- iter: 06208/10000
[A[ATraining Step: 3552  | total loss: [1m[32m0.52404[0m[0m | time: 102.405s
[2K| Adam | epoch: 023 | loss: 0.52404 - acc: 0.8107 -- iter: 06272/10000
[A[ATraining Step: 3553  | total loss: [1m[32m0.52146[0m[0m | time: 103.552s
[2K| Adam | epoch: 023 | loss: 0.52146 - acc: 0.8093 -- iter: 06336/10000
[A[ATraining Step: 3554  | total loss: [1m[32m0.52854[0m[0m | time: 104.667s
[2K| Adam | epoch: 023 | loss: 0.52854 - acc: 0.8065 -- iter: 06400/10000
[A[ATraining Step: 3555  | total loss: [1m[32m0.52132[0m[0m | time: 105.768s
[2K| Adam | epoch: 023 | loss: 0.52132 - acc: 0.8087 -- iter: 06464/10000
[A[ATraining Step: 3556  | total loss: [1m[32m0.52167[0m[0m | time: 106.770s
[2K| Adam | epoch: 023 | loss: 0.52167 - acc: 0.8138 -- iter: 06528/10000
[A[ATraining Step: 3557  | total loss: [1m[32m0.52292[0m[0m | time: 107.692s
[2K| Adam | epoch: 023 | loss: 0.52292 - acc: 0.8152 -- iter: 06592/10000
[A[ATraining Step: 3558  | total loss: [1m[32m0.52236[0m[0m | time: 108.656s
[2K| Adam | epoch: 023 | loss: 0.52236 - acc: 0.8196 -- iter: 06656/10000
[A[ATraining Step: 3559  | total loss: [1m[32m0.52072[0m[0m | time: 109.617s
[2K| Adam | epoch: 023 | loss: 0.52072 - acc: 0.8095 -- iter: 06720/10000
[A[ATraining Step: 3560  | total loss: [1m[32m0.53807[0m[0m | time: 110.577s
[2K| Adam | epoch: 023 | loss: 0.53807 - acc: 0.8020 -- iter: 06784/10000
[A[ATraining Step: 3561  | total loss: [1m[32m0.54484[0m[0m | time: 111.526s
[2K| Adam | epoch: 023 | loss: 0.54484 - acc: 0.7952 -- iter: 06848/10000
[A[ATraining Step: 3562  | total loss: [1m[32m0.53776[0m[0m | time: 112.501s
[2K| Adam | epoch: 023 | loss: 0.53776 - acc: 0.7938 -- iter: 06912/10000
[A[ATraining Step: 3563  | total loss: [1m[32m0.54765[0m[0m | time: 113.503s
[2K| Adam | epoch: 023 | loss: 0.54765 - acc: 0.7863 -- iter: 06976/10000
[A[ATraining Step: 3564  | total loss: [1m[32m0.53431[0m[0m | time: 114.501s
[2K| Adam | epoch: 023 | loss: 0.53431 - acc: 0.7874 -- iter: 07040/10000
[A[ATraining Step: 3565  | total loss: [1m[32m0.52781[0m[0m | time: 115.497s
[2K| Adam | epoch: 023 | loss: 0.52781 - acc: 0.7852 -- iter: 07104/10000
[A[ATraining Step: 3566  | total loss: [1m[32m0.51528[0m[0m | time: 116.498s
[2K| Adam | epoch: 023 | loss: 0.51528 - acc: 0.7895 -- iter: 07168/10000
[A[ATraining Step: 3567  | total loss: [1m[32m0.51726[0m[0m | time: 117.535s
[2K| Adam | epoch: 023 | loss: 0.51726 - acc: 0.7902 -- iter: 07232/10000
[A[ATraining Step: 3568  | total loss: [1m[32m0.51998[0m[0m | time: 118.555s
[2K| Adam | epoch: 023 | loss: 0.51998 - acc: 0.7925 -- iter: 07296/10000
[A[ATraining Step: 3569  | total loss: [1m[32m0.51013[0m[0m | time: 119.638s
[2K| Adam | epoch: 023 | loss: 0.51013 - acc: 0.7976 -- iter: 07360/10000
[A[ATraining Step: 3570  | total loss: [1m[32m0.50603[0m[0m | time: 120.706s
[2K| Adam | epoch: 023 | loss: 0.50603 - acc: 0.8006 -- iter: 07424/10000
[A[ATraining Step: 3571  | total loss: [1m[32m0.52015[0m[0m | time: 121.768s
[2K| Adam | epoch: 023 | loss: 0.52015 - acc: 0.7925 -- iter: 07488/10000
[A[ATraining Step: 3572  | total loss: [1m[32m0.51993[0m[0m | time: 122.828s
[2K| Adam | epoch: 023 | loss: 0.51993 - acc: 0.7945 -- iter: 07552/10000
[A[ATraining Step: 3573  | total loss: [1m[32m0.51004[0m[0m | time: 123.886s
[2K| Adam | epoch: 023 | loss: 0.51004 - acc: 0.7963 -- iter: 07616/10000
[A[ATraining Step: 3574  | total loss: [1m[32m0.50267[0m[0m | time: 124.940s
[2K| Adam | epoch: 023 | loss: 0.50267 - acc: 0.7979 -- iter: 07680/10000
[A[ATraining Step: 3575  | total loss: [1m[32m0.50098[0m[0m | time: 126.012s
[2K| Adam | epoch: 023 | loss: 0.50098 - acc: 0.8009 -- iter: 07744/10000
[A[ATraining Step: 3576  | total loss: [1m[32m0.49227[0m[0m | time: 127.111s
[2K| Adam | epoch: 023 | loss: 0.49227 - acc: 0.8068 -- iter: 07808/10000
[A[ATraining Step: 3577  | total loss: [1m[32m0.50375[0m[0m | time: 128.137s
[2K| Adam | epoch: 023 | loss: 0.50375 - acc: 0.8042 -- iter: 07872/10000
[A[ATraining Step: 3578  | total loss: [1m[32m0.52364[0m[0m | time: 129.193s
[2K| Adam | epoch: 023 | loss: 0.52364 - acc: 0.7988 -- iter: 07936/10000
[A[ATraining Step: 3579  | total loss: [1m[32m0.51797[0m[0m | time: 130.352s
[2K| Adam | epoch: 023 | loss: 0.51797 - acc: 0.8017 -- iter: 08000/10000
[A[ATraining Step: 3580  | total loss: [1m[32m0.52276[0m[0m | time: 131.414s
[2K| Adam | epoch: 023 | loss: 0.52276 - acc: 0.8012 -- iter: 08064/10000
[A[ATraining Step: 3581  | total loss: [1m[32m0.51939[0m[0m | time: 132.479s
[2K| Adam | epoch: 023 | loss: 0.51939 - acc: 0.8024 -- iter: 08128/10000
[A[ATraining Step: 3582  | total loss: [1m[32m0.52118[0m[0m | time: 133.544s
[2K| Adam | epoch: 023 | loss: 0.52118 - acc: 0.7971 -- iter: 08192/10000
[A[ATraining Step: 3583  | total loss: [1m[32m0.51654[0m[0m | time: 134.598s
[2K| Adam | epoch: 023 | loss: 0.51654 - acc: 0.8018 -- iter: 08256/10000
[A[ATraining Step: 3584  | total loss: [1m[32m0.50869[0m[0m | time: 135.663s
[2K| Adam | epoch: 023 | loss: 0.50869 - acc: 0.8075 -- iter: 08320/10000
[A[ATraining Step: 3585  | total loss: [1m[32m0.50966[0m[0m | time: 136.705s
[2K| Adam | epoch: 023 | loss: 0.50966 - acc: 0.8018 -- iter: 08384/10000
[A[ATraining Step: 3586  | total loss: [1m[32m0.51150[0m[0m | time: 137.775s
[2K| Adam | epoch: 023 | loss: 0.51150 - acc: 0.7966 -- iter: 08448/10000
[A[ATraining Step: 3587  | total loss: [1m[32m0.51434[0m[0m | time: 138.869s
[2K| Adam | epoch: 023 | loss: 0.51434 - acc: 0.7920 -- iter: 08512/10000
[A[ATraining Step: 3588  | total loss: [1m[32m0.52288[0m[0m | time: 140.001s
[2K| Adam | epoch: 023 | loss: 0.52288 - acc: 0.7971 -- iter: 08576/10000
[A[ATraining Step: 3589  | total loss: [1m[32m0.50785[0m[0m | time: 141.014s
[2K| Adam | epoch: 023 | loss: 0.50785 - acc: 0.8034 -- iter: 08640/10000
[A[ATraining Step: 3590  | total loss: [1m[32m0.50381[0m[0m | time: 141.949s
[2K| Adam | epoch: 023 | loss: 0.50381 - acc: 0.8090 -- iter: 08704/10000
[A[ATraining Step: 3591  | total loss: [1m[32m0.49704[0m[0m | time: 142.940s
[2K| Adam | epoch: 023 | loss: 0.49704 - acc: 0.8140 -- iter: 08768/10000
[A[ATraining Step: 3592  | total loss: [1m[32m0.49364[0m[0m | time: 143.910s
[2K| Adam | epoch: 023 | loss: 0.49364 - acc: 0.8123 -- iter: 08832/10000
[A[ATraining Step: 3593  | total loss: [1m[32m0.48618[0m[0m | time: 144.892s
[2K| Adam | epoch: 023 | loss: 0.48618 - acc: 0.8170 -- iter: 08896/10000
[A[ATraining Step: 3594  | total loss: [1m[32m0.49275[0m[0m | time: 145.903s
[2K| Adam | epoch: 023 | loss: 0.49275 - acc: 0.8087 -- iter: 08960/10000
[A[ATraining Step: 3595  | total loss: [1m[32m0.48196[0m[0m | time: 146.937s
[2K| Adam | epoch: 023 | loss: 0.48196 - acc: 0.8107 -- iter: 09024/10000
[A[ATraining Step: 3596  | total loss: [1m[32m0.49590[0m[0m | time: 147.944s
[2K| Adam | epoch: 023 | loss: 0.49590 - acc: 0.8046 -- iter: 09088/10000
[A[ATraining Step: 3597  | total loss: [1m[32m0.52158[0m[0m | time: 148.954s
[2K| Adam | epoch: 023 | loss: 0.52158 - acc: 0.7991 -- iter: 09152/10000
[A[ATraining Step: 3598  | total loss: [1m[32m0.51028[0m[0m | time: 149.984s
[2K| Adam | epoch: 023 | loss: 0.51028 - acc: 0.8052 -- iter: 09216/10000
[A[ATraining Step: 3599  | total loss: [1m[32m0.51543[0m[0m | time: 151.052s
[2K| Adam | epoch: 023 | loss: 0.51543 - acc: 0.8012 -- iter: 09280/10000
[A[ATraining Step: 3600  | total loss: [1m[32m0.50347[0m[0m | time: 155.344s
[2K| Adam | epoch: 023 | loss: 0.50347 - acc: 0.8055 | val_loss: 2.92263 - val_acc: 0.3800 -- iter: 09344/10000
--
Training Step: 3601  | total loss: [1m[32m0.50002[0m[0m | time: 156.431s
[2K| Adam | epoch: 023 | loss: 0.50002 - acc: 0.8062 -- iter: 09408/10000
[A[ATraining Step: 3602  | total loss: [1m[32m1.56528[0m[0m | time: 157.584s
[2K| Adam | epoch: 023 | loss: 1.56528 - acc: 0.7396 -- iter: 09472/10000
[A[ATraining Step: 3603  | total loss: [1m[32m1.45210[0m[0m | time: 158.641s
[2K| Adam | epoch: 023 | loss: 1.45210 - acc: 0.7532 -- iter: 09536/10000
[A[ATraining Step: 3604  | total loss: [1m[32m1.36280[0m[0m | time: 159.658s
[2K| Adam | epoch: 023 | loss: 1.36280 - acc: 0.7607 -- iter: 09600/10000
[A[ATraining Step: 3605  | total loss: [1m[32m1.26391[0m[0m | time: 160.610s
[2K| Adam | epoch: 023 | loss: 1.26391 - acc: 0.7736 -- iter: 09664/10000
[A[ATraining Step: 3606  | total loss: [1m[32m1.18093[0m[0m | time: 161.559s
[2K| Adam | epoch: 023 | loss: 1.18093 - acc: 0.7822 -- iter: 09728/10000
[A[ATraining Step: 3607  | total loss: [1m[32m1.13210[0m[0m | time: 162.516s
[2K| Adam | epoch: 023 | loss: 1.13210 - acc: 0.7884 -- iter: 09792/10000
[A[ATraining Step: 3608  | total loss: [1m[32m1.06273[0m[0m | time: 163.468s
[2K| Adam | epoch: 023 | loss: 1.06273 - acc: 0.7955 -- iter: 09856/10000
[A[ATraining Step: 3609  | total loss: [1m[32m1.00597[0m[0m | time: 164.441s
[2K| Adam | epoch: 023 | loss: 1.00597 - acc: 0.7972 -- iter: 09920/10000
[A[ATraining Step: 3610  | total loss: [1m[32m0.95666[0m[0m | time: 165.452s
[2K| Adam | epoch: 023 | loss: 0.95666 - acc: 0.7909 -- iter: 09984/10000
[A[ATraining Step: 3611  | total loss: [1m[32m0.91836[0m[0m | time: 169.308s
[2K| Adam | epoch: 023 | loss: 0.91836 - acc: 0.7821 | val_loss: 2.92168 - val_acc: 0.3771 -- iter: 10000/10000
--
Training Step: 3612  | total loss: [1m[32m0.86692[0m[0m | time: 1.053s
[2K| Adam | epoch: 024 | loss: 0.86692 - acc: 0.7867 -- iter: 00064/10000
[A[ATraining Step: 3613  | total loss: [1m[32m0.85306[0m[0m | time: 2.069s
[2K| Adam | epoch: 024 | loss: 0.85306 - acc: 0.7846 -- iter: 00128/10000
[A[ATraining Step: 3614  | total loss: [1m[32m0.82551[0m[0m | time: 3.133s
[2K| Adam | epoch: 024 | loss: 0.82551 - acc: 0.7843 -- iter: 00192/10000
[A[ATraining Step: 3615  | total loss: [1m[32m0.79659[0m[0m | time: 4.201s
[2K| Adam | epoch: 024 | loss: 0.79659 - acc: 0.7918 -- iter: 00256/10000
[A[ATraining Step: 3616  | total loss: [1m[32m0.78796[0m[0m | time: 5.254s
[2K| Adam | epoch: 024 | loss: 0.78796 - acc: 0.7970 -- iter: 00320/10000
[A[ATraining Step: 3617  | total loss: [1m[32m0.75490[0m[0m | time: 6.311s
[2K| Adam | epoch: 024 | loss: 0.75490 - acc: 0.8001 -- iter: 00384/10000
[A[ATraining Step: 3618  | total loss: [1m[32m0.73861[0m[0m | time: 7.394s
[2K| Adam | epoch: 024 | loss: 0.73861 - acc: 0.7982 -- iter: 00448/10000
[A[ATraining Step: 3619  | total loss: [1m[32m0.71906[0m[0m | time: 8.494s
[2K| Adam | epoch: 024 | loss: 0.71906 - acc: 0.7950 -- iter: 00512/10000
[A[ATraining Step: 3620  | total loss: [1m[32m0.69891[0m[0m | time: 9.559s
[2K| Adam | epoch: 024 | loss: 0.69891 - acc: 0.7951 -- iter: 00576/10000
[A[ATraining Step: 3621  | total loss: [1m[32m0.66717[0m[0m | time: 10.649s
[2K| Adam | epoch: 024 | loss: 0.66717 - acc: 0.7953 -- iter: 00640/10000
[A[ATraining Step: 3622  | total loss: [1m[32m0.65556[0m[0m | time: 11.750s
[2K| Adam | epoch: 024 | loss: 0.65556 - acc: 0.7923 -- iter: 00704/10000
[A[ATraining Step: 3623  | total loss: [1m[32m0.64126[0m[0m | time: 12.857s
[2K| Adam | epoch: 024 | loss: 0.64126 - acc: 0.7928 -- iter: 00768/10000
[A[ATraining Step: 3624  | total loss: [1m[32m0.63260[0m[0m | time: 14.012s
[2K| Adam | epoch: 024 | loss: 0.63260 - acc: 0.7885 -- iter: 00832/10000
[A[ATraining Step: 3625  | total loss: [1m[32m0.61327[0m[0m | time: 15.158s
[2K| Adam | epoch: 024 | loss: 0.61327 - acc: 0.7940 -- iter: 00896/10000
[A[ATraining Step: 3626  | total loss: [1m[32m0.62265[0m[0m | time: 16.250s
[2K| Adam | epoch: 024 | loss: 0.62265 - acc: 0.7912 -- iter: 00960/10000
[A[ATraining Step: 3627  | total loss: [1m[32m0.61719[0m[0m | time: 17.539s
[2K| Adam | epoch: 024 | loss: 0.61719 - acc: 0.7918 -- iter: 01024/10000
[A[ATraining Step: 3628  | total loss: [1m[32m0.58934[0m[0m | time: 18.676s
[2K| Adam | epoch: 024 | loss: 0.58934 - acc: 0.8017 -- iter: 01088/10000
[A[ATraining Step: 3629  | total loss: [1m[32m0.57853[0m[0m | time: 19.703s
[2K| Adam | epoch: 024 | loss: 0.57853 - acc: 0.8012 -- iter: 01152/10000
[A[ATraining Step: 3630  | total loss: [1m[32m0.57621[0m[0m | time: 20.623s
[2K| Adam | epoch: 024 | loss: 0.57621 - acc: 0.7992 -- iter: 01216/10000
[A[ATraining Step: 3631  | total loss: [1m[32m0.55875[0m[0m | time: 21.578s
[2K| Adam | epoch: 024 | loss: 0.55875 - acc: 0.8068 -- iter: 01280/10000
[A[ATraining Step: 3632  | total loss: [1m[32m0.56025[0m[0m | time: 22.535s
[2K| Adam | epoch: 024 | loss: 0.56025 - acc: 0.8042 -- iter: 01344/10000
[A[ATraining Step: 3633  | total loss: [1m[32m0.55312[0m[0m | time: 22.985s
[2K| Adam | epoch: 024 | loss: 0.55312 - acc: 0.8050 -- iter: 01408/10000
[A[ATraining Step: 3634  | total loss: [1m[32m0.57242[0m[0m | time: 23.412s
[2K| Adam | epoch: 024 | loss: 0.57242 - acc: 0.7995 -- iter: 01472/10000
[A[ATraining Step: 3635  | total loss: [1m[32m0.55791[0m[0m | time: 24.423s
[2K| Adam | epoch: 024 | loss: 0.55791 - acc: 0.8071 -- iter: 01536/10000
[A[ATraining Step: 3636  | total loss: [1m[32m0.54264[0m[0m | time: 25.427s
[2K| Adam | epoch: 024 | loss: 0.54264 - acc: 0.8061 -- iter: 01600/10000
[A[ATraining Step: 3637  | total loss: [1m[32m0.55064[0m[0m | time: 26.433s
[2K| Adam | epoch: 024 | loss: 0.55064 - acc: 0.8020 -- iter: 01664/10000
[A[ATraining Step: 3638  | total loss: [1m[32m0.53670[0m[0m | time: 27.488s
[2K| Adam | epoch: 024 | loss: 0.53670 - acc: 0.8078 -- iter: 01728/10000
[A[ATraining Step: 3639  | total loss: [1m[32m0.52621[0m[0m | time: 28.614s
[2K| Adam | epoch: 024 | loss: 0.52621 - acc: 0.8176 -- iter: 01792/10000
[A[ATraining Step: 3640  | total loss: [1m[32m0.53335[0m[0m | time: 29.783s
[2K| Adam | epoch: 024 | loss: 0.53335 - acc: 0.8124 -- iter: 01856/10000
[A[ATraining Step: 3641  | total loss: [1m[32m0.52142[0m[0m | time: 30.960s
[2K| Adam | epoch: 024 | loss: 0.52142 - acc: 0.8155 -- iter: 01920/10000
[A[ATraining Step: 3642  | total loss: [1m[32m0.51490[0m[0m | time: 32.104s
[2K| Adam | epoch: 024 | loss: 0.51490 - acc: 0.8262 -- iter: 01984/10000
[A[ATraining Step: 3643  | total loss: [1m[32m0.53145[0m[0m | time: 33.208s
[2K| Adam | epoch: 024 | loss: 0.53145 - acc: 0.8186 -- iter: 02048/10000
[A[ATraining Step: 3644  | total loss: [1m[32m0.52655[0m[0m | time: 34.303s
[2K| Adam | epoch: 024 | loss: 0.52655 - acc: 0.8211 -- iter: 02112/10000
[A[ATraining Step: 3645  | total loss: [1m[32m0.51840[0m[0m | time: 35.272s
[2K| Adam | epoch: 024 | loss: 0.51840 - acc: 0.8218 -- iter: 02176/10000
[A[ATraining Step: 3646  | total loss: [1m[32m0.51469[0m[0m | time: 36.230s
[2K| Adam | epoch: 024 | loss: 0.51469 - acc: 0.8224 -- iter: 02240/10000
[A[ATraining Step: 3647  | total loss: [1m[32m0.53862[0m[0m | time: 37.184s
[2K| Adam | epoch: 024 | loss: 0.53862 - acc: 0.8136 -- iter: 02304/10000
[A[ATraining Step: 3648  | total loss: [1m[32m0.51689[0m[0m | time: 38.182s
[2K| Adam | epoch: 024 | loss: 0.51689 - acc: 0.8198 -- iter: 02368/10000
[A[ATraining Step: 3649  | total loss: [1m[32m0.51330[0m[0m | time: 39.150s
[2K| Adam | epoch: 024 | loss: 0.51330 - acc: 0.8206 -- iter: 02432/10000
[A[ATraining Step: 3650  | total loss: [1m[32m0.53760[0m[0m | time: 40.169s
[2K| Adam | epoch: 024 | loss: 0.53760 - acc: 0.8120 -- iter: 02496/10000
[A[ATraining Step: 3651  | total loss: [1m[32m0.53334[0m[0m | time: 41.174s
[2K| Adam | epoch: 024 | loss: 0.53334 - acc: 0.8151 -- iter: 02560/10000
[A[ATraining Step: 3652  | total loss: [1m[32m0.51225[0m[0m | time: 42.182s
[2K| Adam | epoch: 024 | loss: 0.51225 - acc: 0.8180 -- iter: 02624/10000
[A[ATraining Step: 3653  | total loss: [1m[32m0.50516[0m[0m | time: 43.238s
[2K| Adam | epoch: 024 | loss: 0.50516 - acc: 0.8221 -- iter: 02688/10000
[A[ATraining Step: 3654  | total loss: [1m[32m0.48697[0m[0m | time: 44.342s
[2K| Adam | epoch: 024 | loss: 0.48697 - acc: 0.8259 -- iter: 02752/10000
[A[ATraining Step: 3655  | total loss: [1m[32m0.49062[0m[0m | time: 45.447s
[2K| Adam | epoch: 024 | loss: 0.49062 - acc: 0.8277 -- iter: 02816/10000
[A[ATraining Step: 3656  | total loss: [1m[32m0.48301[0m[0m | time: 46.552s
[2K| Adam | epoch: 024 | loss: 0.48301 - acc: 0.8293 -- iter: 02880/10000
[A[ATraining Step: 3657  | total loss: [1m[32m0.47296[0m[0m | time: 47.696s
[2K| Adam | epoch: 024 | loss: 0.47296 - acc: 0.8370 -- iter: 02944/10000
[A[ATraining Step: 3658  | total loss: [1m[32m0.47965[0m[0m | time: 48.809s
[2K| Adam | epoch: 024 | loss: 0.47965 - acc: 0.8314 -- iter: 03008/10000
[A[ATraining Step: 3659  | total loss: [1m[32m0.48813[0m[0m | time: 50.000s
[2K| Adam | epoch: 024 | loss: 0.48813 - acc: 0.8326 -- iter: 03072/10000
[A[ATraining Step: 3660  | total loss: [1m[32m0.50315[0m[0m | time: 51.094s
[2K| Adam | epoch: 024 | loss: 0.50315 - acc: 0.8275 -- iter: 03136/10000
[A[ATraining Step: 3661  | total loss: [1m[32m0.49128[0m[0m | time: 52.052s
[2K| Adam | epoch: 024 | loss: 0.49128 - acc: 0.8260 -- iter: 03200/10000
[A[ATraining Step: 3662  | total loss: [1m[32m0.49572[0m[0m | time: 53.005s
[2K| Adam | epoch: 024 | loss: 0.49572 - acc: 0.8215 -- iter: 03264/10000
[A[ATraining Step: 3663  | total loss: [1m[32m0.51034[0m[0m | time: 53.977s
[2K| Adam | epoch: 024 | loss: 0.51034 - acc: 0.8206 -- iter: 03328/10000
[A[ATraining Step: 3664  | total loss: [1m[32m0.51814[0m[0m | time: 54.930s
[2K| Adam | epoch: 024 | loss: 0.51814 - acc: 0.8136 -- iter: 03392/10000
[A[ATraining Step: 3665  | total loss: [1m[32m0.50863[0m[0m | time: 55.894s
[2K| Adam | epoch: 024 | loss: 0.50863 - acc: 0.8181 -- iter: 03456/10000
[A[ATraining Step: 3666  | total loss: [1m[32m0.50531[0m[0m | time: 56.897s
[2K| Adam | epoch: 024 | loss: 0.50531 - acc: 0.8176 -- iter: 03520/10000
[A[ATraining Step: 3667  | total loss: [1m[32m0.50191[0m[0m | time: 57.972s
[2K| Adam | epoch: 024 | loss: 0.50191 - acc: 0.8202 -- iter: 03584/10000
[A[ATraining Step: 3668  | total loss: [1m[32m0.50792[0m[0m | time: 59.079s
[2K| Adam | epoch: 024 | loss: 0.50792 - acc: 0.8163 -- iter: 03648/10000
[A[ATraining Step: 3669  | total loss: [1m[32m0.50766[0m[0m | time: 60.199s
[2K| Adam | epoch: 024 | loss: 0.50766 - acc: 0.8128 -- iter: 03712/10000
[A[ATraining Step: 3670  | total loss: [1m[32m0.50790[0m[0m | time: 61.310s
[2K| Adam | epoch: 024 | loss: 0.50790 - acc: 0.8096 -- iter: 03776/10000
[A[ATraining Step: 3671  | total loss: [1m[32m0.51899[0m[0m | time: 62.416s
[2K| Adam | epoch: 024 | loss: 0.51899 - acc: 0.8084 -- iter: 03840/10000
[A[ATraining Step: 3672  | total loss: [1m[32m0.51032[0m[0m | time: 63.522s
[2K| Adam | epoch: 024 | loss: 0.51032 - acc: 0.8135 -- iter: 03904/10000
[A[ATraining Step: 3673  | total loss: [1m[32m0.52603[0m[0m | time: 64.610s
[2K| Adam | epoch: 024 | loss: 0.52603 - acc: 0.8071 -- iter: 03968/10000
[A[ATraining Step: 3674  | total loss: [1m[32m0.51599[0m[0m | time: 65.600s
[2K| Adam | epoch: 024 | loss: 0.51599 - acc: 0.8108 -- iter: 04032/10000
[A[ATraining Step: 3675  | total loss: [1m[32m0.52791[0m[0m | time: 66.555s
[2K| Adam | epoch: 024 | loss: 0.52791 - acc: 0.8031 -- iter: 04096/10000
[A[ATraining Step: 3676  | total loss: [1m[32m0.53366[0m[0m | time: 67.541s
[2K| Adam | epoch: 024 | loss: 0.53366 - acc: 0.7994 -- iter: 04160/10000
[A[ATraining Step: 3677  | total loss: [1m[32m0.55552[0m[0m | time: 68.506s
[2K| Adam | epoch: 024 | loss: 0.55552 - acc: 0.7913 -- iter: 04224/10000
[A[ATraining Step: 3678  | total loss: [1m[32m0.55965[0m[0m | time: 69.484s
[2K| Adam | epoch: 024 | loss: 0.55965 - acc: 0.7856 -- iter: 04288/10000
[A[ATraining Step: 3679  | total loss: [1m[32m0.56784[0m[0m | time: 70.526s
[2K| Adam | epoch: 024 | loss: 0.56784 - acc: 0.7789 -- iter: 04352/10000
[A[ATraining Step: 3680  | total loss: [1m[32m0.57403[0m[0m | time: 71.535s
[2K| Adam | epoch: 024 | loss: 0.57403 - acc: 0.7776 -- iter: 04416/10000
[A[ATraining Step: 3681  | total loss: [1m[32m0.55588[0m[0m | time: 72.516s
[2K| Adam | epoch: 024 | loss: 0.55588 - acc: 0.7858 -- iter: 04480/10000
[A[ATraining Step: 3682  | total loss: [1m[32m0.55421[0m[0m | time: 73.578s
[2K| Adam | epoch: 024 | loss: 0.55421 - acc: 0.7931 -- iter: 04544/10000
[A[ATraining Step: 3683  | total loss: [1m[32m0.53308[0m[0m | time: 74.643s
[2K| Adam | epoch: 024 | loss: 0.53308 - acc: 0.7998 -- iter: 04608/10000
[A[ATraining Step: 3684  | total loss: [1m[32m0.55270[0m[0m | time: 75.717s
[2K| Adam | epoch: 024 | loss: 0.55270 - acc: 0.7948 -- iter: 04672/10000
[A[ATraining Step: 3685  | total loss: [1m[32m0.54299[0m[0m | time: 76.781s
[2K| Adam | epoch: 024 | loss: 0.54299 - acc: 0.7966 -- iter: 04736/10000
[A[ATraining Step: 3686  | total loss: [1m[32m0.53358[0m[0m | time: 77.893s
[2K| Adam | epoch: 024 | loss: 0.53358 - acc: 0.7966 -- iter: 04800/10000
[A[ATraining Step: 3687  | total loss: [1m[32m0.52942[0m[0m | time: 78.954s
[2K| Adam | epoch: 024 | loss: 0.52942 - acc: 0.7919 -- iter: 04864/10000
[A[ATraining Step: 3688  | total loss: [1m[32m0.52853[0m[0m | time: 80.020s
[2K| Adam | epoch: 024 | loss: 0.52853 - acc: 0.7909 -- iter: 04928/10000
[A[ATraining Step: 3689  | total loss: [1m[32m0.50613[0m[0m | time: 81.173s
[2K| Adam | epoch: 024 | loss: 0.50613 - acc: 0.7977 -- iter: 04992/10000
[A[ATraining Step: 3690  | total loss: [1m[32m0.50504[0m[0m | time: 82.326s
[2K| Adam | epoch: 024 | loss: 0.50504 - acc: 0.8023 -- iter: 05056/10000
[A[ATraining Step: 3691  | total loss: [1m[32m0.50531[0m[0m | time: 83.493s
[2K| Adam | epoch: 024 | loss: 0.50531 - acc: 0.8049 -- iter: 05120/10000
[A[ATraining Step: 3692  | total loss: [1m[32m0.50027[0m[0m | time: 84.781s
[2K| Adam | epoch: 024 | loss: 0.50027 - acc: 0.8072 -- iter: 05184/10000
[A[ATraining Step: 3693  | total loss: [1m[32m0.50911[0m[0m | time: 85.918s
[2K| Adam | epoch: 024 | loss: 0.50911 - acc: 0.8046 -- iter: 05248/10000
[A[ATraining Step: 3694  | total loss: [1m[32m0.49598[0m[0m | time: 87.148s
[2K| Adam | epoch: 024 | loss: 0.49598 - acc: 0.8132 -- iter: 05312/10000
[A[ATraining Step: 3695  | total loss: [1m[32m0.48733[0m[0m | time: 88.391s
[2K| Adam | epoch: 024 | loss: 0.48733 - acc: 0.8147 -- iter: 05376/10000
[A[ATraining Step: 3696  | total loss: [1m[32m0.47281[0m[0m | time: 89.565s
[2K| Adam | epoch: 024 | loss: 0.47281 - acc: 0.8270 -- iter: 05440/10000
[A[ATraining Step: 3697  | total loss: [1m[32m0.48207[0m[0m | time: 90.769s
[2K| Adam | epoch: 024 | loss: 0.48207 - acc: 0.8240 -- iter: 05504/10000
[A[ATraining Step: 3698  | total loss: [1m[32m0.48393[0m[0m | time: 91.942s
[2K| Adam | epoch: 024 | loss: 0.48393 - acc: 0.8244 -- iter: 05568/10000
[A[ATraining Step: 3699  | total loss: [1m[32m0.48682[0m[0m | time: 93.115s
[2K| Adam | epoch: 024 | loss: 0.48682 - acc: 0.8201 -- iter: 05632/10000
[A[ATraining Step: 3700  | total loss: [1m[32m0.49249[0m[0m | time: 97.409s
[2K| Adam | epoch: 024 | loss: 0.49249 - acc: 0.8178 | val_loss: 3.06658 - val_acc: 0.3571 -- iter: 05696/10000
--
Training Step: 3701  | total loss: [1m[32m0.49578[0m[0m | time: 98.552s
[2K| Adam | epoch: 024 | loss: 0.49578 - acc: 0.8172 -- iter: 05760/10000
[A[ATraining Step: 3702  | total loss: [1m[32m0.49220[0m[0m | time: 99.748s
[2K| Adam | epoch: 024 | loss: 0.49220 - acc: 0.8152 -- iter: 05824/10000
[A[ATraining Step: 3703  | total loss: [1m[32m0.49844[0m[0m | time: 100.903s
[2K| Adam | epoch: 024 | loss: 0.49844 - acc: 0.8134 -- iter: 05888/10000
[A[ATraining Step: 3704  | total loss: [1m[32m0.50473[0m[0m | time: 102.037s
[2K| Adam | epoch: 024 | loss: 0.50473 - acc: 0.8039 -- iter: 05952/10000
[A[ATraining Step: 3705  | total loss: [1m[32m0.50576[0m[0m | time: 103.175s
[2K| Adam | epoch: 024 | loss: 0.50576 - acc: 0.8063 -- iter: 06016/10000
[A[ATraining Step: 3706  | total loss: [1m[32m0.51496[0m[0m | time: 104.305s
[2K| Adam | epoch: 024 | loss: 0.51496 - acc: 0.8023 -- iter: 06080/10000
[A[ATraining Step: 3707  | total loss: [1m[32m0.53029[0m[0m | time: 105.447s
[2K| Adam | epoch: 024 | loss: 0.53029 - acc: 0.7955 -- iter: 06144/10000
[A[ATraining Step: 3708  | total loss: [1m[32m0.51791[0m[0m | time: 106.617s
[2K| Adam | epoch: 024 | loss: 0.51791 - acc: 0.7972 -- iter: 06208/10000
[A[ATraining Step: 3709  | total loss: [1m[32m0.51193[0m[0m | time: 107.839s
[2K| Adam | epoch: 024 | loss: 0.51193 - acc: 0.7987 -- iter: 06272/10000
[A[ATraining Step: 3710  | total loss: [1m[32m0.51026[0m[0m | time: 109.002s
[2K| Adam | epoch: 024 | loss: 0.51026 - acc: 0.7970 -- iter: 06336/10000
[A[ATraining Step: 3711  | total loss: [1m[32m0.53048[0m[0m | time: 110.141s
[2K| Adam | epoch: 024 | loss: 0.53048 - acc: 0.7954 -- iter: 06400/10000
[A[ATraining Step: 3712  | total loss: [1m[32m0.51368[0m[0m | time: 111.268s
[2K| Adam | epoch: 024 | loss: 0.51368 - acc: 0.8033 -- iter: 06464/10000
[A[ATraining Step: 3713  | total loss: [1m[32m0.50965[0m[0m | time: 112.265s
[2K| Adam | epoch: 024 | loss: 0.50965 - acc: 0.8043 -- iter: 06528/10000
[A[ATraining Step: 3714  | total loss: [1m[32m0.51960[0m[0m | time: 113.221s
[2K| Adam | epoch: 024 | loss: 0.51960 - acc: 0.8082 -- iter: 06592/10000
[A[ATraining Step: 3715  | total loss: [1m[32m0.51651[0m[0m | time: 114.183s
[2K| Adam | epoch: 024 | loss: 0.51651 - acc: 0.8149 -- iter: 06656/10000
[A[ATraining Step: 3716  | total loss: [1m[32m0.53782[0m[0m | time: 115.146s
[2K| Adam | epoch: 024 | loss: 0.53782 - acc: 0.8084 -- iter: 06720/10000
[A[ATraining Step: 3717  | total loss: [1m[32m0.52653[0m[0m | time: 116.101s
[2K| Adam | epoch: 024 | loss: 0.52653 - acc: 0.8119 -- iter: 06784/10000
[A[ATraining Step: 3718  | total loss: [1m[32m0.52173[0m[0m | time: 117.082s
[2K| Adam | epoch: 024 | loss: 0.52173 - acc: 0.8073 -- iter: 06848/10000
[A[ATraining Step: 3719  | total loss: [1m[32m0.51683[0m[0m | time: 118.139s
[2K| Adam | epoch: 024 | loss: 0.51683 - acc: 0.8094 -- iter: 06912/10000
[A[ATraining Step: 3720  | total loss: [1m[32m0.51337[0m[0m | time: 119.142s
[2K| Adam | epoch: 024 | loss: 0.51337 - acc: 0.8128 -- iter: 06976/10000
[A[ATraining Step: 3721  | total loss: [1m[32m0.52208[0m[0m | time: 120.180s
[2K| Adam | epoch: 024 | loss: 0.52208 - acc: 0.8128 -- iter: 07040/10000
[A[ATraining Step: 3722  | total loss: [1m[32m0.53993[0m[0m | time: 121.205s
[2K| Adam | epoch: 024 | loss: 0.53993 - acc: 0.8081 -- iter: 07104/10000
[A[ATraining Step: 3723  | total loss: [1m[32m0.54028[0m[0m | time: 122.271s
[2K| Adam | epoch: 024 | loss: 0.54028 - acc: 0.8132 -- iter: 07168/10000
[A[ATraining Step: 3724  | total loss: [1m[32m0.55019[0m[0m | time: 123.349s
[2K| Adam | epoch: 024 | loss: 0.55019 - acc: 0.8084 -- iter: 07232/10000
[A[ATraining Step: 3725  | total loss: [1m[32m0.53820[0m[0m | time: 124.424s
[2K| Adam | epoch: 024 | loss: 0.53820 - acc: 0.8073 -- iter: 07296/10000
[A[ATraining Step: 3726  | total loss: [1m[32m0.55132[0m[0m | time: 125.503s
[2K| Adam | epoch: 024 | loss: 0.55132 - acc: 0.8062 -- iter: 07360/10000
[A[ATraining Step: 3727  | total loss: [1m[32m0.56421[0m[0m | time: 126.576s
[2K| Adam | epoch: 024 | loss: 0.56421 - acc: 0.8022 -- iter: 07424/10000
[A[ATraining Step: 3728  | total loss: [1m[32m0.56235[0m[0m | time: 127.680s
[2K| Adam | epoch: 024 | loss: 0.56235 - acc: 0.7985 -- iter: 07488/10000
[A[ATraining Step: 3729  | total loss: [1m[32m0.55943[0m[0m | time: 128.748s
[2K| Adam | epoch: 024 | loss: 0.55943 - acc: 0.7984 -- iter: 07552/10000
[A[ATraining Step: 3730  | total loss: [1m[32m0.53804[0m[0m | time: 129.836s
[2K| Adam | epoch: 024 | loss: 0.53804 - acc: 0.8045 -- iter: 07616/10000
[A[ATraining Step: 3731  | total loss: [1m[32m0.53687[0m[0m | time: 130.942s
[2K| Adam | epoch: 024 | loss: 0.53687 - acc: 0.8006 -- iter: 07680/10000
[A[ATraining Step: 3732  | total loss: [1m[32m0.53232[0m[0m | time: 132.011s
[2K| Adam | epoch: 024 | loss: 0.53232 - acc: 0.8018 -- iter: 07744/10000
[A[ATraining Step: 3733  | total loss: [1m[32m0.50899[0m[0m | time: 133.085s
[2K| Adam | epoch: 024 | loss: 0.50899 - acc: 0.8122 -- iter: 07808/10000
[A[ATraining Step: 3734  | total loss: [1m[32m0.49051[0m[0m | time: 134.164s
[2K| Adam | epoch: 024 | loss: 0.49051 - acc: 0.8232 -- iter: 07872/10000
[A[ATraining Step: 3735  | total loss: [1m[32m0.48175[0m[0m | time: 135.238s
[2K| Adam | epoch: 024 | loss: 0.48175 - acc: 0.8284 -- iter: 07936/10000
[A[ATraining Step: 3736  | total loss: [1m[32m0.48243[0m[0m | time: 136.308s
[2K| Adam | epoch: 024 | loss: 0.48243 - acc: 0.8252 -- iter: 08000/10000
[A[ATraining Step: 3737  | total loss: [1m[32m0.47226[0m[0m | time: 137.419s
[2K| Adam | epoch: 024 | loss: 0.47226 - acc: 0.8286 -- iter: 08064/10000
[A[ATraining Step: 3738  | total loss: [1m[32m0.47689[0m[0m | time: 138.513s
[2K| Adam | epoch: 024 | loss: 0.47689 - acc: 0.8255 -- iter: 08128/10000
[A[ATraining Step: 3739  | total loss: [1m[32m0.47732[0m[0m | time: 139.591s
[2K| Adam | epoch: 024 | loss: 0.47732 - acc: 0.8288 -- iter: 08192/10000
[A[ATraining Step: 3740  | total loss: [1m[32m0.47076[0m[0m | time: 140.716s
[2K| Adam | epoch: 024 | loss: 0.47076 - acc: 0.8319 -- iter: 08256/10000
[A[ATraining Step: 3741  | total loss: [1m[32m0.47634[0m[0m | time: 141.792s
[2K| Adam | epoch: 024 | loss: 0.47634 - acc: 0.8284 -- iter: 08320/10000
[A[ATraining Step: 3742  | total loss: [1m[32m0.47536[0m[0m | time: 142.823s
[2K| Adam | epoch: 024 | loss: 0.47536 - acc: 0.8299 -- iter: 08384/10000
[A[ATraining Step: 3743  | total loss: [1m[32m0.48542[0m[0m | time: 143.897s
[2K| Adam | epoch: 024 | loss: 0.48542 - acc: 0.8251 -- iter: 08448/10000
[A[ATraining Step: 3744  | total loss: [1m[32m0.49616[0m[0m | time: 144.961s
[2K| Adam | epoch: 024 | loss: 0.49616 - acc: 0.8207 -- iter: 08512/10000
[A[ATraining Step: 3745  | total loss: [1m[32m0.49220[0m[0m | time: 146.030s
[2K| Adam | epoch: 024 | loss: 0.49220 - acc: 0.8136 -- iter: 08576/10000
[A[ATraining Step: 3746  | total loss: [1m[32m0.48607[0m[0m | time: 147.102s
[2K| Adam | epoch: 024 | loss: 0.48607 - acc: 0.8119 -- iter: 08640/10000
[A[ATraining Step: 3747  | total loss: [1m[32m0.48135[0m[0m | time: 148.224s
[2K| Adam | epoch: 024 | loss: 0.48135 - acc: 0.8104 -- iter: 08704/10000
[A[ATraining Step: 3748  | total loss: [1m[32m0.48424[0m[0m | time: 149.260s
[2K| Adam | epoch: 024 | loss: 0.48424 - acc: 0.8028 -- iter: 08768/10000
[A[ATraining Step: 3749  | total loss: [1m[32m0.47890[0m[0m | time: 150.280s
[2K| Adam | epoch: 024 | loss: 0.47890 - acc: 0.8007 -- iter: 08832/10000
[A[ATraining Step: 3750  | total loss: [1m[32m0.46925[0m[0m | time: 151.297s
[2K| Adam | epoch: 024 | loss: 0.46925 - acc: 0.8065 -- iter: 08896/10000
[A[ATraining Step: 3751  | total loss: [1m[32m0.47935[0m[0m | time: 152.314s
[2K| Adam | epoch: 024 | loss: 0.47935 - acc: 0.8025 -- iter: 08960/10000
[A[ATraining Step: 3752  | total loss: [1m[32m0.50311[0m[0m | time: 153.314s
[2K| Adam | epoch: 024 | loss: 0.50311 - acc: 0.7988 -- iter: 09024/10000
[A[ATraining Step: 3753  | total loss: [1m[32m0.49299[0m[0m | time: 154.330s
[2K| Adam | epoch: 024 | loss: 0.49299 - acc: 0.8064 -- iter: 09088/10000
[A[ATraining Step: 3754  | total loss: [1m[32m0.48402[0m[0m | time: 155.349s
[2K| Adam | epoch: 024 | loss: 0.48402 - acc: 0.8179 -- iter: 09152/10000
[A[ATraining Step: 3755  | total loss: [1m[32m0.47233[0m[0m | time: 156.361s
[2K| Adam | epoch: 024 | loss: 0.47233 - acc: 0.8221 -- iter: 09216/10000
[A[ATraining Step: 3756  | total loss: [1m[32m0.47329[0m[0m | time: 157.400s
[2K| Adam | epoch: 024 | loss: 0.47329 - acc: 0.8196 -- iter: 09280/10000
[A[ATraining Step: 3757  | total loss: [1m[32m0.47723[0m[0m | time: 158.448s
[2K| Adam | epoch: 024 | loss: 0.47723 - acc: 0.8189 -- iter: 09344/10000
[A[ATraining Step: 3758  | total loss: [1m[32m0.47609[0m[0m | time: 159.529s
[2K| Adam | epoch: 024 | loss: 0.47609 - acc: 0.8151 -- iter: 09408/10000
[A[ATraining Step: 3759  | total loss: [1m[32m0.49842[0m[0m | time: 160.620s
[2K| Adam | epoch: 024 | loss: 0.49842 - acc: 0.8117 -- iter: 09472/10000
[A[ATraining Step: 3760  | total loss: [1m[32m1.55977[0m[0m | time: 161.737s
[2K| Adam | epoch: 024 | loss: 1.55977 - acc: 0.7415 -- iter: 09536/10000
[A[ATraining Step: 3761  | total loss: [1m[32m1.43561[0m[0m | time: 162.902s
[2K| Adam | epoch: 024 | loss: 1.43561 - acc: 0.7501 -- iter: 09600/10000
[A[ATraining Step: 3762  | total loss: [1m[32m1.36225[0m[0m | time: 164.069s
[2K| Adam | epoch: 024 | loss: 1.36225 - acc: 0.7548 -- iter: 09664/10000
[A[ATraining Step: 3763  | total loss: [1m[32m1.26826[0m[0m | time: 165.189s
[2K| Adam | epoch: 024 | loss: 1.26826 - acc: 0.7637 -- iter: 09728/10000
[A[ATraining Step: 3764  | total loss: [1m[32m1.19361[0m[0m | time: 166.308s
[2K| Adam | epoch: 024 | loss: 1.19361 - acc: 0.7608 -- iter: 09792/10000
[A[ATraining Step: 3765  | total loss: [1m[32m1.11172[0m[0m | time: 167.326s
[2K| Adam | epoch: 024 | loss: 1.11172 - acc: 0.7706 -- iter: 09856/10000
[A[ATraining Step: 3766  | total loss: [1m[32m1.05428[0m[0m | time: 168.333s
[2K| Adam | epoch: 024 | loss: 1.05428 - acc: 0.7764 -- iter: 09920/10000
[A[ATraining Step: 3767  | total loss: [1m[32m0.99531[0m[0m | time: 169.304s
[2K| Adam | epoch: 024 | loss: 0.99531 - acc: 0.7847 -- iter: 09984/10000
[A[ATraining Step: 3768  | total loss: [1m[32m0.92751[0m[0m | time: 173.081s
[2K| Adam | epoch: 024 | loss: 0.92751 - acc: 0.7922 | val_loss: 2.81616 - val_acc: 0.3557 -- iter: 10000/10000
--
Training Step: 3769  | total loss: [1m[32m0.88371[0m[0m | time: 1.063s
[2K| Adam | epoch: 025 | loss: 0.88371 - acc: 0.7973 -- iter: 00064/10000
[A[ATraining Step: 3770  | total loss: [1m[32m0.83124[0m[0m | time: 2.274s
[2K| Adam | epoch: 025 | loss: 0.83124 - acc: 0.8020 -- iter: 00128/10000
[A[ATraining Step: 3771  | total loss: [1m[32m0.78279[0m[0m | time: 3.645s
[2K| Adam | epoch: 025 | loss: 0.78279 - acc: 0.8093 -- iter: 00192/10000
[A[ATraining Step: 3772  | total loss: [1m[32m0.75694[0m[0m | time: 5.012s
[2K| Adam | epoch: 025 | loss: 0.75694 - acc: 0.8096 -- iter: 00256/10000
[A[ATraining Step: 3773  | total loss: [1m[32m0.72764[0m[0m | time: 6.320s
[2K| Adam | epoch: 025 | loss: 0.72764 - acc: 0.8068 -- iter: 00320/10000
[A[ATraining Step: 3774  | total loss: [1m[32m0.71669[0m[0m | time: 7.637s
[2K| Adam | epoch: 025 | loss: 0.71669 - acc: 0.8011 -- iter: 00384/10000
[A[ATraining Step: 3775  | total loss: [1m[32m0.68453[0m[0m | time: 8.942s
[2K| Adam | epoch: 025 | loss: 0.68453 - acc: 0.8069 -- iter: 00448/10000
[A[ATraining Step: 3776  | total loss: [1m[32m0.67262[0m[0m | time: 10.249s
[2K| Adam | epoch: 025 | loss: 0.67262 - acc: 0.8075 -- iter: 00512/10000
[A[ATraining Step: 3777  | total loss: [1m[32m0.65458[0m[0m | time: 11.634s
[2K| Adam | epoch: 025 | loss: 0.65458 - acc: 0.8080 -- iter: 00576/10000
[A[ATraining Step: 3778  | total loss: [1m[32m0.64205[0m[0m | time: 12.978s
[2K| Adam | epoch: 025 | loss: 0.64205 - acc: 0.8100 -- iter: 00640/10000
[A[ATraining Step: 3779  | total loss: [1m[32m0.61727[0m[0m | time: 14.554s
[2K| Adam | epoch: 025 | loss: 0.61727 - acc: 0.8149 -- iter: 00704/10000
[A[ATraining Step: 3780  | total loss: [1m[32m0.59779[0m[0m | time: 15.947s
[2K| Adam | epoch: 025 | loss: 0.59779 - acc: 0.8162 -- iter: 00768/10000
[A[ATraining Step: 3781  | total loss: [1m[32m0.58400[0m[0m | time: 17.348s
[2K| Adam | epoch: 025 | loss: 0.58400 - acc: 0.8174 -- iter: 00832/10000
[A[ATraining Step: 3782  | total loss: [1m[32m0.58362[0m[0m | time: 18.757s
[2K| Adam | epoch: 025 | loss: 0.58362 - acc: 0.8201 -- iter: 00896/10000
[A[ATraining Step: 3783  | total loss: [1m[32m0.58807[0m[0m | time: 20.184s
[2K| Adam | epoch: 025 | loss: 0.58807 - acc: 0.8115 -- iter: 00960/10000
[A[ATraining Step: 3784  | total loss: [1m[32m0.57349[0m[0m | time: 21.687s
[2K| Adam | epoch: 025 | loss: 0.57349 - acc: 0.8163 -- iter: 01024/10000
[A[ATraining Step: 3785  | total loss: [1m[32m0.56456[0m[0m | time: 23.197s
[2K| Adam | epoch: 025 | loss: 0.56456 - acc: 0.8097 -- iter: 01088/10000
[A[ATraining Step: 3786  | total loss: [1m[32m0.56333[0m[0m | time: 24.768s
[2K| Adam | epoch: 025 | loss: 0.56333 - acc: 0.8037 -- iter: 01152/10000
[A[ATraining Step: 3787  | total loss: [1m[32m0.54906[0m[0m | time: 26.260s
[2K| Adam | epoch: 025 | loss: 0.54906 - acc: 0.8030 -- iter: 01216/10000
[A[ATraining Step: 3788  | total loss: [1m[32m0.55704[0m[0m | time: 27.777s
[2K| Adam | epoch: 025 | loss: 0.55704 - acc: 0.8008 -- iter: 01280/10000
[A[ATraining Step: 3789  | total loss: [1m[32m0.57961[0m[0m | time: 29.406s
[2K| Adam | epoch: 025 | loss: 0.57961 - acc: 0.7895 -- iter: 01344/10000
[A[ATraining Step: 3790  | total loss: [1m[32m0.55758[0m[0m | time: 31.003s
[2K| Adam | epoch: 025 | loss: 0.55758 - acc: 0.7965 -- iter: 01408/10000
[A[ATraining Step: 3791  | total loss: [1m[32m0.55514[0m[0m | time: 31.778s
[2K| Adam | epoch: 025 | loss: 0.55514 - acc: 0.7997 -- iter: 01472/10000
[A[ATraining Step: 3792  | total loss: [1m[32m0.56773[0m[0m | time: 32.486s
[2K| Adam | epoch: 025 | loss: 0.56773 - acc: 0.8009 -- iter: 01536/10000
[A[ATraining Step: 3793  | total loss: [1m[32m0.56150[0m[0m | time: 34.057s
[2K| Adam | epoch: 025 | loss: 0.56150 - acc: 0.8146 -- iter: 01600/10000
[A[ATraining Step: 3794  | total loss: [1m[32m0.55044[0m[0m | time: 35.680s
[2K| Adam | epoch: 025 | loss: 0.55044 - acc: 0.8128 -- iter: 01664/10000
[A[ATraining Step: 3795  | total loss: [1m[32m0.53153[0m[0m | time: 37.270s
[2K| Adam | epoch: 025 | loss: 0.53153 - acc: 0.8190 -- iter: 01728/10000
[A[ATraining Step: 3796  | total loss: [1m[32m0.54192[0m[0m | time: 38.887s
[2K| Adam | epoch: 025 | loss: 0.54192 - acc: 0.8106 -- iter: 01792/10000
[A[ATraining Step: 3797  | total loss: [1m[32m0.54079[0m[0m | time: 40.616s
[2K| Adam | epoch: 025 | loss: 0.54079 - acc: 0.8092 -- iter: 01856/10000
[A[ATraining Step: 3798  | total loss: [1m[32m0.52349[0m[0m | time: 42.361s
[2K| Adam | epoch: 025 | loss: 0.52349 - acc: 0.8095 -- iter: 01920/10000
[A[ATraining Step: 3799  | total loss: [1m[32m0.51819[0m[0m | time: 44.129s
[2K| Adam | epoch: 025 | loss: 0.51819 - acc: 0.8114 -- iter: 01984/10000
[A[ATraining Step: 3800  | total loss: [1m[32m0.52071[0m[0m | time: 50.713s
[2K| Adam | epoch: 025 | loss: 0.52071 - acc: 0.8115 | val_loss: 2.99726 - val_acc: 0.3757 -- iter: 02048/10000
--
Training Step: 3801  | total loss: [1m[32m0.51624[0m[0m | time: 52.385s
[2K| Adam | epoch: 025 | loss: 0.51624 - acc: 0.8147 -- iter: 02112/10000
[A[ATraining Step: 3802  | total loss: [1m[32m0.52034[0m[0m | time: 54.176s
[2K| Adam | epoch: 025 | loss: 0.52034 - acc: 0.8192 -- iter: 02176/10000
[A[ATraining Step: 3803  | total loss: [1m[32m0.51274[0m[0m | time: 55.998s
[2K| Adam | epoch: 025 | loss: 0.51274 - acc: 0.8279 -- iter: 02240/10000
[A[ATraining Step: 3804  | total loss: [1m[32m0.50255[0m[0m | time: 57.743s
[2K| Adam | epoch: 025 | loss: 0.50255 - acc: 0.8357 -- iter: 02304/10000
[A[ATraining Step: 3805  | total loss: [1m[32m0.48777[0m[0m | time: 59.475s
[2K| Adam | epoch: 025 | loss: 0.48777 - acc: 0.8381 -- iter: 02368/10000
[A[ATraining Step: 3806  | total loss: [1m[32m0.46845[0m[0m | time: 61.215s
[2K| Adam | epoch: 025 | loss: 0.46845 - acc: 0.8402 -- iter: 02432/10000
[A[ATraining Step: 3807  | total loss: [1m[32m0.46919[0m[0m | time: 62.955s
[2K| Adam | epoch: 025 | loss: 0.46919 - acc: 0.8375 -- iter: 02496/10000
[A[ATraining Step: 3808  | total loss: [1m[32m0.46848[0m[0m | time: 64.942s
[2K| Adam | epoch: 025 | loss: 0.46848 - acc: 0.8334 -- iter: 02560/10000
[A[ATraining Step: 3809  | total loss: [1m[32m0.46306[0m[0m | time: 66.688s
[2K| Adam | epoch: 025 | loss: 0.46306 - acc: 0.8297 -- iter: 02624/10000
[A[ATraining Step: 3810  | total loss: [1m[32m0.46514[0m[0m | time: 68.428s
[2K| Adam | epoch: 025 | loss: 0.46514 - acc: 0.8202 -- iter: 02688/10000
[A[ATraining Step: 3811  | total loss: [1m[32m0.45973[0m[0m | time: 70.075s
[2K| Adam | epoch: 025 | loss: 0.45973 - acc: 0.8147 -- iter: 02752/10000
[A[ATraining Step: 3812  | total loss: [1m[32m0.46332[0m[0m | time: 71.722s
[2K| Adam | epoch: 025 | loss: 0.46332 - acc: 0.8114 -- iter: 02816/10000
[A[ATraining Step: 3813  | total loss: [1m[32m0.46205[0m[0m | time: 73.332s
[2K| Adam | epoch: 025 | loss: 0.46205 - acc: 0.8099 -- iter: 02880/10000
[A[ATraining Step: 3814  | total loss: [1m[32m0.47001[0m[0m | time: 74.944s
[2K| Adam | epoch: 025 | loss: 0.47001 - acc: 0.8102 -- iter: 02944/10000
[A[ATraining Step: 3815  | total loss: [1m[32m0.47839[0m[0m | time: 76.675s
[2K| Adam | epoch: 025 | loss: 0.47839 - acc: 0.8089 -- iter: 03008/10000
[A[ATraining Step: 3816  | total loss: [1m[32m0.48363[0m[0m | time: 78.417s
[2K| Adam | epoch: 025 | loss: 0.48363 - acc: 0.8124 -- iter: 03072/10000
[A[ATraining Step: 3817  | total loss: [1m[32m0.49505[0m[0m | time: 80.162s
[2K| Adam | epoch: 025 | loss: 0.49505 - acc: 0.8186 -- iter: 03136/10000
[A[ATraining Step: 3818  | total loss: [1m[32m0.49289[0m[0m | time: 81.942s
[2K| Adam | epoch: 025 | loss: 0.49289 - acc: 0.8149 -- iter: 03200/10000
[A[ATraining Step: 3819  | total loss: [1m[32m0.49896[0m[0m | time: 83.688s
[2K| Adam | epoch: 025 | loss: 0.49896 - acc: 0.8162 -- iter: 03264/10000
[A[ATraining Step: 3820  | total loss: [1m[32m0.49544[0m[0m | time: 85.520s
[2K| Adam | epoch: 025 | loss: 0.49544 - acc: 0.8158 -- iter: 03328/10000
[A[ATraining Step: 3821  | total loss: [1m[32m0.48183[0m[0m | time: 87.260s
[2K| Adam | epoch: 025 | loss: 0.48183 - acc: 0.8233 -- iter: 03392/10000
[A[ATraining Step: 3822  | total loss: [1m[32m0.48151[0m[0m | time: 89.018s
[2K| Adam | epoch: 025 | loss: 0.48151 - acc: 0.8175 -- iter: 03456/10000
[A[ATraining Step: 3823  | total loss: [1m[32m0.48197[0m[0m | time: 90.748s
[2K| Adam | epoch: 025 | loss: 0.48197 - acc: 0.8170 -- iter: 03520/10000
[A[ATraining Step: 3824  | total loss: [1m[32m0.47262[0m[0m | time: 92.477s
[2K| Adam | epoch: 025 | loss: 0.47262 - acc: 0.8182 -- iter: 03584/10000
[A[ATraining Step: 3825  | total loss: [1m[32m0.47085[0m[0m | time: 94.204s
[2K| Adam | epoch: 025 | loss: 0.47085 - acc: 0.8160 -- iter: 03648/10000
[A[ATraining Step: 3826  | total loss: [1m[32m0.46672[0m[0m | time: 96.004s
[2K| Adam | epoch: 025 | loss: 0.46672 - acc: 0.8204 -- iter: 03712/10000
[A[ATraining Step: 3827  | total loss: [1m[32m0.45487[0m[0m | time: 97.954s
[2K| Adam | epoch: 025 | loss: 0.45487 - acc: 0.8243 -- iter: 03776/10000
[A[ATraining Step: 3828  | total loss: [1m[32m0.47945[0m[0m | time: 99.702s
[2K| Adam | epoch: 025 | loss: 0.47945 - acc: 0.8121 -- iter: 03840/10000
[A[ATraining Step: 3829  | total loss: [1m[32m0.47543[0m[0m | time: 101.445s
[2K| Adam | epoch: 025 | loss: 0.47543 - acc: 0.8153 -- iter: 03904/10000
[A[ATraining Step: 3830  | total loss: [1m[32m0.48847[0m[0m | time: 103.189s
[2K| Adam | epoch: 025 | loss: 0.48847 - acc: 0.8135 -- iter: 03968/10000
[A[ATraining Step: 3831  | total loss: [1m[32m0.48493[0m[0m | time: 104.986s
[2K| Adam | epoch: 025 | loss: 0.48493 - acc: 0.8149 -- iter: 04032/10000
[A[ATraining Step: 3832  | total loss: [1m[32m0.48249[0m[0m | time: 106.781s
[2K| Adam | epoch: 025 | loss: 0.48249 - acc: 0.8194 -- iter: 04096/10000
[A[ATraining Step: 3833  | total loss: [1m[32m0.48561[0m[0m | time: 108.439s
[2K| Adam | epoch: 025 | loss: 0.48561 - acc: 0.8156 -- iter: 04160/10000
[A[ATraining Step: 3834  | total loss: [1m[32m0.47700[0m[0m | time: 110.180s
[2K| Adam | epoch: 025 | loss: 0.47700 - acc: 0.8231 -- iter: 04224/10000
[A[ATraining Step: 3835  | total loss: [1m[32m0.46293[0m[0m | time: 111.931s
[2K| Adam | epoch: 025 | loss: 0.46293 - acc: 0.8329 -- iter: 04288/10000
[A[ATraining Step: 3836  | total loss: [1m[32m0.45778[0m[0m | time: 113.635s
[2K| Adam | epoch: 025 | loss: 0.45778 - acc: 0.8309 -- iter: 04352/10000
[A[ATraining Step: 3837  | total loss: [1m[32m0.44497[0m[0m | time: 115.443s
[2K| Adam | epoch: 025 | loss: 0.44497 - acc: 0.8306 -- iter: 04416/10000
[A[ATraining Step: 3838  | total loss: [1m[32m0.45168[0m[0m | time: 117.206s
[2K| Adam | epoch: 025 | loss: 0.45168 - acc: 0.8241 -- iter: 04480/10000
[A[ATraining Step: 3839  | total loss: [1m[32m0.46074[0m[0m | time: 118.956s
[2K| Adam | epoch: 025 | loss: 0.46074 - acc: 0.8198 -- iter: 04544/10000
[A[ATraining Step: 3840  | total loss: [1m[32m0.46211[0m[0m | time: 120.701s
[2K| Adam | epoch: 025 | loss: 0.46211 - acc: 0.8160 -- iter: 04608/10000
[A[ATraining Step: 3841  | total loss: [1m[32m0.47225[0m[0m | time: 122.455s
[2K| Adam | epoch: 025 | loss: 0.47225 - acc: 0.8156 -- iter: 04672/10000
[A[ATraining Step: 3842  | total loss: [1m[32m0.48766[0m[0m | time: 124.224s
[2K| Adam | epoch: 025 | loss: 0.48766 - acc: 0.8044 -- iter: 04736/10000
[A[ATraining Step: 3843  | total loss: [1m[32m0.49662[0m[0m | time: 126.047s
[2K| Adam | epoch: 025 | loss: 0.49662 - acc: 0.7974 -- iter: 04800/10000
[A[ATraining Step: 3844  | total loss: [1m[32m0.48808[0m[0m | time: 127.782s
[2K| Adam | epoch: 025 | loss: 0.48808 - acc: 0.8051 -- iter: 04864/10000
[A[ATraining Step: 3845  | total loss: [1m[32m0.49149[0m[0m | time: 129.527s
[2K| Adam | epoch: 025 | loss: 0.49149 - acc: 0.7965 -- iter: 04928/10000
[A[ATraining Step: 3846  | total loss: [1m[32m0.49090[0m[0m | time: 131.194s
[2K| Adam | epoch: 025 | loss: 0.49090 - acc: 0.7997 -- iter: 04992/10000
[A[ATraining Step: 3847  | total loss: [1m[32m0.49187[0m[0m | time: 132.832s
[2K| Adam | epoch: 025 | loss: 0.49187 - acc: 0.8009 -- iter: 05056/10000
[A[ATraining Step: 3848  | total loss: [1m[32m0.51115[0m[0m | time: 134.483s
[2K| Adam | epoch: 025 | loss: 0.51115 - acc: 0.8052 -- iter: 05120/10000
[A[ATraining Step: 3849  | total loss: [1m[32m0.51226[0m[0m | time: 136.118s
[2K| Adam | epoch: 025 | loss: 0.51226 - acc: 0.8028 -- iter: 05184/10000
[A[ATraining Step: 3850  | total loss: [1m[32m0.51104[0m[0m | time: 137.725s
[2K| Adam | epoch: 025 | loss: 0.51104 - acc: 0.8132 -- iter: 05248/10000
[A[ATraining Step: 3851  | total loss: [1m[32m0.50687[0m[0m | time: 139.328s
[2K| Adam | epoch: 025 | loss: 0.50687 - acc: 0.8178 -- iter: 05312/10000
[A[ATraining Step: 3852  | total loss: [1m[32m0.50297[0m[0m | time: 141.105s
[2K| Adam | epoch: 025 | loss: 0.50297 - acc: 0.8188 -- iter: 05376/10000
[A[ATraining Step: 3853  | total loss: [1m[32m0.50065[0m[0m | time: 142.860s
[2K| Adam | epoch: 025 | loss: 0.50065 - acc: 0.8151 -- iter: 05440/10000
[A[ATraining Step: 3854  | total loss: [1m[32m0.51224[0m[0m | time: 144.713s
[2K| Adam | epoch: 025 | loss: 0.51224 - acc: 0.8054 -- iter: 05504/10000
[A[ATraining Step: 3855  | total loss: [1m[32m0.49844[0m[0m | time: 146.450s
[2K| Adam | epoch: 025 | loss: 0.49844 - acc: 0.8093 -- iter: 05568/10000
[A[ATraining Step: 3856  | total loss: [1m[32m0.50228[0m[0m | time: 148.183s
[2K| Adam | epoch: 025 | loss: 0.50228 - acc: 0.8002 -- iter: 05632/10000
[A[ATraining Step: 3857  | total loss: [1m[32m0.50561[0m[0m | time: 149.854s
[2K| Adam | epoch: 025 | loss: 0.50561 - acc: 0.7921 -- iter: 05696/10000
[A[ATraining Step: 3858  | total loss: [1m[32m0.50266[0m[0m | time: 151.569s
[2K| Adam | epoch: 025 | loss: 0.50266 - acc: 0.7926 -- iter: 05760/10000
[A[ATraining Step: 3859  | total loss: [1m[32m0.53384[0m[0m | time: 153.340s
[2K| Adam | epoch: 025 | loss: 0.53384 - acc: 0.7867 -- iter: 05824/10000
[A[ATraining Step: 3860  | total loss: [1m[32m0.55148[0m[0m | time: 155.161s
[2K| Adam | epoch: 025 | loss: 0.55148 - acc: 0.7799 -- iter: 05888/10000
[A[ATraining Step: 3861  | total loss: [1m[32m0.56128[0m[0m | time: 156.905s
[2K| Adam | epoch: 025 | loss: 0.56128 - acc: 0.7785 -- iter: 05952/10000
[A[ATraining Step: 3862  | total loss: [1m[32m0.55959[0m[0m | time: 158.652s
[2K| Adam | epoch: 025 | loss: 0.55959 - acc: 0.7819 -- iter: 06016/10000
[A[ATraining Step: 3863  | total loss: [1m[32m0.54929[0m[0m | time: 160.399s
[2K| Adam | epoch: 025 | loss: 0.54929 - acc: 0.7897 -- iter: 06080/10000
[A[ATraining Step: 3864  | total loss: [1m[32m0.55014[0m[0m | time: 162.133s
[2K| Adam | epoch: 025 | loss: 0.55014 - acc: 0.8013 -- iter: 06144/10000
[A[ATraining Step: 3865  | total loss: [1m[32m0.54851[0m[0m | time: 164.007s
[2K| Adam | epoch: 025 | loss: 0.54851 - acc: 0.8087 -- iter: 06208/10000
[A[ATraining Step: 3866  | total loss: [1m[32m0.54517[0m[0m | time: 165.737s
[2K| Adam | epoch: 025 | loss: 0.54517 - acc: 0.8153 -- iter: 06272/10000
[A[ATraining Step: 3867  | total loss: [1m[32m0.54666[0m[0m | time: 167.359s
[2K| Adam | epoch: 025 | loss: 0.54666 - acc: 0.8150 -- iter: 06336/10000
[A[ATraining Step: 3868  | total loss: [1m[32m0.53252[0m[0m | time: 168.961s
[2K| Adam | epoch: 025 | loss: 0.53252 - acc: 0.8148 -- iter: 06400/10000
[A[ATraining Step: 3869  | total loss: [1m[32m0.52824[0m[0m | time: 170.568s
[2K| Adam | epoch: 025 | loss: 0.52824 - acc: 0.8177 -- iter: 06464/10000
[A[ATraining Step: 3870  | total loss: [1m[32m0.52757[0m[0m | time: 172.172s
[2K| Adam | epoch: 025 | loss: 0.52757 - acc: 0.8140 -- iter: 06528/10000
[A[ATraining Step: 3871  | total loss: [1m[32m0.51788[0m[0m | time: 173.809s
[2K| Adam | epoch: 025 | loss: 0.51788 - acc: 0.8170 -- iter: 06592/10000
[A[ATraining Step: 3872  | total loss: [1m[32m0.52106[0m[0m | time: 175.503s
[2K| Adam | epoch: 025 | loss: 0.52106 - acc: 0.8134 -- iter: 06656/10000
[A[ATraining Step: 3873  | total loss: [1m[32m0.50147[0m[0m | time: 177.229s
[2K| Adam | epoch: 025 | loss: 0.50147 - acc: 0.8180 -- iter: 06720/10000
[A[ATraining Step: 3874  | total loss: [1m[32m0.49884[0m[0m | time: 178.961s
[2K| Adam | epoch: 025 | loss: 0.49884 - acc: 0.8253 -- iter: 06784/10000
[A[ATraining Step: 3875  | total loss: [1m[32m0.47550[0m[0m | time: 180.705s
[2K| Adam | epoch: 025 | loss: 0.47550 - acc: 0.8318 -- iter: 06848/10000
[A[ATraining Step: 3876  | total loss: [1m[32m0.50334[0m[0m | time: 182.448s
[2K| Adam | epoch: 025 | loss: 0.50334 - acc: 0.8236 -- iter: 06912/10000
[A[ATraining Step: 3877  | total loss: [1m[32m0.50472[0m[0m | time: 184.223s
[2K| Adam | epoch: 025 | loss: 0.50472 - acc: 0.8225 -- iter: 06976/10000
[A[ATraining Step: 3878  | total loss: [1m[32m0.51784[0m[0m | time: 186.071s
[2K| Adam | epoch: 025 | loss: 0.51784 - acc: 0.8075 -- iter: 07040/10000
[A[ATraining Step: 3879  | total loss: [1m[32m0.52452[0m[0m | time: 187.745s
[2K| Adam | epoch: 025 | loss: 0.52452 - acc: 0.8095 -- iter: 07104/10000
[A[ATraining Step: 3880  | total loss: [1m[32m0.52599[0m[0m | time: 189.405s
[2K| Adam | epoch: 025 | loss: 0.52599 - acc: 0.8067 -- iter: 07168/10000
[A[ATraining Step: 3881  | total loss: [1m[32m0.52357[0m[0m | time: 191.129s
[2K| Adam | epoch: 025 | loss: 0.52357 - acc: 0.8088 -- iter: 07232/10000
[A[ATraining Step: 3882  | total loss: [1m[32m0.52158[0m[0m | time: 192.891s
[2K| Adam | epoch: 025 | loss: 0.52158 - acc: 0.8123 -- iter: 07296/10000
[A[ATraining Step: 3883  | total loss: [1m[32m0.54651[0m[0m | time: 194.575s
[2K| Adam | epoch: 025 | loss: 0.54651 - acc: 0.8045 -- iter: 07360/10000
[A[ATraining Step: 3884  | total loss: [1m[32m0.53854[0m[0m | time: 196.198s
[2K| Adam | epoch: 025 | loss: 0.53854 - acc: 0.8022 -- iter: 07424/10000
[A[ATraining Step: 3885  | total loss: [1m[32m0.54389[0m[0m | time: 197.801s
[2K| Adam | epoch: 025 | loss: 0.54389 - acc: 0.8001 -- iter: 07488/10000
[A[ATraining Step: 3886  | total loss: [1m[32m0.51869[0m[0m | time: 199.409s
[2K| Adam | epoch: 025 | loss: 0.51869 - acc: 0.8092 -- iter: 07552/10000
[A[ATraining Step: 3887  | total loss: [1m[32m0.52316[0m[0m | time: 201.021s
[2K| Adam | epoch: 025 | loss: 0.52316 - acc: 0.8048 -- iter: 07616/10000
[A[ATraining Step: 3888  | total loss: [1m[32m0.52446[0m[0m | time: 202.648s
[2K| Adam | epoch: 025 | loss: 0.52446 - acc: 0.8071 -- iter: 07680/10000
[A[ATraining Step: 3889  | total loss: [1m[32m0.52115[0m[0m | time: 204.316s
[2K| Adam | epoch: 025 | loss: 0.52115 - acc: 0.8046 -- iter: 07744/10000
[A[ATraining Step: 3890  | total loss: [1m[32m0.51794[0m[0m | time: 206.182s
[2K| Adam | epoch: 025 | loss: 0.51794 - acc: 0.8053 -- iter: 07808/10000
[A[ATraining Step: 3891  | total loss: [1m[32m0.50683[0m[0m | time: 208.101s
[2K| Adam | epoch: 025 | loss: 0.50683 - acc: 0.8045 -- iter: 07872/10000
[A[ATraining Step: 3892  | total loss: [1m[32m0.51039[0m[0m | time: 209.922s
[2K| Adam | epoch: 025 | loss: 0.51039 - acc: 0.7959 -- iter: 07936/10000
[A[ATraining Step: 3893  | total loss: [1m[32m0.50345[0m[0m | time: 211.659s
[2K| Adam | epoch: 025 | loss: 0.50345 - acc: 0.8007 -- iter: 08000/10000
[A[ATraining Step: 3894  | total loss: [1m[32m0.49592[0m[0m | time: 213.428s
[2K| Adam | epoch: 025 | loss: 0.49592 - acc: 0.8003 -- iter: 08064/10000
[A[ATraining Step: 3895  | total loss: [1m[32m0.50657[0m[0m | time: 215.205s
[2K| Adam | epoch: 025 | loss: 0.50657 - acc: 0.7984 -- iter: 08128/10000
[A[ATraining Step: 3896  | total loss: [1m[32m0.50326[0m[0m | time: 216.944s
[2K| Adam | epoch: 025 | loss: 0.50326 - acc: 0.8045 -- iter: 08192/10000
[A[ATraining Step: 3897  | total loss: [1m[32m0.49342[0m[0m | time: 218.690s
[2K| Adam | epoch: 025 | loss: 0.49342 - acc: 0.8069 -- iter: 08256/10000
[A[ATraining Step: 3898  | total loss: [1m[32m0.48464[0m[0m | time: 220.427s
[2K| Adam | epoch: 025 | loss: 0.48464 - acc: 0.8090 -- iter: 08320/10000
[A[ATraining Step: 3899  | total loss: [1m[32m0.48301[0m[0m | time: 222.138s
[2K| Adam | epoch: 025 | loss: 0.48301 - acc: 0.8140 -- iter: 08384/10000
[A[ATraining Step: 3900  | total loss: [1m[32m0.47298[0m[0m | time: 228.418s
[2K| Adam | epoch: 025 | loss: 0.47298 - acc: 0.8217 | val_loss: 2.65605 - val_acc: 0.3671 -- iter: 08448/10000
--
Training Step: 3901  | total loss: [1m[32m0.47189[0m[0m | time: 229.947s
[2K| Adam | epoch: 025 | loss: 0.47189 - acc: 0.8286 -- iter: 08512/10000
[A[ATraining Step: 3902  | total loss: [1m[32m0.46205[0m[0m | time: 231.581s
[2K| Adam | epoch: 025 | loss: 0.46205 - acc: 0.8332 -- iter: 08576/10000
[A[ATraining Step: 3903  | total loss: [1m[32m0.45580[0m[0m | time: 233.189s
[2K| Adam | epoch: 025 | loss: 0.45580 - acc: 0.8312 -- iter: 08640/10000
[A[ATraining Step: 3904  | total loss: [1m[32m0.44861[0m[0m | time: 234.963s
[2K| Adam | epoch: 025 | loss: 0.44861 - acc: 0.8309 -- iter: 08704/10000
[A[ATraining Step: 3905  | total loss: [1m[32m0.43271[0m[0m | time: 236.700s
[2K| Adam | epoch: 025 | loss: 0.43271 - acc: 0.8368 -- iter: 08768/10000
[A[ATraining Step: 3906  | total loss: [1m[32m0.43961[0m[0m | time: 238.434s
[2K| Adam | epoch: 025 | loss: 0.43961 - acc: 0.8328 -- iter: 08832/10000
[A[ATraining Step: 3907  | total loss: [1m[32m0.47538[0m[0m | time: 240.186s
[2K| Adam | epoch: 025 | loss: 0.47538 - acc: 0.8230 -- iter: 08896/10000
[A[ATraining Step: 3908  | total loss: [1m[32m0.49968[0m[0m | time: 241.913s
[2K| Adam | epoch: 025 | loss: 0.49968 - acc: 0.8048 -- iter: 08960/10000
[A[ATraining Step: 3909  | total loss: [1m[32m0.50640[0m[0m | time: 243.672s
[2K| Adam | epoch: 025 | loss: 0.50640 - acc: 0.7977 -- iter: 09024/10000
[A[ATraining Step: 3910  | total loss: [1m[32m0.51206[0m[0m | time: 245.420s
[2K| Adam | epoch: 025 | loss: 0.51206 - acc: 0.7945 -- iter: 09088/10000
[A[ATraining Step: 3911  | total loss: [1m[32m0.49876[0m[0m | time: 247.081s
[2K| Adam | epoch: 025 | loss: 0.49876 - acc: 0.8026 -- iter: 09152/10000
[A[ATraining Step: 3912  | total loss: [1m[32m0.49212[0m[0m | time: 248.689s
[2K| Adam | epoch: 025 | loss: 0.49212 - acc: 0.8067 -- iter: 09216/10000
[A[ATraining Step: 3913  | total loss: [1m[32m0.49852[0m[0m | time: 250.428s
[2K| Adam | epoch: 025 | loss: 0.49852 - acc: 0.8010 -- iter: 09280/10000
[A[ATraining Step: 3914  | total loss: [1m[32m0.50585[0m[0m | time: 252.056s
[2K| Adam | epoch: 025 | loss: 0.50585 - acc: 0.8006 -- iter: 09344/10000
[A[ATraining Step: 3915  | total loss: [1m[32m0.49636[0m[0m | time: 253.690s
[2K| Adam | epoch: 025 | loss: 0.49636 - acc: 0.8080 -- iter: 09408/10000
[A[ATraining Step: 3916  | total loss: [1m[32m0.49361[0m[0m | time: 255.377s
[2K| Adam | epoch: 025 | loss: 0.49361 - acc: 0.8194 -- iter: 09472/10000
[A[ATraining Step: 3917  | total loss: [1m[32m0.48927[0m[0m | time: 256.975s
[2K| Adam | epoch: 025 | loss: 0.48927 - acc: 0.8172 -- iter: 09536/10000
[A[ATraining Step: 3918  | total loss: [1m[32m1.48574[0m[0m | time: 258.587s
[2K| Adam | epoch: 025 | loss: 1.48574 - acc: 0.7417 -- iter: 09600/10000
[A[ATraining Step: 3919  | total loss: [1m[32m1.38591[0m[0m | time: 260.199s
[2K| Adam | epoch: 025 | loss: 1.38591 - acc: 0.7519 -- iter: 09664/10000
[A[ATraining Step: 3920  | total loss: [1m[32m1.28606[0m[0m | time: 261.927s
[2K| Adam | epoch: 025 | loss: 1.28606 - acc: 0.7689 -- iter: 09728/10000
[A[ATraining Step: 3921  | total loss: [1m[32m1.21324[0m[0m | time: 263.713s
[2K| Adam | epoch: 025 | loss: 1.21324 - acc: 0.7764 -- iter: 09792/10000
[A[ATraining Step: 3922  | total loss: [1m[32m1.11858[0m[0m | time: 265.550s
[2K| Adam | epoch: 025 | loss: 1.11858 - acc: 0.7925 -- iter: 09856/10000
[A[ATraining Step: 3923  | total loss: [1m[32m1.05742[0m[0m | time: 267.290s
[2K| Adam | epoch: 025 | loss: 1.05742 - acc: 0.7914 -- iter: 09920/10000
[A[ATraining Step: 3924  | total loss: [1m[32m1.00017[0m[0m | time: 269.038s
[2K| Adam | epoch: 025 | loss: 1.00017 - acc: 0.7966 -- iter: 09984/10000
[A[ATraining Step: 3925  | total loss: [1m[32m0.94708[0m[0m | time: 275.651s
[2K| Adam | epoch: 025 | loss: 0.94708 - acc: 0.8013 | val_loss: 2.94446 - val_acc: 0.3743 -- iter: 10000/10000
--
Training Step: 3926  | total loss: [1m[32m0.91008[0m[0m | time: 1.676s
[2K| Adam | epoch: 026 | loss: 0.91008 - acc: 0.7931 -- iter: 00064/10000
[A[ATraining Step: 3927  | total loss: [1m[32m0.85383[0m[0m | time: 3.310s
[2K| Adam | epoch: 026 | loss: 0.85383 - acc: 0.7981 -- iter: 00128/10000
[A[ATraining Step: 3928  | total loss: [1m[32m0.79796[0m[0m | time: 4.917s
[2K| Adam | epoch: 026 | loss: 0.79796 - acc: 0.8074 -- iter: 00192/10000
[A[ATraining Step: 3929  | total loss: [1m[32m0.76882[0m[0m | time: 6.529s
[2K| Adam | epoch: 026 | loss: 0.76882 - acc: 0.8063 -- iter: 00256/10000
[A[ATraining Step: 3930  | total loss: [1m[32m0.75403[0m[0m | time: 8.182s
[2K| Adam | epoch: 026 | loss: 0.75403 - acc: 0.8038 -- iter: 00320/10000
[A[ATraining Step: 3931  | total loss: [1m[32m0.73530[0m[0m | time: 9.849s
[2K| Adam | epoch: 026 | loss: 0.73530 - acc: 0.7938 -- iter: 00384/10000
[A[ATraining Step: 3932  | total loss: [1m[32m0.71451[0m[0m | time: 11.462s
[2K| Adam | epoch: 026 | loss: 0.71451 - acc: 0.7925 -- iter: 00448/10000
[A[ATraining Step: 3933  | total loss: [1m[32m0.72325[0m[0m | time: 13.058s
[2K| Adam | epoch: 026 | loss: 0.72325 - acc: 0.7804 -- iter: 00512/10000
[A[ATraining Step: 3934  | total loss: [1m[32m0.68914[0m[0m | time: 14.791s
[2K| Adam | epoch: 026 | loss: 0.68914 - acc: 0.7930 -- iter: 00576/10000
[A[ATraining Step: 3935  | total loss: [1m[32m0.66288[0m[0m | time: 16.527s
[2K| Adam | epoch: 026 | loss: 0.66288 - acc: 0.8028 -- iter: 00640/10000
[A[ATraining Step: 3936  | total loss: [1m[32m0.64711[0m[0m | time: 18.299s
[2K| Adam | epoch: 026 | loss: 0.64711 - acc: 0.8069 -- iter: 00704/10000
[A[ATraining Step: 3937  | total loss: [1m[32m0.62540[0m[0m | time: 20.119s
[2K| Adam | epoch: 026 | loss: 0.62540 - acc: 0.8121 -- iter: 00768/10000
[A[ATraining Step: 3938  | total loss: [1m[32m0.60629[0m[0m | time: 21.848s
[2K| Adam | epoch: 026 | loss: 0.60629 - acc: 0.8153 -- iter: 00832/10000
[A[ATraining Step: 3939  | total loss: [1m[32m0.58578[0m[0m | time: 23.591s
[2K| Adam | epoch: 026 | loss: 0.58578 - acc: 0.8150 -- iter: 00896/10000
[A[ATraining Step: 3940  | total loss: [1m[32m0.56720[0m[0m | time: 25.363s
[2K| Adam | epoch: 026 | loss: 0.56720 - acc: 0.8273 -- iter: 00960/10000
[A[ATraining Step: 3941  | total loss: [1m[32m0.56649[0m[0m | time: 27.045s
[2K| Adam | epoch: 026 | loss: 0.56649 - acc: 0.8211 -- iter: 01024/10000
[A[ATraining Step: 3942  | total loss: [1m[32m0.54491[0m[0m | time: 28.672s
[2K| Adam | epoch: 026 | loss: 0.54491 - acc: 0.8234 -- iter: 01088/10000
[A[ATraining Step: 3943  | total loss: [1m[32m0.52253[0m[0m | time: 30.305s
[2K| Adam | epoch: 026 | loss: 0.52253 - acc: 0.8254 -- iter: 01152/10000
[A[ATraining Step: 3944  | total loss: [1m[32m0.52208[0m[0m | time: 31.925s
[2K| Adam | epoch: 026 | loss: 0.52208 - acc: 0.8132 -- iter: 01216/10000
[A[ATraining Step: 3945  | total loss: [1m[32m0.52925[0m[0m | time: 33.525s
[2K| Adam | epoch: 026 | loss: 0.52925 - acc: 0.8084 -- iter: 01280/10000
[A[ATraining Step: 3946  | total loss: [1m[32m0.53793[0m[0m | time: 35.149s
[2K| Adam | epoch: 026 | loss: 0.53793 - acc: 0.8010 -- iter: 01344/10000
[A[ATraining Step: 3947  | total loss: [1m[32m0.52185[0m[0m | time: 36.780s
[2K| Adam | epoch: 026 | loss: 0.52185 - acc: 0.8022 -- iter: 01408/10000
[A[ATraining Step: 3948  | total loss: [1m[32m0.52462[0m[0m | time: 38.504s
[2K| Adam | epoch: 026 | loss: 0.52462 - acc: 0.7954 -- iter: 01472/10000
[A[ATraining Step: 3949  | total loss: [1m[32m0.52566[0m[0m | time: 39.420s
[2K| Adam | epoch: 026 | loss: 0.52566 - acc: 0.7924 -- iter: 01536/10000
[A[ATraining Step: 3950  | total loss: [1m[32m0.49693[0m[0m | time: 40.272s
[2K| Adam | epoch: 026 | loss: 0.49693 - acc: 0.8007 -- iter: 01600/10000
[A[ATraining Step: 3951  | total loss: [1m[32m0.47405[0m[0m | time: 42.063s
[2K| Adam | epoch: 026 | loss: 0.47405 - acc: 0.8144 -- iter: 01664/10000
[A[ATraining Step: 3952  | total loss: [1m[32m0.45899[0m[0m | time: 43.803s
[2K| Adam | epoch: 026 | loss: 0.45899 - acc: 0.8251 -- iter: 01728/10000
[A[ATraining Step: 3953  | total loss: [1m[32m0.47249[0m[0m | time: 45.545s
[2K| Adam | epoch: 026 | loss: 0.47249 - acc: 0.8223 -- iter: 01792/10000
[A[ATraining Step: 3954  | total loss: [1m[32m0.49053[0m[0m | time: 47.303s
[2K| Adam | epoch: 026 | loss: 0.49053 - acc: 0.8197 -- iter: 01856/10000
[A[ATraining Step: 3955  | total loss: [1m[32m0.49525[0m[0m | time: 49.128s
[2K| Adam | epoch: 026 | loss: 0.49525 - acc: 0.8190 -- iter: 01920/10000
[A[ATraining Step: 3956  | total loss: [1m[32m0.48937[0m[0m | time: 50.881s
[2K| Adam | epoch: 026 | loss: 0.48937 - acc: 0.8246 -- iter: 01984/10000
[A[ATraining Step: 3957  | total loss: [1m[32m0.48614[0m[0m | time: 52.806s
[2K| Adam | epoch: 026 | loss: 0.48614 - acc: 0.8234 -- iter: 02048/10000
[A[ATraining Step: 3958  | total loss: [1m[32m0.48165[0m[0m | time: 54.531s
[2K| Adam | epoch: 026 | loss: 0.48165 - acc: 0.8270 -- iter: 02112/10000
[A[ATraining Step: 3959  | total loss: [1m[32m0.49423[0m[0m | time: 56.255s
[2K| Adam | epoch: 026 | loss: 0.49423 - acc: 0.8224 -- iter: 02176/10000
[A[ATraining Step: 3960  | total loss: [1m[32m0.48298[0m[0m | time: 57.822s
[2K| Adam | epoch: 026 | loss: 0.48298 - acc: 0.8277 -- iter: 02240/10000
[A[ATraining Step: 3961  | total loss: [1m[32m0.48621[0m[0m | time: 59.487s
[2K| Adam | epoch: 026 | loss: 0.48621 - acc: 0.8293 -- iter: 02304/10000
[A[ATraining Step: 3962  | total loss: [1m[32m0.47557[0m[0m | time: 61.119s
[2K| Adam | epoch: 026 | loss: 0.47557 - acc: 0.8323 -- iter: 02368/10000
[A[ATraining Step: 3963  | total loss: [1m[32m0.48740[0m[0m | time: 62.715s
[2K| Adam | epoch: 026 | loss: 0.48740 - acc: 0.8303 -- iter: 02432/10000
[A[ATraining Step: 3964  | total loss: [1m[32m0.48609[0m[0m | time: 64.302s
[2K| Adam | epoch: 026 | loss: 0.48609 - acc: 0.8348 -- iter: 02496/10000
[A[ATraining Step: 3965  | total loss: [1m[32m0.49451[0m[0m | time: 65.923s
[2K| Adam | epoch: 026 | loss: 0.49451 - acc: 0.8326 -- iter: 02560/10000
[A[ATraining Step: 3966  | total loss: [1m[32m0.48057[0m[0m | time: 67.667s
[2K| Adam | epoch: 026 | loss: 0.48057 - acc: 0.8415 -- iter: 02624/10000
[A[ATraining Step: 3967  | total loss: [1m[32m0.47500[0m[0m | time: 69.474s
[2K| Adam | epoch: 026 | loss: 0.47500 - acc: 0.8417 -- iter: 02688/10000
[A[ATraining Step: 3968  | total loss: [1m[32m0.48321[0m[0m | time: 71.265s
[2K| Adam | epoch: 026 | loss: 0.48321 - acc: 0.8372 -- iter: 02752/10000
[A[ATraining Step: 3969  | total loss: [1m[32m0.47876[0m[0m | time: 73.028s
[2K| Adam | epoch: 026 | loss: 0.47876 - acc: 0.8363 -- iter: 02816/10000
[A[ATraining Step: 3970  | total loss: [1m[32m0.46672[0m[0m | time: 74.771s
[2K| Adam | epoch: 026 | loss: 0.46672 - acc: 0.8433 -- iter: 02880/10000
[A[ATraining Step: 3971  | total loss: [1m[32m0.46349[0m[0m | time: 76.504s
[2K| Adam | epoch: 026 | loss: 0.46349 - acc: 0.8449 -- iter: 02944/10000
[A[ATraining Step: 3972  | total loss: [1m[32m0.47037[0m[0m | time: 78.258s
[2K| Adam | epoch: 026 | loss: 0.47037 - acc: 0.8307 -- iter: 03008/10000
[A[ATraining Step: 3973  | total loss: [1m[32m0.46347[0m[0m | time: 80.102s
[2K| Adam | epoch: 026 | loss: 0.46347 - acc: 0.8336 -- iter: 03072/10000
[A[ATraining Step: 3974  | total loss: [1m[32m0.47839[0m[0m | time: 81.777s
[2K| Adam | epoch: 026 | loss: 0.47839 - acc: 0.8315 -- iter: 03136/10000
[A[ATraining Step: 3975  | total loss: [1m[32m0.47889[0m[0m | time: 83.378s
[2K| Adam | epoch: 026 | loss: 0.47889 - acc: 0.8265 -- iter: 03200/10000
[A[ATraining Step: 3976  | total loss: [1m[32m0.48532[0m[0m | time: 84.991s
[2K| Adam | epoch: 026 | loss: 0.48532 - acc: 0.8204 -- iter: 03264/10000
[A[ATraining Step: 3977  | total loss: [1m[32m0.49254[0m[0m | time: 86.581s
[2K| Adam | epoch: 026 | loss: 0.49254 - acc: 0.8180 -- iter: 03328/10000
[A[ATraining Step: 3978  | total loss: [1m[32m0.51365[0m[0m | time: 88.197s
[2K| Adam | epoch: 026 | loss: 0.51365 - acc: 0.8097 -- iter: 03392/10000
[A[ATraining Step: 3979  | total loss: [1m[32m0.52980[0m[0m | time: 89.893s
[2K| Adam | epoch: 026 | loss: 0.52980 - acc: 0.8068 -- iter: 03456/10000
[A[ATraining Step: 3980  | total loss: [1m[32m0.51740[0m[0m | time: 91.530s
[2K| Adam | epoch: 026 | loss: 0.51740 - acc: 0.8058 -- iter: 03520/10000
[A[ATraining Step: 3981  | total loss: [1m[32m0.50619[0m[0m | time: 93.148s
[2K| Adam | epoch: 026 | loss: 0.50619 - acc: 0.8143 -- iter: 03584/10000
[A[ATraining Step: 3982  | total loss: [1m[32m0.50732[0m[0m | time: 94.890s
[2K| Adam | epoch: 026 | loss: 0.50732 - acc: 0.8126 -- iter: 03648/10000
[A[ATraining Step: 3983  | total loss: [1m[32m0.50912[0m[0m | time: 96.632s
[2K| Adam | epoch: 026 | loss: 0.50912 - acc: 0.8126 -- iter: 03712/10000
[A[ATraining Step: 3984  | total loss: [1m[32m0.50097[0m[0m | time: 98.383s
[2K| Adam | epoch: 026 | loss: 0.50097 - acc: 0.8141 -- iter: 03776/10000
[A[ATraining Step: 3985  | total loss: [1m[32m0.51043[0m[0m | time: 100.400s
[2K| Adam | epoch: 026 | loss: 0.51043 - acc: 0.8108 -- iter: 03840/10000
[A[ATraining Step: 3986  | total loss: [1m[32m0.50451[0m[0m | time: 102.154s
[2K| Adam | epoch: 026 | loss: 0.50451 - acc: 0.8079 -- iter: 03904/10000
[A[ATraining Step: 3987  | total loss: [1m[32m0.48581[0m[0m | time: 103.890s
[2K| Adam | epoch: 026 | loss: 0.48581 - acc: 0.8208 -- iter: 03968/10000
[A[ATraining Step: 3988  | total loss: [1m[32m0.50986[0m[0m | time: 105.621s
[2K| Adam | epoch: 026 | loss: 0.50986 - acc: 0.8075 -- iter: 04032/10000
[A[ATraining Step: 3989  | total loss: [1m[32m0.52079[0m[0m | time: 107.382s
[2K| Adam | epoch: 026 | loss: 0.52079 - acc: 0.8049 -- iter: 04096/10000
[A[ATraining Step: 3990  | total loss: [1m[32m0.52864[0m[0m | time: 109.055s
[2K| Adam | epoch: 026 | loss: 0.52864 - acc: 0.8041 -- iter: 04160/10000
[A[ATraining Step: 3991  | total loss: [1m[32m0.53707[0m[0m | time: 110.655s
[2K| Adam | epoch: 026 | loss: 0.53707 - acc: 0.8034 -- iter: 04224/10000
[A[ATraining Step: 3992  | total loss: [1m[32m0.52929[0m[0m | time: 112.189s
[2K| Adam | epoch: 026 | loss: 0.52929 - acc: 0.8058 -- iter: 04288/10000
[A[ATraining Step: 3993  | total loss: [1m[32m0.52306[0m[0m | time: 113.830s
[2K| Adam | epoch: 026 | loss: 0.52306 - acc: 0.8065 -- iter: 04352/10000
[A[ATraining Step: 3994  | total loss: [1m[32m0.50891[0m[0m | time: 115.428s
[2K| Adam | epoch: 026 | loss: 0.50891 - acc: 0.8102 -- iter: 04416/10000
[A[ATraining Step: 3995  | total loss: [1m[32m0.52686[0m[0m | time: 117.038s
[2K| Adam | epoch: 026 | loss: 0.52686 - acc: 0.8089 -- iter: 04480/10000
[A[ATraining Step: 3996  | total loss: [1m[32m0.51653[0m[0m | time: 118.652s
[2K| Adam | epoch: 026 | loss: 0.51653 - acc: 0.8108 -- iter: 04544/10000
[A[ATraining Step: 3997  | total loss: [1m[32m0.51903[0m[0m | time: 120.314s
[2K| Adam | epoch: 026 | loss: 0.51903 - acc: 0.8110 -- iter: 04608/10000
[A[ATraining Step: 3998  | total loss: [1m[32m0.52256[0m[0m | time: 121.922s
[2K| Adam | epoch: 026 | loss: 0.52256 - acc: 0.8111 -- iter: 04672/10000
[A[ATraining Step: 3999  | total loss: [1m[32m0.51581[0m[0m | time: 123.522s
[2K| Adam | epoch: 026 | loss: 0.51581 - acc: 0.8128 -- iter: 04736/10000
[A[ATraining Step: 4000  | total loss: [1m[32m0.51722[0m[0m | time: 129.883s
[2K| Adam | epoch: 026 | loss: 0.51722 - acc: 0.8128 | val_loss: 2.78083 - val_acc: 0.3586 -- iter: 04800/10000
--
Training Step: 4001  | total loss: [1m[32m0.52280[0m[0m | time: 131.518s
[2K| Adam | epoch: 026 | loss: 0.52280 - acc: 0.8096 -- iter: 04864/10000
[A[ATraining Step: 4002  | total loss: [1m[32m0.51251[0m[0m | time: 133.275s
[2K| Adam | epoch: 026 | loss: 0.51251 - acc: 0.8099 -- iter: 04928/10000
[A[ATraining Step: 4003  | total loss: [1m[32m0.52927[0m[0m | time: 135.017s
[2K| Adam | epoch: 026 | loss: 0.52927 - acc: 0.8102 -- iter: 04992/10000
[A[ATraining Step: 4004  | total loss: [1m[32m0.53407[0m[0m | time: 136.770s
[2K| Adam | epoch: 026 | loss: 0.53407 - acc: 0.8057 -- iter: 05056/10000
[A[ATraining Step: 4005  | total loss: [1m[32m0.54141[0m[0m | time: 138.426s
[2K| Adam | epoch: 026 | loss: 0.54141 - acc: 0.7970 -- iter: 05120/10000
[A[ATraining Step: 4006  | total loss: [1m[32m0.53456[0m[0m | time: 140.110s
[2K| Adam | epoch: 026 | loss: 0.53456 - acc: 0.7970 -- iter: 05184/10000
[A[ATraining Step: 4007  | total loss: [1m[32m0.52622[0m[0m | time: 141.711s
[2K| Adam | epoch: 026 | loss: 0.52622 - acc: 0.7970 -- iter: 05248/10000
[A[ATraining Step: 4008  | total loss: [1m[32m0.50352[0m[0m | time: 143.357s
[2K| Adam | epoch: 026 | loss: 0.50352 - acc: 0.8079 -- iter: 05312/10000
[A[ATraining Step: 4009  | total loss: [1m[32m0.49262[0m[0m | time: 145.135s
[2K| Adam | epoch: 026 | loss: 0.49262 - acc: 0.8099 -- iter: 05376/10000
[A[ATraining Step: 4010  | total loss: [1m[32m0.48682[0m[0m | time: 146.763s
[2K| Adam | epoch: 026 | loss: 0.48682 - acc: 0.8118 -- iter: 05440/10000
[A[ATraining Step: 4011  | total loss: [1m[32m0.48063[0m[0m | time: 148.382s
[2K| Adam | epoch: 026 | loss: 0.48063 - acc: 0.8103 -- iter: 05504/10000
[A[ATraining Step: 4012  | total loss: [1m[32m0.49285[0m[0m | time: 150.063s
[2K| Adam | epoch: 026 | loss: 0.49285 - acc: 0.8058 -- iter: 05568/10000
[A[ATraining Step: 4013  | total loss: [1m[32m0.48905[0m[0m | time: 151.668s
[2K| Adam | epoch: 026 | loss: 0.48905 - acc: 0.8096 -- iter: 05632/10000
[A[ATraining Step: 4014  | total loss: [1m[32m0.50005[0m[0m | time: 153.293s
[2K| Adam | epoch: 026 | loss: 0.50005 - acc: 0.8115 -- iter: 05696/10000
[A[ATraining Step: 4015  | total loss: [1m[32m0.51233[0m[0m | time: 154.916s
[2K| Adam | epoch: 026 | loss: 0.51233 - acc: 0.8084 -- iter: 05760/10000
[A[ATraining Step: 4016  | total loss: [1m[32m0.50830[0m[0m | time: 156.519s
[2K| Adam | epoch: 026 | loss: 0.50830 - acc: 0.8182 -- iter: 05824/10000
[A[ATraining Step: 4017  | total loss: [1m[32m0.50568[0m[0m | time: 158.126s
[2K| Adam | epoch: 026 | loss: 0.50568 - acc: 0.8161 -- iter: 05888/10000
[A[ATraining Step: 4018  | total loss: [1m[32m0.49777[0m[0m | time: 159.801s
[2K| Adam | epoch: 026 | loss: 0.49777 - acc: 0.8157 -- iter: 05952/10000
[A[ATraining Step: 4019  | total loss: [1m[32m0.51228[0m[0m | time: 161.450s
[2K| Adam | epoch: 026 | loss: 0.51228 - acc: 0.8076 -- iter: 06016/10000
[A[ATraining Step: 4020  | total loss: [1m[32m0.51759[0m[0m | time: 163.059s
[2K| Adam | epoch: 026 | loss: 0.51759 - acc: 0.8081 -- iter: 06080/10000
[A[ATraining Step: 4021  | total loss: [1m[32m0.51641[0m[0m | time: 164.664s
[2K| Adam | epoch: 026 | loss: 0.51641 - acc: 0.8101 -- iter: 06144/10000
[A[ATraining Step: 4022  | total loss: [1m[32m0.50877[0m[0m | time: 166.254s
[2K| Adam | epoch: 026 | loss: 0.50877 - acc: 0.8088 -- iter: 06208/10000
[A[ATraining Step: 4023  | total loss: [1m[32m0.50887[0m[0m | time: 167.847s
[2K| Adam | epoch: 026 | loss: 0.50887 - acc: 0.8123 -- iter: 06272/10000
[A[ATraining Step: 4024  | total loss: [1m[32m0.49445[0m[0m | time: 169.528s
[2K| Adam | epoch: 026 | loss: 0.49445 - acc: 0.8185 -- iter: 06336/10000
[A[ATraining Step: 4025  | total loss: [1m[32m0.47977[0m[0m | time: 171.287s
[2K| Adam | epoch: 026 | loss: 0.47977 - acc: 0.8304 -- iter: 06400/10000
[A[ATraining Step: 4026  | total loss: [1m[32m0.47303[0m[0m | time: 173.064s
[2K| Adam | epoch: 026 | loss: 0.47303 - acc: 0.8302 -- iter: 06464/10000
[A[ATraining Step: 4027  | total loss: [1m[32m0.46246[0m[0m | time: 174.809s
[2K| Adam | epoch: 026 | loss: 0.46246 - acc: 0.8284 -- iter: 06528/10000
[A[ATraining Step: 4028  | total loss: [1m[32m0.47651[0m[0m | time: 176.477s
[2K| Adam | epoch: 026 | loss: 0.47651 - acc: 0.8175 -- iter: 06592/10000
[A[ATraining Step: 4029  | total loss: [1m[32m0.48096[0m[0m | time: 178.092s
[2K| Adam | epoch: 026 | loss: 0.48096 - acc: 0.8170 -- iter: 06656/10000
[A[ATraining Step: 4030  | total loss: [1m[32m0.46879[0m[0m | time: 179.762s
[2K| Adam | epoch: 026 | loss: 0.46879 - acc: 0.8196 -- iter: 06720/10000
[A[ATraining Step: 4031  | total loss: [1m[32m0.46855[0m[0m | time: 181.547s
[2K| Adam | epoch: 026 | loss: 0.46855 - acc: 0.8142 -- iter: 06784/10000
[A[ATraining Step: 4032  | total loss: [1m[32m0.46470[0m[0m | time: 183.108s
[2K| Adam | epoch: 026 | loss: 0.46470 - acc: 0.8172 -- iter: 06848/10000
[A[ATraining Step: 4033  | total loss: [1m[32m0.48973[0m[0m | time: 184.637s
[2K| Adam | epoch: 026 | loss: 0.48973 - acc: 0.8120 -- iter: 06912/10000
[A[ATraining Step: 4034  | total loss: [1m[32m0.49361[0m[0m | time: 186.255s
[2K| Adam | epoch: 026 | loss: 0.49361 - acc: 0.8183 -- iter: 06976/10000
[A[ATraining Step: 4035  | total loss: [1m[32m0.49751[0m[0m | time: 187.860s
[2K| Adam | epoch: 026 | loss: 0.49751 - acc: 0.8193 -- iter: 07040/10000
[A[ATraining Step: 4036  | total loss: [1m[32m0.49204[0m[0m | time: 189.493s
[2K| Adam | epoch: 026 | loss: 0.49204 - acc: 0.8186 -- iter: 07104/10000
[A[ATraining Step: 4037  | total loss: [1m[32m0.48200[0m[0m | time: 191.124s
[2K| Adam | epoch: 026 | loss: 0.48200 - acc: 0.8274 -- iter: 07168/10000
[A[ATraining Step: 4038  | total loss: [1m[32m0.46689[0m[0m | time: 192.749s
[2K| Adam | epoch: 026 | loss: 0.46689 - acc: 0.8337 -- iter: 07232/10000
[A[ATraining Step: 4039  | total loss: [1m[32m0.48567[0m[0m | time: 194.352s
[2K| Adam | epoch: 026 | loss: 0.48567 - acc: 0.8300 -- iter: 07296/10000
[A[ATraining Step: 4040  | total loss: [1m[32m0.46926[0m[0m | time: 195.977s
[2K| Adam | epoch: 026 | loss: 0.46926 - acc: 0.8361 -- iter: 07360/10000
[A[ATraining Step: 4041  | total loss: [1m[32m0.47813[0m[0m | time: 197.560s
[2K| Adam | epoch: 026 | loss: 0.47813 - acc: 0.8353 -- iter: 07424/10000
[A[ATraining Step: 4042  | total loss: [1m[32m0.48445[0m[0m | time: 199.235s
[2K| Adam | epoch: 026 | loss: 0.48445 - acc: 0.8299 -- iter: 07488/10000
[A[ATraining Step: 4043  | total loss: [1m[32m0.47943[0m[0m | time: 200.865s
[2K| Adam | epoch: 026 | loss: 0.47943 - acc: 0.8250 -- iter: 07552/10000
[A[ATraining Step: 4044  | total loss: [1m[32m0.48490[0m[0m | time: 202.470s
[2K| Adam | epoch: 026 | loss: 0.48490 - acc: 0.8222 -- iter: 07616/10000
[A[ATraining Step: 4045  | total loss: [1m[32m0.48586[0m[0m | time: 204.121s
[2K| Adam | epoch: 026 | loss: 0.48586 - acc: 0.8197 -- iter: 07680/10000
[A[ATraining Step: 4046  | total loss: [1m[32m0.49005[0m[0m | time: 205.715s
[2K| Adam | epoch: 026 | loss: 0.49005 - acc: 0.8205 -- iter: 07744/10000
[A[ATraining Step: 4047  | total loss: [1m[32m0.50343[0m[0m | time: 207.306s
[2K| Adam | epoch: 026 | loss: 0.50343 - acc: 0.8213 -- iter: 07808/10000
[A[ATraining Step: 4048  | total loss: [1m[32m0.52324[0m[0m | time: 208.979s
[2K| Adam | epoch: 026 | loss: 0.52324 - acc: 0.8157 -- iter: 07872/10000
[A[ATraining Step: 4049  | total loss: [1m[32m0.51267[0m[0m | time: 210.569s
[2K| Adam | epoch: 026 | loss: 0.51267 - acc: 0.8185 -- iter: 07936/10000
[A[ATraining Step: 4050  | total loss: [1m[32m0.49686[0m[0m | time: 212.210s
[2K| Adam | epoch: 026 | loss: 0.49686 - acc: 0.8273 -- iter: 08000/10000
[A[ATraining Step: 4051  | total loss: [1m[32m0.50320[0m[0m | time: 213.817s
[2K| Adam | epoch: 026 | loss: 0.50320 - acc: 0.8274 -- iter: 08064/10000
[A[ATraining Step: 4052  | total loss: [1m[32m0.49438[0m[0m | time: 215.437s
[2K| Adam | epoch: 026 | loss: 0.49438 - acc: 0.8275 -- iter: 08128/10000
[A[ATraining Step: 4053  | total loss: [1m[32m0.50632[0m[0m | time: 217.039s
[2K| Adam | epoch: 026 | loss: 0.50632 - acc: 0.8260 -- iter: 08192/10000
[A[ATraining Step: 4054  | total loss: [1m[32m0.49649[0m[0m | time: 218.668s
[2K| Adam | epoch: 026 | loss: 0.49649 - acc: 0.8246 -- iter: 08256/10000
[A[ATraining Step: 4055  | total loss: [1m[32m0.50959[0m[0m | time: 220.316s
[2K| Adam | epoch: 026 | loss: 0.50959 - acc: 0.8140 -- iter: 08320/10000
[A[ATraining Step: 4056  | total loss: [1m[32m0.51740[0m[0m | time: 221.962s
[2K| Adam | epoch: 026 | loss: 0.51740 - acc: 0.8092 -- iter: 08384/10000
[A[ATraining Step: 4057  | total loss: [1m[32m0.51565[0m[0m | time: 223.553s
[2K| Adam | epoch: 026 | loss: 0.51565 - acc: 0.8111 -- iter: 08448/10000
[A[ATraining Step: 4058  | total loss: [1m[32m0.51081[0m[0m | time: 225.175s
[2K| Adam | epoch: 026 | loss: 0.51081 - acc: 0.8050 -- iter: 08512/10000
[A[ATraining Step: 4059  | total loss: [1m[32m0.52607[0m[0m | time: 226.777s
[2K| Adam | epoch: 026 | loss: 0.52607 - acc: 0.8073 -- iter: 08576/10000
[A[ATraining Step: 4060  | total loss: [1m[32m0.53088[0m[0m | time: 228.388s
[2K| Adam | epoch: 026 | loss: 0.53088 - acc: 0.8062 -- iter: 08640/10000
[A[ATraining Step: 4061  | total loss: [1m[32m0.52061[0m[0m | time: 230.100s
[2K| Adam | epoch: 026 | loss: 0.52061 - acc: 0.8100 -- iter: 08704/10000
[A[ATraining Step: 4062  | total loss: [1m[32m0.50873[0m[0m | time: 231.884s
[2K| Adam | epoch: 026 | loss: 0.50873 - acc: 0.8134 -- iter: 08768/10000
[A[ATraining Step: 4063  | total loss: [1m[32m0.51966[0m[0m | time: 233.638s
[2K| Adam | epoch: 026 | loss: 0.51966 - acc: 0.8039 -- iter: 08832/10000
[A[ATraining Step: 4064  | total loss: [1m[32m0.51856[0m[0m | time: 235.373s
[2K| Adam | epoch: 026 | loss: 0.51856 - acc: 0.8032 -- iter: 08896/10000
[A[ATraining Step: 4065  | total loss: [1m[32m0.51877[0m[0m | time: 237.111s
[2K| Adam | epoch: 026 | loss: 0.51877 - acc: 0.8010 -- iter: 08960/10000
[A[ATraining Step: 4066  | total loss: [1m[32m0.53522[0m[0m | time: 238.762s
[2K| Adam | epoch: 026 | loss: 0.53522 - acc: 0.7912 -- iter: 09024/10000
[A[ATraining Step: 4067  | total loss: [1m[32m0.53215[0m[0m | time: 240.398s
[2K| Adam | epoch: 026 | loss: 0.53215 - acc: 0.7918 -- iter: 09088/10000
[A[ATraining Step: 4068  | total loss: [1m[32m0.53042[0m[0m | time: 242.042s
[2K| Adam | epoch: 026 | loss: 0.53042 - acc: 0.7923 -- iter: 09152/10000
[A[ATraining Step: 4069  | total loss: [1m[32m0.53816[0m[0m | time: 243.665s
[2K| Adam | epoch: 026 | loss: 0.53816 - acc: 0.7928 -- iter: 09216/10000
[A[ATraining Step: 4070  | total loss: [1m[32m0.54036[0m[0m | time: 245.281s
[2K| Adam | epoch: 026 | loss: 0.54036 - acc: 0.7916 -- iter: 09280/10000
[A[ATraining Step: 4071  | total loss: [1m[32m0.52889[0m[0m | time: 246.885s
[2K| Adam | epoch: 026 | loss: 0.52889 - acc: 0.7953 -- iter: 09344/10000
[A[ATraining Step: 4072  | total loss: [1m[32m0.51616[0m[0m | time: 248.481s
[2K| Adam | epoch: 026 | loss: 0.51616 - acc: 0.8001 -- iter: 09408/10000
[A[ATraining Step: 4073  | total loss: [1m[32m0.52837[0m[0m | time: 250.170s
[2K| Adam | epoch: 026 | loss: 0.52837 - acc: 0.7982 -- iter: 09472/10000
[A[ATraining Step: 4074  | total loss: [1m[32m0.52700[0m[0m | time: 251.912s
[2K| Adam | epoch: 026 | loss: 0.52700 - acc: 0.7996 -- iter: 09536/10000
[A[ATraining Step: 4075  | total loss: [1m[32m0.53123[0m[0m | time: 253.572s
[2K| Adam | epoch: 026 | loss: 0.53123 - acc: 0.8025 -- iter: 09600/10000
[A[ATraining Step: 4076  | total loss: [1m[32m1.63566[0m[0m | time: 255.193s
[2K| Adam | epoch: 026 | loss: 1.63566 - acc: 0.7269 -- iter: 09664/10000
[A[ATraining Step: 4077  | total loss: [1m[32m1.51690[0m[0m | time: 256.800s
[2K| Adam | epoch: 026 | loss: 1.51690 - acc: 0.7292 -- iter: 09728/10000
[A[ATraining Step: 4078  | total loss: [1m[32m1.41920[0m[0m | time: 258.402s
[2K| Adam | epoch: 026 | loss: 1.41920 - acc: 0.7391 -- iter: 09792/10000
[A[ATraining Step: 4079  | total loss: [1m[32m1.33632[0m[0m | time: 260.091s
[2K| Adam | epoch: 026 | loss: 1.33632 - acc: 0.7465 -- iter: 09856/10000
[A[ATraining Step: 4080  | total loss: [1m[32m1.27388[0m[0m | time: 261.732s
[2K| Adam | epoch: 026 | loss: 1.27388 - acc: 0.7546 -- iter: 09920/10000
[A[ATraining Step: 4081  | total loss: [1m[32m1.17878[0m[0m | time: 263.346s
[2K| Adam | epoch: 026 | loss: 1.17878 - acc: 0.7698 -- iter: 09984/10000
[A[ATraining Step: 4082  | total loss: [1m[32m1.12770[0m[0m | time: 269.508s
[2K| Adam | epoch: 026 | loss: 1.12770 - acc: 0.7631 | val_loss: 2.84374 - val_acc: 0.3629 -- iter: 10000/10000
--
Training Step: 4083  | total loss: [1m[32m1.05669[0m[0m | time: 1.764s
[2K| Adam | epoch: 027 | loss: 1.05669 - acc: 0.7712 -- iter: 00064/10000
[A[ATraining Step: 4084  | total loss: [1m[32m1.00361[0m[0m | time: 3.510s
[2K| Adam | epoch: 027 | loss: 1.00361 - acc: 0.7691 -- iter: 00128/10000
[A[ATraining Step: 4085  | total loss: [1m[32m0.94128[0m[0m | time: 5.259s
[2K| Adam | epoch: 027 | loss: 0.94128 - acc: 0.7781 -- iter: 00192/10000
[A[ATraining Step: 4086  | total loss: [1m[32m0.88734[0m[0m | time: 6.995s
[2K| Adam | epoch: 027 | loss: 0.88734 - acc: 0.7878 -- iter: 00256/10000
[A[ATraining Step: 4087  | total loss: [1m[32m0.84738[0m[0m | time: 8.747s
[2K| Adam | epoch: 027 | loss: 0.84738 - acc: 0.7903 -- iter: 00320/10000
[A[ATraining Step: 4088  | total loss: [1m[32m0.81630[0m[0m | time: 10.565s
[2K| Adam | epoch: 027 | loss: 0.81630 - acc: 0.7894 -- iter: 00384/10000
[A[ATraining Step: 4089  | total loss: [1m[32m0.78400[0m[0m | time: 12.286s
[2K| Adam | epoch: 027 | loss: 0.78400 - acc: 0.7964 -- iter: 00448/10000
[A[ATraining Step: 4090  | total loss: [1m[32m0.75082[0m[0m | time: 13.903s
[2K| Adam | epoch: 027 | loss: 0.75082 - acc: 0.8011 -- iter: 00512/10000
[A[ATraining Step: 4091  | total loss: [1m[32m0.73272[0m[0m | time: 15.523s
[2K| Adam | epoch: 027 | loss: 0.73272 - acc: 0.8007 -- iter: 00576/10000
[A[ATraining Step: 4092  | total loss: [1m[32m0.71313[0m[0m | time: 17.136s
[2K| Adam | epoch: 027 | loss: 0.71313 - acc: 0.8034 -- iter: 00640/10000
[A[ATraining Step: 4093  | total loss: [1m[32m0.70228[0m[0m | time: 18.769s
[2K| Adam | epoch: 027 | loss: 0.70228 - acc: 0.8043 -- iter: 00704/10000
[A[ATraining Step: 4094  | total loss: [1m[32m0.67617[0m[0m | time: 20.460s
[2K| Adam | epoch: 027 | loss: 0.67617 - acc: 0.8051 -- iter: 00768/10000
[A[ATraining Step: 4095  | total loss: [1m[32m0.65537[0m[0m | time: 22.086s
[2K| Adam | epoch: 027 | loss: 0.65537 - acc: 0.8106 -- iter: 00832/10000
[A[ATraining Step: 4096  | total loss: [1m[32m0.62760[0m[0m | time: 23.697s
[2K| Adam | epoch: 027 | loss: 0.62760 - acc: 0.8155 -- iter: 00896/10000
[A[ATraining Step: 4097  | total loss: [1m[32m0.60266[0m[0m | time: 25.335s
[2K| Adam | epoch: 027 | loss: 0.60266 - acc: 0.8167 -- iter: 00960/10000
[A[ATraining Step: 4098  | total loss: [1m[32m0.58769[0m[0m | time: 26.942s
[2K| Adam | epoch: 027 | loss: 0.58769 - acc: 0.8163 -- iter: 01024/10000
[A[ATraining Step: 4099  | total loss: [1m[32m0.58193[0m[0m | time: 28.694s
[2K| Adam | epoch: 027 | loss: 0.58193 - acc: 0.8128 -- iter: 01088/10000
[A[ATraining Step: 4100  | total loss: [1m[32m0.57859[0m[0m | time: 35.284s
[2K| Adam | epoch: 027 | loss: 0.57859 - acc: 0.8096 | val_loss: 2.53773 - val_acc: 0.3743 -- iter: 01152/10000
--
Training Step: 4101  | total loss: [1m[32m0.57049[0m[0m | time: 36.947s
[2K| Adam | epoch: 027 | loss: 0.57049 - acc: 0.8130 -- iter: 01216/10000
[A[ATraining Step: 4102  | total loss: [1m[32m0.55343[0m[0m | time: 38.719s
[2K| Adam | epoch: 027 | loss: 0.55343 - acc: 0.8192 -- iter: 01280/10000
[A[ATraining Step: 4103  | total loss: [1m[32m0.54666[0m[0m | time: 40.427s
[2K| Adam | epoch: 027 | loss: 0.54666 - acc: 0.8201 -- iter: 01344/10000
[A[ATraining Step: 4104  | total loss: [1m[32m0.54253[0m[0m | time: 42.053s
[2K| Adam | epoch: 027 | loss: 0.54253 - acc: 0.8256 -- iter: 01408/10000
[A[ATraining Step: 4105  | total loss: [1m[32m0.53833[0m[0m | time: 43.669s
[2K| Adam | epoch: 027 | loss: 0.53833 - acc: 0.8243 -- iter: 01472/10000
[A[ATraining Step: 4106  | total loss: [1m[32m0.53862[0m[0m | time: 45.291s
[2K| Adam | epoch: 027 | loss: 0.53862 - acc: 0.8263 -- iter: 01536/10000
[A[ATraining Step: 4107  | total loss: [1m[32m0.54288[0m[0m | time: 46.068s
[2K| Adam | epoch: 027 | loss: 0.54288 - acc: 0.8280 -- iter: 01600/10000
[A[ATraining Step: 4108  | total loss: [1m[32m0.52827[0m[0m | time: 46.856s
[2K| Adam | epoch: 027 | loss: 0.52827 - acc: 0.8327 -- iter: 01664/10000
[A[ATraining Step: 4109  | total loss: [1m[32m0.50921[0m[0m | time: 48.451s
[2K| Adam | epoch: 027 | loss: 0.50921 - acc: 0.8369 -- iter: 01728/10000
[A[ATraining Step: 4110  | total loss: [1m[32m0.49225[0m[0m | time: 50.126s
[2K| Adam | epoch: 027 | loss: 0.49225 - acc: 0.8392 -- iter: 01792/10000
[A[ATraining Step: 4111  | total loss: [1m[32m0.49575[0m[0m | time: 51.746s
[2K| Adam | epoch: 027 | loss: 0.49575 - acc: 0.8365 -- iter: 01856/10000
[A[ATraining Step: 4112  | total loss: [1m[32m0.49197[0m[0m | time: 53.383s
[2K| Adam | epoch: 027 | loss: 0.49197 - acc: 0.8357 -- iter: 01920/10000
[A[ATraining Step: 4113  | total loss: [1m[32m0.50208[0m[0m | time: 54.817s
[2K| Adam | epoch: 027 | loss: 0.50208 - acc: 0.8224 -- iter: 01984/10000
[A[ATraining Step: 4114  | total loss: [1m[32m0.48849[0m[0m | time: 56.217s
[2K| Adam | epoch: 027 | loss: 0.48849 - acc: 0.8261 -- iter: 02048/10000
[A[ATraining Step: 4115  | total loss: [1m[32m0.47900[0m[0m | time: 57.685s
[2K| Adam | epoch: 027 | loss: 0.47900 - acc: 0.8247 -- iter: 02112/10000
[A[ATraining Step: 4116  | total loss: [1m[32m0.47263[0m[0m | time: 59.145s
[2K| Adam | epoch: 027 | loss: 0.47263 - acc: 0.8282 -- iter: 02176/10000
[A[ATraining Step: 4117  | total loss: [1m[32m0.46909[0m[0m | time: 60.896s
[2K| Adam | epoch: 027 | loss: 0.46909 - acc: 0.8282 -- iter: 02240/10000
[A[ATraining Step: 4118  | total loss: [1m[32m0.47361[0m[0m | time: 62.438s
[2K| Adam | epoch: 027 | loss: 0.47361 - acc: 0.8282 -- iter: 02304/10000
[A[ATraining Step: 4119  | total loss: [1m[32m0.47591[0m[0m | time: 64.050s
[2K| Adam | epoch: 027 | loss: 0.47591 - acc: 0.8282 -- iter: 02368/10000
[A[ATraining Step: 4120  | total loss: [1m[32m0.47124[0m[0m | time: 65.430s
[2K| Adam | epoch: 027 | loss: 0.47124 - acc: 0.8329 -- iter: 02432/10000
[A[ATraining Step: 4121  | total loss: [1m[32m0.47626[0m[0m | time: 66.783s
[2K| Adam | epoch: 027 | loss: 0.47626 - acc: 0.8340 -- iter: 02496/10000
[A[ATraining Step: 4122  | total loss: [1m[32m0.48177[0m[0m | time: 68.155s
[2K| Adam | epoch: 027 | loss: 0.48177 - acc: 0.8349 -- iter: 02560/10000
[A[ATraining Step: 4123  | total loss: [1m[32m0.48422[0m[0m | time: 69.482s
[2K| Adam | epoch: 027 | loss: 0.48422 - acc: 0.8358 -- iter: 02624/10000
[A[ATraining Step: 4124  | total loss: [1m[32m0.49105[0m[0m | time: 70.755s
[2K| Adam | epoch: 027 | loss: 0.49105 - acc: 0.8335 -- iter: 02688/10000
[A[ATraining Step: 4125  | total loss: [1m[32m0.49016[0m[0m | time: 72.027s
[2K| Adam | epoch: 027 | loss: 0.49016 - acc: 0.8283 -- iter: 02752/10000
[A[ATraining Step: 4126  | total loss: [1m[32m0.48592[0m[0m | time: 73.283s
[2K| Adam | epoch: 027 | loss: 0.48592 - acc: 0.8251 -- iter: 02816/10000
[A[ATraining Step: 4127  | total loss: [1m[32m0.49771[0m[0m | time: 74.537s
[2K| Adam | epoch: 027 | loss: 0.49771 - acc: 0.8145 -- iter: 02880/10000
[A[ATraining Step: 4128  | total loss: [1m[32m0.50353[0m[0m | time: 75.731s
[2K| Adam | epoch: 027 | loss: 0.50353 - acc: 0.8096 -- iter: 02944/10000
[A[ATraining Step: 4129  | total loss: [1m[32m0.48591[0m[0m | time: 76.921s
[2K| Adam | epoch: 027 | loss: 0.48591 - acc: 0.8161 -- iter: 03008/10000
[A[ATraining Step: 4130  | total loss: [1m[32m0.48379[0m[0m | time: 78.105s
[2K| Adam | epoch: 027 | loss: 0.48379 - acc: 0.8142 -- iter: 03072/10000
[A[ATraining Step: 4131  | total loss: [1m[32m0.48725[0m[0m | time: 79.339s
[2K| Adam | epoch: 027 | loss: 0.48725 - acc: 0.8094 -- iter: 03136/10000
[A[ATraining Step: 4132  | total loss: [1m[32m0.47800[0m[0m | time: 80.519s
[2K| Adam | epoch: 027 | loss: 0.47800 - acc: 0.8081 -- iter: 03200/10000
[A[ATraining Step: 4133  | total loss: [1m[32m0.47278[0m[0m | time: 81.717s
[2K| Adam | epoch: 027 | loss: 0.47278 - acc: 0.8070 -- iter: 03264/10000
[A[ATraining Step: 4134  | total loss: [1m[32m0.46756[0m[0m | time: 82.863s
[2K| Adam | epoch: 027 | loss: 0.46756 - acc: 0.8169 -- iter: 03328/10000
[A[ATraining Step: 4135  | total loss: [1m[32m0.44822[0m[0m | time: 84.004s
[2K| Adam | epoch: 027 | loss: 0.44822 - acc: 0.8258 -- iter: 03392/10000
[A[ATraining Step: 4136  | total loss: [1m[32m0.44722[0m[0m | time: 85.137s
[2K| Adam | epoch: 027 | loss: 0.44722 - acc: 0.8276 -- iter: 03456/10000
[A[ATraining Step: 4137  | total loss: [1m[32m0.43905[0m[0m | time: 86.267s
[2K| Adam | epoch: 027 | loss: 0.43905 - acc: 0.8308 -- iter: 03520/10000
[A[ATraining Step: 4138  | total loss: [1m[32m0.45771[0m[0m | time: 87.392s
[2K| Adam | epoch: 027 | loss: 0.45771 - acc: 0.8274 -- iter: 03584/10000
[A[ATraining Step: 4139  | total loss: [1m[32m0.46336[0m[0m | time: 88.518s
[2K| Adam | epoch: 027 | loss: 0.46336 - acc: 0.8275 -- iter: 03648/10000
[A[ATraining Step: 4140  | total loss: [1m[32m0.48651[0m[0m | time: 89.682s
[2K| Adam | epoch: 027 | loss: 0.48651 - acc: 0.8260 -- iter: 03712/10000
[A[ATraining Step: 4141  | total loss: [1m[32m0.49977[0m[0m | time: 90.871s
[2K| Adam | epoch: 027 | loss: 0.49977 - acc: 0.8168 -- iter: 03776/10000
[A[ATraining Step: 4142  | total loss: [1m[32m0.50435[0m[0m | time: 92.069s
[2K| Adam | epoch: 027 | loss: 0.50435 - acc: 0.8195 -- iter: 03840/10000
[A[ATraining Step: 4143  | total loss: [1m[32m0.50455[0m[0m | time: 93.273s
[2K| Adam | epoch: 027 | loss: 0.50455 - acc: 0.8110 -- iter: 03904/10000
[A[ATraining Step: 4144  | total loss: [1m[32m0.50161[0m[0m | time: 94.549s
[2K| Adam | epoch: 027 | loss: 0.50161 - acc: 0.8127 -- iter: 03968/10000
[A[ATraining Step: 4145  | total loss: [1m[32m0.50920[0m[0m | time: 95.902s
[2K| Adam | epoch: 027 | loss: 0.50920 - acc: 0.8127 -- iter: 04032/10000
[A[ATraining Step: 4146  | total loss: [1m[32m0.51611[0m[0m | time: 97.460s
[2K| Adam | epoch: 027 | loss: 0.51611 - acc: 0.8096 -- iter: 04096/10000
[A[ATraining Step: 4147  | total loss: [1m[32m0.51868[0m[0m | time: 98.934s
[2K| Adam | epoch: 027 | loss: 0.51868 - acc: 0.8083 -- iter: 04160/10000
[A[ATraining Step: 4148  | total loss: [1m[32m0.51847[0m[0m | time: 100.481s
[2K| Adam | epoch: 027 | loss: 0.51847 - acc: 0.8087 -- iter: 04224/10000
[A[ATraining Step: 4149  | total loss: [1m[32m0.51265[0m[0m | time: 101.816s
[2K| Adam | epoch: 027 | loss: 0.51265 - acc: 0.8091 -- iter: 04288/10000
[A[ATraining Step: 4150  | total loss: [1m[32m0.50912[0m[0m | time: 103.023s
[2K| Adam | epoch: 027 | loss: 0.50912 - acc: 0.8063 -- iter: 04352/10000
[A[ATraining Step: 4151  | total loss: [1m[32m0.49684[0m[0m | time: 104.210s
[2K| Adam | epoch: 027 | loss: 0.49684 - acc: 0.8116 -- iter: 04416/10000
[A[ATraining Step: 4152  | total loss: [1m[32m0.52200[0m[0m | time: 105.394s
[2K| Adam | epoch: 027 | loss: 0.52200 - acc: 0.8101 -- iter: 04480/10000
[A[ATraining Step: 4153  | total loss: [1m[32m0.50883[0m[0m | time: 106.507s
[2K| Adam | epoch: 027 | loss: 0.50883 - acc: 0.8151 -- iter: 04544/10000
[A[ATraining Step: 4154  | total loss: [1m[32m0.50983[0m[0m | time: 107.563s
[2K| Adam | epoch: 027 | loss: 0.50983 - acc: 0.8148 -- iter: 04608/10000
[A[ATraining Step: 4155  | total loss: [1m[32m0.49592[0m[0m | time: 108.529s
[2K| Adam | epoch: 027 | loss: 0.49592 - acc: 0.8224 -- iter: 04672/10000
[A[ATraining Step: 4156  | total loss: [1m[32m0.51320[0m[0m | time: 109.604s
[2K| Adam | epoch: 027 | loss: 0.51320 - acc: 0.8167 -- iter: 04736/10000
[A[ATraining Step: 4157  | total loss: [1m[32m0.50481[0m[0m | time: 110.664s
[2K| Adam | epoch: 027 | loss: 0.50481 - acc: 0.8163 -- iter: 04800/10000
[A[ATraining Step: 4158  | total loss: [1m[32m0.51079[0m[0m | time: 111.746s
[2K| Adam | epoch: 027 | loss: 0.51079 - acc: 0.8143 -- iter: 04864/10000
[A[ATraining Step: 4159  | total loss: [1m[32m0.51677[0m[0m | time: 112.850s
[2K| Adam | epoch: 027 | loss: 0.51677 - acc: 0.8157 -- iter: 04928/10000
[A[ATraining Step: 4160  | total loss: [1m[32m0.50307[0m[0m | time: 113.970s
[2K| Adam | epoch: 027 | loss: 0.50307 - acc: 0.8232 -- iter: 04992/10000
[A[ATraining Step: 4161  | total loss: [1m[32m0.49490[0m[0m | time: 115.118s
[2K| Adam | epoch: 027 | loss: 0.49490 - acc: 0.8284 -- iter: 05056/10000
[A[ATraining Step: 4162  | total loss: [1m[32m0.49055[0m[0m | time: 116.214s
[2K| Adam | epoch: 027 | loss: 0.49055 - acc: 0.8299 -- iter: 05120/10000
[A[ATraining Step: 4163  | total loss: [1m[32m0.50593[0m[0m | time: 117.296s
[2K| Adam | epoch: 027 | loss: 0.50593 - acc: 0.8219 -- iter: 05184/10000
[A[ATraining Step: 4164  | total loss: [1m[32m0.52655[0m[0m | time: 118.439s
[2K| Adam | epoch: 027 | loss: 0.52655 - acc: 0.8163 -- iter: 05248/10000
[A[ATraining Step: 4165  | total loss: [1m[32m0.51701[0m[0m | time: 119.653s
[2K| Adam | epoch: 027 | loss: 0.51701 - acc: 0.8175 -- iter: 05312/10000
[A[ATraining Step: 4166  | total loss: [1m[32m0.50805[0m[0m | time: 120.832s
[2K| Adam | epoch: 027 | loss: 0.50805 - acc: 0.8170 -- iter: 05376/10000
[A[ATraining Step: 4167  | total loss: [1m[32m0.49992[0m[0m | time: 121.998s
[2K| Adam | epoch: 027 | loss: 0.49992 - acc: 0.8197 -- iter: 05440/10000
[A[ATraining Step: 4168  | total loss: [1m[32m0.49776[0m[0m | time: 123.189s
[2K| Adam | epoch: 027 | loss: 0.49776 - acc: 0.8221 -- iter: 05504/10000
[A[ATraining Step: 4169  | total loss: [1m[32m0.50469[0m[0m | time: 124.215s
[2K| Adam | epoch: 027 | loss: 0.50469 - acc: 0.8164 -- iter: 05568/10000
[A[ATraining Step: 4170  | total loss: [1m[32m0.48296[0m[0m | time: 125.199s
[2K| Adam | epoch: 027 | loss: 0.48296 - acc: 0.8238 -- iter: 05632/10000
[A[ATraining Step: 4171  | total loss: [1m[32m0.48226[0m[0m | time: 126.172s
[2K| Adam | epoch: 027 | loss: 0.48226 - acc: 0.8227 -- iter: 05696/10000
[A[ATraining Step: 4172  | total loss: [1m[32m0.49645[0m[0m | time: 127.148s
[2K| Adam | epoch: 027 | loss: 0.49645 - acc: 0.8201 -- iter: 05760/10000
[A[ATraining Step: 4173  | total loss: [1m[32m0.48929[0m[0m | time: 128.119s
[2K| Adam | epoch: 027 | loss: 0.48929 - acc: 0.8194 -- iter: 05824/10000
[A[ATraining Step: 4174  | total loss: [1m[32m0.50174[0m[0m | time: 129.093s
[2K| Adam | epoch: 027 | loss: 0.50174 - acc: 0.8109 -- iter: 05888/10000
[A[ATraining Step: 4175  | total loss: [1m[32m0.50176[0m[0m | time: 130.133s
[2K| Adam | epoch: 027 | loss: 0.50176 - acc: 0.8126 -- iter: 05952/10000
[A[ATraining Step: 4176  | total loss: [1m[32m0.48158[0m[0m | time: 131.158s
[2K| Adam | epoch: 027 | loss: 0.48158 - acc: 0.8220 -- iter: 06016/10000
[A[ATraining Step: 4177  | total loss: [1m[32m0.48831[0m[0m | time: 132.180s
[2K| Adam | epoch: 027 | loss: 0.48831 - acc: 0.8148 -- iter: 06080/10000
[A[ATraining Step: 4178  | total loss: [1m[32m0.47533[0m[0m | time: 133.206s
[2K| Adam | epoch: 027 | loss: 0.47533 - acc: 0.8177 -- iter: 06144/10000
[A[ATraining Step: 4179  | total loss: [1m[32m0.46220[0m[0m | time: 134.229s
[2K| Adam | epoch: 027 | loss: 0.46220 - acc: 0.8171 -- iter: 06208/10000
[A[ATraining Step: 4180  | total loss: [1m[32m0.44951[0m[0m | time: 135.255s
[2K| Adam | epoch: 027 | loss: 0.44951 - acc: 0.8229 -- iter: 06272/10000
[A[ATraining Step: 4181  | total loss: [1m[32m0.44219[0m[0m | time: 136.281s
[2K| Adam | epoch: 027 | loss: 0.44219 - acc: 0.8219 -- iter: 06336/10000
[A[ATraining Step: 4182  | total loss: [1m[32m0.42766[0m[0m | time: 137.308s
[2K| Adam | epoch: 027 | loss: 0.42766 - acc: 0.8272 -- iter: 06400/10000
[A[ATraining Step: 4183  | total loss: [1m[32m0.41578[0m[0m | time: 138.332s
[2K| Adam | epoch: 027 | loss: 0.41578 - acc: 0.8273 -- iter: 06464/10000
[A[ATraining Step: 4184  | total loss: [1m[32m0.42077[0m[0m | time: 139.408s
[2K| Adam | epoch: 027 | loss: 0.42077 - acc: 0.8211 -- iter: 06528/10000
[A[ATraining Step: 4185  | total loss: [1m[32m0.45508[0m[0m | time: 140.454s
[2K| Adam | epoch: 027 | loss: 0.45508 - acc: 0.8156 -- iter: 06592/10000
[A[ATraining Step: 4186  | total loss: [1m[32m0.46805[0m[0m | time: 141.477s
[2K| Adam | epoch: 027 | loss: 0.46805 - acc: 0.8106 -- iter: 06656/10000
[A[ATraining Step: 4187  | total loss: [1m[32m0.46633[0m[0m | time: 142.562s
[2K| Adam | epoch: 027 | loss: 0.46633 - acc: 0.8076 -- iter: 06720/10000
[A[ATraining Step: 4188  | total loss: [1m[32m0.46122[0m[0m | time: 143.680s
[2K| Adam | epoch: 027 | loss: 0.46122 - acc: 0.8128 -- iter: 06784/10000
[A[ATraining Step: 4189  | total loss: [1m[32m0.45175[0m[0m | time: 144.816s
[2K| Adam | epoch: 027 | loss: 0.45175 - acc: 0.8175 -- iter: 06848/10000
[A[ATraining Step: 4190  | total loss: [1m[32m0.45099[0m[0m | time: 145.815s
[2K| Adam | epoch: 027 | loss: 0.45099 - acc: 0.8232 -- iter: 06912/10000
[A[ATraining Step: 4191  | total loss: [1m[32m0.45275[0m[0m | time: 146.784s
[2K| Adam | epoch: 027 | loss: 0.45275 - acc: 0.8268 -- iter: 06976/10000
[A[ATraining Step: 4192  | total loss: [1m[32m0.44847[0m[0m | time: 147.746s
[2K| Adam | epoch: 027 | loss: 0.44847 - acc: 0.8317 -- iter: 07040/10000
[A[ATraining Step: 4193  | total loss: [1m[32m0.50235[0m[0m | time: 148.712s
[2K| Adam | epoch: 027 | loss: 0.50235 - acc: 0.8157 -- iter: 07104/10000
[A[ATraining Step: 4194  | total loss: [1m[32m0.50239[0m[0m | time: 149.731s
[2K| Adam | epoch: 027 | loss: 0.50239 - acc: 0.8169 -- iter: 07168/10000
[A[ATraining Step: 4195  | total loss: [1m[32m0.50161[0m[0m | time: 150.713s
[2K| Adam | epoch: 027 | loss: 0.50161 - acc: 0.8165 -- iter: 07232/10000
[A[ATraining Step: 4196  | total loss: [1m[32m0.50277[0m[0m | time: 151.674s
[2K| Adam | epoch: 027 | loss: 0.50277 - acc: 0.8130 -- iter: 07296/10000
[A[ATraining Step: 4197  | total loss: [1m[32m0.52117[0m[0m | time: 152.644s
[2K| Adam | epoch: 027 | loss: 0.52117 - acc: 0.8082 -- iter: 07360/10000
[A[ATraining Step: 4198  | total loss: [1m[32m0.50052[0m[0m | time: 153.607s
[2K| Adam | epoch: 027 | loss: 0.50052 - acc: 0.8149 -- iter: 07424/10000
[A[ATraining Step: 4199  | total loss: [1m[32m0.48580[0m[0m | time: 154.567s
[2K| Adam | epoch: 027 | loss: 0.48580 - acc: 0.8162 -- iter: 07488/10000
[A[ATraining Step: 4200  | total loss: [1m[32m0.50537[0m[0m | time: 158.164s
[2K| Adam | epoch: 027 | loss: 0.50537 - acc: 0.8112 | val_loss: 3.33880 - val_acc: 0.3686 -- iter: 07552/10000
--
Training Step: 4201  | total loss: [1m[32m0.50526[0m[0m | time: 159.162s
[2K| Adam | epoch: 027 | loss: 0.50526 - acc: 0.8097 -- iter: 07616/10000
[A[ATraining Step: 4202  | total loss: [1m[32m0.50482[0m[0m | time: 160.221s
[2K| Adam | epoch: 027 | loss: 0.50482 - acc: 0.8116 -- iter: 07680/10000
[A[ATraining Step: 4203  | total loss: [1m[32m0.48612[0m[0m | time: 161.247s
[2K| Adam | epoch: 027 | loss: 0.48612 - acc: 0.8195 -- iter: 07744/10000
[A[ATraining Step: 4204  | total loss: [1m[32m0.50532[0m[0m | time: 162.273s
[2K| Adam | epoch: 027 | loss: 0.50532 - acc: 0.8141 -- iter: 07808/10000
[A[ATraining Step: 4205  | total loss: [1m[32m0.51724[0m[0m | time: 163.305s
[2K| Adam | epoch: 027 | loss: 0.51724 - acc: 0.8061 -- iter: 07872/10000
[A[ATraining Step: 4206  | total loss: [1m[32m0.52473[0m[0m | time: 164.321s
[2K| Adam | epoch: 027 | loss: 0.52473 - acc: 0.8083 -- iter: 07936/10000
[A[ATraining Step: 4207  | total loss: [1m[32m0.54003[0m[0m | time: 165.341s
[2K| Adam | epoch: 027 | loss: 0.54003 - acc: 0.8056 -- iter: 08000/10000
[A[ATraining Step: 4208  | total loss: [1m[32m0.54067[0m[0m | time: 166.465s
[2K| Adam | epoch: 027 | loss: 0.54067 - acc: 0.8110 -- iter: 08064/10000
[A[ATraining Step: 4209  | total loss: [1m[32m0.52835[0m[0m | time: 167.592s
[2K| Adam | epoch: 027 | loss: 0.52835 - acc: 0.8096 -- iter: 08128/10000
[A[ATraining Step: 4210  | total loss: [1m[32m0.52117[0m[0m | time: 168.712s
[2K| Adam | epoch: 027 | loss: 0.52117 - acc: 0.8067 -- iter: 08192/10000
[A[ATraining Step: 4211  | total loss: [1m[32m0.51251[0m[0m | time: 169.820s
[2K| Adam | epoch: 027 | loss: 0.51251 - acc: 0.8073 -- iter: 08256/10000
[A[ATraining Step: 4212  | total loss: [1m[32m0.51628[0m[0m | time: 170.883s
[2K| Adam | epoch: 027 | loss: 0.51628 - acc: 0.8016 -- iter: 08320/10000
[A[ATraining Step: 4213  | total loss: [1m[32m0.50299[0m[0m | time: 171.863s
[2K| Adam | epoch: 027 | loss: 0.50299 - acc: 0.8121 -- iter: 08384/10000
[A[ATraining Step: 4214  | total loss: [1m[32m0.50538[0m[0m | time: 172.833s
[2K| Adam | epoch: 027 | loss: 0.50538 - acc: 0.8121 -- iter: 08448/10000
[A[ATraining Step: 4215  | total loss: [1m[32m0.50282[0m[0m | time: 173.810s
[2K| Adam | epoch: 027 | loss: 0.50282 - acc: 0.8075 -- iter: 08512/10000
[A[ATraining Step: 4216  | total loss: [1m[32m0.50263[0m[0m | time: 174.791s
[2K| Adam | epoch: 027 | loss: 0.50263 - acc: 0.8048 -- iter: 08576/10000
[A[ATraining Step: 4217  | total loss: [1m[32m0.50212[0m[0m | time: 175.763s
[2K| Adam | epoch: 027 | loss: 0.50212 - acc: 0.8056 -- iter: 08640/10000
[A[ATraining Step: 4218  | total loss: [1m[32m0.47713[0m[0m | time: 176.731s
[2K| Adam | epoch: 027 | loss: 0.47713 - acc: 0.8141 -- iter: 08704/10000
[A[ATraining Step: 4219  | total loss: [1m[32m0.48324[0m[0m | time: 177.684s
[2K| Adam | epoch: 027 | loss: 0.48324 - acc: 0.8077 -- iter: 08768/10000
[A[ATraining Step: 4220  | total loss: [1m[32m0.48095[0m[0m | time: 178.707s
[2K| Adam | epoch: 027 | loss: 0.48095 - acc: 0.8082 -- iter: 08832/10000
[A[ATraining Step: 4221  | total loss: [1m[32m0.49127[0m[0m | time: 179.784s
[2K| Adam | epoch: 027 | loss: 0.49127 - acc: 0.8086 -- iter: 08896/10000
[A[ATraining Step: 4222  | total loss: [1m[32m0.49491[0m[0m | time: 180.769s
[2K| Adam | epoch: 027 | loss: 0.49491 - acc: 0.8012 -- iter: 08960/10000
[A[ATraining Step: 4223  | total loss: [1m[32m0.49978[0m[0m | time: 181.802s
[2K| Adam | epoch: 027 | loss: 0.49978 - acc: 0.8054 -- iter: 09024/10000
[A[ATraining Step: 4224  | total loss: [1m[32m0.51700[0m[0m | time: 182.822s
[2K| Adam | epoch: 027 | loss: 0.51700 - acc: 0.8030 -- iter: 09088/10000
[A[ATraining Step: 4225  | total loss: [1m[32m0.50285[0m[0m | time: 183.854s
[2K| Adam | epoch: 027 | loss: 0.50285 - acc: 0.8118 -- iter: 09152/10000
[A[ATraining Step: 4226  | total loss: [1m[32m0.50424[0m[0m | time: 184.880s
[2K| Adam | epoch: 027 | loss: 0.50424 - acc: 0.8087 -- iter: 09216/10000
[A[ATraining Step: 4227  | total loss: [1m[32m0.49873[0m[0m | time: 185.876s
[2K| Adam | epoch: 027 | loss: 0.49873 - acc: 0.8138 -- iter: 09280/10000
[A[ATraining Step: 4228  | total loss: [1m[32m0.49744[0m[0m | time: 186.900s
[2K| Adam | epoch: 027 | loss: 0.49744 - acc: 0.8168 -- iter: 09344/10000
[A[ATraining Step: 4229  | total loss: [1m[32m0.50908[0m[0m | time: 187.950s
[2K| Adam | epoch: 027 | loss: 0.50908 - acc: 0.8085 -- iter: 09408/10000
[A[ATraining Step: 4230  | total loss: [1m[32m0.49902[0m[0m | time: 189.068s
[2K| Adam | epoch: 027 | loss: 0.49902 - acc: 0.8136 -- iter: 09472/10000
[A[ATraining Step: 4231  | total loss: [1m[32m0.48669[0m[0m | time: 190.207s
[2K| Adam | epoch: 027 | loss: 0.48669 - acc: 0.8198 -- iter: 09536/10000
[A[ATraining Step: 4232  | total loss: [1m[32m0.47050[0m[0m | time: 191.257s
[2K| Adam | epoch: 027 | loss: 0.47050 - acc: 0.8206 -- iter: 09600/10000
[A[ATraining Step: 4233  | total loss: [1m[32m0.46751[0m[0m | time: 192.248s
[2K| Adam | epoch: 027 | loss: 0.46751 - acc: 0.8198 -- iter: 09664/10000
[A[ATraining Step: 4234  | total loss: [1m[32m1.36245[0m[0m | time: 193.220s
[2K| Adam | epoch: 027 | loss: 1.36245 - acc: 0.7534 -- iter: 09728/10000
[A[ATraining Step: 4235  | total loss: [1m[32m1.27999[0m[0m | time: 194.204s
[2K| Adam | epoch: 027 | loss: 1.27999 - acc: 0.7578 -- iter: 09792/10000
[A[ATraining Step: 4236  | total loss: [1m[32m1.20409[0m[0m | time: 195.178s
[2K| Adam | epoch: 027 | loss: 1.20409 - acc: 0.7695 -- iter: 09856/10000
[A[ATraining Step: 4237  | total loss: [1m[32m1.15138[0m[0m | time: 196.145s
[2K| Adam | epoch: 027 | loss: 1.15138 - acc: 0.7691 -- iter: 09920/10000
[A[ATraining Step: 4238  | total loss: [1m[32m1.08090[0m[0m | time: 197.115s
[2K| Adam | epoch: 027 | loss: 1.08090 - acc: 0.7750 -- iter: 09984/10000
[A[ATraining Step: 4239  | total loss: [1m[32m1.00897[0m[0m | time: 200.862s
[2K| Adam | epoch: 027 | loss: 1.00897 - acc: 0.7819 | val_loss: 3.22725 - val_acc: 0.3314 -- iter: 10000/10000
--
Training Step: 4240  | total loss: [1m[32m0.95640[0m[0m | time: 1.114s
[2K| Adam | epoch: 028 | loss: 0.95640 - acc: 0.7771 -- iter: 00064/10000
[A[ATraining Step: 4241  | total loss: [1m[32m0.91373[0m[0m | time: 2.250s
[2K| Adam | epoch: 028 | loss: 0.91373 - acc: 0.7775 -- iter: 00128/10000
[A[ATraining Step: 4242  | total loss: [1m[32m0.87389[0m[0m | time: 3.382s
[2K| Adam | epoch: 028 | loss: 0.87389 - acc: 0.7748 -- iter: 00192/10000
[A[ATraining Step: 4243  | total loss: [1m[32m0.83976[0m[0m | time: 4.373s
[2K| Adam | epoch: 028 | loss: 0.83976 - acc: 0.7739 -- iter: 00256/10000
[A[ATraining Step: 4244  | total loss: [1m[32m0.82889[0m[0m | time: 5.356s
[2K| Adam | epoch: 028 | loss: 0.82889 - acc: 0.7746 -- iter: 00320/10000
[A[ATraining Step: 4245  | total loss: [1m[32m0.79026[0m[0m | time: 6.327s
[2K| Adam | epoch: 028 | loss: 0.79026 - acc: 0.7862 -- iter: 00384/10000
[A[ATraining Step: 4246  | total loss: [1m[32m0.75140[0m[0m | time: 7.301s
[2K| Adam | epoch: 028 | loss: 0.75140 - acc: 0.7935 -- iter: 00448/10000
[A[ATraining Step: 4247  | total loss: [1m[32m0.72148[0m[0m | time: 8.289s
[2K| Adam | epoch: 028 | loss: 0.72148 - acc: 0.7970 -- iter: 00512/10000
[A[ATraining Step: 4248  | total loss: [1m[32m0.69030[0m[0m | time: 9.308s
[2K| Adam | epoch: 028 | loss: 0.69030 - acc: 0.7985 -- iter: 00576/10000
[A[ATraining Step: 4249  | total loss: [1m[32m0.67183[0m[0m | time: 10.298s
[2K| Adam | epoch: 028 | loss: 0.67183 - acc: 0.8015 -- iter: 00640/10000
[A[ATraining Step: 4250  | total loss: [1m[32m0.63969[0m[0m | time: 11.268s
[2K| Adam | epoch: 028 | loss: 0.63969 - acc: 0.8089 -- iter: 00704/10000
[A[ATraining Step: 4251  | total loss: [1m[32m0.62751[0m[0m | time: 12.290s
[2K| Adam | epoch: 028 | loss: 0.62751 - acc: 0.8092 -- iter: 00768/10000
[A[ATraining Step: 4252  | total loss: [1m[32m0.60373[0m[0m | time: 13.330s
[2K| Adam | epoch: 028 | loss: 0.60373 - acc: 0.8127 -- iter: 00832/10000
[A[ATraining Step: 4253  | total loss: [1m[32m0.59732[0m[0m | time: 14.418s
[2K| Adam | epoch: 028 | loss: 0.59732 - acc: 0.8111 -- iter: 00896/10000
[A[ATraining Step: 4254  | total loss: [1m[32m0.59721[0m[0m | time: 15.446s
[2K| Adam | epoch: 028 | loss: 0.59721 - acc: 0.7987 -- iter: 00960/10000
[A[ATraining Step: 4255  | total loss: [1m[32m0.57424[0m[0m | time: 16.486s
[2K| Adam | epoch: 028 | loss: 0.57424 - acc: 0.8048 -- iter: 01024/10000
[A[ATraining Step: 4256  | total loss: [1m[32m0.55341[0m[0m | time: 17.518s
[2K| Adam | epoch: 028 | loss: 0.55341 - acc: 0.8149 -- iter: 01088/10000
[A[ATraining Step: 4257  | total loss: [1m[32m0.55173[0m[0m | time: 18.587s
[2K| Adam | epoch: 028 | loss: 0.55173 - acc: 0.8163 -- iter: 01152/10000
[A[ATraining Step: 4258  | total loss: [1m[32m0.53179[0m[0m | time: 19.622s
[2K| Adam | epoch: 028 | loss: 0.53179 - acc: 0.8190 -- iter: 01216/10000
[A[ATraining Step: 4259  | total loss: [1m[32m0.52788[0m[0m | time: 20.694s
[2K| Adam | epoch: 028 | loss: 0.52788 - acc: 0.8137 -- iter: 01280/10000
[A[ATraining Step: 4260  | total loss: [1m[32m0.53460[0m[0m | time: 21.677s
[2K| Adam | epoch: 028 | loss: 0.53460 - acc: 0.8136 -- iter: 01344/10000
[A[ATraining Step: 4261  | total loss: [1m[32m0.53482[0m[0m | time: 22.708s
[2K| Adam | epoch: 028 | loss: 0.53482 - acc: 0.8088 -- iter: 01408/10000
[A[ATraining Step: 4262  | total loss: [1m[32m0.52740[0m[0m | time: 23.771s
[2K| Adam | epoch: 028 | loss: 0.52740 - acc: 0.8107 -- iter: 01472/10000
[A[ATraining Step: 4263  | total loss: [1m[32m0.52154[0m[0m | time: 24.802s
[2K| Adam | epoch: 028 | loss: 0.52154 - acc: 0.8109 -- iter: 01536/10000
[A[ATraining Step: 4264  | total loss: [1m[32m0.50918[0m[0m | time: 25.838s
[2K| Adam | epoch: 028 | loss: 0.50918 - acc: 0.8173 -- iter: 01600/10000
[A[ATraining Step: 4265  | total loss: [1m[32m0.49995[0m[0m | time: 26.318s
[2K| Adam | epoch: 028 | loss: 0.49995 - acc: 0.8168 -- iter: 01664/10000
[A[ATraining Step: 4266  | total loss: [1m[32m0.52381[0m[0m | time: 26.807s
[2K| Adam | epoch: 028 | loss: 0.52381 - acc: 0.8039 -- iter: 01728/10000
[A[ATraining Step: 4267  | total loss: [1m[32m0.53057[0m[0m | time: 27.791s
[2K| Adam | epoch: 028 | loss: 0.53057 - acc: 0.8047 -- iter: 01792/10000
[A[ATraining Step: 4268  | total loss: [1m[32m0.52261[0m[0m | time: 28.855s
[2K| Adam | epoch: 028 | loss: 0.52261 - acc: 0.8086 -- iter: 01856/10000
[A[ATraining Step: 4269  | total loss: [1m[32m0.49959[0m[0m | time: 29.943s
[2K| Adam | epoch: 028 | loss: 0.49959 - acc: 0.8184 -- iter: 01920/10000
[A[ATraining Step: 4270  | total loss: [1m[32m0.51129[0m[0m | time: 31.022s
[2K| Adam | epoch: 028 | loss: 0.51129 - acc: 0.8131 -- iter: 01984/10000
[A[ATraining Step: 4271  | total loss: [1m[32m0.52356[0m[0m | time: 32.167s
[2K| Adam | epoch: 028 | loss: 0.52356 - acc: 0.8084 -- iter: 02048/10000
[A[ATraining Step: 4272  | total loss: [1m[32m0.51123[0m[0m | time: 33.262s
[2K| Adam | epoch: 028 | loss: 0.51123 - acc: 0.8119 -- iter: 02112/10000
[A[ATraining Step: 4273  | total loss: [1m[32m0.49314[0m[0m | time: 34.404s
[2K| Adam | epoch: 028 | loss: 0.49314 - acc: 0.8182 -- iter: 02176/10000
[A[ATraining Step: 4274  | total loss: [1m[32m0.49128[0m[0m | time: 35.567s
[2K| Adam | epoch: 028 | loss: 0.49128 - acc: 0.8192 -- iter: 02240/10000
[A[ATraining Step: 4275  | total loss: [1m[32m0.48735[0m[0m | time: 36.646s
[2K| Adam | epoch: 028 | loss: 0.48735 - acc: 0.8139 -- iter: 02304/10000
[A[ATraining Step: 4276  | total loss: [1m[32m0.50344[0m[0m | time: 37.726s
[2K| Adam | epoch: 028 | loss: 0.50344 - acc: 0.8059 -- iter: 02368/10000
[A[ATraining Step: 4277  | total loss: [1m[32m0.51111[0m[0m | time: 38.792s
[2K| Adam | epoch: 028 | loss: 0.51111 - acc: 0.8003 -- iter: 02432/10000
[A[ATraining Step: 4278  | total loss: [1m[32m0.49084[0m[0m | time: 39.808s
[2K| Adam | epoch: 028 | loss: 0.49084 - acc: 0.8078 -- iter: 02496/10000
[A[ATraining Step: 4279  | total loss: [1m[32m0.49035[0m[0m | time: 40.822s
[2K| Adam | epoch: 028 | loss: 0.49035 - acc: 0.8114 -- iter: 02560/10000
[A[ATraining Step: 4280  | total loss: [1m[32m0.47511[0m[0m | time: 41.848s
[2K| Adam | epoch: 028 | loss: 0.47511 - acc: 0.8131 -- iter: 02624/10000
[A[ATraining Step: 4281  | total loss: [1m[32m0.48158[0m[0m | time: 42.866s
[2K| Adam | epoch: 028 | loss: 0.48158 - acc: 0.8052 -- iter: 02688/10000
[A[ATraining Step: 4282  | total loss: [1m[32m0.47432[0m[0m | time: 43.881s
[2K| Adam | epoch: 028 | loss: 0.47432 - acc: 0.8090 -- iter: 02752/10000
[A[ATraining Step: 4283  | total loss: [1m[32m0.48490[0m[0m | time: 44.912s
[2K| Adam | epoch: 028 | loss: 0.48490 - acc: 0.8031 -- iter: 02816/10000
[A[ATraining Step: 4284  | total loss: [1m[32m0.47067[0m[0m | time: 45.936s
[2K| Adam | epoch: 028 | loss: 0.47067 - acc: 0.8119 -- iter: 02880/10000
[A[ATraining Step: 4285  | total loss: [1m[32m0.44890[0m[0m | time: 46.995s
[2K| Adam | epoch: 028 | loss: 0.44890 - acc: 0.8244 -- iter: 02944/10000
[A[ATraining Step: 4286  | total loss: [1m[32m0.45447[0m[0m | time: 48.124s
[2K| Adam | epoch: 028 | loss: 0.45447 - acc: 0.8233 -- iter: 03008/10000
[A[ATraining Step: 4287  | total loss: [1m[32m0.44320[0m[0m | time: 49.177s
[2K| Adam | epoch: 028 | loss: 0.44320 - acc: 0.8316 -- iter: 03072/10000
[A[ATraining Step: 4288  | total loss: [1m[32m0.45895[0m[0m | time: 50.149s
[2K| Adam | epoch: 028 | loss: 0.45895 - acc: 0.8218 -- iter: 03136/10000
[A[ATraining Step: 4289  | total loss: [1m[32m0.47730[0m[0m | time: 51.135s
[2K| Adam | epoch: 028 | loss: 0.47730 - acc: 0.8162 -- iter: 03200/10000
[A[ATraining Step: 4290  | total loss: [1m[32m0.47390[0m[0m | time: 52.103s
[2K| Adam | epoch: 028 | loss: 0.47390 - acc: 0.8174 -- iter: 03264/10000
[A[ATraining Step: 4291  | total loss: [1m[32m0.46612[0m[0m | time: 53.077s
[2K| Adam | epoch: 028 | loss: 0.46612 - acc: 0.8200 -- iter: 03328/10000
[A[ATraining Step: 4292  | total loss: [1m[32m0.45084[0m[0m | time: 54.044s
[2K| Adam | epoch: 028 | loss: 0.45084 - acc: 0.8271 -- iter: 03392/10000
[A[ATraining Step: 4293  | total loss: [1m[32m0.45810[0m[0m | time: 55.026s
[2K| Adam | epoch: 028 | loss: 0.45810 - acc: 0.8225 -- iter: 03456/10000
[A[ATraining Step: 4294  | total loss: [1m[32m0.45580[0m[0m | time: 56.080s
[2K| Adam | epoch: 028 | loss: 0.45580 - acc: 0.8246 -- iter: 03520/10000
[A[ATraining Step: 4295  | total loss: [1m[32m0.45228[0m[0m | time: 57.106s
[2K| Adam | epoch: 028 | loss: 0.45228 - acc: 0.8250 -- iter: 03584/10000
[A[ATraining Step: 4296  | total loss: [1m[32m0.47414[0m[0m | time: 58.141s
[2K| Adam | epoch: 028 | loss: 0.47414 - acc: 0.8222 -- iter: 03648/10000
[A[ATraining Step: 4297  | total loss: [1m[32m0.48747[0m[0m | time: 59.211s
[2K| Adam | epoch: 028 | loss: 0.48747 - acc: 0.8165 -- iter: 03712/10000
[A[ATraining Step: 4298  | total loss: [1m[32m0.48455[0m[0m | time: 60.238s
[2K| Adam | epoch: 028 | loss: 0.48455 - acc: 0.8177 -- iter: 03776/10000
[A[ATraining Step: 4299  | total loss: [1m[32m0.49101[0m[0m | time: 61.269s
[2K| Adam | epoch: 028 | loss: 0.49101 - acc: 0.8156 -- iter: 03840/10000
[A[ATraining Step: 4300  | total loss: [1m[32m0.48664[0m[0m | time: 65.423s
[2K| Adam | epoch: 028 | loss: 0.48664 - acc: 0.8153 | val_loss: 3.18841 - val_acc: 0.3586 -- iter: 03904/10000
--
Training Step: 4301  | total loss: [1m[32m0.51015[0m[0m | time: 66.507s
[2K| Adam | epoch: 028 | loss: 0.51015 - acc: 0.8119 -- iter: 03968/10000
[A[ATraining Step: 4302  | total loss: [1m[32m0.51002[0m[0m | time: 67.656s
[2K| Adam | epoch: 028 | loss: 0.51002 - acc: 0.8135 -- iter: 04032/10000
[A[ATraining Step: 4303  | total loss: [1m[32m0.52659[0m[0m | time: 68.746s
[2K| Adam | epoch: 028 | loss: 0.52659 - acc: 0.8103 -- iter: 04096/10000
[A[ATraining Step: 4304  | total loss: [1m[32m0.53131[0m[0m | time: 69.744s
[2K| Adam | epoch: 028 | loss: 0.53131 - acc: 0.8105 -- iter: 04160/10000
[A[ATraining Step: 4305  | total loss: [1m[32m0.52027[0m[0m | time: 70.723s
[2K| Adam | epoch: 028 | loss: 0.52027 - acc: 0.8123 -- iter: 04224/10000
[A[ATraining Step: 4306  | total loss: [1m[32m0.49643[0m[0m | time: 71.708s
[2K| Adam | epoch: 028 | loss: 0.49643 - acc: 0.8154 -- iter: 04288/10000
[A[ATraining Step: 4307  | total loss: [1m[32m0.50190[0m[0m | time: 72.687s
[2K| Adam | epoch: 028 | loss: 0.50190 - acc: 0.8151 -- iter: 04352/10000
[A[ATraining Step: 4308  | total loss: [1m[32m0.50981[0m[0m | time: 73.662s
[2K| Adam | epoch: 028 | loss: 0.50981 - acc: 0.8117 -- iter: 04416/10000
[A[ATraining Step: 4309  | total loss: [1m[32m0.53331[0m[0m | time: 74.661s
[2K| Adam | epoch: 028 | loss: 0.53331 - acc: 0.7993 -- iter: 04480/10000
[A[ATraining Step: 4310  | total loss: [1m[32m0.51555[0m[0m | time: 75.697s
[2K| Adam | epoch: 028 | loss: 0.51555 - acc: 0.8022 -- iter: 04544/10000
[A[ATraining Step: 4311  | total loss: [1m[32m0.52275[0m[0m | time: 76.819s
[2K| Adam | epoch: 028 | loss: 0.52275 - acc: 0.8032 -- iter: 04608/10000
[A[ATraining Step: 4312  | total loss: [1m[32m0.52032[0m[0m | time: 77.947s
[2K| Adam | epoch: 028 | loss: 0.52032 - acc: 0.8057 -- iter: 04672/10000
[A[ATraining Step: 4313  | total loss: [1m[32m0.51309[0m[0m | time: 79.117s
[2K| Adam | epoch: 028 | loss: 0.51309 - acc: 0.8095 -- iter: 04736/10000
[A[ATraining Step: 4314  | total loss: [1m[32m0.51447[0m[0m | time: 80.161s
[2K| Adam | epoch: 028 | loss: 0.51447 - acc: 0.8036 -- iter: 04800/10000
[A[ATraining Step: 4315  | total loss: [1m[32m0.51008[0m[0m | time: 81.133s
[2K| Adam | epoch: 028 | loss: 0.51008 - acc: 0.8029 -- iter: 04864/10000
[A[ATraining Step: 4316  | total loss: [1m[32m0.51090[0m[0m | time: 82.101s
[2K| Adam | epoch: 028 | loss: 0.51090 - acc: 0.8039 -- iter: 04928/10000
[A[ATraining Step: 4317  | total loss: [1m[32m0.52778[0m[0m | time: 83.074s
[2K| Adam | epoch: 028 | loss: 0.52778 - acc: 0.8032 -- iter: 04992/10000
[A[ATraining Step: 4318  | total loss: [1m[32m0.52103[0m[0m | time: 84.040s
[2K| Adam | epoch: 028 | loss: 0.52103 - acc: 0.8103 -- iter: 05056/10000
[A[ATraining Step: 4319  | total loss: [1m[32m0.53471[0m[0m | time: 85.019s
[2K| Adam | epoch: 028 | loss: 0.53471 - acc: 0.8106 -- iter: 05120/10000
[A[ATraining Step: 4320  | total loss: [1m[32m0.51800[0m[0m | time: 86.006s
[2K| Adam | epoch: 028 | loss: 0.51800 - acc: 0.8170 -- iter: 05184/10000
[A[ATraining Step: 4321  | total loss: [1m[32m0.54606[0m[0m | time: 87.008s
[2K| Adam | epoch: 028 | loss: 0.54606 - acc: 0.8087 -- iter: 05248/10000
[A[ATraining Step: 4322  | total loss: [1m[32m0.54456[0m[0m | time: 88.029s
[2K| Adam | epoch: 028 | loss: 0.54456 - acc: 0.8091 -- iter: 05312/10000
[A[ATraining Step: 4323  | total loss: [1m[32m0.54994[0m[0m | time: 89.106s
[2K| Adam | epoch: 028 | loss: 0.54994 - acc: 0.8063 -- iter: 05376/10000
[A[ATraining Step: 4324  | total loss: [1m[32m0.56378[0m[0m | time: 90.126s
[2K| Adam | epoch: 028 | loss: 0.56378 - acc: 0.8054 -- iter: 05440/10000
[A[ATraining Step: 4325  | total loss: [1m[32m0.55556[0m[0m | time: 91.193s
[2K| Adam | epoch: 028 | loss: 0.55556 - acc: 0.8045 -- iter: 05504/10000
[A[ATraining Step: 4326  | total loss: [1m[32m0.54361[0m[0m | time: 92.325s
[2K| Adam | epoch: 028 | loss: 0.54361 - acc: 0.8006 -- iter: 05568/10000
[A[ATraining Step: 4327  | total loss: [1m[32m0.54100[0m[0m | time: 93.458s
[2K| Adam | epoch: 028 | loss: 0.54100 - acc: 0.8065 -- iter: 05632/10000
[A[ATraining Step: 4328  | total loss: [1m[32m0.53300[0m[0m | time: 94.594s
[2K| Adam | epoch: 028 | loss: 0.53300 - acc: 0.8102 -- iter: 05696/10000
[A[ATraining Step: 4329  | total loss: [1m[32m0.51762[0m[0m | time: 95.663s
[2K| Adam | epoch: 028 | loss: 0.51762 - acc: 0.8152 -- iter: 05760/10000
[A[ATraining Step: 4330  | total loss: [1m[32m0.50524[0m[0m | time: 96.632s
[2K| Adam | epoch: 028 | loss: 0.50524 - acc: 0.8149 -- iter: 05824/10000
[A[ATraining Step: 4331  | total loss: [1m[32m0.50201[0m[0m | time: 97.604s
[2K| Adam | epoch: 028 | loss: 0.50201 - acc: 0.8146 -- iter: 05888/10000
[A[ATraining Step: 4332  | total loss: [1m[32m0.50292[0m[0m | time: 98.606s
[2K| Adam | epoch: 028 | loss: 0.50292 - acc: 0.8144 -- iter: 05952/10000
[A[ATraining Step: 4333  | total loss: [1m[32m0.49574[0m[0m | time: 99.574s
[2K| Adam | epoch: 028 | loss: 0.49574 - acc: 0.8142 -- iter: 06016/10000
[A[ATraining Step: 4334  | total loss: [1m[32m0.48625[0m[0m | time: 100.543s
[2K| Adam | epoch: 028 | loss: 0.48625 - acc: 0.8203 -- iter: 06080/10000
[A[ATraining Step: 4335  | total loss: [1m[32m0.47594[0m[0m | time: 101.523s
[2K| Adam | epoch: 028 | loss: 0.47594 - acc: 0.8258 -- iter: 06144/10000
[A[ATraining Step: 4336  | total loss: [1m[32m0.46787[0m[0m | time: 102.515s
[2K| Adam | epoch: 028 | loss: 0.46787 - acc: 0.8307 -- iter: 06208/10000
[A[ATraining Step: 4337  | total loss: [1m[32m0.47223[0m[0m | time: 103.541s
[2K| Adam | epoch: 028 | loss: 0.47223 - acc: 0.8258 -- iter: 06272/10000
[A[ATraining Step: 4338  | total loss: [1m[32m0.46790[0m[0m | time: 104.564s
[2K| Adam | epoch: 028 | loss: 0.46790 - acc: 0.8307 -- iter: 06336/10000
[A[ATraining Step: 4339  | total loss: [1m[32m0.44988[0m[0m | time: 105.609s
[2K| Adam | epoch: 028 | loss: 0.44988 - acc: 0.8414 -- iter: 06400/10000
[A[ATraining Step: 4340  | total loss: [1m[32m0.45274[0m[0m | time: 106.643s
[2K| Adam | epoch: 028 | loss: 0.45274 - acc: 0.8354 -- iter: 06464/10000
[A[ATraining Step: 4341  | total loss: [1m[32m0.43454[0m[0m | time: 107.665s
[2K| Adam | epoch: 028 | loss: 0.43454 - acc: 0.8424 -- iter: 06528/10000
[A[ATraining Step: 4342  | total loss: [1m[32m0.44115[0m[0m | time: 108.711s
[2K| Adam | epoch: 028 | loss: 0.44115 - acc: 0.8363 -- iter: 06592/10000
[A[ATraining Step: 4343  | total loss: [1m[32m0.43993[0m[0m | time: 109.737s
[2K| Adam | epoch: 028 | loss: 0.43993 - acc: 0.8355 -- iter: 06656/10000
[A[ATraining Step: 4344  | total loss: [1m[32m0.43771[0m[0m | time: 110.760s
[2K| Adam | epoch: 028 | loss: 0.43771 - acc: 0.8332 -- iter: 06720/10000
[A[ATraining Step: 4345  | total loss: [1m[32m0.45155[0m[0m | time: 111.850s
[2K| Adam | epoch: 028 | loss: 0.45155 - acc: 0.8249 -- iter: 06784/10000
[A[ATraining Step: 4346  | total loss: [1m[32m0.46551[0m[0m | time: 112.973s
[2K| Adam | epoch: 028 | loss: 0.46551 - acc: 0.8174 -- iter: 06848/10000
[A[ATraining Step: 4347  | total loss: [1m[32m0.46911[0m[0m | time: 114.094s
[2K| Adam | epoch: 028 | loss: 0.46911 - acc: 0.8138 -- iter: 06912/10000
[A[ATraining Step: 4348  | total loss: [1m[32m0.46463[0m[0m | time: 115.239s
[2K| Adam | epoch: 028 | loss: 0.46463 - acc: 0.8199 -- iter: 06976/10000
[A[ATraining Step: 4349  | total loss: [1m[32m0.47069[0m[0m | time: 116.285s
[2K| Adam | epoch: 028 | loss: 0.47069 - acc: 0.8145 -- iter: 07040/10000
[A[ATraining Step: 4350  | total loss: [1m[32m0.47539[0m[0m | time: 117.258s
[2K| Adam | epoch: 028 | loss: 0.47539 - acc: 0.8096 -- iter: 07104/10000
[A[ATraining Step: 4351  | total loss: [1m[32m0.48362[0m[0m | time: 118.259s
[2K| Adam | epoch: 028 | loss: 0.48362 - acc: 0.8161 -- iter: 07168/10000
[A[ATraining Step: 4352  | total loss: [1m[32m0.48466[0m[0m | time: 119.269s
[2K| Adam | epoch: 028 | loss: 0.48466 - acc: 0.8173 -- iter: 07232/10000
[A[ATraining Step: 4353  | total loss: [1m[32m0.49823[0m[0m | time: 120.230s
[2K| Adam | epoch: 028 | loss: 0.49823 - acc: 0.8231 -- iter: 07296/10000
[A[ATraining Step: 4354  | total loss: [1m[32m0.49653[0m[0m | time: 121.188s
[2K| Adam | epoch: 028 | loss: 0.49653 - acc: 0.8267 -- iter: 07360/10000
[A[ATraining Step: 4355  | total loss: [1m[32m0.50285[0m[0m | time: 122.160s
[2K| Adam | epoch: 028 | loss: 0.50285 - acc: 0.8316 -- iter: 07424/10000
[A[ATraining Step: 4356  | total loss: [1m[32m0.50598[0m[0m | time: 123.178s
[2K| Adam | epoch: 028 | loss: 0.50598 - acc: 0.8312 -- iter: 07488/10000
[A[ATraining Step: 4357  | total loss: [1m[32m0.48810[0m[0m | time: 124.198s
[2K| Adam | epoch: 028 | loss: 0.48810 - acc: 0.8387 -- iter: 07552/10000
[A[ATraining Step: 4358  | total loss: [1m[32m0.48038[0m[0m | time: 125.223s
[2K| Adam | epoch: 028 | loss: 0.48038 - acc: 0.8455 -- iter: 07616/10000
[A[ATraining Step: 4359  | total loss: [1m[32m0.47627[0m[0m | time: 126.322s
[2K| Adam | epoch: 028 | loss: 0.47627 - acc: 0.8390 -- iter: 07680/10000
[A[ATraining Step: 4360  | total loss: [1m[32m0.46507[0m[0m | time: 127.367s
[2K| Adam | epoch: 028 | loss: 0.46507 - acc: 0.8395 -- iter: 07744/10000
[A[ATraining Step: 4361  | total loss: [1m[32m0.45550[0m[0m | time: 128.417s
[2K| Adam | epoch: 028 | loss: 0.45550 - acc: 0.8368 -- iter: 07808/10000
[A[ATraining Step: 4362  | total loss: [1m[32m0.44175[0m[0m | time: 129.459s
[2K| Adam | epoch: 028 | loss: 0.44175 - acc: 0.8359 -- iter: 07872/10000
[A[ATraining Step: 4363  | total loss: [1m[32m0.44018[0m[0m | time: 130.492s
[2K| Adam | epoch: 028 | loss: 0.44018 - acc: 0.8289 -- iter: 07936/10000
[A[ATraining Step: 4364  | total loss: [1m[32m0.44531[0m[0m | time: 131.524s
[2K| Adam | epoch: 028 | loss: 0.44531 - acc: 0.8288 -- iter: 08000/10000
[A[ATraining Step: 4365  | total loss: [1m[32m0.45607[0m[0m | time: 132.616s
[2K| Adam | epoch: 028 | loss: 0.45607 - acc: 0.8241 -- iter: 08064/10000
[A[ATraining Step: 4366  | total loss: [1m[32m0.45755[0m[0m | time: 133.695s
[2K| Adam | epoch: 028 | loss: 0.45755 - acc: 0.8292 -- iter: 08128/10000
[A[ATraining Step: 4367  | total loss: [1m[32m0.45247[0m[0m | time: 134.768s
[2K| Adam | epoch: 028 | loss: 0.45247 - acc: 0.8338 -- iter: 08192/10000
[A[ATraining Step: 4368  | total loss: [1m[32m0.45908[0m[0m | time: 135.838s
[2K| Adam | epoch: 028 | loss: 0.45908 - acc: 0.8316 -- iter: 08256/10000
[A[ATraining Step: 4369  | total loss: [1m[32m0.45990[0m[0m | time: 136.920s
[2K| Adam | epoch: 028 | loss: 0.45990 - acc: 0.8344 -- iter: 08320/10000
[A[ATraining Step: 4370  | total loss: [1m[32m0.46665[0m[0m | time: 138.004s
[2K| Adam | epoch: 028 | loss: 0.46665 - acc: 0.8322 -- iter: 08384/10000
[A[ATraining Step: 4371  | total loss: [1m[32m0.49304[0m[0m | time: 139.141s
[2K| Adam | epoch: 028 | loss: 0.49304 - acc: 0.8193 -- iter: 08448/10000
[A[ATraining Step: 4372  | total loss: [1m[32m0.48706[0m[0m | time: 140.229s
[2K| Adam | epoch: 028 | loss: 0.48706 - acc: 0.8217 -- iter: 08512/10000
[A[ATraining Step: 4373  | total loss: [1m[32m0.47593[0m[0m | time: 141.319s
[2K| Adam | epoch: 028 | loss: 0.47593 - acc: 0.8255 -- iter: 08576/10000
[A[ATraining Step: 4374  | total loss: [1m[32m0.46374[0m[0m | time: 142.402s
[2K| Adam | epoch: 028 | loss: 0.46374 - acc: 0.8289 -- iter: 08640/10000
[A[ATraining Step: 4375  | total loss: [1m[32m0.46267[0m[0m | time: 143.480s
[2K| Adam | epoch: 028 | loss: 0.46267 - acc: 0.8210 -- iter: 08704/10000
[A[ATraining Step: 4376  | total loss: [1m[32m0.46913[0m[0m | time: 144.510s
[2K| Adam | epoch: 028 | loss: 0.46913 - acc: 0.8139 -- iter: 08768/10000
[A[ATraining Step: 4377  | total loss: [1m[32m0.46553[0m[0m | time: 145.631s
[2K| Adam | epoch: 028 | loss: 0.46553 - acc: 0.8138 -- iter: 08832/10000
[A[ATraining Step: 4378  | total loss: [1m[32m0.47538[0m[0m | time: 146.756s
[2K| Adam | epoch: 028 | loss: 0.47538 - acc: 0.8058 -- iter: 08896/10000
[A[ATraining Step: 4379  | total loss: [1m[32m0.50069[0m[0m | time: 147.738s
[2K| Adam | epoch: 028 | loss: 0.50069 - acc: 0.7956 -- iter: 08960/10000
[A[ATraining Step: 4380  | total loss: [1m[32m0.48862[0m[0m | time: 148.739s
[2K| Adam | epoch: 028 | loss: 0.48862 - acc: 0.8004 -- iter: 09024/10000
[A[ATraining Step: 4381  | total loss: [1m[32m0.48880[0m[0m | time: 149.708s
[2K| Adam | epoch: 028 | loss: 0.48880 - acc: 0.7985 -- iter: 09088/10000
[A[ATraining Step: 4382  | total loss: [1m[32m0.49379[0m[0m | time: 150.678s
[2K| Adam | epoch: 028 | loss: 0.49379 - acc: 0.8046 -- iter: 09152/10000
[A[ATraining Step: 4383  | total loss: [1m[32m0.48106[0m[0m | time: 151.651s
[2K| Adam | epoch: 028 | loss: 0.48106 - acc: 0.8069 -- iter: 09216/10000
[A[ATraining Step: 4384  | total loss: [1m[32m0.48312[0m[0m | time: 152.623s
[2K| Adam | epoch: 028 | loss: 0.48312 - acc: 0.8106 -- iter: 09280/10000
[A[ATraining Step: 4385  | total loss: [1m[32m0.47027[0m[0m | time: 153.632s
[2K| Adam | epoch: 028 | loss: 0.47027 - acc: 0.8155 -- iter: 09344/10000
[A[ATraining Step: 4386  | total loss: [1m[32m0.47920[0m[0m | time: 154.654s
[2K| Adam | epoch: 028 | loss: 0.47920 - acc: 0.8152 -- iter: 09408/10000
[A[ATraining Step: 4387  | total loss: [1m[32m0.49012[0m[0m | time: 155.672s
[2K| Adam | epoch: 028 | loss: 0.49012 - acc: 0.8227 -- iter: 09472/10000
[A[ATraining Step: 4388  | total loss: [1m[32m0.48829[0m[0m | time: 156.751s
[2K| Adam | epoch: 028 | loss: 0.48829 - acc: 0.8217 -- iter: 09536/10000
[A[ATraining Step: 4389  | total loss: [1m[32m0.47654[0m[0m | time: 157.863s
[2K| Adam | epoch: 028 | loss: 0.47654 - acc: 0.8270 -- iter: 09600/10000
[A[ATraining Step: 4390  | total loss: [1m[32m0.48909[0m[0m | time: 159.016s
[2K| Adam | epoch: 028 | loss: 0.48909 - acc: 0.8225 -- iter: 09664/10000
[A[ATraining Step: 4391  | total loss: [1m[32m0.49218[0m[0m | time: 160.158s
[2K| Adam | epoch: 028 | loss: 0.49218 - acc: 0.8261 -- iter: 09728/10000
[A[ATraining Step: 4392  | total loss: [1m[32m1.51908[0m[0m | time: 161.303s
[2K| Adam | epoch: 028 | loss: 1.51908 - acc: 0.7498 -- iter: 09792/10000
[A[ATraining Step: 4393  | total loss: [1m[32m1.41225[0m[0m | time: 162.309s
[2K| Adam | epoch: 028 | loss: 1.41225 - acc: 0.7529 -- iter: 09856/10000
[A[ATraining Step: 4394  | total loss: [1m[32m1.30581[0m[0m | time: 163.282s
[2K| Adam | epoch: 028 | loss: 1.30581 - acc: 0.7651 -- iter: 09920/10000
[A[ATraining Step: 4395  | total loss: [1m[32m1.24395[0m[0m | time: 164.247s
[2K| Adam | epoch: 028 | loss: 1.24395 - acc: 0.7652 -- iter: 09984/10000
[A[ATraining Step: 4396  | total loss: [1m[32m1.16713[0m[0m | time: 167.748s
[2K| Adam | epoch: 028 | loss: 1.16713 - acc: 0.7715 | val_loss: 3.50397 - val_acc: 0.3357 -- iter: 10000/10000
--
Training Step: 4397  | total loss: [1m[32m1.08940[0m[0m | time: 1.002s
[2K| Adam | epoch: 029 | loss: 1.08940 - acc: 0.7803 -- iter: 00064/10000
[A[ATraining Step: 4398  | total loss: [1m[32m1.03624[0m[0m | time: 2.017s
[2K| Adam | epoch: 029 | loss: 1.03624 - acc: 0.7851 -- iter: 00128/10000
[A[ATraining Step: 4399  | total loss: [1m[32m0.97561[0m[0m | time: 3.068s
[2K| Adam | epoch: 029 | loss: 0.97561 - acc: 0.7878 -- iter: 00192/10000
[A[ATraining Step: 4400  | total loss: [1m[32m0.91063[0m[0m | time: 7.155s
[2K| Adam | epoch: 029 | loss: 0.91063 - acc: 0.7965 | val_loss: 3.40935 - val_acc: 0.3443 -- iter: 00256/10000
--
Training Step: 4401  | total loss: [1m[32m0.86644[0m[0m | time: 8.277s
[2K| Adam | epoch: 029 | loss: 0.86644 - acc: 0.8028 -- iter: 00320/10000
[A[ATraining Step: 4402  | total loss: [1m[32m0.83620[0m[0m | time: 9.430s
[2K| Adam | epoch: 029 | loss: 0.83620 - acc: 0.7991 -- iter: 00384/10000
[A[ATraining Step: 4403  | total loss: [1m[32m0.80690[0m[0m | time: 10.589s
[2K| Adam | epoch: 029 | loss: 0.80690 - acc: 0.7957 -- iter: 00448/10000
[A[ATraining Step: 4404  | total loss: [1m[32m0.76811[0m[0m | time: 11.628s
[2K| Adam | epoch: 029 | loss: 0.76811 - acc: 0.8037 -- iter: 00512/10000
[A[ATraining Step: 4405  | total loss: [1m[32m0.75441[0m[0m | time: 12.605s
[2K| Adam | epoch: 029 | loss: 0.75441 - acc: 0.7999 -- iter: 00576/10000
[A[ATraining Step: 4406  | total loss: [1m[32m0.72576[0m[0m | time: 13.597s
[2K| Adam | epoch: 029 | loss: 0.72576 - acc: 0.8011 -- iter: 00640/10000
[A[ATraining Step: 4407  | total loss: [1m[32m0.70218[0m[0m | time: 14.573s
[2K| Adam | epoch: 029 | loss: 0.70218 - acc: 0.8054 -- iter: 00704/10000
[A[ATraining Step: 4408  | total loss: [1m[32m0.69199[0m[0m | time: 15.544s
[2K| Adam | epoch: 029 | loss: 0.69199 - acc: 0.7967 -- iter: 00768/10000
[A[ATraining Step: 4409  | total loss: [1m[32m0.66225[0m[0m | time: 16.520s
[2K| Adam | epoch: 029 | loss: 0.66225 - acc: 0.8030 -- iter: 00832/10000
[A[ATraining Step: 4410  | total loss: [1m[32m0.64250[0m[0m | time: 17.523s
[2K| Adam | epoch: 029 | loss: 0.64250 - acc: 0.8055 -- iter: 00896/10000
[A[ATraining Step: 4411  | total loss: [1m[32m0.65194[0m[0m | time: 18.549s
[2K| Adam | epoch: 029 | loss: 0.65194 - acc: 0.8062 -- iter: 00960/10000
[A[ATraining Step: 4412  | total loss: [1m[32m0.63871[0m[0m | time: 19.597s
[2K| Adam | epoch: 029 | loss: 0.63871 - acc: 0.8100 -- iter: 01024/10000
[A[ATraining Step: 4413  | total loss: [1m[32m0.61672[0m[0m | time: 20.729s
[2K| Adam | epoch: 029 | loss: 0.61672 - acc: 0.8102 -- iter: 01088/10000
[A[ATraining Step: 4414  | total loss: [1m[32m0.61393[0m[0m | time: 21.821s
[2K| Adam | epoch: 029 | loss: 0.61393 - acc: 0.8042 -- iter: 01152/10000
[A[ATraining Step: 4415  | total loss: [1m[32m0.60327[0m[0m | time: 22.923s
[2K| Adam | epoch: 029 | loss: 0.60327 - acc: 0.8097 -- iter: 01216/10000
[A[ATraining Step: 4416  | total loss: [1m[32m0.59412[0m[0m | time: 24.122s
[2K| Adam | epoch: 029 | loss: 0.59412 - acc: 0.8131 -- iter: 01280/10000
[A[ATraining Step: 4417  | total loss: [1m[32m0.58879[0m[0m | time: 25.298s
[2K| Adam | epoch: 029 | loss: 0.58879 - acc: 0.8115 -- iter: 01344/10000
[A[ATraining Step: 4418  | total loss: [1m[32m0.60070[0m[0m | time: 26.464s
[2K| Adam | epoch: 029 | loss: 0.60070 - acc: 0.8053 -- iter: 01408/10000
[A[ATraining Step: 4419  | total loss: [1m[32m0.57659[0m[0m | time: 27.598s
[2K| Adam | epoch: 029 | loss: 0.57659 - acc: 0.8107 -- iter: 01472/10000
[A[ATraining Step: 4420  | total loss: [1m[32m0.56159[0m[0m | time: 28.741s
[2K| Adam | epoch: 029 | loss: 0.56159 - acc: 0.8172 -- iter: 01536/10000
[A[ATraining Step: 4421  | total loss: [1m[32m0.57357[0m[0m | time: 29.871s
[2K| Adam | epoch: 029 | loss: 0.57357 - acc: 0.8120 -- iter: 01600/10000
[A[ATraining Step: 4422  | total loss: [1m[32m0.55845[0m[0m | time: 30.894s
[2K| Adam | epoch: 029 | loss: 0.55845 - acc: 0.8089 -- iter: 01664/10000
[A[ATraining Step: 4423  | total loss: [1m[32m0.55925[0m[0m | time: 31.346s
[2K| Adam | epoch: 029 | loss: 0.55925 - acc: 0.8109 -- iter: 01728/10000
[A[ATraining Step: 4424  | total loss: [1m[32m0.56777[0m[0m | time: 31.810s
[2K| Adam | epoch: 029 | loss: 0.56777 - acc: 0.7985 -- iter: 01792/10000
[A[ATraining Step: 4425  | total loss: [1m[32m0.58088[0m[0m | time: 32.782s
[2K| Adam | epoch: 029 | loss: 0.58088 - acc: 0.7874 -- iter: 01856/10000
[A[ATraining Step: 4426  | total loss: [1m[32m0.58867[0m[0m | time: 33.781s
[2K| Adam | epoch: 029 | loss: 0.58867 - acc: 0.7868 -- iter: 01920/10000
[A[ATraining Step: 4427  | total loss: [1m[32m0.57631[0m[0m | time: 34.760s
[2K| Adam | epoch: 029 | loss: 0.57631 - acc: 0.7925 -- iter: 01984/10000
[A[ATraining Step: 4428  | total loss: [1m[32m0.59201[0m[0m | time: 35.721s
[2K| Adam | epoch: 029 | loss: 0.59201 - acc: 0.7867 -- iter: 02048/10000
[A[ATraining Step: 4429  | total loss: [1m[32m0.58443[0m[0m | time: 36.729s
[2K| Adam | epoch: 029 | loss: 0.58443 - acc: 0.7924 -- iter: 02112/10000
[A[ATraining Step: 4430  | total loss: [1m[32m0.56141[0m[0m | time: 37.825s
[2K| Adam | epoch: 029 | loss: 0.56141 - acc: 0.8022 -- iter: 02176/10000
[A[ATraining Step: 4431  | total loss: [1m[32m0.56093[0m[0m | time: 38.945s
[2K| Adam | epoch: 029 | loss: 0.56093 - acc: 0.8001 -- iter: 02240/10000
[A[ATraining Step: 4432  | total loss: [1m[32m0.55554[0m[0m | time: 40.074s
[2K| Adam | epoch: 029 | loss: 0.55554 - acc: 0.7982 -- iter: 02304/10000
[A[ATraining Step: 4433  | total loss: [1m[32m0.54656[0m[0m | time: 41.227s
[2K| Adam | epoch: 029 | loss: 0.54656 - acc: 0.8043 -- iter: 02368/10000
[A[ATraining Step: 4434  | total loss: [1m[32m0.53741[0m[0m | time: 42.265s
[2K| Adam | epoch: 029 | loss: 0.53741 - acc: 0.8020 -- iter: 02432/10000
[A[ATraining Step: 4435  | total loss: [1m[32m0.53094[0m[0m | time: 43.247s
[2K| Adam | epoch: 029 | loss: 0.53094 - acc: 0.8046 -- iter: 02496/10000
[A[ATraining Step: 4436  | total loss: [1m[32m0.52976[0m[0m | time: 44.228s
[2K| Adam | epoch: 029 | loss: 0.52976 - acc: 0.7961 -- iter: 02560/10000
[A[ATraining Step: 4437  | total loss: [1m[32m0.51311[0m[0m | time: 45.196s
[2K| Adam | epoch: 029 | loss: 0.51311 - acc: 0.7993 -- iter: 02624/10000
[A[ATraining Step: 4438  | total loss: [1m[32m0.51414[0m[0m | time: 46.167s
[2K| Adam | epoch: 029 | loss: 0.51414 - acc: 0.8006 -- iter: 02688/10000
[A[ATraining Step: 4439  | total loss: [1m[32m0.52087[0m[0m | time: 47.130s
[2K| Adam | epoch: 029 | loss: 0.52087 - acc: 0.7908 -- iter: 02752/10000
[A[ATraining Step: 4440  | total loss: [1m[32m0.51417[0m[0m | time: 48.157s
[2K| Adam | epoch: 029 | loss: 0.51417 - acc: 0.7946 -- iter: 02816/10000
[A[ATraining Step: 4441  | total loss: [1m[32m0.49144[0m[0m | time: 49.210s
[2K| Adam | epoch: 029 | loss: 0.49144 - acc: 0.8073 -- iter: 02880/10000
[A[ATraining Step: 4442  | total loss: [1m[32m0.48811[0m[0m | time: 50.232s
[2K| Adam | epoch: 029 | loss: 0.48811 - acc: 0.8047 -- iter: 02944/10000
[A[ATraining Step: 4443  | total loss: [1m[32m0.46784[0m[0m | time: 51.351s
[2K| Adam | epoch: 029 | loss: 0.46784 - acc: 0.8086 -- iter: 03008/10000
[A[ATraining Step: 4444  | total loss: [1m[32m0.46186[0m[0m | time: 52.396s
[2K| Adam | epoch: 029 | loss: 0.46186 - acc: 0.8137 -- iter: 03072/10000
[A[ATraining Step: 4445  | total loss: [1m[32m0.45670[0m[0m | time: 53.637s
[2K| Adam | epoch: 029 | loss: 0.45670 - acc: 0.8182 -- iter: 03136/10000
[A[ATraining Step: 4446  | total loss: [1m[32m0.45181[0m[0m | time: 54.769s
[2K| Adam | epoch: 029 | loss: 0.45181 - acc: 0.8177 -- iter: 03200/10000
[A[ATraining Step: 4447  | total loss: [1m[32m0.44490[0m[0m | time: 55.923s
[2K| Adam | epoch: 029 | loss: 0.44490 - acc: 0.8234 -- iter: 03264/10000
[A[ATraining Step: 4448  | total loss: [1m[32m0.45672[0m[0m | time: 57.110s
[2K| Adam | epoch: 029 | loss: 0.45672 - acc: 0.8239 -- iter: 03328/10000
[A[ATraining Step: 4449  | total loss: [1m[32m0.45013[0m[0m | time: 58.335s
[2K| Adam | epoch: 029 | loss: 0.45013 - acc: 0.8337 -- iter: 03392/10000
[A[ATraining Step: 4450  | total loss: [1m[32m0.44175[0m[0m | time: 59.484s
[2K| Adam | epoch: 029 | loss: 0.44175 - acc: 0.8394 -- iter: 03456/10000
[A[ATraining Step: 4451  | total loss: [1m[32m0.43773[0m[0m | time: 60.693s
[2K| Adam | epoch: 029 | loss: 0.43773 - acc: 0.8429 -- iter: 03520/10000
[A[ATraining Step: 4452  | total loss: [1m[32m0.45105[0m[0m | time: 61.921s
[2K| Adam | epoch: 029 | loss: 0.45105 - acc: 0.8430 -- iter: 03584/10000
[A[ATraining Step: 4453  | total loss: [1m[32m0.43378[0m[0m | time: 63.177s
[2K| Adam | epoch: 029 | loss: 0.43378 - acc: 0.8493 -- iter: 03648/10000
[A[ATraining Step: 4454  | total loss: [1m[32m0.45198[0m[0m | time: 64.324s
[2K| Adam | epoch: 029 | loss: 0.45198 - acc: 0.8394 -- iter: 03712/10000
[A[ATraining Step: 4455  | total loss: [1m[32m0.45222[0m[0m | time: 65.547s
[2K| Adam | epoch: 029 | loss: 0.45222 - acc: 0.8367 -- iter: 03776/10000
[A[ATraining Step: 4456  | total loss: [1m[32m0.46252[0m[0m | time: 66.762s
[2K| Adam | epoch: 029 | loss: 0.46252 - acc: 0.8312 -- iter: 03840/10000
[A[ATraining Step: 4457  | total loss: [1m[32m0.46625[0m[0m | time: 67.960s
[2K| Adam | epoch: 029 | loss: 0.46625 - acc: 0.8231 -- iter: 03904/10000
[A[ATraining Step: 4458  | total loss: [1m[32m0.46713[0m[0m | time: 69.129s
[2K| Adam | epoch: 029 | loss: 0.46713 - acc: 0.8220 -- iter: 03968/10000
[A[ATraining Step: 4459  | total loss: [1m[32m0.45928[0m[0m | time: 70.312s
[2K| Adam | epoch: 029 | loss: 0.45928 - acc: 0.8179 -- iter: 04032/10000
[A[ATraining Step: 4460  | total loss: [1m[32m0.46579[0m[0m | time: 71.540s
[2K| Adam | epoch: 029 | loss: 0.46579 - acc: 0.8174 -- iter: 04096/10000
[A[ATraining Step: 4461  | total loss: [1m[32m0.45754[0m[0m | time: 72.692s
[2K| Adam | epoch: 029 | loss: 0.45754 - acc: 0.8216 -- iter: 04160/10000
[A[ATraining Step: 4462  | total loss: [1m[32m0.47280[0m[0m | time: 73.829s
[2K| Adam | epoch: 029 | loss: 0.47280 - acc: 0.8254 -- iter: 04224/10000
[A[ATraining Step: 4463  | total loss: [1m[32m0.45728[0m[0m | time: 74.960s
[2K| Adam | epoch: 029 | loss: 0.45728 - acc: 0.8334 -- iter: 04288/10000
[A[ATraining Step: 4464  | total loss: [1m[32m0.45084[0m[0m | time: 75.964s
[2K| Adam | epoch: 029 | loss: 0.45084 - acc: 0.8392 -- iter: 04352/10000
[A[ATraining Step: 4465  | total loss: [1m[32m0.45610[0m[0m | time: 76.927s
[2K| Adam | epoch: 029 | loss: 0.45610 - acc: 0.8427 -- iter: 04416/10000
[A[ATraining Step: 4466  | total loss: [1m[32m0.46950[0m[0m | time: 77.895s
[2K| Adam | epoch: 029 | loss: 0.46950 - acc: 0.8319 -- iter: 04480/10000
[A[ATraining Step: 4467  | total loss: [1m[32m0.46302[0m[0m | time: 78.863s
[2K| Adam | epoch: 029 | loss: 0.46302 - acc: 0.8284 -- iter: 04544/10000
[A[ATraining Step: 4468  | total loss: [1m[32m0.47556[0m[0m | time: 79.841s
[2K| Adam | epoch: 029 | loss: 0.47556 - acc: 0.8237 -- iter: 04608/10000
[A[ATraining Step: 4469  | total loss: [1m[32m0.47105[0m[0m | time: 80.916s
[2K| Adam | epoch: 029 | loss: 0.47105 - acc: 0.8226 -- iter: 04672/10000
[A[ATraining Step: 4470  | total loss: [1m[32m0.46238[0m[0m | time: 81.937s
[2K| Adam | epoch: 029 | loss: 0.46238 - acc: 0.8247 -- iter: 04736/10000
[A[ATraining Step: 4471  | total loss: [1m[32m0.47107[0m[0m | time: 82.973s
[2K| Adam | epoch: 029 | loss: 0.47107 - acc: 0.8188 -- iter: 04800/10000
[A[ATraining Step: 4472  | total loss: [1m[32m0.48753[0m[0m | time: 84.056s
[2K| Adam | epoch: 029 | loss: 0.48753 - acc: 0.8150 -- iter: 04864/10000
[A[ATraining Step: 4473  | total loss: [1m[32m0.50146[0m[0m | time: 85.141s
[2K| Adam | epoch: 029 | loss: 0.50146 - acc: 0.8054 -- iter: 04928/10000
[A[ATraining Step: 4474  | total loss: [1m[32m0.50665[0m[0m | time: 86.254s
[2K| Adam | epoch: 029 | loss: 0.50665 - acc: 0.8045 -- iter: 04992/10000
[A[ATraining Step: 4475  | total loss: [1m[32m0.49959[0m[0m | time: 87.384s
[2K| Adam | epoch: 029 | loss: 0.49959 - acc: 0.8085 -- iter: 05056/10000
[A[ATraining Step: 4476  | total loss: [1m[32m0.49897[0m[0m | time: 88.557s
[2K| Adam | epoch: 029 | loss: 0.49897 - acc: 0.8120 -- iter: 05120/10000
[A[ATraining Step: 4477  | total loss: [1m[32m0.51079[0m[0m | time: 89.732s
[2K| Adam | epoch: 029 | loss: 0.51079 - acc: 0.8136 -- iter: 05184/10000
[A[ATraining Step: 4478  | total loss: [1m[32m0.50429[0m[0m | time: 90.883s
[2K| Adam | epoch: 029 | loss: 0.50429 - acc: 0.8229 -- iter: 05248/10000
[A[ATraining Step: 4479  | total loss: [1m[32m0.50340[0m[0m | time: 92.012s
[2K| Adam | epoch: 029 | loss: 0.50340 - acc: 0.8250 -- iter: 05312/10000
[A[ATraining Step: 4480  | total loss: [1m[32m0.50366[0m[0m | time: 92.987s
[2K| Adam | epoch: 029 | loss: 0.50366 - acc: 0.8268 -- iter: 05376/10000
[A[ATraining Step: 4481  | total loss: [1m[32m0.50640[0m[0m | time: 93.980s
[2K| Adam | epoch: 029 | loss: 0.50640 - acc: 0.8332 -- iter: 05440/10000
[A[ATraining Step: 4482  | total loss: [1m[32m0.49696[0m[0m | time: 94.954s
[2K| Adam | epoch: 029 | loss: 0.49696 - acc: 0.8390 -- iter: 05504/10000
[A[ATraining Step: 4483  | total loss: [1m[32m0.50413[0m[0m | time: 95.939s
[2K| Adam | epoch: 029 | loss: 0.50413 - acc: 0.8269 -- iter: 05568/10000
[A[ATraining Step: 4484  | total loss: [1m[32m0.51291[0m[0m | time: 96.971s
[2K| Adam | epoch: 029 | loss: 0.51291 - acc: 0.8192 -- iter: 05632/10000
[A[ATraining Step: 4485  | total loss: [1m[32m0.50739[0m[0m | time: 97.988s
[2K| Adam | epoch: 029 | loss: 0.50739 - acc: 0.8201 -- iter: 05696/10000
[A[ATraining Step: 4486  | total loss: [1m[32m0.52391[0m[0m | time: 99.015s
[2K| Adam | epoch: 029 | loss: 0.52391 - acc: 0.8116 -- iter: 05760/10000
[A[ATraining Step: 4487  | total loss: [1m[32m0.51807[0m[0m | time: 100.059s
[2K| Adam | epoch: 029 | loss: 0.51807 - acc: 0.8117 -- iter: 05824/10000
[A[ATraining Step: 4488  | total loss: [1m[32m0.51722[0m[0m | time: 101.194s
[2K| Adam | epoch: 029 | loss: 0.51722 - acc: 0.8024 -- iter: 05888/10000
[A[ATraining Step: 4489  | total loss: [1m[32m0.51149[0m[0m | time: 102.268s
[2K| Adam | epoch: 029 | loss: 0.51149 - acc: 0.8034 -- iter: 05952/10000
[A[ATraining Step: 4490  | total loss: [1m[32m0.51551[0m[0m | time: 103.356s
[2K| Adam | epoch: 029 | loss: 0.51551 - acc: 0.7980 -- iter: 06016/10000
[A[ATraining Step: 4491  | total loss: [1m[32m0.48554[0m[0m | time: 104.439s
[2K| Adam | epoch: 029 | loss: 0.48554 - acc: 0.8120 -- iter: 06080/10000
[A[ATraining Step: 4492  | total loss: [1m[32m0.48727[0m[0m | time: 105.519s
[2K| Adam | epoch: 029 | loss: 0.48727 - acc: 0.8152 -- iter: 06144/10000
[A[ATraining Step: 4493  | total loss: [1m[32m0.49139[0m[0m | time: 106.606s
[2K| Adam | epoch: 029 | loss: 0.49139 - acc: 0.8180 -- iter: 06208/10000
[A[ATraining Step: 4494  | total loss: [1m[32m0.49506[0m[0m | time: 107.693s
[2K| Adam | epoch: 029 | loss: 0.49506 - acc: 0.8237 -- iter: 06272/10000
[A[ATraining Step: 4495  | total loss: [1m[32m0.48575[0m[0m | time: 108.776s
[2K| Adam | epoch: 029 | loss: 0.48575 - acc: 0.8351 -- iter: 06336/10000
[A[ATraining Step: 4496  | total loss: [1m[32m0.46927[0m[0m | time: 109.865s
[2K| Adam | epoch: 029 | loss: 0.46927 - acc: 0.8406 -- iter: 06400/10000
[A[ATraining Step: 4497  | total loss: [1m[32m0.45603[0m[0m | time: 111.119s
[2K| Adam | epoch: 029 | loss: 0.45603 - acc: 0.8472 -- iter: 06464/10000
[A[ATraining Step: 4498  | total loss: [1m[32m0.45143[0m[0m | time: 112.216s
[2K| Adam | epoch: 029 | loss: 0.45143 - acc: 0.8437 -- iter: 06528/10000
[A[ATraining Step: 4499  | total loss: [1m[32m0.45454[0m[0m | time: 113.291s
[2K| Adam | epoch: 029 | loss: 0.45454 - acc: 0.8422 -- iter: 06592/10000
[A[ATraining Step: 4500  | total loss: [1m[32m0.45636[0m[0m | time: 117.108s
[2K| Adam | epoch: 029 | loss: 0.45636 - acc: 0.8392 | val_loss: 3.32492 - val_acc: 0.3771 -- iter: 06656/10000
--
Training Step: 4501  | total loss: [1m[32m0.47147[0m[0m | time: 118.148s
[2K| Adam | epoch: 029 | loss: 0.47147 - acc: 0.8225 -- iter: 06720/10000
[A[ATraining Step: 4502  | total loss: [1m[32m0.46998[0m[0m | time: 119.236s
[2K| Adam | epoch: 029 | loss: 0.46998 - acc: 0.8215 -- iter: 06784/10000
[A[ATraining Step: 4503  | total loss: [1m[32m0.46634[0m[0m | time: 120.314s
[2K| Adam | epoch: 029 | loss: 0.46634 - acc: 0.8190 -- iter: 06848/10000
[A[ATraining Step: 4504  | total loss: [1m[32m0.46856[0m[0m | time: 121.516s
[2K| Adam | epoch: 029 | loss: 0.46856 - acc: 0.8152 -- iter: 06912/10000
[A[ATraining Step: 4505  | total loss: [1m[32m0.46867[0m[0m | time: 122.692s
[2K| Adam | epoch: 029 | loss: 0.46867 - acc: 0.8134 -- iter: 06976/10000
[A[ATraining Step: 4506  | total loss: [1m[32m0.49393[0m[0m | time: 123.875s
[2K| Adam | epoch: 029 | loss: 0.49393 - acc: 0.8164 -- iter: 07040/10000
[A[ATraining Step: 4507  | total loss: [1m[32m0.50774[0m[0m | time: 125.006s
[2K| Adam | epoch: 029 | loss: 0.50774 - acc: 0.8176 -- iter: 07104/10000
[A[ATraining Step: 4508  | total loss: [1m[32m0.50763[0m[0m | time: 126.133s
[2K| Adam | epoch: 029 | loss: 0.50763 - acc: 0.8187 -- iter: 07168/10000
[A[ATraining Step: 4509  | total loss: [1m[32m0.49188[0m[0m | time: 127.153s
[2K| Adam | epoch: 029 | loss: 0.49188 - acc: 0.8290 -- iter: 07232/10000
[A[ATraining Step: 4510  | total loss: [1m[32m0.49651[0m[0m | time: 128.122s
[2K| Adam | epoch: 029 | loss: 0.49651 - acc: 0.8258 -- iter: 07296/10000
[A[ATraining Step: 4511  | total loss: [1m[32m0.49076[0m[0m | time: 129.094s
[2K| Adam | epoch: 029 | loss: 0.49076 - acc: 0.8307 -- iter: 07360/10000
[A[ATraining Step: 4512  | total loss: [1m[32m0.47868[0m[0m | time: 130.066s
[2K| Adam | epoch: 029 | loss: 0.47868 - acc: 0.8367 -- iter: 07424/10000
[A[ATraining Step: 4513  | total loss: [1m[32m0.46874[0m[0m | time: 131.088s
[2K| Adam | epoch: 029 | loss: 0.46874 - acc: 0.8405 -- iter: 07488/10000
[A[ATraining Step: 4514  | total loss: [1m[32m0.46270[0m[0m | time: 132.109s
[2K| Adam | epoch: 029 | loss: 0.46270 - acc: 0.8471 -- iter: 07552/10000
[A[ATraining Step: 4515  | total loss: [1m[32m0.45573[0m[0m | time: 133.142s
[2K| Adam | epoch: 029 | loss: 0.45573 - acc: 0.8452 -- iter: 07616/10000
[A[ATraining Step: 4516  | total loss: [1m[32m0.46600[0m[0m | time: 134.174s
[2K| Adam | epoch: 029 | loss: 0.46600 - acc: 0.8388 -- iter: 07680/10000
[A[ATraining Step: 4517  | total loss: [1m[32m0.46952[0m[0m | time: 135.192s
[2K| Adam | epoch: 029 | loss: 0.46952 - acc: 0.8362 -- iter: 07744/10000
[A[ATraining Step: 4518  | total loss: [1m[32m0.47438[0m[0m | time: 136.218s
[2K| Adam | epoch: 029 | loss: 0.47438 - acc: 0.8291 -- iter: 07808/10000
[A[ATraining Step: 4519  | total loss: [1m[32m0.47946[0m[0m | time: 137.300s
[2K| Adam | epoch: 029 | loss: 0.47946 - acc: 0.8259 -- iter: 07872/10000
[A[ATraining Step: 4520  | total loss: [1m[32m0.47418[0m[0m | time: 138.383s
[2K| Adam | epoch: 029 | loss: 0.47418 - acc: 0.8246 -- iter: 07936/10000
[A[ATraining Step: 4521  | total loss: [1m[32m0.47458[0m[0m | time: 139.464s
[2K| Adam | epoch: 029 | loss: 0.47458 - acc: 0.8265 -- iter: 08000/10000
[A[ATraining Step: 4522  | total loss: [1m[32m0.47210[0m[0m | time: 140.581s
[2K| Adam | epoch: 029 | loss: 0.47210 - acc: 0.8282 -- iter: 08064/10000
[A[ATraining Step: 4523  | total loss: [1m[32m0.48009[0m[0m | time: 141.725s
[2K| Adam | epoch: 029 | loss: 0.48009 - acc: 0.8173 -- iter: 08128/10000
[A[ATraining Step: 4524  | total loss: [1m[32m0.49236[0m[0m | time: 142.806s
[2K| Adam | epoch: 029 | loss: 0.49236 - acc: 0.8183 -- iter: 08192/10000
[A[ATraining Step: 4525  | total loss: [1m[32m0.48228[0m[0m | time: 143.898s
[2K| Adam | epoch: 029 | loss: 0.48228 - acc: 0.8256 -- iter: 08256/10000
[A[ATraining Step: 4526  | total loss: [1m[32m0.48978[0m[0m | time: 144.973s
[2K| Adam | epoch: 029 | loss: 0.48978 - acc: 0.8274 -- iter: 08320/10000
[A[ATraining Step: 4527  | total loss: [1m[32m0.48332[0m[0m | time: 146.051s
[2K| Adam | epoch: 029 | loss: 0.48332 - acc: 0.8321 -- iter: 08384/10000
[A[ATraining Step: 4528  | total loss: [1m[32m0.49539[0m[0m | time: 147.129s
[2K| Adam | epoch: 029 | loss: 0.49539 - acc: 0.8333 -- iter: 08448/10000
[A[ATraining Step: 4529  | total loss: [1m[32m0.48301[0m[0m | time: 148.212s
[2K| Adam | epoch: 029 | loss: 0.48301 - acc: 0.8375 -- iter: 08512/10000
[A[ATraining Step: 4530  | total loss: [1m[32m0.47581[0m[0m | time: 149.293s
[2K| Adam | epoch: 029 | loss: 0.47581 - acc: 0.8444 -- iter: 08576/10000
[A[ATraining Step: 4531  | total loss: [1m[32m0.47331[0m[0m | time: 150.372s
[2K| Adam | epoch: 029 | loss: 0.47331 - acc: 0.8396 -- iter: 08640/10000
[A[ATraining Step: 4532  | total loss: [1m[32m0.48172[0m[0m | time: 151.525s
[2K| Adam | epoch: 029 | loss: 0.48172 - acc: 0.8306 -- iter: 08704/10000
[A[ATraining Step: 4533  | total loss: [1m[32m0.48108[0m[0m | time: 152.616s
[2K| Adam | epoch: 029 | loss: 0.48108 - acc: 0.8273 -- iter: 08768/10000
[A[ATraining Step: 4534  | total loss: [1m[32m0.48500[0m[0m | time: 153.711s
[2K| Adam | epoch: 029 | loss: 0.48500 - acc: 0.8211 -- iter: 08832/10000
[A[ATraining Step: 4535  | total loss: [1m[32m0.47308[0m[0m | time: 154.798s
[2K| Adam | epoch: 029 | loss: 0.47308 - acc: 0.8234 -- iter: 08896/10000
[A[ATraining Step: 4536  | total loss: [1m[32m0.48617[0m[0m | time: 155.882s
[2K| Adam | epoch: 029 | loss: 0.48617 - acc: 0.8192 -- iter: 08960/10000
[A[ATraining Step: 4537  | total loss: [1m[32m0.49119[0m[0m | time: 156.982s
[2K| Adam | epoch: 029 | loss: 0.49119 - acc: 0.8185 -- iter: 09024/10000
[A[ATraining Step: 4538  | total loss: [1m[32m0.49026[0m[0m | time: 158.066s
[2K| Adam | epoch: 029 | loss: 0.49026 - acc: 0.8163 -- iter: 09088/10000
[A[ATraining Step: 4539  | total loss: [1m[32m0.48248[0m[0m | time: 159.140s
[2K| Adam | epoch: 029 | loss: 0.48248 - acc: 0.8175 -- iter: 09152/10000
[A[ATraining Step: 4540  | total loss: [1m[32m0.48735[0m[0m | time: 160.225s
[2K| Adam | epoch: 029 | loss: 0.48735 - acc: 0.8123 -- iter: 09216/10000
[A[ATraining Step: 4541  | total loss: [1m[32m0.49501[0m[0m | time: 161.381s
[2K| Adam | epoch: 029 | loss: 0.49501 - acc: 0.8123 -- iter: 09280/10000
[A[ATraining Step: 4542  | total loss: [1m[32m0.49002[0m[0m | time: 162.515s
[2K| Adam | epoch: 029 | loss: 0.49002 - acc: 0.8170 -- iter: 09344/10000
[A[ATraining Step: 4543  | total loss: [1m[32m0.47924[0m[0m | time: 163.646s
[2K| Adam | epoch: 029 | loss: 0.47924 - acc: 0.8150 -- iter: 09408/10000
[A[ATraining Step: 4544  | total loss: [1m[32m0.46924[0m[0m | time: 164.752s
[2K| Adam | epoch: 029 | loss: 0.46924 - acc: 0.8179 -- iter: 09472/10000
[A[ATraining Step: 4545  | total loss: [1m[32m0.46371[0m[0m | time: 165.734s
[2K| Adam | epoch: 029 | loss: 0.46371 - acc: 0.8142 -- iter: 09536/10000
[A[ATraining Step: 4546  | total loss: [1m[32m0.46213[0m[0m | time: 166.702s
[2K| Adam | epoch: 029 | loss: 0.46213 - acc: 0.8172 -- iter: 09600/10000
[A[ATraining Step: 4547  | total loss: [1m[32m0.46080[0m[0m | time: 167.674s
[2K| Adam | epoch: 029 | loss: 0.46080 - acc: 0.8120 -- iter: 09664/10000
[A[ATraining Step: 4548  | total loss: [1m[32m0.47058[0m[0m | time: 168.648s
[2K| Adam | epoch: 029 | loss: 0.47058 - acc: 0.8090 -- iter: 09728/10000
[A[ATraining Step: 4549  | total loss: [1m[32m0.47491[0m[0m | time: 169.638s
[2K| Adam | epoch: 029 | loss: 0.47491 - acc: 0.8124 -- iter: 09792/10000
[A[ATraining Step: 4550  | total loss: [1m[32m1.40045[0m[0m | time: 170.798s
[2K| Adam | epoch: 029 | loss: 1.40045 - acc: 0.7390 -- iter: 09856/10000
[A[ATraining Step: 4551  | total loss: [1m[32m1.31872[0m[0m | time: 171.942s
[2K| Adam | epoch: 029 | loss: 1.31872 - acc: 0.7401 -- iter: 09920/10000
[A[ATraining Step: 4552  | total loss: [1m[32m1.23777[0m[0m | time: 173.058s
[2K| Adam | epoch: 029 | loss: 1.23777 - acc: 0.7442 -- iter: 09984/10000
[A[ATraining Step: 4553  | total loss: [1m[32m1.15603[0m[0m | time: 177.275s
[2K| Adam | epoch: 029 | loss: 1.15603 - acc: 0.7542 | val_loss: 3.00066 - val_acc: 0.3757 -- iter: 10000/10000
--
Training Step: 4554  | total loss: [1m[32m1.10500[0m[0m | time: 1.072s
[2K| Adam | epoch: 030 | loss: 1.10500 - acc: 0.7647 -- iter: 00064/10000
[A[ATraining Step: 4555  | total loss: [1m[32m1.03445[0m[0m | time: 2.092s
[2K| Adam | epoch: 030 | loss: 1.03445 - acc: 0.7726 -- iter: 00128/10000
[A[ATraining Step: 4556  | total loss: [1m[32m0.97165[0m[0m | time: 3.075s
[2K| Adam | epoch: 030 | loss: 0.97165 - acc: 0.7797 -- iter: 00192/10000
[A[ATraining Step: 4557  | total loss: [1m[32m0.90210[0m[0m | time: 4.108s
[2K| Adam | epoch: 030 | loss: 0.90210 - acc: 0.7924 -- iter: 00256/10000
[A[ATraining Step: 4558  | total loss: [1m[32m0.86137[0m[0m | time: 5.084s
[2K| Adam | epoch: 030 | loss: 0.86137 - acc: 0.7928 -- iter: 00320/10000
[A[ATraining Step: 4559  | total loss: [1m[32m0.82425[0m[0m | time: 6.110s
[2K| Adam | epoch: 030 | loss: 0.82425 - acc: 0.7932 -- iter: 00384/10000
[A[ATraining Step: 4560  | total loss: [1m[32m0.78794[0m[0m | time: 7.141s
[2K| Adam | epoch: 030 | loss: 0.78794 - acc: 0.7936 -- iter: 00448/10000
[A[ATraining Step: 4561  | total loss: [1m[32m0.79174[0m[0m | time: 8.160s
[2K| Adam | epoch: 030 | loss: 0.79174 - acc: 0.7814 -- iter: 00512/10000
[A[ATraining Step: 4562  | total loss: [1m[32m0.75104[0m[0m | time: 9.221s
[2K| Adam | epoch: 030 | loss: 0.75104 - acc: 0.7908 -- iter: 00576/10000
[A[ATraining Step: 4563  | total loss: [1m[32m0.71249[0m[0m | time: 10.311s
[2K| Adam | epoch: 030 | loss: 0.71249 - acc: 0.8023 -- iter: 00640/10000
[A[ATraining Step: 4564  | total loss: [1m[32m0.67280[0m[0m | time: 11.396s
[2K| Adam | epoch: 030 | loss: 0.67280 - acc: 0.8080 -- iter: 00704/10000
[A[ATraining Step: 4565  | total loss: [1m[32m0.66494[0m[0m | time: 12.482s
[2K| Adam | epoch: 030 | loss: 0.66494 - acc: 0.8069 -- iter: 00768/10000
[A[ATraining Step: 4566  | total loss: [1m[32m0.63847[0m[0m | time: 13.652s
[2K| Adam | epoch: 030 | loss: 0.63847 - acc: 0.8122 -- iter: 00832/10000
[A[ATraining Step: 4567  | total loss: [1m[32m0.63244[0m[0m | time: 14.728s
[2K| Adam | epoch: 030 | loss: 0.63244 - acc: 0.8044 -- iter: 00896/10000
[A[ATraining Step: 4568  | total loss: [1m[32m0.63139[0m[0m | time: 15.882s
[2K| Adam | epoch: 030 | loss: 0.63139 - acc: 0.7927 -- iter: 00960/10000
[A[ATraining Step: 4569  | total loss: [1m[32m0.60702[0m[0m | time: 17.000s
[2K| Adam | epoch: 030 | loss: 0.60702 - acc: 0.8009 -- iter: 01024/10000
[A[ATraining Step: 4570  | total loss: [1m[32m0.58816[0m[0m | time: 18.082s
[2K| Adam | epoch: 030 | loss: 0.58816 - acc: 0.8052 -- iter: 01088/10000
[A[ATraining Step: 4571  | total loss: [1m[32m0.56178[0m[0m | time: 19.264s
[2K| Adam | epoch: 030 | loss: 0.56178 - acc: 0.8153 -- iter: 01152/10000
[A[ATraining Step: 4572  | total loss: [1m[32m0.57484[0m[0m | time: 20.435s
[2K| Adam | epoch: 030 | loss: 0.57484 - acc: 0.8119 -- iter: 01216/10000
[A[ATraining Step: 4573  | total loss: [1m[32m0.57798[0m[0m | time: 21.625s
[2K| Adam | epoch: 030 | loss: 0.57798 - acc: 0.8057 -- iter: 01280/10000
[A[ATraining Step: 4574  | total loss: [1m[32m0.56679[0m[0m | time: 22.757s
[2K| Adam | epoch: 030 | loss: 0.56679 - acc: 0.8064 -- iter: 01344/10000
[A[ATraining Step: 4575  | total loss: [1m[32m0.55284[0m[0m | time: 23.928s
[2K| Adam | epoch: 030 | loss: 0.55284 - acc: 0.8133 -- iter: 01408/10000
[A[ATraining Step: 4576  | total loss: [1m[32m0.54083[0m[0m | time: 25.063s
[2K| Adam | epoch: 030 | loss: 0.54083 - acc: 0.8163 -- iter: 01472/10000
[A[ATraining Step: 4577  | total loss: [1m[32m0.53236[0m[0m | time: 26.039s
[2K| Adam | epoch: 030 | loss: 0.53236 - acc: 0.8159 -- iter: 01536/10000
[A[ATraining Step: 4578  | total loss: [1m[32m0.52697[0m[0m | time: 27.015s
[2K| Adam | epoch: 030 | loss: 0.52697 - acc: 0.8125 -- iter: 01600/10000
[A[ATraining Step: 4579  | total loss: [1m[32m0.51619[0m[0m | time: 27.982s
[2K| Adam | epoch: 030 | loss: 0.51619 - acc: 0.8187 -- iter: 01664/10000
[A[ATraining Step: 4580  | total loss: [1m[32m0.49801[0m[0m | time: 28.949s
[2K| Adam | epoch: 030 | loss: 0.49801 - acc: 0.8197 -- iter: 01728/10000
[A[ATraining Step: 4581  | total loss: [1m[32m0.49252[0m[0m | time: 29.406s
[2K| Adam | epoch: 030 | loss: 0.49252 - acc: 0.8205 -- iter: 01792/10000
[A[ATraining Step: 4582  | total loss: [1m[32m0.46744[0m[0m | time: 29.885s
[2K| Adam | epoch: 030 | loss: 0.46744 - acc: 0.8322 -- iter: 01856/10000
[A[ATraining Step: 4583  | total loss: [1m[32m0.44783[0m[0m | time: 30.872s
[2K| Adam | epoch: 030 | loss: 0.44783 - acc: 0.8427 -- iter: 01920/10000
[A[ATraining Step: 4584  | total loss: [1m[32m0.45440[0m[0m | time: 31.853s
[2K| Adam | epoch: 030 | loss: 0.45440 - acc: 0.8397 -- iter: 01984/10000
[A[ATraining Step: 4585  | total loss: [1m[32m0.43831[0m[0m | time: 32.905s
[2K| Adam | epoch: 030 | loss: 0.43831 - acc: 0.8432 -- iter: 02048/10000
[A[ATraining Step: 4586  | total loss: [1m[32m0.44217[0m[0m | time: 34.072s
[2K| Adam | epoch: 030 | loss: 0.44217 - acc: 0.8402 -- iter: 02112/10000
[A[ATraining Step: 4587  | total loss: [1m[32m0.45347[0m[0m | time: 35.168s
[2K| Adam | epoch: 030 | loss: 0.45347 - acc: 0.8296 -- iter: 02176/10000
[A[ATraining Step: 4588  | total loss: [1m[32m0.45430[0m[0m | time: 36.301s
[2K| Adam | epoch: 030 | loss: 0.45430 - acc: 0.8310 -- iter: 02240/10000
[A[ATraining Step: 4589  | total loss: [1m[32m0.44340[0m[0m | time: 37.480s
[2K| Adam | epoch: 030 | loss: 0.44340 - acc: 0.8354 -- iter: 02304/10000
[A[ATraining Step: 4590  | total loss: [1m[32m0.45975[0m[0m | time: 38.660s
[2K| Adam | epoch: 030 | loss: 0.45975 - acc: 0.8237 -- iter: 02368/10000
[A[ATraining Step: 4591  | total loss: [1m[32m0.45642[0m[0m | time: 39.816s
[2K| Adam | epoch: 030 | loss: 0.45642 - acc: 0.8273 -- iter: 02432/10000
[A[ATraining Step: 4592  | total loss: [1m[32m0.45398[0m[0m | time: 40.936s
[2K| Adam | epoch: 030 | loss: 0.45398 - acc: 0.8227 -- iter: 02496/10000
[A[ATraining Step: 4593  | total loss: [1m[32m0.44822[0m[0m | time: 42.046s
[2K| Adam | epoch: 030 | loss: 0.44822 - acc: 0.8170 -- iter: 02560/10000
[A[ATraining Step: 4594  | total loss: [1m[32m0.43805[0m[0m | time: 43.026s
[2K| Adam | epoch: 030 | loss: 0.43805 - acc: 0.8228 -- iter: 02624/10000
[A[ATraining Step: 4595  | total loss: [1m[32m0.44835[0m[0m | time: 44.058s
[2K| Adam | epoch: 030 | loss: 0.44835 - acc: 0.8233 -- iter: 02688/10000
[A[ATraining Step: 4596  | total loss: [1m[32m0.45481[0m[0m | time: 45.036s
[2K| Adam | epoch: 030 | loss: 0.45481 - acc: 0.8207 -- iter: 02752/10000
[A[ATraining Step: 4597  | total loss: [1m[32m0.46789[0m[0m | time: 46.016s
[2K| Adam | epoch: 030 | loss: 0.46789 - acc: 0.8074 -- iter: 02816/10000
[A[ATraining Step: 4598  | total loss: [1m[32m0.47492[0m[0m | time: 47.027s
[2K| Adam | epoch: 030 | loss: 0.47492 - acc: 0.8079 -- iter: 02880/10000
[A[ATraining Step: 4599  | total loss: [1m[32m0.48585[0m[0m | time: 48.051s
[2K| Adam | epoch: 030 | loss: 0.48585 - acc: 0.8021 -- iter: 02944/10000
[A[ATraining Step: 4600  | total loss: [1m[32m0.50032[0m[0m | time: 52.103s
[2K| Adam | epoch: 030 | loss: 0.50032 - acc: 0.7984 | val_loss: 2.98605 - val_acc: 0.3957 -- iter: 03008/10000
--
Training Step: 4601  | total loss: [1m[32m0.49087[0m[0m | time: 53.183s
[2K| Adam | epoch: 030 | loss: 0.49087 - acc: 0.7983 -- iter: 03072/10000
[A[ATraining Step: 4602  | total loss: [1m[32m0.48844[0m[0m | time: 54.348s
[2K| Adam | epoch: 030 | loss: 0.48844 - acc: 0.7966 -- iter: 03136/10000
[A[ATraining Step: 4603  | total loss: [1m[32m0.50302[0m[0m | time: 55.485s
[2K| Adam | epoch: 030 | loss: 0.50302 - acc: 0.7935 -- iter: 03200/10000
[A[ATraining Step: 4604  | total loss: [1m[32m0.49311[0m[0m | time: 56.598s
[2K| Adam | epoch: 030 | loss: 0.49311 - acc: 0.8001 -- iter: 03264/10000
[A[ATraining Step: 4605  | total loss: [1m[32m0.50042[0m[0m | time: 57.722s
[2K| Adam | epoch: 030 | loss: 0.50042 - acc: 0.8013 -- iter: 03328/10000
[A[ATraining Step: 4606  | total loss: [1m[32m0.51220[0m[0m | time: 58.838s
[2K| Adam | epoch: 030 | loss: 0.51220 - acc: 0.7962 -- iter: 03392/10000
[A[ATraining Step: 4607  | total loss: [1m[32m0.49554[0m[0m | time: 59.862s
[2K| Adam | epoch: 030 | loss: 0.49554 - acc: 0.8009 -- iter: 03456/10000
[A[ATraining Step: 4608  | total loss: [1m[32m0.48155[0m[0m | time: 60.828s
[2K| Adam | epoch: 030 | loss: 0.48155 - acc: 0.8083 -- iter: 03520/10000
[A[ATraining Step: 4609  | total loss: [1m[32m0.50165[0m[0m | time: 61.823s
[2K| Adam | epoch: 030 | loss: 0.50165 - acc: 0.8009 -- iter: 03584/10000
[A[ATraining Step: 4610  | total loss: [1m[32m0.49546[0m[0m | time: 62.800s
[2K| Adam | epoch: 030 | loss: 0.49546 - acc: 0.8052 -- iter: 03648/10000
[A[ATraining Step: 4611  | total loss: [1m[32m0.48296[0m[0m | time: 63.813s
[2K| Adam | epoch: 030 | loss: 0.48296 - acc: 0.8169 -- iter: 03712/10000
[A[ATraining Step: 4612  | total loss: [1m[32m0.48065[0m[0m | time: 64.834s
[2K| Adam | epoch: 030 | loss: 0.48065 - acc: 0.8211 -- iter: 03776/10000
[A[ATraining Step: 4613  | total loss: [1m[32m0.47147[0m[0m | time: 65.861s
[2K| Adam | epoch: 030 | loss: 0.47147 - acc: 0.8218 -- iter: 03840/10000
[A[ATraining Step: 4614  | total loss: [1m[32m0.47452[0m[0m | time: 66.901s
[2K| Adam | epoch: 030 | loss: 0.47452 - acc: 0.8240 -- iter: 03904/10000
[A[ATraining Step: 4615  | total loss: [1m[32m0.47100[0m[0m | time: 68.040s
[2K| Adam | epoch: 030 | loss: 0.47100 - acc: 0.8260 -- iter: 03968/10000
[A[ATraining Step: 4616  | total loss: [1m[32m0.47809[0m[0m | time: 69.176s
[2K| Adam | epoch: 030 | loss: 0.47809 - acc: 0.8247 -- iter: 04032/10000
[A[ATraining Step: 4617  | total loss: [1m[32m0.46515[0m[0m | time: 70.305s
[2K| Adam | epoch: 030 | loss: 0.46515 - acc: 0.8266 -- iter: 04096/10000
[A[ATraining Step: 4618  | total loss: [1m[32m0.46487[0m[0m | time: 71.426s
[2K| Adam | epoch: 030 | loss: 0.46487 - acc: 0.8220 -- iter: 04160/10000
[A[ATraining Step: 4619  | total loss: [1m[32m0.46877[0m[0m | time: 72.688s
[2K| Adam | epoch: 030 | loss: 0.46877 - acc: 0.8148 -- iter: 04224/10000
[A[ATraining Step: 4620  | total loss: [1m[32m0.46006[0m[0m | time: 73.753s
[2K| Adam | epoch: 030 | loss: 0.46006 - acc: 0.8240 -- iter: 04288/10000
[A[ATraining Step: 4621  | total loss: [1m[32m0.45916[0m[0m | time: 74.726s
[2K| Adam | epoch: 030 | loss: 0.45916 - acc: 0.8244 -- iter: 04352/10000
[A[ATraining Step: 4622  | total loss: [1m[32m0.45504[0m[0m | time: 75.699s
[2K| Adam | epoch: 030 | loss: 0.45504 - acc: 0.8216 -- iter: 04416/10000
[A[ATraining Step: 4623  | total loss: [1m[32m0.46850[0m[0m | time: 76.674s
[2K| Adam | epoch: 030 | loss: 0.46850 - acc: 0.8129 -- iter: 04480/10000
[A[ATraining Step: 4624  | total loss: [1m[32m0.47054[0m[0m | time: 77.654s
[2K| Adam | epoch: 030 | loss: 0.47054 - acc: 0.8160 -- iter: 04544/10000
[A[ATraining Step: 4625  | total loss: [1m[32m0.46733[0m[0m | time: 78.656s
[2K| Adam | epoch: 030 | loss: 0.46733 - acc: 0.8156 -- iter: 04608/10000
[A[ATraining Step: 4626  | total loss: [1m[32m0.45724[0m[0m | time: 79.681s
[2K| Adam | epoch: 030 | loss: 0.45724 - acc: 0.8138 -- iter: 04672/10000
[A[ATraining Step: 4627  | total loss: [1m[32m0.45938[0m[0m | time: 80.709s
[2K| Adam | epoch: 030 | loss: 0.45938 - acc: 0.8121 -- iter: 04736/10000
[A[ATraining Step: 4628  | total loss: [1m[32m0.45090[0m[0m | time: 81.754s
[2K| Adam | epoch: 030 | loss: 0.45090 - acc: 0.8168 -- iter: 04800/10000
[A[ATraining Step: 4629  | total loss: [1m[32m0.43834[0m[0m | time: 82.796s
[2K| Adam | epoch: 030 | loss: 0.43834 - acc: 0.8211 -- iter: 04864/10000
[A[ATraining Step: 4630  | total loss: [1m[32m0.44730[0m[0m | time: 83.929s
[2K| Adam | epoch: 030 | loss: 0.44730 - acc: 0.8233 -- iter: 04928/10000
[A[ATraining Step: 4631  | total loss: [1m[32m0.44275[0m[0m | time: 85.014s
[2K| Adam | epoch: 030 | loss: 0.44275 - acc: 0.8285 -- iter: 04992/10000
[A[ATraining Step: 4632  | total loss: [1m[32m0.44076[0m[0m | time: 86.103s
[2K| Adam | epoch: 030 | loss: 0.44076 - acc: 0.8269 -- iter: 05056/10000
[A[ATraining Step: 4633  | total loss: [1m[32m0.44033[0m[0m | time: 87.230s
[2K| Adam | epoch: 030 | loss: 0.44033 - acc: 0.8255 -- iter: 05120/10000
[A[ATraining Step: 4634  | total loss: [1m[32m0.46042[0m[0m | time: 88.408s
[2K| Adam | epoch: 030 | loss: 0.46042 - acc: 0.8226 -- iter: 05184/10000
[A[ATraining Step: 4635  | total loss: [1m[32m0.45837[0m[0m | time: 89.607s
[2K| Adam | epoch: 030 | loss: 0.45837 - acc: 0.8169 -- iter: 05248/10000
[A[ATraining Step: 4636  | total loss: [1m[32m0.44186[0m[0m | time: 90.782s
[2K| Adam | epoch: 030 | loss: 0.44186 - acc: 0.8290 -- iter: 05312/10000
[A[ATraining Step: 4637  | total loss: [1m[32m0.44877[0m[0m | time: 91.911s
[2K| Adam | epoch: 030 | loss: 0.44877 - acc: 0.8242 -- iter: 05376/10000
[A[ATraining Step: 4638  | total loss: [1m[32m0.46731[0m[0m | time: 92.955s
[2K| Adam | epoch: 030 | loss: 0.46731 - acc: 0.8199 -- iter: 05440/10000
[A[ATraining Step: 4639  | total loss: [1m[32m0.45763[0m[0m | time: 93.970s
[2K| Adam | epoch: 030 | loss: 0.45763 - acc: 0.8192 -- iter: 05504/10000
[A[ATraining Step: 4640  | total loss: [1m[32m0.44710[0m[0m | time: 94.943s
[2K| Adam | epoch: 030 | loss: 0.44710 - acc: 0.8247 -- iter: 05568/10000
[A[ATraining Step: 4641  | total loss: [1m[32m0.45853[0m[0m | time: 95.918s
[2K| Adam | epoch: 030 | loss: 0.45853 - acc: 0.8251 -- iter: 05632/10000
[A[ATraining Step: 4642  | total loss: [1m[32m0.44255[0m[0m | time: 96.896s
[2K| Adam | epoch: 030 | loss: 0.44255 - acc: 0.8332 -- iter: 05696/10000
[A[ATraining Step: 4643  | total loss: [1m[32m0.44530[0m[0m | time: 97.921s
[2K| Adam | epoch: 030 | loss: 0.44530 - acc: 0.8280 -- iter: 05760/10000
[A[ATraining Step: 4644  | total loss: [1m[32m0.44335[0m[0m | time: 98.953s
[2K| Adam | epoch: 030 | loss: 0.44335 - acc: 0.8280 -- iter: 05824/10000
[A[ATraining Step: 4645  | total loss: [1m[32m0.47102[0m[0m | time: 99.987s
[2K| Adam | epoch: 030 | loss: 0.47102 - acc: 0.8265 -- iter: 05888/10000
[A[ATraining Step: 4646  | total loss: [1m[32m0.46768[0m[0m | time: 101.050s
[2K| Adam | epoch: 030 | loss: 0.46768 - acc: 0.8282 -- iter: 05952/10000
[A[ATraining Step: 4647  | total loss: [1m[32m0.46127[0m[0m | time: 102.111s
[2K| Adam | epoch: 030 | loss: 0.46127 - acc: 0.8297 -- iter: 06016/10000
[A[ATraining Step: 4648  | total loss: [1m[32m0.45746[0m[0m | time: 103.198s
[2K| Adam | epoch: 030 | loss: 0.45746 - acc: 0.8296 -- iter: 06080/10000
[A[ATraining Step: 4649  | total loss: [1m[32m0.45823[0m[0m | time: 104.335s
[2K| Adam | epoch: 030 | loss: 0.45823 - acc: 0.8248 -- iter: 06144/10000
[A[ATraining Step: 4650  | total loss: [1m[32m0.46738[0m[0m | time: 105.432s
[2K| Adam | epoch: 030 | loss: 0.46738 - acc: 0.8220 -- iter: 06208/10000
[A[ATraining Step: 4651  | total loss: [1m[32m0.48338[0m[0m | time: 106.525s
[2K| Adam | epoch: 030 | loss: 0.48338 - acc: 0.8116 -- iter: 06272/10000
[A[ATraining Step: 4652  | total loss: [1m[32m0.48268[0m[0m | time: 107.666s
[2K| Adam | epoch: 030 | loss: 0.48268 - acc: 0.8070 -- iter: 06336/10000
[A[ATraining Step: 4653  | total loss: [1m[32m0.47093[0m[0m | time: 108.842s
[2K| Adam | epoch: 030 | loss: 0.47093 - acc: 0.8138 -- iter: 06400/10000
[A[ATraining Step: 4654  | total loss: [1m[32m0.46767[0m[0m | time: 110.039s
[2K| Adam | epoch: 030 | loss: 0.46767 - acc: 0.8153 -- iter: 06464/10000
[A[ATraining Step: 4655  | total loss: [1m[32m0.46089[0m[0m | time: 111.168s
[2K| Adam | epoch: 030 | loss: 0.46089 - acc: 0.8181 -- iter: 06528/10000
[A[ATraining Step: 4656  | total loss: [1m[32m0.46419[0m[0m | time: 112.306s
[2K| Adam | epoch: 030 | loss: 0.46419 - acc: 0.8254 -- iter: 06592/10000
[A[ATraining Step: 4657  | total loss: [1m[32m0.47539[0m[0m | time: 113.342s
[2K| Adam | epoch: 030 | loss: 0.47539 - acc: 0.8241 -- iter: 06656/10000
[A[ATraining Step: 4658  | total loss: [1m[32m0.48013[0m[0m | time: 114.331s
[2K| Adam | epoch: 030 | loss: 0.48013 - acc: 0.8214 -- iter: 06720/10000
[A[ATraining Step: 4659  | total loss: [1m[32m0.47028[0m[0m | time: 115.303s
[2K| Adam | epoch: 030 | loss: 0.47028 - acc: 0.8236 -- iter: 06784/10000
[A[ATraining Step: 4660  | total loss: [1m[32m0.48150[0m[0m | time: 116.284s
[2K| Adam | epoch: 030 | loss: 0.48150 - acc: 0.8225 -- iter: 06848/10000
[A[ATraining Step: 4661  | total loss: [1m[32m0.46511[0m[0m | time: 117.266s
[2K| Adam | epoch: 030 | loss: 0.46511 - acc: 0.8324 -- iter: 06912/10000
[A[ATraining Step: 4662  | total loss: [1m[32m0.47288[0m[0m | time: 118.247s
[2K| Adam | epoch: 030 | loss: 0.47288 - acc: 0.8289 -- iter: 06976/10000
[A[ATraining Step: 4663  | total loss: [1m[32m0.47522[0m[0m | time: 119.273s
[2K| Adam | epoch: 030 | loss: 0.47522 - acc: 0.8304 -- iter: 07040/10000
[A[ATraining Step: 4664  | total loss: [1m[32m0.47378[0m[0m | time: 120.314s
[2K| Adam | epoch: 030 | loss: 0.47378 - acc: 0.8286 -- iter: 07104/10000
[A[ATraining Step: 4665  | total loss: [1m[32m0.48796[0m[0m | time: 121.351s
[2K| Adam | epoch: 030 | loss: 0.48796 - acc: 0.8223 -- iter: 07168/10000
[A[ATraining Step: 4666  | total loss: [1m[32m0.48049[0m[0m | time: 122.435s
[2K| Adam | epoch: 030 | loss: 0.48049 - acc: 0.8229 -- iter: 07232/10000
[A[ATraining Step: 4667  | total loss: [1m[32m0.47089[0m[0m | time: 123.558s
[2K| Adam | epoch: 030 | loss: 0.47089 - acc: 0.8265 -- iter: 07296/10000
[A[ATraining Step: 4668  | total loss: [1m[32m0.46795[0m[0m | time: 124.637s
[2K| Adam | epoch: 030 | loss: 0.46795 - acc: 0.8298 -- iter: 07360/10000
[A[ATraining Step: 4669  | total loss: [1m[32m0.46390[0m[0m | time: 125.717s
[2K| Adam | epoch: 030 | loss: 0.46390 - acc: 0.8328 -- iter: 07424/10000
[A[ATraining Step: 4670  | total loss: [1m[32m0.46777[0m[0m | time: 126.805s
[2K| Adam | epoch: 030 | loss: 0.46777 - acc: 0.8245 -- iter: 07488/10000
[A[ATraining Step: 4671  | total loss: [1m[32m0.45807[0m[0m | time: 127.892s
[2K| Adam | epoch: 030 | loss: 0.45807 - acc: 0.8264 -- iter: 07552/10000
[A[ATraining Step: 4672  | total loss: [1m[32m0.46780[0m[0m | time: 128.979s
[2K| Adam | epoch: 030 | loss: 0.46780 - acc: 0.8219 -- iter: 07616/10000
[A[ATraining Step: 4673  | total loss: [1m[32m0.45738[0m[0m | time: 130.075s
[2K| Adam | epoch: 030 | loss: 0.45738 - acc: 0.8256 -- iter: 07680/10000
[A[ATraining Step: 4674  | total loss: [1m[32m0.46187[0m[0m | time: 131.164s
[2K| Adam | epoch: 030 | loss: 0.46187 - acc: 0.8290 -- iter: 07744/10000
[A[ATraining Step: 4675  | total loss: [1m[32m0.45981[0m[0m | time: 132.251s
[2K| Adam | epoch: 030 | loss: 0.45981 - acc: 0.8274 -- iter: 07808/10000
[A[ATraining Step: 4676  | total loss: [1m[32m0.45225[0m[0m | time: 133.389s
[2K| Adam | epoch: 030 | loss: 0.45225 - acc: 0.8321 -- iter: 07872/10000
[A[ATraining Step: 4677  | total loss: [1m[32m0.47365[0m[0m | time: 134.489s
[2K| Adam | epoch: 030 | loss: 0.47365 - acc: 0.8302 -- iter: 07936/10000
[A[ATraining Step: 4678  | total loss: [1m[32m0.49217[0m[0m | time: 135.570s
[2K| Adam | epoch: 030 | loss: 0.49217 - acc: 0.8206 -- iter: 08000/10000
[A[ATraining Step: 4679  | total loss: [1m[32m0.49698[0m[0m | time: 136.649s
[2K| Adam | epoch: 030 | loss: 0.49698 - acc: 0.8229 -- iter: 08064/10000
[A[ATraining Step: 4680  | total loss: [1m[32m0.48516[0m[0m | time: 137.730s
[2K| Adam | epoch: 030 | loss: 0.48516 - acc: 0.8219 -- iter: 08128/10000
[A[ATraining Step: 4681  | total loss: [1m[32m0.48377[0m[0m | time: 138.810s
[2K| Adam | epoch: 030 | loss: 0.48377 - acc: 0.8241 -- iter: 08192/10000
[A[ATraining Step: 4682  | total loss: [1m[32m0.47877[0m[0m | time: 139.912s
[2K| Adam | epoch: 030 | loss: 0.47877 - acc: 0.8229 -- iter: 08256/10000
[A[ATraining Step: 4683  | total loss: [1m[32m0.46659[0m[0m | time: 141.088s
[2K| Adam | epoch: 030 | loss: 0.46659 - acc: 0.8250 -- iter: 08320/10000
[A[ATraining Step: 4684  | total loss: [1m[32m0.49469[0m[0m | time: 142.173s
[2K| Adam | epoch: 030 | loss: 0.49469 - acc: 0.8112 -- iter: 08384/10000
[A[ATraining Step: 4685  | total loss: [1m[32m0.50395[0m[0m | time: 143.356s
[2K| Adam | epoch: 030 | loss: 0.50395 - acc: 0.8020 -- iter: 08448/10000
[A[ATraining Step: 4686  | total loss: [1m[32m0.50603[0m[0m | time: 144.548s
[2K| Adam | epoch: 030 | loss: 0.50603 - acc: 0.8030 -- iter: 08512/10000
[A[ATraining Step: 4687  | total loss: [1m[32m0.49756[0m[0m | time: 145.739s
[2K| Adam | epoch: 030 | loss: 0.49756 - acc: 0.8055 -- iter: 08576/10000
[A[ATraining Step: 4688  | total loss: [1m[32m0.51489[0m[0m | time: 146.872s
[2K| Adam | epoch: 030 | loss: 0.51489 - acc: 0.8016 -- iter: 08640/10000
[A[ATraining Step: 4689  | total loss: [1m[32m0.51453[0m[0m | time: 147.994s
[2K| Adam | epoch: 030 | loss: 0.51453 - acc: 0.8026 -- iter: 08704/10000
[A[ATraining Step: 4690  | total loss: [1m[32m0.51705[0m[0m | time: 149.003s
[2K| Adam | epoch: 030 | loss: 0.51705 - acc: 0.8021 -- iter: 08768/10000
[A[ATraining Step: 4691  | total loss: [1m[32m0.50420[0m[0m | time: 150.000s
[2K| Adam | epoch: 030 | loss: 0.50420 - acc: 0.8109 -- iter: 08832/10000
[A[ATraining Step: 4692  | total loss: [1m[32m0.48646[0m[0m | time: 150.971s
[2K| Adam | epoch: 030 | loss: 0.48646 - acc: 0.8189 -- iter: 08896/10000
[A[ATraining Step: 4693  | total loss: [1m[32m0.49262[0m[0m | time: 151.946s
[2K| Adam | epoch: 030 | loss: 0.49262 - acc: 0.8167 -- iter: 08960/10000
[A[ATraining Step: 4694  | total loss: [1m[32m0.48754[0m[0m | time: 152.947s
[2K| Adam | epoch: 030 | loss: 0.48754 - acc: 0.8163 -- iter: 09024/10000
[A[ATraining Step: 4695  | total loss: [1m[32m0.47709[0m[0m | time: 154.017s
[2K| Adam | epoch: 030 | loss: 0.47709 - acc: 0.8221 -- iter: 09088/10000
[A[ATraining Step: 4696  | total loss: [1m[32m0.47622[0m[0m | time: 155.042s
[2K| Adam | epoch: 030 | loss: 0.47622 - acc: 0.8181 -- iter: 09152/10000
[A[ATraining Step: 4697  | total loss: [1m[32m0.48940[0m[0m | time: 156.100s
[2K| Adam | epoch: 030 | loss: 0.48940 - acc: 0.8159 -- iter: 09216/10000
[A[ATraining Step: 4698  | total loss: [1m[32m0.48505[0m[0m | time: 157.191s
[2K| Adam | epoch: 030 | loss: 0.48505 - acc: 0.8187 -- iter: 09280/10000
[A[ATraining Step: 4699  | total loss: [1m[32m0.47051[0m[0m | time: 158.284s
[2K| Adam | epoch: 030 | loss: 0.47051 - acc: 0.8243 -- iter: 09344/10000
[A[ATraining Step: 4700  | total loss: [1m[32m0.47399[0m[0m | time: 162.158s
[2K| Adam | epoch: 030 | loss: 0.47399 - acc: 0.8200 | val_loss: 3.51335 - val_acc: 0.3686 -- iter: 09408/10000
--
Training Step: 4701  | total loss: [1m[32m0.47220[0m[0m | time: 163.209s
[2K| Adam | epoch: 030 | loss: 0.47220 - acc: 0.8193 -- iter: 09472/10000
[A[ATraining Step: 4702  | total loss: [1m[32m0.47284[0m[0m | time: 164.340s
[2K| Adam | epoch: 030 | loss: 0.47284 - acc: 0.8077 -- iter: 09536/10000
[A[ATraining Step: 4703  | total loss: [1m[32m0.46903[0m[0m | time: 165.428s
[2K| Adam | epoch: 030 | loss: 0.46903 - acc: 0.8082 -- iter: 09600/10000
[A[ATraining Step: 4704  | total loss: [1m[32m0.46471[0m[0m | time: 166.514s
[2K| Adam | epoch: 030 | loss: 0.46471 - acc: 0.8117 -- iter: 09664/10000
[A[ATraining Step: 4705  | total loss: [1m[32m0.46531[0m[0m | time: 167.609s
[2K| Adam | epoch: 030 | loss: 0.46531 - acc: 0.8149 -- iter: 09728/10000
[A[ATraining Step: 4706  | total loss: [1m[32m0.48174[0m[0m | time: 168.693s
[2K| Adam | epoch: 030 | loss: 0.48174 - acc: 0.8115 -- iter: 09792/10000
[A[ATraining Step: 4707  | total loss: [1m[32m0.48806[0m[0m | time: 169.797s
[2K| Adam | epoch: 030 | loss: 0.48806 - acc: 0.8179 -- iter: 09856/10000
[A[ATraining Step: 4708  | total loss: [1m[32m1.66598[0m[0m | time: 170.881s
[2K| Adam | epoch: 030 | loss: 1.66598 - acc: 0.7470 -- iter: 09920/10000
[A[ATraining Step: 4709  | total loss: [1m[32m1.55029[0m[0m | time: 172.032s
[2K| Adam | epoch: 030 | loss: 1.55029 - acc: 0.7583 -- iter: 09984/10000
[A[ATraining Step: 4710  | total loss: [1m[32m1.43539[0m[0m | time: 176.474s
[2K| Adam | epoch: 030 | loss: 1.43539 - acc: 0.7715 | val_loss: 3.24555 - val_acc: 0.3871 -- iter: 10000/10000
--
[B[B[B[?12;25h